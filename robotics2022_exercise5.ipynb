{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Anchor nodes of system A and system B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AN_sysA = [(30, 200, 40), (100, 200, 10), (0, 0, 30), (200, 100, 20)]\n",
    "AN_sysB = [(0, 100, 10), (50, 150, 70), (100,100, 100), (200, 200, 60), (100, 0, 20), (200, 0, 30)]\n",
    "ANs = AN_sysA + AN_sysB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define UD locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "UD_orig = (100, 100, 20)\n",
    "UDs = []\n",
    "r = 20.0\n",
    "PI = 3.1416\n",
    "NUM_EXAMPLES = 3000\n",
    "\n",
    "for theta in np.arange(0.0, 2*PI*6, 2*PI*6/NUM_EXAMPLES):\n",
    "    x = r * math.cos(theta) + UD_orig[0]\n",
    "    y = r * math.sin(theta) + UD_orig[1]\n",
    "    z = theta + UD_orig[2]\n",
    "    UDs.append((x, y, z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(UDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 3D scatterplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (16, 9)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.view_init(azim=235, elev=30)   # set view port according to the fig.4 in paper\n",
    "\n",
    "# plot AN points for system A\n",
    "marker = '^'\n",
    "for xs, ys, zs in AN_sysA:\n",
    "    ax.scatter(xs, ys, zs, marker=marker, c='r', s=100)\n",
    "\n",
    "# plot AN points for system B\n",
    "marker = '*'\n",
    "for xs, ys, zs in AN_sysB:\n",
    "    ax.scatter(xs, ys, zs, marker=marker, c='g', s=100)\n",
    "\n",
    "# plot UD points\n",
    "marker = '.'\n",
    "for xs, ys, zs in UDs:\n",
    "    ax.scatter(xs, ys, zs, marker=marker, c='b', s=100)\n",
    "\n",
    "    \n",
    "ax.set_xlabel('X-Axis')\n",
    "ax.set_ylabel('Y-Axis')\n",
    "ax.set_zlabel('Z-Axis')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dataset  by computing the distances between UD and ANs\n",
    "# The dataset is defined to be (3000, 13) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_3d_distance(p1, p2):\n",
    "    x1 = p1[0]\n",
    "    y1 = p1[1]\n",
    "    z1 = p1[2]\n",
    "    x2 = p2[0]\n",
    "    y2 = p2[1]\n",
    "    z2 = p2[2]\n",
    "    \n",
    "    d = math.sqrt((x2 - x1)**2 + (y2 - y1)**2 + (z2 - z1)**2)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset without any noise\n",
    "i = 0\n",
    "my_dataset = []\n",
    "for ud in UDs:\n",
    "    example = []\n",
    "    for an in ANs:\n",
    "        d = compute_3d_distance(ud, an)\n",
    "        example.append(d)\n",
    "    \n",
    "    # append x, y, z as col#10, #11, #12\n",
    "    example.append(ud[0])\n",
    "    example.append(ud[1])\n",
    "    example.append(ud[2])\n",
    "    \n",
    "    # append 1x13 example row into my_dataset\n",
    "    my_dataset.append(example)  # expected to be 3000x13  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to show the 1st example of my_dataset for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[136.01470508735443,\n",
       " 102.46950765959599,\n",
       " 156.52475842498527,\n",
       " 80.0,\n",
       " 120.41594578792295,\n",
       " 99.498743710662,\n",
       " 82.46211251235322,\n",
       " 134.16407864998737,\n",
       " 101.9803902718557,\n",
       " 128.4523257866513,\n",
       " 120.0,\n",
       " 100.0,\n",
       " 20.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset[0]   # Looks fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Field Explaination of my_dataset\n",
    "## Example of my_dataset = [rA0, rA1, rA2, rA3, rB0, rB1,rB2, rB3, rB4, rB5, x, y, z]\n",
    "\n",
    "    * rA0, rA1, rA2, rA3, rB0, rB1, ... rB5: distance between ANi to UD (in meters)\n",
    "    * x, y, z:  UD location (in meters, ground truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify the dataset dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.array(my_dataset)   #  expect to be (3000, 13)\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset loader and data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exercise5Dataset(Dataset):\n",
    "    \"\"\"Exercise5 dataset.\"\"\"\n",
    "    def __init__(self, list_dataset, shuffle=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        list_dataset (list): Directory with the dataset files.\n",
    "        shuffle (bool): Shuffle or not\n",
    "        \"\"\"\n",
    "        self.all_data = list_dataset\n",
    "\n",
    "        # Reorder the sequence of the dataset\n",
    "        if shuffle:\n",
    "            random.shuffle(self.all_data)\n",
    "            print(\"Dataset shuffle = True!\")\n",
    "\n",
    "        ### Data preprocessing\n",
    "        # Compute dataset mean and std\n",
    "        examples = torch.from_numpy(np.array(self.all_data)[:, :10]).float()    \n",
    "        #print(examples.shape) # (3000, 10)\n",
    "        self.labels = torch.from_numpy(np.array(self.all_data)[:, 10:]).float()\n",
    "        #print(self.labels.shape)  #(3000, 3)\n",
    "\n",
    "        # Compute mean and std\n",
    "        mu = examples.mean(dim=0)\n",
    "        sigma = examples.std(dim=0, unbiased=False)\n",
    "\n",
    "        # Compute normalized examples:\n",
    "        x_prime = (x - mu) / sigma\n",
    "        self.normalized_examples = (examples - mu) / sigma\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.normalized_examples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        example = self.normalized_examples[idx]   #(N, 10)\n",
    "        xyz = self.labels[idx]   #(N,3)\n",
    "        return example, xyz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffle = True!\n"
     ]
    }
   ],
   "source": [
    "exercise5_dataset = Exercise5Dataset(list_dataset = my_dataset, shuffle=True)   #Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exercise5_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset by 0.8: 0.1: 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples, train_labels = exercise5_dataset[:int(3000*0.8)]  # (2400, 10)   # (2400, 3)\n",
    "val_examples, val_labels = exercise5_dataset[int(3000*0.8):int(3000*0.9)]    # (300, 10)   #(300, 3)\n",
    "test_examples, test_labels = exercise5_dataset[int(3000*0.9):]     #(300, 10)   # (300, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2400, 10])\n",
      "torch.Size([2400, 3])\n",
      "torch.Size([300, 10])\n",
      "torch.Size([300, 3])\n",
      "torch.Size([300, 10])\n",
      "torch.Size([300, 3])\n"
     ]
    }
   ],
   "source": [
    "print(train_examples.shape)\n",
    "print(train_labels.shape)\n",
    "print(val_examples.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_examples.shape)\n",
    "print(test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define our model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MYLSTM\n",
    "class MYLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, bidirectional=False):\n",
    "        super(MYLSTM, self).__init__()\n",
    "        # input dim (batch_size, seq_len, input_size)\n",
    "        # modelbatch_size & seq_len, batch_size & seq_len\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            #bidirectional=bidirectional,\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, 3)   # final output dim is (N, 3)\n",
    "        #self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        out, (h, c) = self.lstm(inputs, None)\n",
    "        #print(\"[KK] inputs.shape: \", inputs.shape)\n",
    "        #print(\"[KK] h[-1].shape: \", h[-1].shape)\n",
    "        #print(\"[KK] h[-1].squeeze(0).shape: \", h[-1].squeeze(0).shape)\n",
    "        \n",
    "        fc_outputs = self.fc(h[-1].squeeze(0))\n",
    "        #print(\"[KK] outputs.shape: \", outputs.shape)\n",
    "\n",
    "        return fc_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model, loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we have GPU, then use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define model\n",
    "#model = Net(x_dim = train_examples.shape[1], y_dim = train_labels.shape[1]).to(device)\n",
    "input_dim = 1     #input dim is 1, seq_len = 10\n",
    "hidden_dim = 64   #hidden state dim is 64\n",
    "n_layers = 3             #3-layered LSTM\n",
    "model = MYLSTM(input_dim, hidden_dim, n_layers).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "MYLSTM(\n",
      "  (lstm): LSTM(1, 64, num_layers=3, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct the input/output shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct the input/output shape for LSTM\n",
    "train_inputs = torch.unsqueeze(train_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "train_inputs = train_inputs.to(device) \n",
    "\n",
    "val_inputs = torch.unsqueeze(val_examples, dim=-1)   # (N, 10) -> (N, 10, 1)\n",
    "val_inputs = val_inputs.to(device) \n",
    "\n",
    "train_labels = train_labels.to(device)   #(N, 3)\n",
    "val_labels = val_labels.to(device)          #(N, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 train_loss: 7368.60498046875 val_loss: 7390.89013671875\n",
      "epoch:  100 train_loss: 6059.06787109375 val_loss: 6068.29833984375\n",
      "epoch:  200 train_loss: 5138.39013671875 val_loss: 5146.056640625\n",
      "epoch:  300 train_loss: 4380.10400390625 val_loss: 4385.97265625\n",
      "epoch:  400 train_loss: 3734.226318359375 val_loss: 3738.318359375\n",
      "epoch:  500 train_loss: 3179.090087890625 val_loss: 3181.87109375\n",
      "epoch:  600 train_loss: 2701.050048828125 val_loss: 2702.257568359375\n",
      "epoch:  700 train_loss: 2288.547119140625 val_loss: 2288.824951171875\n",
      "epoch:  800 train_loss: 1909.179443359375 val_loss: 1908.6697998046875\n",
      "epoch:  900 train_loss: 1595.8544921875 val_loss: 1594.907958984375\n",
      "epoch:  1000 train_loss: 1331.42822265625 val_loss: 1330.230712890625\n",
      "epoch:  1100 train_loss: 1108.134521484375 val_loss: 1107.0162353515625\n",
      "epoch:  1200 train_loss: 920.6688232421875 val_loss: 919.5908813476562\n",
      "epoch:  1300 train_loss: 764.4835205078125 val_loss: 763.5940551757812\n",
      "epoch:  1400 train_loss: 635.5841064453125 val_loss: 634.8129272460938\n",
      "epoch:  1500 train_loss: 530.1985473632812 val_loss: 529.6622314453125\n",
      "epoch:  1600 train_loss: 445.1347961425781 val_loss: 444.72808837890625\n",
      "epoch:  1700 train_loss: 377.4041748046875 val_loss: 377.08685302734375\n",
      "epoch:  1800 train_loss: 324.121337890625 val_loss: 323.9679260253906\n",
      "epoch:  1900 train_loss: 282.9677734375 val_loss: 282.77215576171875\n",
      "epoch:  2000 train_loss: 251.49612426757812 val_loss: 251.54763793945312\n",
      "epoch:  2100 train_loss: 228.06800842285156 val_loss: 228.14886474609375\n",
      "epoch:  2200 train_loss: 210.80079650878906 val_loss: 210.98495483398438\n",
      "epoch:  2300 train_loss: 198.3846893310547 val_loss: 198.59458923339844\n",
      "epoch:  2400 train_loss: 189.63430786132812 val_loss: 189.90618896484375\n",
      "epoch:  2500 train_loss: 183.62295532226562 val_loss: 183.90744018554688\n",
      "epoch:  2600 train_loss: 179.59442138671875 val_loss: 179.92294311523438\n",
      "epoch:  2700 train_loss: 176.92129516601562 val_loss: 177.2806396484375\n",
      "epoch:  2800 train_loss: 175.22901916503906 val_loss: 175.61947631835938\n",
      "epoch:  2900 train_loss: 174.17198181152344 val_loss: 174.57945251464844\n",
      "epoch:  3000 train_loss: 173.5391387939453 val_loss: 173.970458984375\n",
      "epoch:  3100 train_loss: 173.16879272460938 val_loss: 173.6128387451172\n",
      "epoch:  3200 train_loss: 172.9623260498047 val_loss: 173.41433715820312\n",
      "epoch:  3300 train_loss: 172.84750366210938 val_loss: 173.30882263183594\n",
      "epoch:  3400 train_loss: 172.78640747070312 val_loss: 173.25489807128906\n",
      "epoch:  3500 train_loss: 172.75550842285156 val_loss: 173.2351837158203\n",
      "epoch:  3600 train_loss: 172.7407684326172 val_loss: 173.22198486328125\n",
      "epoch:  3700 train_loss: 172.7334442138672 val_loss: 173.2193145751953\n",
      "epoch:  3800 train_loss: 172.73086547851562 val_loss: 173.21888732910156\n",
      "epoch:  3900 train_loss: 172.7291717529297 val_loss: 173.2193603515625\n",
      "epoch:  4000 train_loss: 172.7286834716797 val_loss: 173.219970703125\n",
      "epoch:  4100 train_loss: 172.72845458984375 val_loss: 173.22018432617188\n",
      "epoch:  4200 train_loss: 172.72840881347656 val_loss: 173.21823120117188\n",
      "epoch:  4300 train_loss: 172.7283477783203 val_loss: 173.22036743164062\n",
      "epoch:  4400 train_loss: 172.72833251953125 val_loss: 173.2206573486328\n",
      "epoch:  4500 train_loss: 172.72833251953125 val_loss: 173.22242736816406\n",
      "epoch:  4600 train_loss: 172.72833251953125 val_loss: 173.22225952148438\n",
      "epoch:  4700 train_loss: 172.72833251953125 val_loss: 173.22225952148438\n",
      "epoch:  4800 train_loss: 172.72833251953125 val_loss: 173.22239685058594\n",
      "epoch:  4900 train_loss: 172.72833251953125 val_loss: 173.22225952148438\n",
      "epoch:  5000 train_loss: 172.72833251953125 val_loss: 173.22225952148438\n",
      "epoch:  5100 train_loss: 172.72833251953125 val_loss: 173.22225952148438\n",
      "epoch:  5200 train_loss: 172.72833251953125 val_loss: 173.22225952148438\n",
      "epoch:  5300 train_loss: 172.72833251953125 val_loss: 173.22225952148438\n",
      "epoch:  5400 train_loss: 172.72833251953125 val_loss: 173.22225952148438\n",
      "epoch:  5500 train_loss: 172.72833251953125 val_loss: 173.2218475341797\n",
      "epoch:  5600 train_loss: 172.72833251953125 val_loss: 173.22225952148438\n",
      "epoch:  5700 train_loss: 172.72833251953125 val_loss: 173.22225952148438\n",
      "epoch:  5800 train_loss: 172.72833251953125 val_loss: 173.22239685058594\n",
      "epoch:  5900 train_loss: 172.72833251953125 val_loss: 173.2218475341797\n",
      "epoch:  6000 train_loss: 172.72833251953125 val_loss: 173.22239685058594\n",
      "epoch:  6100 train_loss: 172.72833251953125 val_loss: 173.2218475341797\n",
      "epoch:  6200 train_loss: 172.72833251953125 val_loss: 173.22239685058594\n",
      "epoch:  6300 train_loss: 172.72833251953125 val_loss: 173.22225952148438\n",
      "epoch:  6400 train_loss: 172.7283477783203 val_loss: 173.22157287597656\n",
      "epoch:  6500 train_loss: 172.72833251953125 val_loss: 173.2218475341797\n",
      "epoch:  6600 train_loss: 172.72833251953125 val_loss: 173.22198486328125\n",
      "epoch:  6700 train_loss: 172.72833251953125 val_loss: 173.22225952148438\n",
      "epoch:  6800 train_loss: 172.7283477783203 val_loss: 173.22142028808594\n",
      "epoch:  6900 train_loss: 172.72833251953125 val_loss: 173.2218475341797\n",
      "epoch:  7000 train_loss: 170.21646118164062 val_loss: 171.15396118164062\n",
      "epoch:  7100 train_loss: 172.87176513671875 val_loss: 173.4243621826172\n",
      "epoch:  7200 train_loss: 131.27830505371094 val_loss: 135.7432098388672\n",
      "epoch:  7300 train_loss: 111.35621643066406 val_loss: 116.16461944580078\n",
      "epoch:  7400 train_loss: 102.7134780883789 val_loss: 107.49019622802734\n",
      "epoch:  7500 train_loss: 92.929443359375 val_loss: 96.97679138183594\n",
      "epoch:  7600 train_loss: 83.11363220214844 val_loss: 87.00281524658203\n",
      "epoch:  7700 train_loss: 73.1171875 val_loss: 76.51231384277344\n",
      "epoch:  7800 train_loss: 61.31037139892578 val_loss: 64.70573425292969\n",
      "epoch:  7900 train_loss: 42.40834045410156 val_loss: 45.599273681640625\n",
      "epoch:  8000 train_loss: 30.995725631713867 val_loss: 33.114471435546875\n",
      "epoch:  8100 train_loss: 21.74177360534668 val_loss: 23.478059768676758\n",
      "epoch:  8200 train_loss: 15.767739295959473 val_loss: 17.211589813232422\n",
      "epoch:  8300 train_loss: 11.35987663269043 val_loss: 12.520608901977539\n",
      "epoch:  8400 train_loss: 8.40192699432373 val_loss: 9.248205184936523\n",
      "epoch:  8500 train_loss: 6.373549461364746 val_loss: 6.969357967376709\n",
      "epoch:  8600 train_loss: 4.827450752258301 val_loss: 5.25068473815918\n",
      "epoch:  8700 train_loss: 3.5142922401428223 val_loss: 3.949191093444824\n",
      "epoch:  8800 train_loss: 3.0009467601776123 val_loss: 3.3524537086486816\n",
      "epoch:  8900 train_loss: 2.223740339279175 val_loss: 2.534336566925049\n",
      "epoch:  9000 train_loss: 1.8553698062896729 val_loss: 2.0439722537994385\n",
      "epoch:  9100 train_loss: 1.2839590311050415 val_loss: 1.470556378364563\n",
      "epoch:  9200 train_loss: 1.1341302394866943 val_loss: 1.288339376449585\n",
      "epoch:  9300 train_loss: 0.8520798087120056 val_loss: 1.0028327703475952\n",
      "epoch:  9400 train_loss: 0.8958508372306824 val_loss: 0.9696890115737915\n",
      "epoch:  9500 train_loss: 0.590965986251831 val_loss: 0.7020361423492432\n",
      "epoch:  9600 train_loss: 0.5699089765548706 val_loss: 0.678623378276825\n",
      "epoch:  9700 train_loss: 0.5773771405220032 val_loss: 0.6887162327766418\n",
      "epoch:  9800 train_loss: 0.4208836555480957 val_loss: 0.45450344681739807\n",
      "epoch:  9900 train_loss: 0.3245076835155487 val_loss: 0.3862483501434326\n",
      "epoch:  10000 train_loss: 0.2912660837173462 val_loss: 0.33845189213752747\n",
      "epoch:  10100 train_loss: 0.35911494493484497 val_loss: 0.37654900550842285\n",
      "epoch:  10200 train_loss: 0.22673183679580688 val_loss: 0.2719891667366028\n",
      "epoch:  10300 train_loss: 0.19588737189769745 val_loss: 0.24823401868343353\n",
      "epoch:  10400 train_loss: 0.28549906611442566 val_loss: 0.2613503932952881\n",
      "epoch:  10500 train_loss: 0.2009482979774475 val_loss: 0.20675164461135864\n",
      "epoch:  10600 train_loss: 0.21432553231716156 val_loss: 0.24360442161560059\n",
      "epoch:  10700 train_loss: 0.11793499439954758 val_loss: 0.1443810760974884\n",
      "epoch:  10800 train_loss: 0.10361874103546143 val_loss: 0.12790949642658234\n",
      "epoch:  10900 train_loss: 0.13114139437675476 val_loss: 0.13529719412326813\n",
      "epoch:  11000 train_loss: 0.0962546244263649 val_loss: 0.13653992116451263\n",
      "epoch:  11100 train_loss: 0.2233744114637375 val_loss: 0.2559325098991394\n",
      "epoch:  11200 train_loss: 0.09426837414503098 val_loss: 0.08947062492370605\n",
      "epoch:  11300 train_loss: 0.10033033043146133 val_loss: 0.14090083539485931\n",
      "epoch:  11400 train_loss: 0.09093838185071945 val_loss: 0.12089503556489944\n",
      "epoch:  11500 train_loss: 0.09495604038238525 val_loss: 0.10614489018917084\n",
      "epoch:  11600 train_loss: 0.06954170763492584 val_loss: 0.09089960902929306\n",
      "epoch:  11700 train_loss: 0.0411817729473114 val_loss: 0.048205576837062836\n",
      "epoch:  11800 train_loss: 0.03579733148217201 val_loss: 0.04392475634813309\n",
      "epoch:  11900 train_loss: 0.031233826652169228 val_loss: 0.0373869463801384\n",
      "epoch:  12000 train_loss: 0.03423111513257027 val_loss: 0.035901810973882675\n",
      "epoch:  12100 train_loss: 0.04451751708984375 val_loss: 0.06201300397515297\n",
      "epoch:  12200 train_loss: 0.02487022429704666 val_loss: 0.03197402507066727\n",
      "epoch:  12300 train_loss: 0.04102876037359238 val_loss: 0.0391472689807415\n",
      "epoch:  12400 train_loss: 0.026463041082024574 val_loss: 0.03345257416367531\n",
      "epoch:  12500 train_loss: 0.1585620492696762 val_loss: 0.12174636870622635\n",
      "epoch:  12600 train_loss: 0.05915403738617897 val_loss: 0.058869123458862305\n",
      "epoch:  12700 train_loss: 0.015662185847759247 val_loss: 0.018704978749155998\n",
      "epoch:  12800 train_loss: 0.1440364271402359 val_loss: 0.0559835322201252\n",
      "epoch:  12900 train_loss: 0.013883971609175205 val_loss: 0.01620280183851719\n",
      "epoch:  13000 train_loss: 0.12898921966552734 val_loss: 0.15008124709129333\n",
      "epoch:  13100 train_loss: 0.03740715980529785 val_loss: 0.04139980673789978\n",
      "epoch:  13200 train_loss: 0.046414852142333984 val_loss: 0.052094023674726486\n",
      "epoch:  13300 train_loss: 0.026167839765548706 val_loss: 0.02543248049914837\n",
      "epoch:  13400 train_loss: 0.03228437528014183 val_loss: 0.060846347361803055\n",
      "epoch:  13500 train_loss: 0.013569088652729988 val_loss: 0.014560148119926453\n",
      "epoch:  13600 train_loss: 0.18560466170310974 val_loss: 0.24902063608169556\n",
      "epoch:  13700 train_loss: 0.0088959950953722 val_loss: 0.01012443657964468\n",
      "epoch:  13800 train_loss: 0.015533201396465302 val_loss: 0.02081228978931904\n",
      "epoch:  13900 train_loss: 0.010997732169926167 val_loss: 0.013567534275352955\n",
      "epoch:  14000 train_loss: 0.00957266055047512 val_loss: 0.010774165391921997\n",
      "epoch:  14100 train_loss: 0.007923793978989124 val_loss: 0.008867082186043262\n",
      "epoch:  14200 train_loss: 0.00836785975843668 val_loss: 0.008854707702994347\n",
      "epoch:  14300 train_loss: 0.007878347299993038 val_loss: 0.008999329060316086\n",
      "epoch:  14400 train_loss: 0.016872026026248932 val_loss: 0.01815062202513218\n",
      "epoch:  14500 train_loss: 0.018783273175358772 val_loss: 0.023131100460886955\n",
      "epoch:  14600 train_loss: 0.08002011477947235 val_loss: 0.08090782910585403\n",
      "epoch:  14700 train_loss: 0.04086765646934509 val_loss: 0.016727684065699577\n",
      "epoch:  14800 train_loss: 0.01649525761604309 val_loss: 0.014057829044759274\n",
      "epoch:  14900 train_loss: 0.009193375706672668 val_loss: 0.008044781163334846\n",
      "epoch:  15000 train_loss: 0.12942537665367126 val_loss: 0.2196401208639145\n",
      "epoch:  15100 train_loss: 0.006428478751331568 val_loss: 0.006810920313000679\n",
      "epoch:  15200 train_loss: 0.00484444061294198 val_loss: 0.005414120387285948\n",
      "epoch:  15300 train_loss: 0.006435144226998091 val_loss: 0.007335624657571316\n",
      "epoch:  15400 train_loss: 0.007148112170398235 val_loss: 0.007152425590902567\n",
      "epoch:  15500 train_loss: 0.00497728306800127 val_loss: 0.005435563158243895\n",
      "epoch:  15600 train_loss: 0.006043806206434965 val_loss: 0.007248885929584503\n",
      "epoch:  15700 train_loss: 0.04252199828624725 val_loss: 0.041209831833839417\n",
      "epoch:  15800 train_loss: 0.03629248961806297 val_loss: 0.04251859709620476\n",
      "epoch:  15900 train_loss: 0.04013054072856903 val_loss: 0.026457861065864563\n",
      "epoch:  16000 train_loss: 0.010905740782618523 val_loss: 0.017385875806212425\n",
      "epoch:  16100 train_loss: 0.017706820741295815 val_loss: 0.01917203888297081\n",
      "epoch:  16200 train_loss: 0.006012495141476393 val_loss: 0.0057238624431192875\n",
      "epoch:  16300 train_loss: 0.003731330158188939 val_loss: 0.004339114762842655\n",
      "epoch:  16400 train_loss: 0.010065548121929169 val_loss: 0.009873542934656143\n",
      "epoch:  16500 train_loss: 0.010764234699308872 val_loss: 0.006333203986287117\n",
      "epoch:  16600 train_loss: 0.018663669005036354 val_loss: 0.00871853157877922\n",
      "epoch:  16700 train_loss: 0.012610504403710365 val_loss: 0.012092755176126957\n",
      "epoch:  16800 train_loss: 0.004984300583600998 val_loss: 0.007620445918291807\n",
      "epoch:  16900 train_loss: 0.0586906336247921 val_loss: 0.05306505411863327\n",
      "epoch:  17000 train_loss: 0.011800654232501984 val_loss: 0.014922169037163258\n",
      "epoch:  17100 train_loss: 0.005266285035759211 val_loss: 0.006167383398860693\n",
      "epoch:  17200 train_loss: 0.41613566875457764 val_loss: 0.29116693139076233\n",
      "epoch:  17300 train_loss: 0.006354231853038073 val_loss: 0.007854867726564407\n",
      "epoch:  17400 train_loss: 0.004154032561928034 val_loss: 0.0053329262882471085\n",
      "epoch:  17500 train_loss: 0.0033480722922831774 val_loss: 0.004262852482497692\n",
      "epoch:  17600 train_loss: 0.002999036805704236 val_loss: 0.0037662724498659372\n",
      "epoch:  17700 train_loss: 0.02129579894244671 val_loss: 0.019817205145955086\n",
      "epoch:  17800 train_loss: 0.02391120046377182 val_loss: 0.021679507568478584\n",
      "epoch:  17900 train_loss: 0.010456615127623081 val_loss: 0.00887632928788662\n",
      "epoch:  18000 train_loss: 0.030765067785978317 val_loss: 0.036070335656404495\n",
      "epoch:  18100 train_loss: 0.004310358315706253 val_loss: 0.00573199987411499\n",
      "epoch:  18200 train_loss: 0.27356353402137756 val_loss: 0.4858149588108063\n",
      "epoch:  18300 train_loss: 0.003004553960636258 val_loss: 0.0036098395939916372\n",
      "epoch:  18400 train_loss: 0.0023853215388953686 val_loss: 0.0030027974862605333\n",
      "epoch:  18500 train_loss: 0.0021282690577208996 val_loss: 0.0026650421787053347\n",
      "epoch:  18600 train_loss: 0.002276236889883876 val_loss: 0.0027049530763179064\n",
      "epoch:  18700 train_loss: 0.0029726887587457895 val_loss: 0.004162273369729519\n",
      "epoch:  18800 train_loss: 0.0037437088321894407 val_loss: 0.005126307252794504\n",
      "epoch:  18900 train_loss: 0.0025183663237839937 val_loss: 0.003049068618565798\n",
      "epoch:  19000 train_loss: 0.0022177512291818857 val_loss: 0.0026748196687549353\n",
      "epoch:  19100 train_loss: 0.0021194717846810818 val_loss: 0.0026023034006357193\n",
      "epoch:  19200 train_loss: 0.0018330035964027047 val_loss: 0.002293624682351947\n",
      "epoch:  19300 train_loss: 0.0017628673231229186 val_loss: 0.002163537545129657\n",
      "epoch:  19400 train_loss: 0.022639144212007523 val_loss: 0.026902547106146812\n",
      "epoch:  19500 train_loss: 0.003942703362554312 val_loss: 0.004316709470003843\n",
      "epoch:  19600 train_loss: 0.0045899213291704655 val_loss: 0.0045092785730957985\n",
      "epoch:  19700 train_loss: 0.014109143055975437 val_loss: 0.008354796096682549\n",
      "epoch:  19800 train_loss: 0.10816822201013565 val_loss: 0.0676761269569397\n",
      "epoch:  19900 train_loss: 0.001519229612313211 val_loss: 0.001924355048686266\n",
      "epoch:  20000 train_loss: 0.43216052651405334 val_loss: 0.22297050058841705\n",
      "epoch:  20100 train_loss: 0.002557199215516448 val_loss: 0.0029858213383704424\n",
      "epoch:  20200 train_loss: 0.0019158392678946257 val_loss: 0.0022291543427854776\n",
      "epoch:  20300 train_loss: 0.0017611047951504588 val_loss: 0.0021384661085903645\n",
      "epoch:  20400 train_loss: 0.0015155058354139328 val_loss: 0.001831008936278522\n",
      "epoch:  20500 train_loss: 0.0015933183021843433 val_loss: 0.0020120504777878523\n",
      "epoch:  20600 train_loss: 0.0017072506016120315 val_loss: 0.0022663387935608625\n",
      "epoch:  20700 train_loss: 0.002278981963172555 val_loss: 0.0027378113009035587\n",
      "epoch:  20800 train_loss: 0.01473260298371315 val_loss: 0.014434020034968853\n",
      "epoch:  20900 train_loss: 0.012121173553168774 val_loss: 0.008877072483301163\n",
      "epoch:  21000 train_loss: 0.0012841434217989445 val_loss: 0.0016077379696071148\n",
      "epoch:  21100 train_loss: 0.0030010149348527193 val_loss: 0.003886489663273096\n",
      "epoch:  21200 train_loss: 0.0015304791741073132 val_loss: 0.0017861849628388882\n",
      "epoch:  21300 train_loss: 0.001465693349018693 val_loss: 0.0018619042821228504\n",
      "epoch:  21400 train_loss: 0.002723714103922248 val_loss: 0.0024381198454648256\n",
      "epoch:  21500 train_loss: 0.001241546357050538 val_loss: 0.0014673876576125622\n",
      "epoch:  21600 train_loss: 0.001205232460051775 val_loss: 0.0017878884682431817\n",
      "epoch:  21700 train_loss: 0.049826085567474365 val_loss: 0.06263145804405212\n",
      "epoch:  21800 train_loss: 0.006703403312712908 val_loss: 0.0074980068020522594\n",
      "epoch:  21900 train_loss: 0.0011441545793786645 val_loss: 0.001358875771984458\n",
      "epoch:  22000 train_loss: 0.0014812821755185723 val_loss: 0.001632697880268097\n",
      "epoch:  22100 train_loss: 0.0026005073450505733 val_loss: 0.0030036699026823044\n",
      "epoch:  22200 train_loss: 0.0013273576041683555 val_loss: 0.001587884733453393\n",
      "epoch:  22300 train_loss: 0.0011976929381489754 val_loss: 0.0013641484547406435\n",
      "epoch:  22400 train_loss: 0.0010623884154483676 val_loss: 0.0012442502193152905\n",
      "epoch:  22500 train_loss: 0.002378718927502632 val_loss: 0.004221252165734768\n",
      "epoch:  22600 train_loss: 0.0030833620112389326 val_loss: 0.003985986113548279\n",
      "epoch:  22700 train_loss: 0.22279588878154755 val_loss: 0.173603355884552\n",
      "epoch:  22800 train_loss: 0.000979325850494206 val_loss: 0.0011222013272345066\n",
      "epoch:  22900 train_loss: 0.01503133773803711 val_loss: 0.0023654340766370296\n",
      "epoch:  23000 train_loss: 0.0015953994588926435 val_loss: 0.0018373369239270687\n",
      "epoch:  23100 train_loss: 0.00854606181383133 val_loss: 0.00733108539134264\n",
      "epoch:  23200 train_loss: 0.009988214820623398 val_loss: 0.010107176378369331\n",
      "epoch:  23300 train_loss: 0.025768917053937912 val_loss: 0.021965820342302322\n",
      "epoch:  23400 train_loss: 0.00450531393289566 val_loss: 0.006761057302355766\n",
      "epoch:  23500 train_loss: 0.10260719060897827 val_loss: 0.26930758357048035\n",
      "epoch:  23600 train_loss: 0.0013659187825396657 val_loss: 0.0015684543177485466\n",
      "epoch:  23700 train_loss: 0.0010371417738497257 val_loss: 0.001253745285794139\n",
      "epoch:  23800 train_loss: 0.0011630731169134378 val_loss: 0.0012582872295752168\n",
      "epoch:  23900 train_loss: 0.017879903316497803 val_loss: 0.02038123458623886\n",
      "epoch:  24000 train_loss: 0.0055681802332401276 val_loss: 0.005778204649686813\n",
      "epoch:  24100 train_loss: 0.010311665013432503 val_loss: 0.012303395196795464\n",
      "epoch:  24200 train_loss: 0.0008403473766520619 val_loss: 0.000991585198789835\n",
      "epoch:  24300 train_loss: 0.0017791189020499587 val_loss: 0.0016363270115107298\n",
      "epoch:  24400 train_loss: 0.004206694196909666 val_loss: 0.004735418129712343\n",
      "epoch:  24500 train_loss: 0.0006911687669344246 val_loss: 0.0008785338141024113\n",
      "epoch:  24600 train_loss: 0.004060718230903149 val_loss: 0.004894340876489878\n",
      "epoch:  24700 train_loss: 0.0017404796089977026 val_loss: 0.0018659859197214246\n",
      "epoch:  24800 train_loss: 0.0012882740702480078 val_loss: 0.001419238978996873\n",
      "epoch:  24900 train_loss: 0.0010710536735132337 val_loss: 0.0012411130592226982\n",
      "epoch:  25000 train_loss: 0.0009586426895111799 val_loss: 0.0011029497254639864\n",
      "epoch:  25100 train_loss: 0.0009025572799146175 val_loss: 0.001086716540157795\n",
      "epoch:  25200 train_loss: 0.0008407767163589597 val_loss: 0.00098581169731915\n",
      "epoch:  25300 train_loss: 0.0008242950425483286 val_loss: 0.0009318819502368569\n",
      "epoch:  25400 train_loss: 0.0007978251669555902 val_loss: 0.0009161940542981029\n",
      "epoch:  25500 train_loss: 0.003536190604791045 val_loss: 0.004417284857481718\n",
      "epoch:  25600 train_loss: 0.009130168706178665 val_loss: 0.010345526970922947\n",
      "epoch:  25700 train_loss: 0.003335817251354456 val_loss: 0.0052933469414711\n",
      "epoch:  25800 train_loss: 0.00235115853138268 val_loss: 0.0011183347087353468\n",
      "epoch:  25900 train_loss: 0.04690370336174965 val_loss: 0.030116526409983635\n",
      "epoch:  26000 train_loss: 0.0006824439042247832 val_loss: 0.0008162978338077664\n",
      "epoch:  26100 train_loss: 0.0016518546035513282 val_loss: 0.0017066478030756116\n",
      "epoch:  26200 train_loss: 0.008365483954548836 val_loss: 0.008630461059510708\n",
      "epoch:  26300 train_loss: 0.005951024126261473 val_loss: 0.007536160293966532\n",
      "epoch:  26400 train_loss: 0.0031447967048734426 val_loss: 0.004402347840368748\n",
      "epoch:  26500 train_loss: 0.0060225785709917545 val_loss: 0.009582147002220154\n",
      "epoch:  26600 train_loss: 0.0020455620251595974 val_loss: 0.002797654364258051\n",
      "epoch:  26700 train_loss: 0.0015516226412728429 val_loss: 0.0019015386933460832\n",
      "epoch:  26800 train_loss: 0.0008419975056312978 val_loss: 0.0011093768989667296\n",
      "epoch:  26900 train_loss: 0.000713962537702173 val_loss: 0.0009277719655074179\n",
      "epoch:  27000 train_loss: 0.0007135776686482131 val_loss: 0.0008892926853150129\n",
      "epoch:  27100 train_loss: 0.0006617045728489757 val_loss: 0.000782827555667609\n",
      "epoch:  27200 train_loss: 0.0033348784781992435 val_loss: 0.00483710877597332\n",
      "epoch:  27300 train_loss: 0.0005536606186069548 val_loss: 0.0007225644658319652\n",
      "epoch:  27400 train_loss: 0.006818627007305622 val_loss: 0.006311728619039059\n",
      "epoch:  27500 train_loss: 0.000779228750616312 val_loss: 0.0008423850522376597\n",
      "epoch:  27600 train_loss: 0.0070427036844193935 val_loss: 0.006534498184919357\n",
      "epoch:  27700 train_loss: 0.004120944533497095 val_loss: 0.0040249209851026535\n",
      "epoch:  27800 train_loss: 0.006532095838338137 val_loss: 0.007312871050089598\n",
      "epoch:  27900 train_loss: 0.0008934272918850183 val_loss: 0.0009898615535348654\n",
      "epoch:  28000 train_loss: 0.00323839345946908 val_loss: 0.0034006235655397177\n",
      "epoch:  28100 train_loss: 0.004744383972138166 val_loss: 0.00520608015358448\n",
      "epoch:  28200 train_loss: 0.004802617710083723 val_loss: 0.0047943782992661\n",
      "epoch:  28300 train_loss: 0.0031499494798481464 val_loss: 0.00365701736882329\n",
      "epoch:  28400 train_loss: 0.01042372826486826 val_loss: 0.010567638091742992\n",
      "epoch:  28500 train_loss: 0.004586207214742899 val_loss: 0.004712373949587345\n",
      "epoch:  28600 train_loss: 0.0020470868330448866 val_loss: 0.002842947607859969\n",
      "epoch:  28700 train_loss: 0.0009994670981541276 val_loss: 0.0017213578103110194\n",
      "epoch:  28800 train_loss: 0.002348939422518015 val_loss: 0.002488800324499607\n",
      "epoch:  28900 train_loss: 0.007889431901276112 val_loss: 0.007806127425283194\n",
      "epoch:  29000 train_loss: 0.0015473508974537253 val_loss: 0.0018535833805799484\n",
      "epoch:  29100 train_loss: 0.0010226918384432793 val_loss: 0.0012937813298776746\n",
      "epoch:  29200 train_loss: 0.0008241034229286015 val_loss: 0.0010820834431797266\n",
      "epoch:  29300 train_loss: 0.0007150205201469362 val_loss: 0.0008921861299313605\n",
      "epoch:  29400 train_loss: 0.0006473975372500718 val_loss: 0.000805591291282326\n",
      "epoch:  29500 train_loss: 0.0006027173949405551 val_loss: 0.0007987903663888574\n",
      "epoch:  29600 train_loss: 0.0006285611889325082 val_loss: 0.0007567864959128201\n",
      "epoch:  29700 train_loss: 0.03613007441163063 val_loss: 0.04492127522826195\n",
      "epoch:  29800 train_loss: 0.0006148420507088304 val_loss: 0.001639706315472722\n",
      "epoch:  29900 train_loss: 0.0014331643469631672 val_loss: 0.0010875730076804757\n",
      "epoch:  30000 train_loss: 0.0012681789230555296 val_loss: 0.0011659016599878669\n",
      "epoch:  30100 train_loss: 0.003507775254547596 val_loss: 0.0030800120439380407\n",
      "epoch:  30200 train_loss: 0.0007068740087561309 val_loss: 0.0009742659749463201\n",
      "epoch:  30300 train_loss: 0.3567322790622711 val_loss: 0.12850379943847656\n",
      "epoch:  30400 train_loss: 0.0005629868246614933 val_loss: 0.0008215928100980818\n",
      "epoch:  30500 train_loss: 0.0004784567572642118 val_loss: 0.0006726030842401087\n",
      "epoch:  30600 train_loss: 0.000586595619097352 val_loss: 0.0007457761676050723\n",
      "epoch:  30700 train_loss: 0.00844352226704359 val_loss: 0.010379640385508537\n",
      "epoch:  30800 train_loss: 0.03361859545111656 val_loss: 0.020427118986845016\n",
      "epoch:  30900 train_loss: 0.0052191391587257385 val_loss: 0.006690668873488903\n",
      "epoch:  31000 train_loss: 0.00918191485106945 val_loss: 0.010714167729020119\n",
      "epoch:  31100 train_loss: 0.005732472985982895 val_loss: 0.004374098498374224\n",
      "epoch:  31200 train_loss: 0.011159655638039112 val_loss: 0.013333962298929691\n",
      "epoch:  31300 train_loss: 0.0004888985422439873 val_loss: 0.0006483629113063216\n",
      "epoch:  31400 train_loss: 0.0015871981158852577 val_loss: 0.0017860474763438106\n",
      "epoch:  31500 train_loss: 0.0006426296895369887 val_loss: 0.0008334569283761084\n",
      "epoch:  31600 train_loss: 0.0005120709538459778 val_loss: 0.0006897898856550455\n",
      "epoch:  31700 train_loss: 0.0005227273795753717 val_loss: 0.0007304510800167918\n",
      "epoch:  31800 train_loss: 0.0017621667357161641 val_loss: 0.0018930393271148205\n",
      "epoch:  31900 train_loss: 0.0008661317406222224 val_loss: 0.0013250013580545783\n",
      "epoch:  32000 train_loss: 0.03102957084774971 val_loss: 0.03942316025495529\n",
      "epoch:  32100 train_loss: 0.028865674510598183 val_loss: 0.028653426095843315\n",
      "epoch:  32200 train_loss: 0.0007174717029556632 val_loss: 0.0008716419106349349\n",
      "epoch:  32300 train_loss: 0.0003797074896283448 val_loss: 0.0005629262304864824\n",
      "epoch:  32400 train_loss: 0.00045018037781119347 val_loss: 0.0008274593274109066\n",
      "epoch:  32500 train_loss: 0.0008235232089646161 val_loss: 0.0008729839464649558\n",
      "epoch:  32600 train_loss: 0.0009563620551489294 val_loss: 0.0006885069888085127\n",
      "epoch:  32700 train_loss: 0.005197207443416119 val_loss: 0.0085078040137887\n",
      "epoch:  32800 train_loss: 0.0026058945804834366 val_loss: 0.003086889861151576\n",
      "epoch:  32900 train_loss: 0.005924533121287823 val_loss: 0.005336786154657602\n",
      "epoch:  33000 train_loss: 0.0021980940364301205 val_loss: 0.0029067867435514927\n",
      "epoch:  33100 train_loss: 0.0734097957611084 val_loss: 0.10614867508411407\n",
      "epoch:  33200 train_loss: 0.002569721546024084 val_loss: 0.0025768429040908813\n",
      "epoch:  33300 train_loss: 0.0009451102814637125 val_loss: 0.000913364696316421\n",
      "epoch:  33400 train_loss: 0.0068140472285449505 val_loss: 0.008001967333257198\n",
      "epoch:  33500 train_loss: 0.0012702825479209423 val_loss: 0.0017432813765481114\n",
      "epoch:  33600 train_loss: 0.005229411646723747 val_loss: 0.0068780542351305485\n",
      "epoch:  33700 train_loss: 0.005593742709606886 val_loss: 0.0065950313583016396\n",
      "epoch:  33800 train_loss: 0.16800157725811005 val_loss: 0.10932374000549316\n",
      "epoch:  33900 train_loss: 0.001515468000434339 val_loss: 0.0020128386095166206\n",
      "epoch:  34000 train_loss: 0.0008963422733359039 val_loss: 0.001266749226488173\n",
      "epoch:  34100 train_loss: 0.0006857658736407757 val_loss: 0.0010208988096565008\n",
      "epoch:  34200 train_loss: 0.0005723578506149352 val_loss: 0.0008441684767603874\n",
      "epoch:  34300 train_loss: 0.0004945743712596595 val_loss: 0.0007186410366557539\n",
      "epoch:  34400 train_loss: 0.000548780313692987 val_loss: 0.0008046808652579784\n",
      "epoch:  34500 train_loss: 0.0004307819181121886 val_loss: 0.0006419035489670932\n",
      "epoch:  34600 train_loss: 0.01156082283705473 val_loss: 0.005725810304284096\n",
      "epoch:  34700 train_loss: 0.007745986804366112 val_loss: 0.0027615849394351244\n",
      "epoch:  34800 train_loss: 0.00047858041943982244 val_loss: 0.0005850060260854661\n",
      "epoch:  34900 train_loss: 0.0008223020704463124 val_loss: 0.0013598018558695912\n",
      "epoch:  35000 train_loss: 0.007774334866553545 val_loss: 0.006196041125804186\n",
      "epoch:  35100 train_loss: 0.008328904397785664 val_loss: 0.015621388331055641\n",
      "epoch:  35200 train_loss: 0.00039144608308561146 val_loss: 0.0006049966905266047\n",
      "epoch:  35300 train_loss: 0.00035883221426047385 val_loss: 0.0005990316858515143\n",
      "epoch:  35400 train_loss: 0.0010925520909950137 val_loss: 0.0009342269040644169\n",
      "epoch:  35500 train_loss: 0.0030441214330494404 val_loss: 0.003933877684175968\n",
      "epoch:  35600 train_loss: 0.00041997182415798306 val_loss: 0.0006401859573088586\n",
      "epoch:  35700 train_loss: 0.07075623422861099 val_loss: 0.06356789916753769\n",
      "epoch:  35800 train_loss: 0.0007502633961848915 val_loss: 0.0011285784421488643\n",
      "epoch:  35900 train_loss: 0.0004855256120208651 val_loss: 0.0007348178769461811\n"
     ]
    }
   ],
   "source": [
    "# Define the loss threshold, if the current train loss is lower than the threshold, we will begin to save the model\n",
    "best_loss = 10.0\n",
    "\n",
    "# Define the model filename for model.save()\n",
    "MODEL_FILENAME = \"best.pth\"\n",
    "\n",
    "# set model to Training mode\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "NUM_OF_EPOCH = 36000\n",
    "\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    y_pred = model(train_inputs)\n",
    "    loss = loss_fn(y_pred, train_labels).cpu()\n",
    "    #print(t, loss.item())\n",
    "    train_losses.append(loss.item())\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    # BGD\n",
    "    optimizer.step()\n",
    "    \n",
    "    # evaluate validation loss\n",
    "    val_pred = model(val_inputs)\n",
    "    loss = loss_fn(val_pred, val_labels)\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "    # check if we got better loss\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n",
    "\n",
    "    if (epoch % 100) == 0:\n",
    "        print(\"epoch: \", epoch, \"train_loss:\", train_losses[-1], \"val_loss:\", val_losses[-1])\n",
    "        \n",
    "        # check if we got better loss\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the Loss history for training set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_train_history(train_history, val_history):\n",
    "    plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
    "    plt.plot(np.log(train_history))\n",
    "    plt.plot(np.log(val_history))\n",
    "    plt.title(\"Train_history\")\n",
    "    plt.ylabel(\"Log(MSELoss)\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend(['train', 'val'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_train_history(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the best model on previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the best model on previous step\n",
    "model.load_state_dict(torch.load(\"best.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference a single testing example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 1])\n",
      "example:  tensor([[[ 0.6579],\n",
      "         [ 1.4555],\n",
      "         [-1.2833],\n",
      "         [ 0.9791],\n",
      "         [-0.2415],\n",
      "         [ 0.0059],\n",
      "         [-1.5257],\n",
      "         [ 1.2105],\n",
      "         [-0.9333],\n",
      "         [-0.1988]]])\n",
      "========================================\n",
      "ground_truth (x, y, z in meters):  tensor([89.9290, 82.7207, 55.6006])\n",
      "prediction (x, y, z in meters):  tensor([89.9310, 82.7032, 55.6131], grad_fn=<CopyBackwards>)\n",
      "========================================\n",
      "Error (euclidean distance in meters):  tensor(0.0216, grad_fn=<CopyBackwards>)\n"
     ]
    }
   ],
   "source": [
    "def euclidean_distance(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  euclidena_dist = torch.sqrt(loss_fn(a, b))\n",
    "  return euclidena_dist\n",
    "\n",
    "model.eval() # inference mode\n",
    "idx = 188\n",
    "\n",
    "test_inputs = torch.unsqueeze(test_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "test_inputs = test_inputs.to(device)\n",
    "test_labels =  test_labels.to(device)\n",
    "\n",
    "test_input =  torch.unsqueeze(test_inputs[idx], dim=0)  #(10,1) -> (1, 10, 1)\n",
    "print(test_input.shape)\n",
    "test_label = test_labels[idx]\n",
    "test_pred = model(test_input)\n",
    "print(\"example: \", test_input.cpu())\n",
    "print(\"========================================\")\n",
    "print(\"ground_truth (x, y, z in meters): \", test_label.cpu())\n",
    "print(\"prediction (x, y, z in meters): \", test_pred.cpu())\n",
    "print(\"========================================\")\n",
    "\n",
    "\n",
    "#print(\"Loss: \",  loss_fn(test_pred, test_label).cpu())\n",
    "print(\"Error (euclidean distance in meters): \",  euclidean_distance(test_pred, test_label).cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference all testing examples and compute RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  tensor(0.0341, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "def square_error(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  square_error= loss_fn(a, b)\n",
    "  return square_error\n",
    "\n",
    "model.eval() # inference mode\n",
    "test_inputs = torch.unsqueeze(test_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "test_inputs = test_inputs.to(device)\n",
    "test_labels =  test_labels.to(device)\n",
    "\n",
    "test_preds = model(test_inputs)\n",
    "#print(\"example: \", test_example.cpu())\n",
    "#print(\"========================================\")\n",
    "#print(\"ground_truth:\", test_label.cpu())\n",
    "#print(\"prediction:\", test_pred.cpu())\n",
    "#print(\"========================================\")\n",
    "\n",
    "\n",
    "total_errors = 0.0\n",
    "for idx in range(len(test_inputs)):\n",
    "    total_errors += square_error(test_preds[idx], test_labels[idx])\n",
    "    \n",
    "RMSE = torch.sqrt(total_errors / len(test_inputs))\n",
    "print(\"RMSE: \",  RMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the test set prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (16, 9)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.view_init(azim=235, elev=30)   # set view port to fit the fig.4 in paper\n",
    "\n",
    "# plot AN points for system A\n",
    "marker = '^'\n",
    "for xs, ys, zs in AN_sysA:\n",
    "    ax.scatter(xs, ys, zs, marker=marker, c='r', s=100)\n",
    "\n",
    "# plot AN points for system B\n",
    "marker = '*'\n",
    "for xs, ys, zs in AN_sysB:\n",
    "    ax.scatter(xs, ys, zs, marker=marker, c='g', s=100)\n",
    "\n",
    "# plot testset prediction points\n",
    "marker = '.'\n",
    "for xs, ys, zs in test_preds.cpu().detach().numpy():\n",
    "    ax.scatter(xs, ys, zs, marker=marker, c='orange', s=100)\n",
    "\n",
    "    \n",
    "ax.set_xlabel('X-Axis')\n",
    "ax.set_ylabel('Y-Axis')\n",
    "ax.set_zlabel('Z-Axis')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty sigmas and RMSEs\n",
    "sigmas = []\n",
    "RMSEs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOW we are going to add measurement noises into the dataset\n",
    "* Based on the paper, we will add some noise into measurements r by N(0, sigma), \n",
    "* sigma = 0.1, 1.0, 1,9, 2.8, 3.7, 4.6, 5.5, 6.4, 7.3, 8.2, 9.1, 10.0 respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Then, We will retrain 12 models and evaluate the RMSEs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffle = True!\n",
      "epoch:  0 train_loss: 7334.25537109375 val_loss: 7244.10107421875\n",
      "epoch:  100 train_loss: 5912.68017578125 val_loss: 5822.01806640625\n",
      "epoch:  200 train_loss: 5004.66455078125 val_loss: 4920.923828125\n",
      "epoch:  300 train_loss: 4254.7822265625 val_loss: 4176.927734375\n",
      "epoch:  400 train_loss: 3616.832275390625 val_loss: 3544.433349609375\n",
      "epoch:  500 train_loss: 3069.88818359375 val_loss: 3002.862060546875\n",
      "epoch:  600 train_loss: 2599.6162109375 val_loss: 2537.73779296875\n",
      "epoch:  700 train_loss: 2194.963623046875 val_loss: 2138.031982421875\n",
      "epoch:  800 train_loss: 1847.146484375 val_loss: 1795.0030517578125\n",
      "epoch:  900 train_loss: 1548.99169921875 val_loss: 1501.3828125\n",
      "epoch:  1000 train_loss: 1294.4736328125 val_loss: 1251.3231201171875\n",
      "epoch:  1100 train_loss: 1078.5166015625 val_loss: 1039.729736328125\n",
      "epoch:  1200 train_loss: 896.6746215820312 val_loss: 862.0421142578125\n",
      "epoch:  1300 train_loss: 745.1541137695312 val_loss: 714.0287475585938\n",
      "epoch:  1400 train_loss: 619.8143310546875 val_loss: 592.3430786132812\n",
      "epoch:  1500 train_loss: 517.58837890625 val_loss: 493.3206787109375\n",
      "epoch:  1600 train_loss: 435.0355529785156 val_loss: 413.8009033203125\n",
      "epoch:  1700 train_loss: 369.3761901855469 val_loss: 350.8188171386719\n",
      "epoch:  1800 train_loss: 317.7764587402344 val_loss: 301.7890319824219\n",
      "epoch:  1900 train_loss: 278.01177978515625 val_loss: 264.1985168457031\n",
      "epoch:  2000 train_loss: 247.7181854248047 val_loss: 235.9566192626953\n",
      "epoch:  2100 train_loss: 225.14117431640625 val_loss: 215.09347534179688\n",
      "epoch:  2200 train_loss: 208.60446166992188 val_loss: 200.1237030029297\n",
      "epoch:  2300 train_loss: 196.73886108398438 val_loss: 189.58580017089844\n",
      "epoch:  2400 train_loss: 188.3996124267578 val_loss: 182.385498046875\n",
      "epoch:  2500 train_loss: 182.689208984375 val_loss: 177.64895629882812\n",
      "epoch:  2600 train_loss: 178.85304260253906 val_loss: 174.6259765625\n",
      "epoch:  2700 train_loss: 176.35736083984375 val_loss: 172.7954559326172\n",
      "epoch:  2800 train_loss: 174.76608276367188 val_loss: 171.74989318847656\n",
      "epoch:  2900 train_loss: 173.7875518798828 val_loss: 171.21240234375\n",
      "epoch:  3000 train_loss: 173.1934814453125 val_loss: 170.9747314453125\n",
      "epoch:  3100 train_loss: 172.8539581298828 val_loss: 170.90692138671875\n",
      "epoch:  3200 train_loss: 172.66403198242188 val_loss: 170.92404174804688\n",
      "epoch:  3300 train_loss: 172.5584716796875 val_loss: 170.97958374023438\n",
      "epoch:  3400 train_loss: 172.50323486328125 val_loss: 171.04525756835938\n",
      "epoch:  3500 train_loss: 172.47744750976562 val_loss: 171.0989990234375\n",
      "epoch:  3600 train_loss: 172.46368408203125 val_loss: 171.1463623046875\n",
      "epoch:  3700 train_loss: 172.4566650390625 val_loss: 171.1884765625\n",
      "epoch:  3800 train_loss: 172.45431518554688 val_loss: 171.21180725097656\n",
      "epoch:  3900 train_loss: 172.45330810546875 val_loss: 171.22813415527344\n",
      "epoch:  4000 train_loss: 172.4526824951172 val_loss: 171.2454833984375\n",
      "epoch:  4100 train_loss: 172.45260620117188 val_loss: 171.25010681152344\n",
      "epoch:  4200 train_loss: 172.4525909423828 val_loss: 171.2510528564453\n",
      "epoch:  4300 train_loss: 172.45254516601562 val_loss: 171.2542724609375\n",
      "epoch:  4400 train_loss: 172.45249938964844 val_loss: 171.25965881347656\n",
      "epoch:  4500 train_loss: 172.4525146484375 val_loss: 171.26025390625\n",
      "epoch:  4600 train_loss: 172.4525146484375 val_loss: 171.26025390625\n",
      "epoch:  4700 train_loss: 172.4525146484375 val_loss: 171.26025390625\n",
      "epoch:  4800 train_loss: 172.4525146484375 val_loss: 171.26025390625\n",
      "epoch:  4900 train_loss: 172.45249938964844 val_loss: 171.2600860595703\n",
      "epoch:  5000 train_loss: 172.45249938964844 val_loss: 171.26052856445312\n",
      "epoch:  5100 train_loss: 172.45249938964844 val_loss: 171.26025390625\n",
      "epoch:  5200 train_loss: 172.45249938964844 val_loss: 171.2606658935547\n",
      "epoch:  5300 train_loss: 172.45249938964844 val_loss: 171.2605438232422\n",
      "epoch:  5400 train_loss: 172.45249938964844 val_loss: 171.26010131835938\n",
      "epoch:  5500 train_loss: 172.45249938964844 val_loss: 171.2605438232422\n",
      "epoch:  5600 train_loss: 172.45249938964844 val_loss: 171.26063537597656\n",
      "epoch:  5700 train_loss: 172.4525146484375 val_loss: 171.26010131835938\n",
      "epoch:  5800 train_loss: 172.45249938964844 val_loss: 171.2606964111328\n",
      "epoch:  5900 train_loss: 172.4525146484375 val_loss: 171.2606964111328\n",
      "epoch:  6000 train_loss: 172.45249938964844 val_loss: 171.2610626220703\n",
      "epoch:  6100 train_loss: 172.4525146484375 val_loss: 171.2605438232422\n",
      "epoch:  6200 train_loss: 172.4525146484375 val_loss: 171.2605438232422\n",
      "epoch:  6300 train_loss: 172.45249938964844 val_loss: 171.26026916503906\n",
      "epoch:  6400 train_loss: 172.4525146484375 val_loss: 171.26121520996094\n",
      "epoch:  6500 train_loss: 172.4525146484375 val_loss: 171.2605438232422\n",
      "epoch:  6600 train_loss: 172.4525146484375 val_loss: 171.2605438232422\n",
      "epoch:  6700 train_loss: 172.45249938964844 val_loss: 171.26026916503906\n",
      "epoch:  6800 train_loss: 172.45249938964844 val_loss: 171.2610626220703\n",
      "epoch:  6900 train_loss: 172.45249938964844 val_loss: 171.2610626220703\n",
      "epoch:  7000 train_loss: 172.45249938964844 val_loss: 171.26063537597656\n",
      "epoch:  7100 train_loss: 172.45249938964844 val_loss: 171.26104736328125\n",
      "epoch:  7200 train_loss: 172.39630126953125 val_loss: 171.0242462158203\n",
      "epoch:  7300 train_loss: 129.02149963378906 val_loss: 125.42089080810547\n",
      "epoch:  7400 train_loss: 106.30198669433594 val_loss: 103.3302993774414\n",
      "epoch:  7500 train_loss: 93.89117431640625 val_loss: 90.09249877929688\n",
      "epoch:  7600 train_loss: 79.32926940917969 val_loss: 76.34034729003906\n",
      "epoch:  7700 train_loss: 63.12105178833008 val_loss: 60.20541763305664\n",
      "epoch:  7800 train_loss: 46.842445373535156 val_loss: 44.18366241455078\n",
      "epoch:  7900 train_loss: 34.00904846191406 val_loss: 32.27659606933594\n",
      "epoch:  8000 train_loss: 24.75882911682129 val_loss: 23.517494201660156\n",
      "epoch:  8100 train_loss: 18.014610290527344 val_loss: 17.079952239990234\n",
      "epoch:  8200 train_loss: 12.847763061523438 val_loss: 12.24593448638916\n",
      "epoch:  8300 train_loss: 9.272151947021484 val_loss: 8.780915260314941\n",
      "epoch:  8400 train_loss: 6.604330539703369 val_loss: 6.358913898468018\n",
      "epoch:  8500 train_loss: 4.910599708557129 val_loss: 4.733291149139404\n",
      "epoch:  8600 train_loss: 3.531951665878296 val_loss: 3.451460599899292\n",
      "epoch:  8700 train_loss: 2.6118290424346924 val_loss: 2.57926607131958\n",
      "epoch:  8800 train_loss: 2.0367379188537598 val_loss: 2.0897462368011475\n",
      "epoch:  8900 train_loss: 1.6974021196365356 val_loss: 1.7276183366775513\n",
      "epoch:  9000 train_loss: 1.209372878074646 val_loss: 1.211327075958252\n",
      "epoch:  9100 train_loss: 1.000213861465454 val_loss: 1.0019638538360596\n",
      "epoch:  9200 train_loss: 0.8149440288543701 val_loss: 0.8071519732475281\n",
      "epoch:  9300 train_loss: 0.7052657008171082 val_loss: 0.6604105830192566\n",
      "epoch:  9400 train_loss: 0.862398624420166 val_loss: 0.7628327012062073\n",
      "epoch:  9500 train_loss: 0.5151813626289368 val_loss: 0.5263234376907349\n",
      "epoch:  9600 train_loss: 0.3975274860858917 val_loss: 0.39919930696487427\n",
      "epoch:  9700 train_loss: 0.3467531204223633 val_loss: 0.3516347408294678\n",
      "epoch:  9800 train_loss: 0.35862022638320923 val_loss: 0.34462958574295044\n",
      "epoch:  9900 train_loss: 0.26972687244415283 val_loss: 0.27027615904808044\n",
      "epoch:  10000 train_loss: 0.34517693519592285 val_loss: 0.32922279834747314\n",
      "epoch:  10100 train_loss: 0.20969992876052856 val_loss: 0.20281420648097992\n",
      "epoch:  10200 train_loss: 0.18227683007717133 val_loss: 0.18021441996097565\n",
      "epoch:  10300 train_loss: 0.22884491086006165 val_loss: 0.231035515666008\n",
      "epoch:  10400 train_loss: 0.14883162081241608 val_loss: 0.1478210687637329\n",
      "epoch:  10500 train_loss: 0.13286583125591278 val_loss: 0.1289648711681366\n",
      "epoch:  10600 train_loss: 0.21123361587524414 val_loss: 0.22704100608825684\n",
      "epoch:  10700 train_loss: 0.12051303684711456 val_loss: 0.1114414855837822\n",
      "epoch:  10800 train_loss: 0.1285080462694168 val_loss: 0.1315552443265915\n",
      "epoch:  10900 train_loss: 0.09424705058336258 val_loss: 0.0915512889623642\n",
      "epoch:  11000 train_loss: 0.13901670277118683 val_loss: 0.1178731843829155\n",
      "epoch:  11100 train_loss: 0.11958327889442444 val_loss: 0.1468314379453659\n",
      "epoch:  11200 train_loss: 0.08458912372589111 val_loss: 0.08450395613908768\n",
      "epoch:  11300 train_loss: 0.0726538747549057 val_loss: 0.0682225152850151\n",
      "epoch:  11400 train_loss: 0.10202165693044662 val_loss: 0.0985758826136589\n",
      "epoch:  11500 train_loss: 0.09071457386016846 val_loss: 0.08695182204246521\n",
      "epoch:  11600 train_loss: 0.05634169653058052 val_loss: 0.056339867413043976\n",
      "epoch:  11700 train_loss: 0.05375796929001808 val_loss: 0.055875543504953384\n",
      "epoch:  11800 train_loss: 0.08482854068279266 val_loss: 0.07651745527982712\n",
      "epoch:  11900 train_loss: 0.050637196749448776 val_loss: 0.05187458172440529\n",
      "epoch:  12000 train_loss: 0.047505829483270645 val_loss: 0.048544228076934814\n",
      "epoch:  12100 train_loss: 0.16625189781188965 val_loss: 0.1788751482963562\n",
      "epoch:  12200 train_loss: 0.04215521737933159 val_loss: 0.04435735195875168\n",
      "epoch:  12300 train_loss: 0.050261590629816055 val_loss: 0.047480061650276184\n",
      "epoch:  12400 train_loss: 0.06396385282278061 val_loss: 0.06717565655708313\n",
      "epoch:  12500 train_loss: 0.08822942525148392 val_loss: 0.0986427441239357\n",
      "epoch:  12600 train_loss: 0.04242329299449921 val_loss: 0.04685092717409134\n",
      "epoch:  12700 train_loss: 0.047495704144239426 val_loss: 0.04152423515915871\n",
      "epoch:  12800 train_loss: 0.0394895114004612 val_loss: 0.03952399641275406\n",
      "epoch:  12900 train_loss: 0.038035012781620026 val_loss: 0.038256704807281494\n",
      "epoch:  13000 train_loss: 0.03771256282925606 val_loss: 0.040399111807346344\n",
      "epoch:  13100 train_loss: 0.03403371945023537 val_loss: 0.03694058954715729\n",
      "epoch:  13200 train_loss: 0.03516749292612076 val_loss: 0.03729243203997612\n",
      "epoch:  13300 train_loss: 0.08632884174585342 val_loss: 0.14724548161029816\n",
      "epoch:  13400 train_loss: 0.02883373759686947 val_loss: 0.029695874080061913\n",
      "epoch:  13500 train_loss: 0.03389330953359604 val_loss: 0.03645278885960579\n",
      "epoch:  13600 train_loss: 0.10193154960870743 val_loss: 0.08936764299869537\n",
      "epoch:  13700 train_loss: 0.04001714289188385 val_loss: 0.04290841519832611\n",
      "epoch:  13800 train_loss: 0.05394894257187843 val_loss: 0.10560913383960724\n",
      "epoch:  13900 train_loss: 0.026607682928442955 val_loss: 0.027832992374897003\n",
      "epoch:  14000 train_loss: 0.037501975893974304 val_loss: 0.038422614336013794\n",
      "epoch:  14100 train_loss: 0.03575306385755539 val_loss: 0.03820473700761795\n",
      "epoch:  14200 train_loss: 0.034255847334861755 val_loss: 0.03413323685526848\n",
      "epoch:  14300 train_loss: 0.024527670815587044 val_loss: 0.025657285004854202\n",
      "epoch:  14400 train_loss: 0.024366317316889763 val_loss: 0.025118716061115265\n",
      "epoch:  14500 train_loss: 0.02304000034928322 val_loss: 0.024796761572360992\n",
      "epoch:  14600 train_loss: 0.19833247363567352 val_loss: 0.13865570724010468\n",
      "epoch:  14700 train_loss: 0.021851133555173874 val_loss: 0.02380131185054779\n",
      "epoch:  14800 train_loss: 0.022695856168866158 val_loss: 0.024300487712025642\n",
      "epoch:  14900 train_loss: 0.021310489624738693 val_loss: 0.022359877824783325\n",
      "epoch:  15000 train_loss: 0.031199896708130836 val_loss: 0.03267042338848114\n",
      "epoch:  15100 train_loss: 0.02648639865219593 val_loss: 0.03015466034412384\n",
      "epoch:  15200 train_loss: 0.028238072991371155 val_loss: 0.026997482404112816\n",
      "epoch:  15300 train_loss: 0.04134765639901161 val_loss: 0.04413557052612305\n",
      "epoch:  15400 train_loss: 0.041507601737976074 val_loss: 0.03451228141784668\n",
      "epoch:  15500 train_loss: 0.13092920184135437 val_loss: 0.11932475119829178\n",
      "epoch:  15600 train_loss: 0.020754186436533928 val_loss: 0.022806154564023018\n",
      "epoch:  15700 train_loss: 0.022577527910470963 val_loss: 0.026119858026504517\n",
      "epoch:  15800 train_loss: 0.02610933966934681 val_loss: 0.026964105665683746\n",
      "epoch:  15900 train_loss: 0.025774037465453148 val_loss: 0.02316678874194622\n",
      "epoch:  16000 train_loss: 0.03145630285143852 val_loss: 0.03205949440598488\n",
      "epoch:  16100 train_loss: 0.03785300999879837 val_loss: 0.04369126260280609\n",
      "epoch:  16200 train_loss: 0.029301544651389122 val_loss: 0.03177691251039505\n",
      "epoch:  16300 train_loss: 0.027552083134651184 val_loss: 0.031638409942388535\n",
      "epoch:  16400 train_loss: 0.027070628479123116 val_loss: 0.03112665005028248\n",
      "epoch:  16500 train_loss: 0.01841166988015175 val_loss: 0.01991957798600197\n",
      "epoch:  16600 train_loss: 0.020179037004709244 val_loss: 0.020160019397735596\n",
      "epoch:  16700 train_loss: 0.06290925294160843 val_loss: 0.04916805028915405\n",
      "epoch:  16800 train_loss: 0.03585824742913246 val_loss: 0.03740060329437256\n",
      "epoch:  16900 train_loss: 0.021523181349039078 val_loss: 0.022193627431988716\n",
      "epoch:  17000 train_loss: 0.047599636018276215 val_loss: 0.03303086385130882\n",
      "epoch:  17100 train_loss: 0.01560324989259243 val_loss: 0.017374716699123383\n",
      "epoch:  17200 train_loss: 0.1776372194290161 val_loss: 0.2531663477420807\n",
      "epoch:  17300 train_loss: 0.015623288229107857 val_loss: 0.01801960915327072\n",
      "epoch:  17400 train_loss: 0.022370317950844765 val_loss: 0.023351825773715973\n",
      "epoch:  17500 train_loss: 0.015044981613755226 val_loss: 0.017047792673110962\n",
      "epoch:  17600 train_loss: 0.015926575288176537 val_loss: 0.017393535003066063\n",
      "epoch:  17700 train_loss: 0.04567356035113335 val_loss: 0.03014085441827774\n",
      "epoch:  17800 train_loss: 0.020870184525847435 val_loss: 0.022887345403432846\n",
      "epoch:  17900 train_loss: 0.021219953894615173 val_loss: 0.025102542713284492\n",
      "epoch:  18000 train_loss: 0.015118414536118507 val_loss: 0.016303949058055878\n",
      "epoch:  18100 train_loss: 0.030925549566745758 val_loss: 0.036915190517902374\n",
      "epoch:  18200 train_loss: 0.04827897250652313 val_loss: 0.050573866814374924\n",
      "epoch:  18300 train_loss: 0.014260474592447281 val_loss: 0.017252415418624878\n",
      "epoch:  18400 train_loss: 0.019802572205662727 val_loss: 0.020537709817290306\n",
      "epoch:  18500 train_loss: 0.028918640688061714 val_loss: 0.0335029736161232\n",
      "epoch:  18600 train_loss: 0.01877731643617153 val_loss: 0.019859453663229942\n",
      "epoch:  18700 train_loss: 0.018323048949241638 val_loss: 0.01940005272626877\n",
      "epoch:  18800 train_loss: 0.0153478579595685 val_loss: 0.017847323790192604\n",
      "epoch:  18900 train_loss: 0.01669815555214882 val_loss: 0.020585857331752777\n",
      "epoch:  19000 train_loss: 0.01786602847278118 val_loss: 0.022394750267267227\n",
      "epoch:  19100 train_loss: 0.019992616027593613 val_loss: 0.023818131536245346\n",
      "epoch:  19200 train_loss: 0.017134802415966988 val_loss: 0.017786158248782158\n",
      "epoch:  19300 train_loss: 0.015613455325365067 val_loss: 0.018196281045675278\n",
      "epoch:  19400 train_loss: 0.02220994420349598 val_loss: 0.02506422810256481\n",
      "epoch:  19500 train_loss: 0.013637744821608067 val_loss: 0.015380555763840675\n",
      "epoch:  19600 train_loss: 0.019830718636512756 val_loss: 0.02153369039297104\n",
      "epoch:  19700 train_loss: 0.017046499997377396 val_loss: 0.017856774851679802\n",
      "epoch:  19800 train_loss: 0.016727887094020844 val_loss: 0.018380310386419296\n",
      "epoch:  19900 train_loss: 0.01973305456340313 val_loss: 0.022159449756145477\n",
      "epoch:  20000 train_loss: 0.02582000568509102 val_loss: 0.027526576071977615\n",
      "epoch:  20100 train_loss: 0.022796902805566788 val_loss: 0.038173649460077286\n",
      "epoch:  20200 train_loss: 0.012374961748719215 val_loss: 0.014260164462029934\n",
      "epoch:  20300 train_loss: 0.01988195814192295 val_loss: 0.021565986797213554\n",
      "epoch:  20400 train_loss: 0.03951563686132431 val_loss: 0.04326622933149338\n",
      "epoch:  20500 train_loss: 0.014917908236384392 val_loss: 0.014958017505705357\n",
      "epoch:  20600 train_loss: 0.019579023122787476 val_loss: 0.01956965960562229\n",
      "epoch:  20700 train_loss: 0.014605781063437462 val_loss: 0.01667959801852703\n",
      "epoch:  20800 train_loss: 0.07544811815023422 val_loss: 0.06459743529558182\n",
      "epoch:  20900 train_loss: 0.012996803037822247 val_loss: 0.014467853121459484\n",
      "epoch:  21000 train_loss: 0.018267828971147537 val_loss: 0.018745189532637596\n",
      "epoch:  21100 train_loss: 0.27558067440986633 val_loss: 0.17027971148490906\n",
      "epoch:  21200 train_loss: 0.013917991891503334 val_loss: 0.01649211347103119\n",
      "epoch:  21300 train_loss: 0.02540683001279831 val_loss: 0.026514939963817596\n",
      "epoch:  21400 train_loss: 0.0356917567551136 val_loss: 0.035753581672906876\n",
      "epoch:  21500 train_loss: 0.01668095402419567 val_loss: 0.019234318286180496\n",
      "epoch:  21600 train_loss: 0.025265013799071312 val_loss: 0.01612423174083233\n",
      "epoch:  21700 train_loss: 0.026370033621788025 val_loss: 0.032979585230350494\n",
      "epoch:  21800 train_loss: 0.016035059466958046 val_loss: 0.020232463255524635\n",
      "epoch:  21900 train_loss: 0.013776305131614208 val_loss: 0.01502305269241333\n",
      "epoch:  22000 train_loss: 0.012492029927670956 val_loss: 0.01436236035078764\n",
      "epoch:  22100 train_loss: 0.021391678601503372 val_loss: 0.023531490936875343\n",
      "epoch:  22200 train_loss: 0.016011614352464676 val_loss: 0.016868941485881805\n",
      "epoch:  22300 train_loss: 0.011119387112557888 val_loss: 0.012857736088335514\n",
      "epoch:  22400 train_loss: 0.018527433276176453 val_loss: 0.020465541630983353\n",
      "epoch:  22500 train_loss: 0.021945135667920113 val_loss: 0.022077644243836403\n",
      "epoch:  22600 train_loss: 0.013364726677536964 val_loss: 0.014945928938686848\n",
      "epoch:  22700 train_loss: 0.013044681400060654 val_loss: 0.014664181508123875\n",
      "epoch:  22800 train_loss: 0.010651052929461002 val_loss: 0.01255460362881422\n",
      "epoch:  22900 train_loss: 0.012876387685537338 val_loss: 0.01592855341732502\n",
      "epoch:  23000 train_loss: 0.011971177533268929 val_loss: 0.015424704179167747\n",
      "epoch:  23100 train_loss: 0.014285271987318993 val_loss: 0.017888959497213364\n",
      "epoch:  23200 train_loss: 0.013051093555986881 val_loss: 0.01489747129380703\n",
      "epoch:  23300 train_loss: 0.01520537305623293 val_loss: 0.017119286581873894\n",
      "epoch:  23400 train_loss: 0.016137804836034775 val_loss: 0.018420502543449402\n",
      "epoch:  23500 train_loss: 0.021942347288131714 val_loss: 0.026560915634036064\n",
      "epoch:  23600 train_loss: 0.018630530685186386 val_loss: 0.01798587292432785\n",
      "epoch:  23700 train_loss: 0.06762541830539703 val_loss: 0.030697772279381752\n",
      "epoch:  23800 train_loss: 0.012403630651533604 val_loss: 0.01357385702431202\n",
      "epoch:  23900 train_loss: 0.01171533390879631 val_loss: 0.013710812665522099\n",
      "epoch:  24000 train_loss: 0.012885869480669498 val_loss: 0.01691010221838951\n",
      "epoch:  24100 train_loss: 0.01423647627234459 val_loss: 0.015777068212628365\n",
      "epoch:  24200 train_loss: 0.013945328071713448 val_loss: 0.016650406643748283\n",
      "epoch:  24300 train_loss: 0.029523201286792755 val_loss: 0.02760384790599346\n",
      "epoch:  24400 train_loss: 0.01757090352475643 val_loss: 0.02060423232614994\n",
      "epoch:  24500 train_loss: 0.01012172270566225 val_loss: 0.012800276279449463\n",
      "epoch:  24600 train_loss: 0.03145560994744301 val_loss: 0.03462991863489151\n",
      "epoch:  24700 train_loss: 0.010842406190931797 val_loss: 0.01273441780358553\n",
      "epoch:  24800 train_loss: 0.017963698133826256 val_loss: 0.015734337270259857\n",
      "epoch:  24900 train_loss: 0.02152826078236103 val_loss: 0.024450819939374924\n",
      "epoch:  25000 train_loss: 0.02612149529159069 val_loss: 0.030548226088285446\n",
      "epoch:  25100 train_loss: 0.05205272510647774 val_loss: 0.04896826297044754\n",
      "epoch:  25200 train_loss: 0.05089025944471359 val_loss: 0.057340797036886215\n",
      "epoch:  25300 train_loss: 0.009814930148422718 val_loss: 0.011262851767241955\n",
      "epoch:  25400 train_loss: 0.01107572577893734 val_loss: 0.014332331717014313\n",
      "epoch:  25500 train_loss: 0.013827544637024403 val_loss: 0.013967970386147499\n",
      "epoch:  25600 train_loss: 0.011672346852719784 val_loss: 0.01417394820600748\n",
      "epoch:  25700 train_loss: 0.009443545714020729 val_loss: 0.01162638608366251\n",
      "epoch:  25800 train_loss: 0.010791771113872528 val_loss: 0.012412579730153084\n",
      "epoch:  25900 train_loss: 0.030727077275514603 val_loss: 0.028096983209252357\n",
      "epoch:  26000 train_loss: 0.01118756365031004 val_loss: 0.013589861802756786\n",
      "epoch:  26100 train_loss: 0.009644192643463612 val_loss: 0.01171726081520319\n",
      "epoch:  26200 train_loss: 0.010174748487770557 val_loss: 0.015497845597565174\n",
      "epoch:  26300 train_loss: 0.011055421084165573 val_loss: 0.011729178950190544\n",
      "epoch:  26400 train_loss: 0.00946507602930069 val_loss: 0.011255122721195221\n",
      "epoch:  26500 train_loss: 0.010769426822662354 val_loss: 0.012498762458562851\n",
      "epoch:  26600 train_loss: 0.009915275499224663 val_loss: 0.012715532444417477\n",
      "epoch:  26700 train_loss: 0.014846463687717915 val_loss: 0.013280113227665424\n",
      "epoch:  26800 train_loss: 0.013267955742776394 val_loss: 0.0133851058781147\n",
      "epoch:  26900 train_loss: 0.011159687303006649 val_loss: 0.013223023153841496\n",
      "epoch:  27000 train_loss: 0.01208651065826416 val_loss: 0.01587846502661705\n",
      "epoch:  27100 train_loss: 0.032054539769887924 val_loss: 0.04483833536505699\n",
      "epoch:  27200 train_loss: 0.02008008025586605 val_loss: 0.019594311714172363\n",
      "epoch:  27300 train_loss: 0.013517268933355808 val_loss: 0.014713061973452568\n",
      "epoch:  27400 train_loss: 0.00951546523720026 val_loss: 0.010939551517367363\n",
      "epoch:  27500 train_loss: 0.008526472374796867 val_loss: 0.010476788505911827\n",
      "epoch:  27600 train_loss: 0.010305758565664291 val_loss: 0.013182752765715122\n",
      "epoch:  27700 train_loss: 0.008352367207407951 val_loss: 0.01024024747312069\n",
      "epoch:  27800 train_loss: 0.009314498864114285 val_loss: 0.010139064863324165\n",
      "epoch:  27900 train_loss: 0.008860119618475437 val_loss: 0.010507980361580849\n",
      "epoch:  28000 train_loss: 0.008343178778886795 val_loss: 0.010075626894831657\n",
      "epoch:  28100 train_loss: 0.06893610209226608 val_loss: 0.07740146666765213\n",
      "epoch:  28200 train_loss: 0.00978131778538227 val_loss: 0.011842903681099415\n",
      "epoch:  28300 train_loss: 0.04246855154633522 val_loss: 0.06177512928843498\n",
      "epoch:  28400 train_loss: 0.008066993206739426 val_loss: 0.009993690066039562\n",
      "epoch:  28500 train_loss: 0.00945583637803793 val_loss: 0.011414185166358948\n",
      "epoch:  28600 train_loss: 0.015135110355913639 val_loss: 0.017699427902698517\n",
      "epoch:  28700 train_loss: 0.009002319537103176 val_loss: 0.012669230811297894\n",
      "epoch:  28800 train_loss: 0.056700754910707474 val_loss: 0.02971389889717102\n",
      "epoch:  28900 train_loss: 0.008864407427608967 val_loss: 0.01023910567164421\n",
      "epoch:  29000 train_loss: 0.012437419965863228 val_loss: 0.012614485807716846\n",
      "epoch:  29100 train_loss: 0.014067706651985645 val_loss: 0.01540851965546608\n",
      "epoch:  29200 train_loss: 0.012657808139920235 val_loss: 0.013884826563298702\n",
      "epoch:  29300 train_loss: 0.021510770544409752 val_loss: 0.023237178102135658\n",
      "epoch:  29400 train_loss: 0.011071444489061832 val_loss: 0.013834496028721333\n",
      "epoch:  29500 train_loss: 0.008572490885853767 val_loss: 0.009937490336596966\n",
      "epoch:  29600 train_loss: 0.012394790537655354 val_loss: 0.013982219621539116\n",
      "epoch:  29700 train_loss: 0.00943312980234623 val_loss: 0.011114755645394325\n",
      "epoch:  29800 train_loss: 0.021314790472388268 val_loss: 0.029037807136774063\n",
      "epoch:  29900 train_loss: 0.024228597059845924 val_loss: 0.021851690486073494\n",
      "epoch:  30000 train_loss: 0.008117464371025562 val_loss: 0.010495966300368309\n",
      "epoch:  30100 train_loss: 0.008824202232062817 val_loss: 0.010590072721242905\n",
      "epoch:  30200 train_loss: 0.016083918511867523 val_loss: 0.014593478292226791\n",
      "epoch:  30300 train_loss: 0.008411000482738018 val_loss: 0.010000303387641907\n",
      "epoch:  30400 train_loss: 0.017233287915587425 val_loss: 0.016670292243361473\n",
      "epoch:  30500 train_loss: 0.012815403752028942 val_loss: 0.012790597975254059\n",
      "epoch:  30600 train_loss: 0.013991046696901321 val_loss: 0.015067176893353462\n",
      "epoch:  30700 train_loss: 0.1421484798192978 val_loss: 0.11788106709718704\n",
      "epoch:  30800 train_loss: 0.010922870598733425 val_loss: 0.01453964039683342\n",
      "epoch:  30900 train_loss: 0.008380659855902195 val_loss: 0.010210299864411354\n",
      "epoch:  31000 train_loss: 0.008084171451628208 val_loss: 0.010904704220592976\n",
      "epoch:  31100 train_loss: 0.007752733305096626 val_loss: 0.009441467002034187\n",
      "epoch:  31200 train_loss: 0.011847447603940964 val_loss: 0.010841306298971176\n",
      "epoch:  31300 train_loss: 0.009747592732310295 val_loss: 0.011127149686217308\n",
      "epoch:  31400 train_loss: 0.013036878779530525 val_loss: 0.013127144426107407\n",
      "epoch:  31500 train_loss: 0.017156442627310753 val_loss: 0.020683081820607185\n",
      "epoch:  31600 train_loss: 0.014579225331544876 val_loss: 0.015014475211501122\n",
      "epoch:  31700 train_loss: 0.01141220424324274 val_loss: 0.013905370607972145\n",
      "epoch:  31800 train_loss: 0.008181155659258366 val_loss: 0.010748913511633873\n",
      "epoch:  31900 train_loss: 0.008760844357311726 val_loss: 0.01100856252014637\n",
      "epoch:  32000 train_loss: 0.014479546807706356 val_loss: 0.010525095276534557\n",
      "epoch:  32100 train_loss: 0.01374990027397871 val_loss: 0.017474884167313576\n",
      "epoch:  32200 train_loss: 0.007686052471399307 val_loss: 0.00882669072598219\n",
      "epoch:  32300 train_loss: 0.013813518919050694 val_loss: 0.0133894057944417\n",
      "epoch:  32400 train_loss: 0.022200128063559532 val_loss: 0.013540742918848991\n",
      "epoch:  32500 train_loss: 0.00975312851369381 val_loss: 0.011248458176851273\n",
      "epoch:  32600 train_loss: 0.010483523830771446 val_loss: 0.009851870127022266\n",
      "epoch:  32700 train_loss: 0.008064039051532745 val_loss: 0.00923691876232624\n",
      "epoch:  32800 train_loss: 0.006922475062310696 val_loss: 0.008708842098712921\n",
      "epoch:  32900 train_loss: 0.015690132975578308 val_loss: 0.01853146031498909\n",
      "epoch:  33000 train_loss: 0.008970099501311779 val_loss: 0.009567375294864178\n",
      "epoch:  33100 train_loss: 0.010470968671143055 val_loss: 0.010982478968799114\n",
      "epoch:  33200 train_loss: 0.009756786748766899 val_loss: 0.008985218591988087\n",
      "epoch:  33300 train_loss: 0.018847104161977768 val_loss: 0.024423733353614807\n",
      "epoch:  33400 train_loss: 0.0064839874394237995 val_loss: 0.007987204007804394\n",
      "epoch:  33500 train_loss: 0.008656851947307587 val_loss: 0.009694487787783146\n",
      "epoch:  33600 train_loss: 0.012046737596392632 val_loss: 0.0128936767578125\n",
      "epoch:  33700 train_loss: 0.011587018147110939 val_loss: 0.014337330125272274\n",
      "epoch:  33800 train_loss: 0.008159292861819267 val_loss: 0.00812526699155569\n",
      "epoch:  33900 train_loss: 0.009591899812221527 val_loss: 0.0111086405813694\n",
      "epoch:  34000 train_loss: 0.009256348013877869 val_loss: 0.009953672997653484\n",
      "epoch:  34100 train_loss: 0.014896390959620476 val_loss: 0.01749703288078308\n",
      "epoch:  34200 train_loss: 0.017585283145308495 val_loss: 0.019710121676325798\n",
      "epoch:  34300 train_loss: 0.0073377760127186775 val_loss: 0.00862580630928278\n",
      "epoch:  34400 train_loss: 0.017355987802147865 val_loss: 0.011974629946053028\n",
      "epoch:  34500 train_loss: 0.009957479313015938 val_loss: 0.010055516846477985\n",
      "epoch:  34600 train_loss: 0.0149136483669281 val_loss: 0.019247625023126602\n",
      "epoch:  34700 train_loss: 0.006235072854906321 val_loss: 0.007578283082693815\n",
      "epoch:  34800 train_loss: 0.007715058978646994 val_loss: 0.011412655003368855\n",
      "epoch:  34900 train_loss: 0.008782722055912018 val_loss: 0.009274255484342575\n",
      "epoch:  35000 train_loss: 0.008088091388344765 val_loss: 0.009097164496779442\n",
      "epoch:  35100 train_loss: 0.007269727066159248 val_loss: 0.007896787486970425\n",
      "epoch:  35200 train_loss: 0.00909724086523056 val_loss: 0.008988033048808575\n",
      "epoch:  35300 train_loss: 0.009045196697115898 val_loss: 0.009043488651514053\n",
      "epoch:  35400 train_loss: 0.010853606276214123 val_loss: 0.011133654043078423\n",
      "epoch:  35500 train_loss: 0.012833372689783573 val_loss: 0.015036972239613533\n",
      "epoch:  35600 train_loss: 0.016905616968870163 val_loss: 0.01463910099118948\n",
      "epoch:  35700 train_loss: 0.006189178675413132 val_loss: 0.00767761142924428\n",
      "epoch:  35800 train_loss: 0.036364007741212845 val_loss: 0.03613433241844177\n",
      "epoch:  35900 train_loss: 0.010985339991748333 val_loss: 0.010831297375261784\n",
      "sigma: 0.1 RMSE:  tensor(0.1518, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Generate the dataset with noise N(0, sigma)\n",
    "i = 0\n",
    "sigma = 0.1\n",
    "my_dataset = []\n",
    "for ud in UDs:\n",
    "    example = []\n",
    "    for an in ANs:\n",
    "        noise = np.random.normal(0,sigma)\n",
    "        # 0 is mean\n",
    "        # sigma is the deviation of the normal distribution\n",
    "        d = compute_3d_distance(ud, an) + noise\n",
    "        example.append(d)\n",
    "    \n",
    "    # append x, y, z as col#10, #11, #12\n",
    "    example.append(ud[0])\n",
    "    example.append(ud[1])\n",
    "    example.append(ud[2])\n",
    "    \n",
    "    # append 1x13 example row into my_dataset\n",
    "    my_dataset.append(example)  # expected to be 3000x13  \n",
    "    \n",
    "# Load dataset\n",
    "exercise5_dataset = Exercise5Dataset(list_dataset = my_dataset, shuffle=True)\n",
    "\n",
    "#Split dataset by 0.8: 0.1: 0.1\n",
    "train_examples, train_labels = exercise5_dataset[:int(3000*0.8)]  # (2400, 10)   # (2400, 3)\n",
    "val_examples, val_labels = exercise5_dataset[int(3000*0.8):int(3000*0.9)]    # (300, 10)   #(300, 3)\n",
    "test_examples, test_labels = exercise5_dataset[int(3000*0.9):]     #(300, 10)   # (300, 3)\n",
    "\n",
    "###Define model, loss function and optimizer\n",
    "# if we have GPU, then use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define model\n",
    "#model = Net(x_dim = train_examples.shape[1], y_dim = train_labels.shape[1]).to(device)\n",
    "input_dim = 1     #input dim is 1, seq_len = 10\n",
    "hidden_dim = 64   #hidden state dim is 64\n",
    "n_layers = 3             #3-layered LSTM\n",
    "model = MYLSTM(input_dim, hidden_dim, n_layers).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Correct the input/output shape for LSTM\n",
    "train_inputs = torch.unsqueeze(train_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "train_inputs = train_inputs.to(device) \n",
    "\n",
    "val_inputs = torch.unsqueeze(val_examples, dim=-1)   # (N, 10) -> (N, 10, 1)\n",
    "val_inputs = val_inputs.to(device) \n",
    "\n",
    "train_labels = train_labels.to(device)   #(N, 3)\n",
    "val_labels = val_labels.to(device)          #(N, 3)\n",
    "\n",
    "\n",
    "# Define the loss threshold, if the current train loss is lower than the threshold, we will begin to save the model\n",
    "best_loss = 100.0\n",
    "\n",
    "# Define the model filename for model.save()\n",
    "MODEL_FILENAME = \"best.pth\"\n",
    "\n",
    "# set model to Training mode\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "NUM_OF_EPOCH = 36000\n",
    "\n",
    "# Train\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    y_pred = model(train_inputs)\n",
    "    loss = loss_fn(y_pred, train_labels).cpu()\n",
    "    #print(t, loss.item())\n",
    "    train_losses.append(loss.item())\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    # BGD\n",
    "    optimizer.step()\n",
    "    \n",
    "    # evaluate validation loss\n",
    "    val_pred = model(val_inputs)\n",
    "    loss = loss_fn(val_pred, val_labels)\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "\n",
    "\n",
    "    if (epoch % 100) == 0:\n",
    "        print(\"epoch: \", epoch, \"train_loss:\", train_losses[-1], \"val_loss:\", val_losses[-1])\n",
    "        # check if we got better loss\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n",
    "        \n",
    "# Load the best model on previous step\n",
    "model.load_state_dict(torch.load(\"best.pth\"))\n",
    "\n",
    "# Inference all testing examples and compute RMSE\n",
    "def square_error(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  square_error= loss_fn(a, b)\n",
    "  return square_error\n",
    "\n",
    "model.eval() # inference mode\n",
    "test_inputs = torch.unsqueeze(test_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "test_inputs = test_inputs.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "\n",
    "test_preds = model(test_inputs)\n",
    "#print(\"example: \", test_example.cpu())\n",
    "#print(\"========================================\")\n",
    "#print(\"ground_truth:\", test_label.cpu())\n",
    "#print(\"prediction:\", test_pred.cpu())\n",
    "#print(\"========================================\")\n",
    "\n",
    "\n",
    "total_errors = 0.0\n",
    "for idx in range(len(test_inputs)):\n",
    "    total_errors += square_error(test_preds[idx], test_labels[idx])\n",
    "    \n",
    "RMSE = torch.sqrt(total_errors / len(test_inputs))\n",
    "print(\"sigma:\", sigma, \"RMSE: \",  RMSE)\n",
    "\n",
    "sigmas.append(sigma)\n",
    "RMSEs.append(RMSE.cpu().detach().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigma = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffle = True!\n",
      "epoch:  0 train_loss: 7313.40869140625 val_loss: 7433.78369140625\n",
      "epoch:  100 train_loss: 5946.6279296875 val_loss: 6051.322265625\n",
      "epoch:  200 train_loss: 5023.58447265625 val_loss: 5123.6298828125\n",
      "epoch:  300 train_loss: 4267.34326171875 val_loss: 4362.455078125\n",
      "epoch:  400 train_loss: 3626.171142578125 val_loss: 3715.88623046875\n",
      "epoch:  500 train_loss: 3076.933349609375 val_loss: 3161.3212890625\n",
      "epoch:  600 train_loss: 2604.886962890625 val_loss: 2683.823486328125\n",
      "epoch:  700 train_loss: 2199.042724609375 val_loss: 2272.45068359375\n",
      "epoch:  800 train_loss: 1850.475341796875 val_loss: 1917.9718017578125\n",
      "epoch:  900 train_loss: 1551.568359375 val_loss: 1613.582275390625\n",
      "epoch:  1000 train_loss: 1296.630126953125 val_loss: 1353.1602783203125\n",
      "epoch:  1100 train_loss: 1080.37353515625 val_loss: 1131.628173828125\n",
      "epoch:  1200 train_loss: 898.3497924804688 val_loss: 944.280029296875\n",
      "epoch:  1300 train_loss: 746.4129638671875 val_loss: 787.5970458984375\n",
      "epoch:  1400 train_loss: 621.0023803710938 val_loss: 657.6024169921875\n",
      "epoch:  1500 train_loss: 518.5770263671875 val_loss: 550.6805419921875\n",
      "epoch:  1600 train_loss: 435.8871765136719 val_loss: 463.9852294921875\n",
      "epoch:  1700 train_loss: 370.064453125 val_loss: 394.4548034667969\n",
      "epoch:  1800 train_loss: 318.4271240234375 val_loss: 339.3395690917969\n",
      "epoch:  1900 train_loss: 278.5246276855469 val_loss: 296.38360595703125\n",
      "epoch:  2000 train_loss: 248.1702880859375 val_loss: 263.30511474609375\n",
      "epoch:  2100 train_loss: 225.52511596679688 val_loss: 238.1623992919922\n",
      "epoch:  2200 train_loss: 208.94451904296875 val_loss: 219.41256713867188\n",
      "epoch:  2300 train_loss: 197.0675811767578 val_loss: 205.61366271972656\n",
      "epoch:  2400 train_loss: 188.68125915527344 val_loss: 195.57723999023438\n",
      "epoch:  2500 train_loss: 182.95034790039062 val_loss: 188.4346160888672\n",
      "epoch:  2600 train_loss: 179.12649536132812 val_loss: 183.3889923095703\n",
      "epoch:  2700 train_loss: 176.59632873535156 val_loss: 179.89541625976562\n",
      "epoch:  2800 train_loss: 175.00209045410156 val_loss: 177.4827880859375\n",
      "epoch:  2900 train_loss: 174.01461791992188 val_loss: 175.83128356933594\n",
      "epoch:  3000 train_loss: 173.42088317871094 val_loss: 174.71725463867188\n",
      "epoch:  3100 train_loss: 173.0759735107422 val_loss: 173.9550018310547\n",
      "epoch:  3200 train_loss: 172.88424682617188 val_loss: 173.4432373046875\n",
      "epoch:  3300 train_loss: 172.77786254882812 val_loss: 173.0945587158203\n",
      "epoch:  3400 train_loss: 172.72288513183594 val_loss: 172.85711669921875\n",
      "epoch:  3500 train_loss: 172.69476318359375 val_loss: 172.69613647460938\n",
      "epoch:  3600 train_loss: 172.68174743652344 val_loss: 172.5891571044922\n",
      "epoch:  3700 train_loss: 172.67587280273438 val_loss: 172.51919555664062\n",
      "epoch:  3800 train_loss: 172.67295837402344 val_loss: 172.4710693359375\n",
      "epoch:  3900 train_loss: 172.67181396484375 val_loss: 172.4368133544922\n",
      "epoch:  4000 train_loss: 172.67149353027344 val_loss: 172.42364501953125\n",
      "epoch:  4100 train_loss: 172.6712188720703 val_loss: 172.40965270996094\n",
      "epoch:  4200 train_loss: 172.671142578125 val_loss: 172.39747619628906\n",
      "epoch:  4300 train_loss: 172.67111206054688 val_loss: 172.39329528808594\n",
      "epoch:  4400 train_loss: 172.67111206054688 val_loss: 172.39060974121094\n",
      "epoch:  4500 train_loss: 172.67111206054688 val_loss: 172.39059448242188\n",
      "epoch:  4600 train_loss: 172.67111206054688 val_loss: 172.3905792236328\n",
      "epoch:  4700 train_loss: 172.67111206054688 val_loss: 172.38934326171875\n",
      "epoch:  4800 train_loss: 172.67111206054688 val_loss: 172.3892059326172\n",
      "epoch:  4900 train_loss: 172.67111206054688 val_loss: 172.3892059326172\n",
      "epoch:  5000 train_loss: 172.67111206054688 val_loss: 172.38919067382812\n",
      "epoch:  5100 train_loss: 172.67111206054688 val_loss: 172.38894653320312\n",
      "epoch:  5200 train_loss: 172.67111206054688 val_loss: 172.3889923095703\n",
      "epoch:  5300 train_loss: 172.67111206054688 val_loss: 172.38912963867188\n",
      "epoch:  5400 train_loss: 172.67111206054688 val_loss: 172.3889923095703\n",
      "epoch:  5500 train_loss: 172.67111206054688 val_loss: 172.38912963867188\n",
      "epoch:  5600 train_loss: 172.67111206054688 val_loss: 172.38912963867188\n",
      "epoch:  5700 train_loss: 172.67111206054688 val_loss: 172.38912963867188\n",
      "epoch:  5800 train_loss: 172.67111206054688 val_loss: 172.38909912109375\n",
      "epoch:  5900 train_loss: 172.67111206054688 val_loss: 172.3889923095703\n",
      "epoch:  6000 train_loss: 172.67111206054688 val_loss: 172.3889923095703\n",
      "epoch:  6100 train_loss: 172.67111206054688 val_loss: 172.3889923095703\n",
      "epoch:  6200 train_loss: 172.67111206054688 val_loss: 172.38909912109375\n",
      "epoch:  6300 train_loss: 172.67111206054688 val_loss: 172.3889923095703\n",
      "epoch:  6400 train_loss: 172.67111206054688 val_loss: 172.3889923095703\n",
      "epoch:  6500 train_loss: 172.67111206054688 val_loss: 172.3889923095703\n",
      "epoch:  6600 train_loss: 172.67111206054688 val_loss: 172.3889923095703\n",
      "epoch:  6700 train_loss: 172.67111206054688 val_loss: 172.38917541503906\n",
      "epoch:  6800 train_loss: 172.67111206054688 val_loss: 172.38795471191406\n",
      "epoch:  6900 train_loss: 172.67111206054688 val_loss: 172.38909912109375\n",
      "epoch:  7000 train_loss: 172.67111206054688 val_loss: 172.38897705078125\n",
      "epoch:  7100 train_loss: 172.67111206054688 val_loss: 172.3877716064453\n",
      "epoch:  7200 train_loss: 170.62167358398438 val_loss: 171.36538696289062\n",
      "epoch:  7300 train_loss: 127.06816101074219 val_loss: 127.58748626708984\n",
      "epoch:  7400 train_loss: 112.11157989501953 val_loss: 111.56859588623047\n",
      "epoch:  7500 train_loss: 103.32378387451172 val_loss: 102.32050323486328\n",
      "epoch:  7600 train_loss: 95.4623794555664 val_loss: 94.43071746826172\n",
      "epoch:  7700 train_loss: 86.4265365600586 val_loss: 85.25238800048828\n",
      "epoch:  7800 train_loss: 76.10563659667969 val_loss: 75.44579315185547\n",
      "epoch:  7900 train_loss: 66.23809814453125 val_loss: 65.67317199707031\n",
      "epoch:  8000 train_loss: 57.176204681396484 val_loss: 56.44880294799805\n",
      "epoch:  8100 train_loss: 46.155235290527344 val_loss: 45.96136474609375\n",
      "epoch:  8200 train_loss: 35.468994140625 val_loss: 35.12767791748047\n",
      "epoch:  8300 train_loss: 27.299779891967773 val_loss: 27.63102912902832\n",
      "epoch:  8400 train_loss: 21.24424934387207 val_loss: 21.634445190429688\n",
      "epoch:  8500 train_loss: 16.06675148010254 val_loss: 16.718875885009766\n",
      "epoch:  8600 train_loss: 12.27931022644043 val_loss: 12.681163787841797\n",
      "epoch:  8700 train_loss: 9.61572551727295 val_loss: 10.01179027557373\n",
      "epoch:  8800 train_loss: 7.692646026611328 val_loss: 8.405077934265137\n",
      "epoch:  8900 train_loss: 6.5950751304626465 val_loss: 6.595564842224121\n",
      "epoch:  9000 train_loss: 4.849370002746582 val_loss: 5.215434551239014\n",
      "epoch:  9100 train_loss: 3.9561452865600586 val_loss: 4.258638858795166\n",
      "epoch:  9200 train_loss: 3.4071006774902344 val_loss: 3.7433643341064453\n",
      "epoch:  9300 train_loss: 2.7719249725341797 val_loss: 3.0604426860809326\n",
      "epoch:  9400 train_loss: 2.358234405517578 val_loss: 2.5825908184051514\n",
      "epoch:  9500 train_loss: 2.0499608516693115 val_loss: 2.318850517272949\n",
      "epoch:  9600 train_loss: 1.8345084190368652 val_loss: 2.0692763328552246\n",
      "epoch:  9700 train_loss: 1.7022963762283325 val_loss: 2.0850417613983154\n",
      "epoch:  9800 train_loss: 1.4949010610580444 val_loss: 1.67891526222229\n",
      "epoch:  9900 train_loss: 1.32610285282135 val_loss: 1.5203155279159546\n",
      "epoch:  10000 train_loss: 1.2029907703399658 val_loss: 1.3976465463638306\n",
      "epoch:  10100 train_loss: 1.1212395429611206 val_loss: 1.305263876914978\n",
      "epoch:  10200 train_loss: 1.15827476978302 val_loss: 1.3069236278533936\n",
      "epoch:  10300 train_loss: 0.9920015931129456 val_loss: 1.142295002937317\n",
      "epoch:  10400 train_loss: 0.9191164374351501 val_loss: 1.0897040367126465\n",
      "epoch:  10500 train_loss: 1.196704387664795 val_loss: 1.5711792707443237\n",
      "epoch:  10600 train_loss: 0.8702162504196167 val_loss: 1.0178449153900146\n",
      "epoch:  10700 train_loss: 0.7992191314697266 val_loss: 0.9526278376579285\n",
      "epoch:  10800 train_loss: 0.9478739500045776 val_loss: 1.0142868757247925\n",
      "epoch:  10900 train_loss: 0.7257190346717834 val_loss: 0.8672992587089539\n",
      "epoch:  11000 train_loss: 0.7398262619972229 val_loss: 0.9126154184341431\n",
      "epoch:  11100 train_loss: 0.6735625863075256 val_loss: 0.8072969913482666\n",
      "epoch:  11200 train_loss: 0.6564518213272095 val_loss: 0.7798806428909302\n",
      "epoch:  11300 train_loss: 0.6435189247131348 val_loss: 0.7590105533599854\n",
      "epoch:  11400 train_loss: 0.6372756958007812 val_loss: 0.764702320098877\n",
      "epoch:  11500 train_loss: 0.6447475552558899 val_loss: 0.7603591680526733\n",
      "epoch:  11600 train_loss: 0.5907365083694458 val_loss: 0.6981808543205261\n",
      "epoch:  11700 train_loss: 0.5876935124397278 val_loss: 0.7060369253158569\n",
      "epoch:  11800 train_loss: 0.5733203291893005 val_loss: 0.6792722344398499\n",
      "epoch:  11900 train_loss: 0.788006067276001 val_loss: 1.0131487846374512\n",
      "epoch:  12000 train_loss: 0.571727991104126 val_loss: 0.6784318089485168\n",
      "epoch:  12100 train_loss: 0.6024709343910217 val_loss: 0.7153939008712769\n",
      "epoch:  12200 train_loss: 0.6769728660583496 val_loss: 0.8307316303253174\n",
      "epoch:  12300 train_loss: 0.820879340171814 val_loss: 1.1674041748046875\n",
      "epoch:  12400 train_loss: 0.5137637257575989 val_loss: 0.6090018153190613\n",
      "epoch:  12500 train_loss: 0.5050245523452759 val_loss: 0.6023439168930054\n",
      "epoch:  12600 train_loss: 0.5186750292778015 val_loss: 0.646685004234314\n",
      "epoch:  12700 train_loss: 0.49300524592399597 val_loss: 0.5864332318305969\n",
      "epoch:  12800 train_loss: 0.5786158442497253 val_loss: 0.6821138262748718\n",
      "epoch:  12900 train_loss: 0.5101636648178101 val_loss: 0.5964215993881226\n",
      "epoch:  13000 train_loss: 0.5103070735931396 val_loss: 0.5915541648864746\n",
      "epoch:  13100 train_loss: 0.5024786591529846 val_loss: 0.5801699161529541\n",
      "epoch:  13200 train_loss: 0.48152968287467957 val_loss: 0.5913354754447937\n",
      "epoch:  13300 train_loss: 0.4968276023864746 val_loss: 0.5641406178474426\n",
      "epoch:  13400 train_loss: 0.4992600083351135 val_loss: 0.5923260450363159\n",
      "epoch:  13500 train_loss: 0.4590977132320404 val_loss: 0.5361210703849792\n",
      "epoch:  13600 train_loss: 0.46506237983703613 val_loss: 0.5352025628089905\n",
      "epoch:  13700 train_loss: 0.5512917637825012 val_loss: 0.6369216442108154\n",
      "epoch:  13800 train_loss: 0.6060428619384766 val_loss: 0.7129100561141968\n",
      "epoch:  13900 train_loss: 0.46006304025650024 val_loss: 0.5501729846000671\n",
      "epoch:  14000 train_loss: 0.6755357980728149 val_loss: 0.7330849766731262\n",
      "epoch:  14100 train_loss: 1.3842765092849731 val_loss: 2.278928279876709\n",
      "epoch:  14200 train_loss: 0.4506590664386749 val_loss: 0.5256200432777405\n",
      "epoch:  14300 train_loss: 0.4298350512981415 val_loss: 0.5026513934135437\n",
      "epoch:  14400 train_loss: 0.4274744689464569 val_loss: 0.4960831105709076\n",
      "epoch:  14500 train_loss: 0.423341304063797 val_loss: 0.500000536441803\n",
      "epoch:  14600 train_loss: 0.42774298787117004 val_loss: 0.505922257900238\n",
      "epoch:  14700 train_loss: 0.42158743739128113 val_loss: 0.49705982208251953\n",
      "epoch:  14800 train_loss: 0.4245551526546478 val_loss: 0.4876660406589508\n",
      "epoch:  14900 train_loss: 0.4653300344944 val_loss: 0.5473059415817261\n",
      "epoch:  15000 train_loss: 0.541439414024353 val_loss: 0.5529640316963196\n",
      "epoch:  15100 train_loss: 0.41616883873939514 val_loss: 0.47914233803749084\n",
      "epoch:  15200 train_loss: 0.4056163430213928 val_loss: 0.4863605797290802\n",
      "epoch:  15300 train_loss: 0.416072815656662 val_loss: 0.49452129006385803\n",
      "epoch:  15400 train_loss: 0.4187874495983124 val_loss: 0.5015407204627991\n",
      "epoch:  15500 train_loss: 0.4192291498184204 val_loss: 0.5214784741401672\n",
      "epoch:  15600 train_loss: 0.4190486669540405 val_loss: 0.5154882669448853\n",
      "epoch:  15700 train_loss: 0.4106922149658203 val_loss: 0.49870675802230835\n",
      "epoch:  15800 train_loss: 0.4879172444343567 val_loss: 0.508851945400238\n",
      "epoch:  15900 train_loss: 0.3908648192882538 val_loss: 0.4694136679172516\n",
      "epoch:  16000 train_loss: 0.43284106254577637 val_loss: 0.4853329360485077\n",
      "epoch:  16100 train_loss: 0.3934507966041565 val_loss: 0.4630894064903259\n",
      "epoch:  16200 train_loss: 0.3985772132873535 val_loss: 0.466025710105896\n",
      "epoch:  16300 train_loss: 1.3453643321990967 val_loss: 1.8107367753982544\n",
      "epoch:  16400 train_loss: 0.3900371193885803 val_loss: 0.46423855423927307\n",
      "epoch:  16500 train_loss: 0.39051908254623413 val_loss: 0.45858120918273926\n",
      "epoch:  16600 train_loss: 0.3828107714653015 val_loss: 0.46662530303001404\n",
      "epoch:  16700 train_loss: 0.38297125697135925 val_loss: 0.4634217917919159\n",
      "epoch:  16800 train_loss: 0.45177969336509705 val_loss: 0.5048650503158569\n",
      "epoch:  16900 train_loss: 0.37199729681015015 val_loss: 0.4504786729812622\n",
      "epoch:  17000 train_loss: 0.38468533754348755 val_loss: 0.44757014513015747\n",
      "epoch:  17100 train_loss: 0.3887420892715454 val_loss: 0.4507700800895691\n",
      "epoch:  17200 train_loss: 0.3705213963985443 val_loss: 0.46023979783058167\n",
      "epoch:  17300 train_loss: 0.36817362904548645 val_loss: 0.44780126214027405\n",
      "epoch:  17400 train_loss: 0.40864455699920654 val_loss: 0.4735969603061676\n",
      "epoch:  17500 train_loss: 0.36497825384140015 val_loss: 0.4390484690666199\n",
      "epoch:  17600 train_loss: 0.36692383885383606 val_loss: 0.44001635909080505\n",
      "epoch:  17700 train_loss: 0.3604888617992401 val_loss: 0.4448888599872589\n",
      "epoch:  17800 train_loss: 0.3580464720726013 val_loss: 0.43002888560295105\n",
      "epoch:  17900 train_loss: 0.36484357714653015 val_loss: 0.43885940313339233\n",
      "epoch:  18000 train_loss: 0.3556228280067444 val_loss: 0.4314468204975128\n",
      "epoch:  18100 train_loss: 0.36485111713409424 val_loss: 0.4377155303955078\n",
      "epoch:  18200 train_loss: 0.3817196786403656 val_loss: 0.4744983911514282\n",
      "epoch:  18300 train_loss: 0.3533843159675598 val_loss: 0.4304579198360443\n",
      "epoch:  18400 train_loss: 0.3571135103702545 val_loss: 0.4243214428424835\n",
      "epoch:  18500 train_loss: 0.3773835301399231 val_loss: 0.4433597922325134\n",
      "epoch:  18600 train_loss: 0.38605576753616333 val_loss: 0.4517960846424103\n",
      "epoch:  18700 train_loss: 0.35694485902786255 val_loss: 0.4393799602985382\n",
      "epoch:  18800 train_loss: 0.34293606877326965 val_loss: 0.4192330241203308\n",
      "epoch:  18900 train_loss: 0.3439665138721466 val_loss: 0.4200759530067444\n",
      "epoch:  19000 train_loss: 0.3478982150554657 val_loss: 0.4201433062553406\n",
      "epoch:  19100 train_loss: 0.34226372838020325 val_loss: 0.4177684187889099\n",
      "epoch:  19200 train_loss: 0.3412727415561676 val_loss: 0.42024192214012146\n",
      "epoch:  19300 train_loss: 0.34523531794548035 val_loss: 0.4235757887363434\n",
      "epoch:  19400 train_loss: 0.4147360026836395 val_loss: 0.5198608040809631\n",
      "epoch:  19500 train_loss: 0.34085166454315186 val_loss: 0.4225781261920929\n",
      "epoch:  19600 train_loss: 0.33734503388404846 val_loss: 0.41099777817726135\n",
      "epoch:  19700 train_loss: 0.3328765034675598 val_loss: 0.4083332121372223\n",
      "epoch:  19800 train_loss: 0.3677596151828766 val_loss: 0.4320162534713745\n",
      "epoch:  19900 train_loss: 0.3291166126728058 val_loss: 0.40470942854881287\n",
      "epoch:  20000 train_loss: 0.3345243036746979 val_loss: 0.40670618414878845\n",
      "epoch:  20100 train_loss: 0.3290427625179291 val_loss: 0.4006016254425049\n",
      "epoch:  20200 train_loss: 0.33343079686164856 val_loss: 0.41480448842048645\n",
      "epoch:  20300 train_loss: 0.3414391577243805 val_loss: 0.42483046650886536\n",
      "epoch:  20400 train_loss: 0.32823535799980164 val_loss: 0.4032871723175049\n",
      "epoch:  20500 train_loss: 0.3521113395690918 val_loss: 0.4535689353942871\n",
      "epoch:  20600 train_loss: 0.3244495093822479 val_loss: 0.4001007080078125\n",
      "epoch:  20700 train_loss: 0.32110920548439026 val_loss: 0.3971920907497406\n",
      "epoch:  20800 train_loss: 0.33518877625465393 val_loss: 0.3975658714771271\n",
      "epoch:  20900 train_loss: 0.32602232694625854 val_loss: 0.39529216289520264\n",
      "epoch:  21000 train_loss: 0.3575875461101532 val_loss: 0.44236239790916443\n",
      "epoch:  21100 train_loss: 0.31817686557769775 val_loss: 0.39967605471611023\n",
      "epoch:  21200 train_loss: 0.33419421315193176 val_loss: 0.41894999146461487\n",
      "epoch:  21300 train_loss: 0.31293946504592896 val_loss: 0.39086487889289856\n",
      "epoch:  21400 train_loss: 0.32502833008766174 val_loss: 0.424655556678772\n",
      "epoch:  21500 train_loss: 0.3312576413154602 val_loss: 0.39595064520835876\n",
      "epoch:  21600 train_loss: 0.3291698396205902 val_loss: 0.4225620627403259\n",
      "epoch:  21700 train_loss: 0.3081689774990082 val_loss: 0.3879625201225281\n",
      "epoch:  21800 train_loss: 0.3135809004306793 val_loss: 0.4006338119506836\n",
      "epoch:  21900 train_loss: 0.3070717453956604 val_loss: 0.3848400413990021\n",
      "epoch:  22000 train_loss: 0.30552199482917786 val_loss: 0.3842603266239166\n",
      "epoch:  22100 train_loss: 0.3065981864929199 val_loss: 0.39098620414733887\n",
      "epoch:  22200 train_loss: 0.3505633771419525 val_loss: 0.430052250623703\n",
      "epoch:  22300 train_loss: 0.3135904371738434 val_loss: 0.3932754397392273\n",
      "epoch:  22400 train_loss: 0.3316272795200348 val_loss: 0.3913779556751251\n",
      "epoch:  22500 train_loss: 0.3032620847225189 val_loss: 0.3826248347759247\n",
      "epoch:  22600 train_loss: 0.29888108372688293 val_loss: 0.38601958751678467\n",
      "epoch:  22700 train_loss: 0.3237099349498749 val_loss: 0.3927788734436035\n",
      "epoch:  22800 train_loss: 0.30146482586860657 val_loss: 0.3889766335487366\n",
      "epoch:  22900 train_loss: 0.3044619560241699 val_loss: 0.3851662874221802\n",
      "epoch:  23000 train_loss: 0.309457927942276 val_loss: 0.3857736587524414\n",
      "epoch:  23100 train_loss: 0.3028460144996643 val_loss: 0.384704053401947\n",
      "epoch:  23200 train_loss: 0.2936796247959137 val_loss: 0.38145607709884644\n",
      "epoch:  23300 train_loss: 0.4662768542766571 val_loss: 0.5562686324119568\n",
      "epoch:  23400 train_loss: 0.2919522523880005 val_loss: 0.385151207447052\n",
      "epoch:  23500 train_loss: 0.3053998649120331 val_loss: 0.4005138576030731\n",
      "epoch:  23600 train_loss: 0.33254796266555786 val_loss: 0.44996821880340576\n",
      "epoch:  23700 train_loss: 0.317562997341156 val_loss: 0.3839639723300934\n",
      "epoch:  23800 train_loss: 0.2854905128479004 val_loss: 0.3786298930644989\n",
      "epoch:  23900 train_loss: 0.28895148634910583 val_loss: 0.37574440240859985\n",
      "epoch:  24000 train_loss: 0.28522562980651855 val_loss: 0.370208203792572\n",
      "epoch:  24100 train_loss: 0.28378474712371826 val_loss: 0.36965179443359375\n",
      "epoch:  24200 train_loss: 0.2830655574798584 val_loss: 0.36955246329307556\n",
      "epoch:  24300 train_loss: 0.2956273853778839 val_loss: 0.41028645634651184\n",
      "epoch:  24400 train_loss: 0.34851083159446716 val_loss: 0.38545334339141846\n",
      "epoch:  24500 train_loss: 0.28267714381217957 val_loss: 0.37658995389938354\n",
      "epoch:  24600 train_loss: 0.31494542956352234 val_loss: 0.39574095606803894\n",
      "epoch:  24700 train_loss: 0.2827494442462921 val_loss: 0.3739973306655884\n",
      "epoch:  24800 train_loss: 0.31416821479797363 val_loss: 0.37957412004470825\n",
      "epoch:  24900 train_loss: 0.29073286056518555 val_loss: 0.3735976219177246\n",
      "epoch:  25000 train_loss: 0.2740505337715149 val_loss: 0.36990121006965637\n",
      "epoch:  25100 train_loss: 0.2790381610393524 val_loss: 0.37332582473754883\n",
      "epoch:  25200 train_loss: 0.2733382284641266 val_loss: 0.3648994266986847\n",
      "epoch:  25300 train_loss: 0.27304336428642273 val_loss: 0.3669150173664093\n",
      "epoch:  25400 train_loss: 0.2726534903049469 val_loss: 0.3685034215450287\n",
      "epoch:  25500 train_loss: 0.2693352997303009 val_loss: 0.3654831349849701\n",
      "epoch:  25600 train_loss: 0.26886945962905884 val_loss: 0.36840739846229553\n",
      "epoch:  25700 train_loss: 0.2699759602546692 val_loss: 0.37160009145736694\n",
      "epoch:  25800 train_loss: 0.26812034845352173 val_loss: 0.37090861797332764\n",
      "epoch:  25900 train_loss: 0.2682262063026428 val_loss: 0.3624540865421295\n",
      "epoch:  26000 train_loss: 0.2927875220775604 val_loss: 0.38263261318206787\n",
      "epoch:  26100 train_loss: 0.27868399024009705 val_loss: 0.36774060130119324\n",
      "epoch:  26200 train_loss: 0.33243638277053833 val_loss: 0.4071093797683716\n",
      "epoch:  26300 train_loss: 0.2636754810810089 val_loss: 0.357857882976532\n",
      "epoch:  26400 train_loss: 0.26527267694473267 val_loss: 0.36402228474617004\n",
      "epoch:  26500 train_loss: 0.5193682909011841 val_loss: 0.5963082909584045\n",
      "epoch:  26600 train_loss: 0.25975748896598816 val_loss: 0.3574256896972656\n",
      "epoch:  26700 train_loss: 0.267049640417099 val_loss: 0.36198222637176514\n",
      "epoch:  26800 train_loss: 0.27256539463996887 val_loss: 0.3699740469455719\n",
      "epoch:  26900 train_loss: 0.25737687945365906 val_loss: 0.35667961835861206\n",
      "epoch:  27000 train_loss: 0.2593342959880829 val_loss: 0.3680441081523895\n",
      "epoch:  27100 train_loss: 0.2559109628200531 val_loss: 0.35525524616241455\n",
      "epoch:  27200 train_loss: 0.25753137469291687 val_loss: 0.3599734306335449\n",
      "epoch:  27300 train_loss: 0.2597436010837555 val_loss: 0.36541980504989624\n",
      "epoch:  27400 train_loss: 0.2700689136981964 val_loss: 0.3735475540161133\n",
      "epoch:  27500 train_loss: 0.2672755718231201 val_loss: 0.3768402338027954\n",
      "epoch:  27600 train_loss: 0.4090770483016968 val_loss: 0.5009703636169434\n",
      "epoch:  27700 train_loss: 0.25922977924346924 val_loss: 0.3616432845592499\n",
      "epoch:  27800 train_loss: 0.276708722114563 val_loss: 0.3910011351108551\n",
      "epoch:  27900 train_loss: 0.25617170333862305 val_loss: 0.3611161410808563\n",
      "epoch:  28000 train_loss: 0.3952852189540863 val_loss: 0.4788718819618225\n",
      "epoch:  28100 train_loss: 0.25692281126976013 val_loss: 0.35025468468666077\n",
      "epoch:  28200 train_loss: 0.25053727626800537 val_loss: 0.3459305167198181\n",
      "epoch:  28300 train_loss: 0.24756494164466858 val_loss: 0.3458445966243744\n",
      "epoch:  28400 train_loss: 0.24560756981372833 val_loss: 0.347534716129303\n",
      "epoch:  28500 train_loss: 0.25232869386672974 val_loss: 0.35395047068595886\n",
      "epoch:  28600 train_loss: 0.24539168179035187 val_loss: 0.3504394590854645\n",
      "epoch:  28700 train_loss: 0.3745349645614624 val_loss: 0.42316338419914246\n",
      "epoch:  28800 train_loss: 0.24483218789100647 val_loss: 0.35850682854652405\n",
      "epoch:  28900 train_loss: 0.24149814248085022 val_loss: 0.3502182364463806\n",
      "epoch:  29000 train_loss: 0.2463052123785019 val_loss: 0.35474202036857605\n",
      "epoch:  29100 train_loss: 0.24343709647655487 val_loss: 0.35475364327430725\n",
      "epoch:  29200 train_loss: 0.24018551409244537 val_loss: 0.3516676127910614\n",
      "epoch:  29300 train_loss: 0.23770101368427277 val_loss: 0.34745582938194275\n",
      "epoch:  29400 train_loss: 0.2417387068271637 val_loss: 0.3497271239757538\n",
      "epoch:  29500 train_loss: 0.23815417289733887 val_loss: 0.35165852308273315\n",
      "epoch:  29600 train_loss: 0.29467666149139404 val_loss: 0.4521191418170929\n",
      "epoch:  29700 train_loss: 0.2520532011985779 val_loss: 0.36969321966171265\n",
      "epoch:  29800 train_loss: 0.2631499767303467 val_loss: 0.3683912456035614\n",
      "epoch:  29900 train_loss: 0.2363637387752533 val_loss: 0.34156563878059387\n",
      "epoch:  30000 train_loss: 0.23353438079357147 val_loss: 0.3423774540424347\n",
      "epoch:  30100 train_loss: 0.23241235315799713 val_loss: 0.34438878297805786\n",
      "epoch:  30200 train_loss: 0.23236477375030518 val_loss: 0.3440268337726593\n",
      "epoch:  30300 train_loss: 0.23043057322502136 val_loss: 0.3445063829421997\n",
      "epoch:  30400 train_loss: 0.22915460169315338 val_loss: 0.34415507316589355\n",
      "epoch:  30500 train_loss: 0.22908508777618408 val_loss: 0.34516608715057373\n",
      "epoch:  30600 train_loss: 0.22895434498786926 val_loss: 0.3434935212135315\n",
      "epoch:  30700 train_loss: 0.2306155562400818 val_loss: 0.35107362270355225\n",
      "epoch:  30800 train_loss: 0.24803833663463593 val_loss: 0.3671592175960541\n",
      "epoch:  30900 train_loss: 0.2576795816421509 val_loss: 0.4050968289375305\n",
      "epoch:  31000 train_loss: 0.22548502683639526 val_loss: 0.34582045674324036\n",
      "epoch:  31100 train_loss: 0.2238444685935974 val_loss: 0.3422424793243408\n",
      "epoch:  31200 train_loss: 0.22334924340248108 val_loss: 0.34661078453063965\n",
      "epoch:  31300 train_loss: 0.22506484389305115 val_loss: 0.3445172905921936\n",
      "epoch:  31400 train_loss: 0.2273702770471573 val_loss: 0.3484484851360321\n",
      "epoch:  31500 train_loss: 0.26052772998809814 val_loss: 0.3926432728767395\n",
      "epoch:  31600 train_loss: 0.22128385305404663 val_loss: 0.35282307863235474\n",
      "epoch:  31700 train_loss: 0.30829569697380066 val_loss: 0.408197820186615\n",
      "epoch:  31800 train_loss: 0.3933495581150055 val_loss: 0.5823873281478882\n",
      "epoch:  31900 train_loss: 0.21493694186210632 val_loss: 0.3430364429950714\n",
      "epoch:  32000 train_loss: 0.21542565524578094 val_loss: 0.3436899781227112\n",
      "epoch:  32100 train_loss: 0.22817179560661316 val_loss: 0.3506483733654022\n",
      "epoch:  32200 train_loss: 0.24779872596263885 val_loss: 0.3784954249858856\n",
      "epoch:  32300 train_loss: 0.21159744262695312 val_loss: 0.3418078124523163\n",
      "epoch:  32400 train_loss: 0.21293915808200836 val_loss: 0.3426511585712433\n",
      "epoch:  32500 train_loss: 0.2932906150817871 val_loss: 0.4007328450679779\n",
      "epoch:  32600 train_loss: 0.21841640770435333 val_loss: 0.32866767048835754\n",
      "epoch:  32700 train_loss: 0.2122829556465149 val_loss: 0.32967668771743774\n",
      "epoch:  32800 train_loss: 0.20962823927402496 val_loss: 0.33106833696365356\n",
      "epoch:  32900 train_loss: 0.20777517557144165 val_loss: 0.33308085799217224\n",
      "epoch:  33000 train_loss: 0.2063710242509842 val_loss: 0.3339134454727173\n",
      "epoch:  33100 train_loss: 0.2248278558254242 val_loss: 0.3591732680797577\n",
      "epoch:  33200 train_loss: 0.20456041395664215 val_loss: 0.3357475996017456\n",
      "epoch:  33300 train_loss: 0.23330172896385193 val_loss: 0.36608821153640747\n",
      "epoch:  33400 train_loss: 0.20555643737316132 val_loss: 0.3423457145690918\n",
      "epoch:  33500 train_loss: 0.2403843253850937 val_loss: 0.3638632893562317\n",
      "epoch:  33600 train_loss: 0.20705337822437286 val_loss: 0.341230183839798\n",
      "epoch:  33700 train_loss: 0.20068569481372833 val_loss: 0.3417583703994751\n",
      "epoch:  33800 train_loss: 0.20744235813617706 val_loss: 0.3427079916000366\n",
      "epoch:  33900 train_loss: 0.19705112278461456 val_loss: 0.3369235694408417\n",
      "epoch:  34000 train_loss: 0.19642436504364014 val_loss: 0.33999165892601013\n",
      "epoch:  34100 train_loss: 0.22534222900867462 val_loss: 0.3713071644306183\n",
      "epoch:  34200 train_loss: 0.2004697322845459 val_loss: 0.34521010518074036\n",
      "epoch:  34300 train_loss: 0.1938098520040512 val_loss: 0.3361201584339142\n",
      "epoch:  34400 train_loss: 0.21267706155776978 val_loss: 0.34164905548095703\n",
      "epoch:  34500 train_loss: 0.19099728763103485 val_loss: 0.3373609185218811\n",
      "epoch:  34600 train_loss: 0.20322009921073914 val_loss: 0.33949536085128784\n",
      "epoch:  34700 train_loss: 0.1927957385778427 val_loss: 0.3468566834926605\n",
      "epoch:  34800 train_loss: 0.21835066378116608 val_loss: 0.3514118492603302\n",
      "epoch:  34900 train_loss: 0.19224397838115692 val_loss: 0.34150493144989014\n",
      "epoch:  35000 train_loss: 0.18765228986740112 val_loss: 0.34039536118507385\n",
      "epoch:  35100 train_loss: 0.2084304690361023 val_loss: 0.3505439758300781\n",
      "epoch:  35200 train_loss: 0.19570215046405792 val_loss: 0.3614017069339752\n",
      "epoch:  35300 train_loss: 0.18255208432674408 val_loss: 0.3426908850669861\n",
      "epoch:  35400 train_loss: 0.30455031991004944 val_loss: 0.38735827803611755\n",
      "epoch:  35500 train_loss: 0.2405448853969574 val_loss: 0.3390926122665405\n",
      "epoch:  35600 train_loss: 0.21872781217098236 val_loss: 0.3354666531085968\n",
      "epoch:  35700 train_loss: 0.20911626517772675 val_loss: 0.33474665880203247\n",
      "epoch:  35800 train_loss: 0.20382660627365112 val_loss: 0.3342922627925873\n",
      "epoch:  35900 train_loss: 0.20027048885822296 val_loss: 0.33572015166282654\n",
      "sigma: 1.0 RMSE:  tensor(0.9586, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Generate the dataset with noise N(0, sigma)\n",
    "i = 0\n",
    "sigma = 1.0\n",
    "my_dataset = []\n",
    "for ud in UDs:\n",
    "    example = []\n",
    "    for an in ANs:\n",
    "        noise = np.random.normal(0,sigma)\n",
    "        # 0 is mean\n",
    "        # sigma is the deviation of the normal distribution\n",
    "        d = compute_3d_distance(ud, an) + noise\n",
    "        example.append(d)\n",
    "    \n",
    "    # append x, y, z as col#10, #11, #12\n",
    "    example.append(ud[0])\n",
    "    example.append(ud[1])\n",
    "    example.append(ud[2])\n",
    "    \n",
    "    # append 1x13 example row into my_dataset\n",
    "    my_dataset.append(example)  # expected to be 3000x13  \n",
    "    \n",
    "# Load dataset\n",
    "exercise5_dataset = Exercise5Dataset(list_dataset = my_dataset, shuffle=True)\n",
    "\n",
    "#Split dataset by 0.8: 0.1: 0.1\n",
    "train_examples, train_labels = exercise5_dataset[:int(3000*0.8)]  # (2400, 10)   # (2400, 3)\n",
    "val_examples, val_labels = exercise5_dataset[int(3000*0.8):int(3000*0.9)]    # (300, 10)   #(300, 3)\n",
    "test_examples, test_labels = exercise5_dataset[int(3000*0.9):]     #(300, 10)   # (300, 3)\n",
    "\n",
    "###Define model, loss function and optimizer\n",
    "# if we have GPU, then use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define model\n",
    "#model = Net(x_dim = train_examples.shape[1], y_dim = train_labels.shape[1]).to(device)\n",
    "input_dim = 1     #input dim is 1, seq_len = 10\n",
    "hidden_dim = 64   #hidden state dim is 64\n",
    "n_layers = 3             #3-layered LSTM\n",
    "model = MYLSTM(input_dim, hidden_dim, n_layers).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Correct the input/output shape for LSTM\n",
    "train_inputs = torch.unsqueeze(train_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "train_inputs = train_inputs.to(device) \n",
    "\n",
    "val_inputs = torch.unsqueeze(val_examples, dim=-1)   # (N, 10) -> (N, 10, 1)\n",
    "val_inputs = val_inputs.to(device) \n",
    "\n",
    "train_labels = train_labels.to(device)   #(N, 3)\n",
    "val_labels = val_labels.to(device)          #(N, 3)\n",
    "\n",
    "\n",
    "# Define the loss threshold, if the current train loss is lower than the threshold, we will begin to save the model\n",
    "best_loss = 100.0\n",
    "\n",
    "# Define the model filename for model.save()\n",
    "MODEL_FILENAME = \"best.pth\"\n",
    "\n",
    "# set model to Training mode\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "NUM_OF_EPOCH = 36000\n",
    "\n",
    "# Train\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    y_pred = model(train_inputs)\n",
    "    loss = loss_fn(y_pred, train_labels).cpu()\n",
    "    #print(t, loss.item())\n",
    "    train_losses.append(loss.item())\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    # BGD\n",
    "    optimizer.step()\n",
    "    \n",
    "    # evaluate validation loss\n",
    "    val_pred = model(val_inputs)\n",
    "    loss = loss_fn(val_pred, val_labels)\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "\n",
    "\n",
    "    if (epoch % 100) == 0:\n",
    "        print(\"epoch: \", epoch, \"train_loss:\", train_losses[-1], \"val_loss:\", val_losses[-1])\n",
    "        # check if we got better loss\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n",
    "        \n",
    "# Load the best model on previous step\n",
    "model.load_state_dict(torch.load(\"best.pth\"))\n",
    "\n",
    "# Inference all testing examples and compute RMSE\n",
    "def square_error(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  square_error= loss_fn(a, b)\n",
    "  return square_error\n",
    "\n",
    "model.eval() # inference mode\n",
    "test_inputs = torch.unsqueeze(test_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "test_inputs = test_inputs.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "\n",
    "test_preds = model(test_inputs)\n",
    "#print(\"example: \", test_example.cpu())\n",
    "#print(\"========================================\")\n",
    "#print(\"ground_truth:\", test_label.cpu())\n",
    "#print(\"prediction:\", test_pred.cpu())\n",
    "#print(\"========================================\")\n",
    "\n",
    "\n",
    "total_errors = 0.0\n",
    "for idx in range(len(test_inputs)):\n",
    "    total_errors += square_error(test_preds[idx], test_labels[idx])\n",
    "    \n",
    "RMSE = torch.sqrt(total_errors / len(test_inputs))\n",
    "print(\"sigma:\", sigma, \"RMSE: \",  RMSE)\n",
    "\n",
    "sigmas.append(sigma)\n",
    "RMSEs.append(RMSE.cpu().detach().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigma = 1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffle = True!\n",
      "epoch:  0 train_loss: 7323.82958984375 val_loss: 7367.9365234375\n",
      "epoch:  100 train_loss: 5918.06396484375 val_loss: 5948.935546875\n",
      "epoch:  200 train_loss: 4995.9296875 val_loss: 5023.96337890625\n",
      "epoch:  300 train_loss: 4240.40478515625 val_loss: 4265.703125\n",
      "epoch:  400 train_loss: 3599.52392578125 val_loss: 3622.12841796875\n",
      "epoch:  500 train_loss: 3051.093994140625 val_loss: 3071.300048828125\n",
      "epoch:  600 train_loss: 2580.416015625 val_loss: 2598.6015625\n",
      "epoch:  700 train_loss: 2176.310791015625 val_loss: 2192.5009765625\n",
      "epoch:  800 train_loss: 1829.499267578125 val_loss: 1844.273681640625\n",
      "epoch:  900 train_loss: 1532.8216552734375 val_loss: 1546.019775390625\n",
      "epoch:  1000 train_loss: 1279.9588623046875 val_loss: 1291.985595703125\n",
      "epoch:  1100 train_loss: 1065.864013671875 val_loss: 1076.725341796875\n",
      "epoch:  1200 train_loss: 885.6777954101562 val_loss: 895.7160034179688\n",
      "epoch:  1300 train_loss: 735.5491333007812 val_loss: 744.9340209960938\n",
      "epoch:  1400 train_loss: 611.8837890625 val_loss: 620.3573608398438\n",
      "epoch:  1500 train_loss: 510.9510498046875 val_loss: 518.6412353515625\n",
      "epoch:  1600 train_loss: 429.5992431640625 val_loss: 436.73724365234375\n",
      "epoch:  1700 train_loss: 364.87750244140625 val_loss: 371.5470275878906\n",
      "epoch:  1800 train_loss: 314.3031921386719 val_loss: 320.3363952636719\n",
      "epoch:  1900 train_loss: 275.22552490234375 val_loss: 280.78936767578125\n",
      "epoch:  2000 train_loss: 245.65184020996094 val_loss: 250.74049377441406\n",
      "epoch:  2100 train_loss: 223.62596130371094 val_loss: 228.22021484375\n",
      "epoch:  2200 train_loss: 207.5103302001953 val_loss: 211.75848388671875\n",
      "epoch:  2300 train_loss: 195.9505157470703 val_loss: 199.89337158203125\n",
      "epoch:  2400 train_loss: 187.88673400878906 val_loss: 191.53524780273438\n",
      "epoch:  2500 train_loss: 182.3530731201172 val_loss: 185.7635040283203\n",
      "epoch:  2600 train_loss: 178.6725616455078 val_loss: 181.87652587890625\n",
      "epoch:  2700 train_loss: 176.25546264648438 val_loss: 179.28573608398438\n",
      "epoch:  2800 train_loss: 174.73489379882812 val_loss: 177.6251983642578\n",
      "epoch:  2900 train_loss: 173.79656982421875 val_loss: 176.5709228515625\n",
      "epoch:  3000 train_loss: 173.242431640625 val_loss: 175.91928100585938\n",
      "epoch:  3100 train_loss: 172.9195556640625 val_loss: 175.5244140625\n",
      "epoch:  3200 train_loss: 172.73500061035156 val_loss: 175.28224182128906\n",
      "epoch:  3300 train_loss: 172.6401824951172 val_loss: 175.14500427246094\n",
      "epoch:  3400 train_loss: 172.5893096923828 val_loss: 175.06118774414062\n",
      "epoch:  3500 train_loss: 172.563232421875 val_loss: 175.011962890625\n",
      "epoch:  3600 train_loss: 172.55125427246094 val_loss: 174.98385620117188\n",
      "epoch:  3700 train_loss: 172.54544067382812 val_loss: 174.9667510986328\n",
      "epoch:  3800 train_loss: 172.5426788330078 val_loss: 174.95486450195312\n",
      "epoch:  3900 train_loss: 172.54164123535156 val_loss: 174.94833374023438\n",
      "epoch:  4000 train_loss: 172.5413360595703 val_loss: 174.94593811035156\n",
      "epoch:  4100 train_loss: 172.5411376953125 val_loss: 174.94277954101562\n",
      "epoch:  4200 train_loss: 172.54107666015625 val_loss: 174.94129943847656\n",
      "epoch:  4300 train_loss: 172.54104614257812 val_loss: 174.9405975341797\n",
      "epoch:  4400 train_loss: 172.54104614257812 val_loss: 174.94000244140625\n",
      "epoch:  4500 train_loss: 172.54104614257812 val_loss: 174.93983459472656\n",
      "epoch:  4600 train_loss: 172.54104614257812 val_loss: 174.94003295898438\n",
      "epoch:  4700 train_loss: 172.54104614257812 val_loss: 174.9398651123047\n",
      "epoch:  4800 train_loss: 172.54104614257812 val_loss: 174.9398651123047\n",
      "epoch:  4900 train_loss: 172.54104614257812 val_loss: 174.9398651123047\n",
      "epoch:  5000 train_loss: 172.54104614257812 val_loss: 174.9398651123047\n",
      "epoch:  5100 train_loss: 172.54104614257812 val_loss: 174.93963623046875\n",
      "epoch:  5200 train_loss: 172.54104614257812 val_loss: 174.9396514892578\n",
      "epoch:  5300 train_loss: 172.54104614257812 val_loss: 174.93955993652344\n",
      "epoch:  5400 train_loss: 172.54104614257812 val_loss: 174.9396514892578\n",
      "epoch:  5500 train_loss: 172.54104614257812 val_loss: 174.93975830078125\n",
      "epoch:  5600 train_loss: 172.54104614257812 val_loss: 174.9398651123047\n",
      "epoch:  5700 train_loss: 172.54104614257812 val_loss: 174.9398651123047\n",
      "epoch:  5800 train_loss: 172.54104614257812 val_loss: 174.9396514892578\n",
      "epoch:  5900 train_loss: 172.54104614257812 val_loss: 174.93963623046875\n",
      "epoch:  6000 train_loss: 172.54104614257812 val_loss: 174.9398651123047\n",
      "epoch:  6100 train_loss: 172.54104614257812 val_loss: 174.93955993652344\n",
      "epoch:  6200 train_loss: 172.54104614257812 val_loss: 174.93955993652344\n",
      "epoch:  6300 train_loss: 172.54104614257812 val_loss: 174.93984985351562\n",
      "epoch:  6400 train_loss: 172.54104614257812 val_loss: 174.93955993652344\n",
      "epoch:  6500 train_loss: 170.62767028808594 val_loss: 173.7500457763672\n",
      "epoch:  6600 train_loss: 132.25018310546875 val_loss: 136.2133331298828\n",
      "epoch:  6700 train_loss: 114.72471618652344 val_loss: 119.0003433227539\n",
      "epoch:  6800 train_loss: 106.54927062988281 val_loss: 110.78093719482422\n",
      "epoch:  6900 train_loss: 99.9052963256836 val_loss: 103.35021209716797\n",
      "epoch:  7000 train_loss: 90.86089324951172 val_loss: 94.5751724243164\n",
      "epoch:  7100 train_loss: 80.3682861328125 val_loss: 84.23494720458984\n",
      "epoch:  7200 train_loss: 69.81387329101562 val_loss: 73.08831787109375\n",
      "epoch:  7300 train_loss: 59.47850799560547 val_loss: 62.064029693603516\n",
      "epoch:  7400 train_loss: 48.07224655151367 val_loss: 50.124168395996094\n",
      "epoch:  7500 train_loss: 38.32642364501953 val_loss: 40.16007995605469\n",
      "epoch:  7600 train_loss: 30.419973373413086 val_loss: 31.733720779418945\n",
      "epoch:  7700 train_loss: 24.19706153869629 val_loss: 25.322649002075195\n",
      "epoch:  7800 train_loss: 19.301250457763672 val_loss: 20.145647048950195\n",
      "epoch:  7900 train_loss: 15.336950302124023 val_loss: 16.087600708007812\n",
      "epoch:  8000 train_loss: 12.272290229797363 val_loss: 12.853385925292969\n",
      "epoch:  8100 train_loss: 9.909664154052734 val_loss: 10.401815414428711\n",
      "epoch:  8200 train_loss: 8.13255786895752 val_loss: 8.576961517333984\n",
      "epoch:  8300 train_loss: 6.60640811920166 val_loss: 7.0604777336120605\n",
      "epoch:  8400 train_loss: 5.608405113220215 val_loss: 6.132900714874268\n",
      "epoch:  8500 train_loss: 4.702319622039795 val_loss: 5.158787250518799\n",
      "epoch:  8600 train_loss: 4.1044206619262695 val_loss: 4.510609149932861\n",
      "epoch:  8700 train_loss: 3.638139247894287 val_loss: 4.061022758483887\n",
      "epoch:  8800 train_loss: 3.2729859352111816 val_loss: 3.6761231422424316\n",
      "epoch:  8900 train_loss: 2.8997507095336914 val_loss: 3.3100693225860596\n",
      "epoch:  9000 train_loss: 2.641705274581909 val_loss: 3.046053409576416\n",
      "epoch:  9100 train_loss: 2.5142383575439453 val_loss: 2.8514139652252197\n",
      "epoch:  9200 train_loss: 2.364449977874756 val_loss: 2.87699031829834\n",
      "epoch:  9300 train_loss: 2.2059288024902344 val_loss: 2.6708898544311523\n",
      "epoch:  9400 train_loss: 2.017031669616699 val_loss: 2.3888847827911377\n",
      "epoch:  9500 train_loss: 1.9623370170593262 val_loss: 2.3314387798309326\n",
      "epoch:  9600 train_loss: 1.8157292604446411 val_loss: 2.2018144130706787\n",
      "epoch:  9700 train_loss: 1.7455472946166992 val_loss: 2.13179087638855\n",
      "epoch:  9800 train_loss: 1.7135151624679565 val_loss: 2.0705950260162354\n",
      "epoch:  9900 train_loss: 1.7460371255874634 val_loss: 2.1566002368927\n",
      "epoch:  10000 train_loss: 1.6530019044876099 val_loss: 2.0200304985046387\n",
      "epoch:  10100 train_loss: 1.5377092361450195 val_loss: 1.929539680480957\n",
      "epoch:  10200 train_loss: 1.4877707958221436 val_loss: 1.8800737857818604\n",
      "epoch:  10300 train_loss: 1.451088786125183 val_loss: 1.8516596555709839\n",
      "epoch:  10400 train_loss: 1.6251698732376099 val_loss: 1.9541672468185425\n",
      "epoch:  10500 train_loss: 1.4034785032272339 val_loss: 1.815732717514038\n",
      "epoch:  10600 train_loss: 1.4096384048461914 val_loss: 1.8283971548080444\n",
      "epoch:  10700 train_loss: 1.3849958181381226 val_loss: 1.8069109916687012\n",
      "epoch:  10800 train_loss: 1.4703119993209839 val_loss: 1.9864144325256348\n",
      "epoch:  10900 train_loss: 1.4428209066390991 val_loss: 1.8443820476531982\n",
      "epoch:  11000 train_loss: 1.3805242776870728 val_loss: 1.8388350009918213\n",
      "epoch:  11100 train_loss: 1.3006243705749512 val_loss: 1.6976680755615234\n",
      "epoch:  11200 train_loss: 1.5108717679977417 val_loss: 2.0500714778900146\n",
      "epoch:  11300 train_loss: 1.376440167427063 val_loss: 1.7320107221603394\n",
      "epoch:  11400 train_loss: 1.2887667417526245 val_loss: 1.6700321435928345\n",
      "epoch:  11500 train_loss: 1.2452353239059448 val_loss: 1.6505037546157837\n",
      "epoch:  11600 train_loss: 1.2592371702194214 val_loss: 1.6503926515579224\n",
      "epoch:  11700 train_loss: 1.227830171585083 val_loss: 1.6293909549713135\n",
      "epoch:  11800 train_loss: 1.300304651260376 val_loss: 1.7263319492340088\n",
      "epoch:  11900 train_loss: 1.319371223449707 val_loss: 1.7034265995025635\n",
      "epoch:  12000 train_loss: 1.2419219017028809 val_loss: 1.658814787864685\n",
      "epoch:  12100 train_loss: 1.2155637741088867 val_loss: 1.6229394674301147\n",
      "epoch:  12200 train_loss: 1.2260944843292236 val_loss: 1.639082670211792\n",
      "epoch:  12300 train_loss: 1.1976293325424194 val_loss: 1.6213569641113281\n",
      "epoch:  12400 train_loss: 1.88131844997406 val_loss: 2.2936296463012695\n",
      "epoch:  12500 train_loss: 1.1914640665054321 val_loss: 1.6285940408706665\n",
      "epoch:  12600 train_loss: 1.1674338579177856 val_loss: 1.6004831790924072\n",
      "epoch:  12700 train_loss: 1.2733756303787231 val_loss: 1.6915463209152222\n",
      "epoch:  12800 train_loss: 1.1763933897018433 val_loss: 1.5888129472732544\n",
      "epoch:  12900 train_loss: 1.1741143465042114 val_loss: 1.610801100730896\n",
      "epoch:  13000 train_loss: 1.1806498765945435 val_loss: 1.6131857633590698\n",
      "epoch:  13100 train_loss: 1.1679397821426392 val_loss: 1.6102274656295776\n",
      "epoch:  13200 train_loss: 1.1452586650848389 val_loss: 1.5956603288650513\n",
      "epoch:  13300 train_loss: 1.1769137382507324 val_loss: 1.6247406005859375\n",
      "epoch:  13400 train_loss: 1.152376651763916 val_loss: 1.591658353805542\n",
      "epoch:  13500 train_loss: 1.1321922540664673 val_loss: 1.5757237672805786\n",
      "epoch:  13600 train_loss: 1.125662922859192 val_loss: 1.5792368650436401\n",
      "epoch:  13700 train_loss: 1.1255704164505005 val_loss: 1.5798050165176392\n",
      "epoch:  13800 train_loss: 1.1129181385040283 val_loss: 1.5833227634429932\n",
      "epoch:  13900 train_loss: 1.1077567338943481 val_loss: 1.5677227973937988\n",
      "epoch:  14000 train_loss: 1.1662017107009888 val_loss: 1.6368414163589478\n",
      "epoch:  14100 train_loss: 1.1153082847595215 val_loss: 1.5866495370864868\n",
      "epoch:  14200 train_loss: 1.1237561702728271 val_loss: 1.5771336555480957\n",
      "epoch:  14300 train_loss: 1.1698734760284424 val_loss: 1.598850965499878\n",
      "epoch:  14400 train_loss: 1.1699073314666748 val_loss: 1.673872470855713\n",
      "epoch:  14500 train_loss: 1.1291310787200928 val_loss: 1.5726262331008911\n",
      "epoch:  14600 train_loss: 1.0828818082809448 val_loss: 1.5543361902236938\n",
      "epoch:  14700 train_loss: 1.2287133932113647 val_loss: 1.6313246488571167\n",
      "epoch:  14800 train_loss: 1.224339246749878 val_loss: 1.6366499662399292\n",
      "epoch:  14900 train_loss: 1.0818182229995728 val_loss: 1.5574442148208618\n",
      "epoch:  15000 train_loss: 1.132899522781372 val_loss: 1.6627707481384277\n",
      "epoch:  15100 train_loss: 1.1813781261444092 val_loss: 1.674692988395691\n",
      "epoch:  15200 train_loss: 1.1066076755523682 val_loss: 1.6039493083953857\n",
      "epoch:  15300 train_loss: 1.4880876541137695 val_loss: 1.714168906211853\n",
      "epoch:  15400 train_loss: 1.3157575130462646 val_loss: 1.8637409210205078\n",
      "epoch:  15500 train_loss: 1.0875983238220215 val_loss: 1.5806752443313599\n",
      "epoch:  15600 train_loss: 1.0619851350784302 val_loss: 1.5589193105697632\n",
      "epoch:  15700 train_loss: 1.1790425777435303 val_loss: 1.6573926210403442\n",
      "epoch:  15800 train_loss: 1.5499886274337769 val_loss: 1.9620497226715088\n",
      "epoch:  15900 train_loss: 1.0413109064102173 val_loss: 1.5482070446014404\n",
      "epoch:  16000 train_loss: 1.083562970161438 val_loss: 1.5838956832885742\n",
      "epoch:  16100 train_loss: 1.0673186779022217 val_loss: 1.5624597072601318\n",
      "epoch:  16200 train_loss: 1.4736543893814087 val_loss: 1.7205017805099487\n",
      "epoch:  16300 train_loss: 1.0263593196868896 val_loss: 1.5393198728561401\n",
      "epoch:  16400 train_loss: 1.0366055965423584 val_loss: 1.5346604585647583\n",
      "epoch:  16500 train_loss: 1.2799999713897705 val_loss: 1.8422930240631104\n",
      "epoch:  16600 train_loss: 1.0086328983306885 val_loss: 1.548161268234253\n",
      "epoch:  16700 train_loss: 1.0122894048690796 val_loss: 1.534195899963379\n",
      "epoch:  16800 train_loss: 1.008251428604126 val_loss: 1.523402214050293\n",
      "epoch:  16900 train_loss: 1.0210986137390137 val_loss: 1.581099271774292\n",
      "epoch:  17000 train_loss: 0.9934807419776917 val_loss: 1.5264482498168945\n",
      "epoch:  17100 train_loss: 0.9890632033348083 val_loss: 1.5199474096298218\n",
      "epoch:  17200 train_loss: 1.0097185373306274 val_loss: 1.556510329246521\n",
      "epoch:  17300 train_loss: 1.036210536956787 val_loss: 1.5703622102737427\n",
      "epoch:  17400 train_loss: 0.9772850275039673 val_loss: 1.5254825353622437\n",
      "epoch:  17500 train_loss: 1.0168774127960205 val_loss: 1.536365270614624\n",
      "epoch:  17600 train_loss: 1.0080885887145996 val_loss: 1.5600179433822632\n",
      "epoch:  17700 train_loss: 0.9690463542938232 val_loss: 1.5167644023895264\n",
      "epoch:  17800 train_loss: 0.9623158574104309 val_loss: 1.5109554529190063\n",
      "epoch:  17900 train_loss: 0.9565834999084473 val_loss: 1.516020655632019\n",
      "epoch:  18000 train_loss: 0.9743691682815552 val_loss: 1.5438002347946167\n",
      "epoch:  18100 train_loss: 1.2105786800384521 val_loss: 1.7389529943466187\n",
      "epoch:  18200 train_loss: 0.9859611392021179 val_loss: 1.5545649528503418\n",
      "epoch:  18300 train_loss: 0.9627828001976013 val_loss: 1.535488486289978\n",
      "epoch:  18400 train_loss: 0.953606903553009 val_loss: 1.5100308656692505\n",
      "epoch:  18500 train_loss: 1.2997641563415527 val_loss: 1.9040956497192383\n",
      "epoch:  18600 train_loss: 0.9446719288825989 val_loss: 1.522756814956665\n",
      "epoch:  18700 train_loss: 0.9386290907859802 val_loss: 1.499642252922058\n",
      "epoch:  18800 train_loss: 0.9451189637184143 val_loss: 1.5216953754425049\n",
      "epoch:  18900 train_loss: 0.9223245978355408 val_loss: 1.5013092756271362\n",
      "epoch:  19000 train_loss: 0.9341256022453308 val_loss: 1.5137988328933716\n",
      "epoch:  19100 train_loss: 0.9249274730682373 val_loss: 1.5057460069656372\n",
      "epoch:  19200 train_loss: 0.9122825860977173 val_loss: 1.497923493385315\n",
      "epoch:  19300 train_loss: 0.9276432394981384 val_loss: 1.5386322736740112\n",
      "epoch:  19400 train_loss: 0.9044415354728699 val_loss: 1.5172425508499146\n",
      "epoch:  19500 train_loss: 1.0524475574493408 val_loss: 1.605642318725586\n",
      "epoch:  19600 train_loss: 0.9038978815078735 val_loss: 1.500060796737671\n",
      "epoch:  19700 train_loss: 0.9417399168014526 val_loss: 1.5605086088180542\n",
      "epoch:  19800 train_loss: 0.8812469840049744 val_loss: 1.5242786407470703\n",
      "epoch:  19900 train_loss: 0.9122365117073059 val_loss: 1.5665204524993896\n",
      "epoch:  20000 train_loss: 0.8823767304420471 val_loss: 1.5184568166732788\n",
      "epoch:  20100 train_loss: 0.8770407438278198 val_loss: 1.5405194759368896\n",
      "epoch:  20200 train_loss: 0.9755403995513916 val_loss: 1.649104356765747\n",
      "epoch:  20300 train_loss: 0.8683227896690369 val_loss: 1.5272883176803589\n",
      "epoch:  20400 train_loss: 0.8806390166282654 val_loss: 1.5516992807388306\n",
      "epoch:  20500 train_loss: 0.8597874641418457 val_loss: 1.5477104187011719\n",
      "epoch:  20600 train_loss: 0.8624796867370605 val_loss: 1.5133720636367798\n",
      "epoch:  20700 train_loss: 0.8581290245056152 val_loss: 1.5429788827896118\n",
      "epoch:  20800 train_loss: 0.8543103933334351 val_loss: 1.5472122430801392\n",
      "epoch:  20900 train_loss: 0.989714503288269 val_loss: 1.6223169565200806\n",
      "epoch:  21000 train_loss: 0.8250554800033569 val_loss: 1.5215952396392822\n",
      "epoch:  21100 train_loss: 0.8318666815757751 val_loss: 1.5451983213424683\n",
      "epoch:  21200 train_loss: 0.97883141040802 val_loss: 1.6637822389602661\n",
      "epoch:  21300 train_loss: 0.849175214767456 val_loss: 1.5328545570373535\n",
      "epoch:  21400 train_loss: 0.8325064778327942 val_loss: 1.5625977516174316\n",
      "epoch:  21500 train_loss: 0.8055822849273682 val_loss: 1.5377575159072876\n",
      "epoch:  21600 train_loss: 0.8076923489570618 val_loss: 1.5318554639816284\n",
      "epoch:  21700 train_loss: 0.8190112113952637 val_loss: 1.5295370817184448\n",
      "epoch:  21800 train_loss: 0.8096323013305664 val_loss: 1.557061791419983\n",
      "epoch:  21900 train_loss: 0.7869532704353333 val_loss: 1.5285712480545044\n",
      "epoch:  22000 train_loss: 0.8044751882553101 val_loss: 1.5635483264923096\n",
      "epoch:  22100 train_loss: 0.7807195782661438 val_loss: 1.544632077217102\n",
      "epoch:  22200 train_loss: 0.7718271613121033 val_loss: 1.5344570875167847\n",
      "epoch:  22300 train_loss: 0.7817579507827759 val_loss: 1.5365980863571167\n",
      "epoch:  22400 train_loss: 0.7967376112937927 val_loss: 1.5776641368865967\n",
      "epoch:  22500 train_loss: 0.7604807615280151 val_loss: 1.5424941778182983\n",
      "epoch:  22600 train_loss: 0.7521344423294067 val_loss: 1.54302978515625\n",
      "epoch:  22700 train_loss: 0.7449325919151306 val_loss: 1.5333813428878784\n",
      "epoch:  22800 train_loss: 0.7602962255477905 val_loss: 1.556460976600647\n",
      "epoch:  22900 train_loss: 0.7634639739990234 val_loss: 1.537279725074768\n",
      "epoch:  23000 train_loss: 0.7477156519889832 val_loss: 1.5809440612792969\n",
      "epoch:  23100 train_loss: 0.7291675209999084 val_loss: 1.5476964712142944\n",
      "epoch:  23200 train_loss: 0.7494933009147644 val_loss: 1.5807563066482544\n",
      "epoch:  23300 train_loss: 0.7527973055839539 val_loss: 1.5954368114471436\n",
      "epoch:  23400 train_loss: 0.7078495621681213 val_loss: 1.5633292198181152\n",
      "epoch:  23500 train_loss: 0.7219929099082947 val_loss: 1.5957223176956177\n",
      "epoch:  23600 train_loss: 0.7907769680023193 val_loss: 1.6201175451278687\n",
      "epoch:  23700 train_loss: 0.6967175602912903 val_loss: 1.5665756464004517\n",
      "epoch:  23800 train_loss: 0.724946141242981 val_loss: 1.6095781326293945\n",
      "epoch:  23900 train_loss: 0.6902395486831665 val_loss: 1.5810378789901733\n",
      "epoch:  24000 train_loss: 0.6820752620697021 val_loss: 1.5895607471466064\n",
      "epoch:  24100 train_loss: 0.6785135865211487 val_loss: 1.6207774877548218\n",
      "epoch:  24200 train_loss: 0.7092819809913635 val_loss: 1.6265816688537598\n",
      "epoch:  24300 train_loss: 0.6826319694519043 val_loss: 1.6076343059539795\n",
      "epoch:  24400 train_loss: 0.6858188509941101 val_loss: 1.6384297609329224\n",
      "epoch:  24500 train_loss: 0.6581637859344482 val_loss: 1.6397206783294678\n",
      "epoch:  24600 train_loss: 0.6561796069145203 val_loss: 1.6237833499908447\n",
      "epoch:  24700 train_loss: 0.671349287033081 val_loss: 1.654404640197754\n",
      "epoch:  24800 train_loss: 0.6621187329292297 val_loss: 1.6700154542922974\n",
      "epoch:  24900 train_loss: 0.6491951942443848 val_loss: 1.663097858428955\n",
      "epoch:  25000 train_loss: 0.68320232629776 val_loss: 1.7000739574432373\n",
      "epoch:  25100 train_loss: 0.6368086934089661 val_loss: 1.6782509088516235\n",
      "epoch:  25200 train_loss: 0.6594021320343018 val_loss: 1.7098034620285034\n",
      "epoch:  25300 train_loss: 0.6516023874282837 val_loss: 1.7284824848175049\n",
      "epoch:  25400 train_loss: 0.6943230032920837 val_loss: 1.71843683719635\n",
      "epoch:  25500 train_loss: 0.6098376512527466 val_loss: 1.7241235971450806\n",
      "epoch:  25600 train_loss: 0.6484628915786743 val_loss: 1.725996732711792\n",
      "epoch:  25700 train_loss: 0.5947922468185425 val_loss: 1.676279902458191\n",
      "epoch:  25800 train_loss: 0.5919015407562256 val_loss: 1.697670340538025\n",
      "epoch:  25900 train_loss: 0.596405565738678 val_loss: 1.7281537055969238\n",
      "epoch:  26000 train_loss: 0.5676054358482361 val_loss: 1.709783673286438\n",
      "epoch:  26100 train_loss: 0.5849036574363708 val_loss: 1.7425806522369385\n",
      "epoch:  26200 train_loss: 0.5663144588470459 val_loss: 1.7482836246490479\n",
      "epoch:  26300 train_loss: 0.6547368168830872 val_loss: 1.7961829900741577\n",
      "epoch:  26400 train_loss: 0.5484903454780579 val_loss: 1.7242225408554077\n",
      "epoch:  26500 train_loss: 0.5491586923599243 val_loss: 1.737074851989746\n",
      "epoch:  26600 train_loss: 0.6595458984375 val_loss: 1.7754719257354736\n",
      "epoch:  26700 train_loss: 0.5384575128555298 val_loss: 1.752977967262268\n",
      "epoch:  26800 train_loss: 0.5290308594703674 val_loss: 1.773764967918396\n",
      "epoch:  26900 train_loss: 0.5355587005615234 val_loss: 1.7718685865402222\n",
      "epoch:  27000 train_loss: 0.522812008857727 val_loss: 1.7747740745544434\n",
      "epoch:  27100 train_loss: 0.8107894062995911 val_loss: 1.913779377937317\n",
      "epoch:  27200 train_loss: 0.5309050679206848 val_loss: 1.7702423334121704\n",
      "epoch:  27300 train_loss: 0.5652811527252197 val_loss: 1.8326940536499023\n",
      "epoch:  27400 train_loss: 0.5313626527786255 val_loss: 1.8305476903915405\n",
      "epoch:  27500 train_loss: 0.5460660457611084 val_loss: 1.8511360883712769\n",
      "epoch:  27600 train_loss: 0.5377116203308105 val_loss: 1.8724135160446167\n",
      "epoch:  27700 train_loss: 0.5073568820953369 val_loss: 1.8429205417633057\n",
      "epoch:  27800 train_loss: 0.4992355704307556 val_loss: 1.8294764757156372\n",
      "epoch:  27900 train_loss: 0.4740407168865204 val_loss: 1.8404028415679932\n",
      "epoch:  28000 train_loss: 0.49888232350349426 val_loss: 1.9002143144607544\n",
      "epoch:  28100 train_loss: 0.46303755044937134 val_loss: 1.864747166633606\n",
      "epoch:  28200 train_loss: 0.46035829186439514 val_loss: 1.8650028705596924\n",
      "epoch:  28300 train_loss: 0.4701680839061737 val_loss: 1.8678356409072876\n",
      "epoch:  28400 train_loss: 0.4511863887310028 val_loss: 1.8681195974349976\n",
      "epoch:  28500 train_loss: 0.44523555040359497 val_loss: 1.892672061920166\n",
      "epoch:  28600 train_loss: 0.45806071162223816 val_loss: 1.9244849681854248\n",
      "epoch:  28700 train_loss: 0.42658957839012146 val_loss: 1.9086122512817383\n",
      "epoch:  28800 train_loss: 0.6406125426292419 val_loss: 2.1291587352752686\n",
      "epoch:  28900 train_loss: 0.436084121465683 val_loss: 1.9281392097473145\n",
      "epoch:  29000 train_loss: 0.42302605509757996 val_loss: 1.9466956853866577\n",
      "epoch:  29100 train_loss: 0.41343066096305847 val_loss: 1.9572875499725342\n",
      "epoch:  29200 train_loss: 0.4247214198112488 val_loss: 1.954155683517456\n",
      "epoch:  29300 train_loss: 0.40638086199760437 val_loss: 1.9833292961120605\n",
      "epoch:  29400 train_loss: 0.3986438810825348 val_loss: 1.962337613105774\n",
      "epoch:  29500 train_loss: 0.39903372526168823 val_loss: 1.9789254665374756\n",
      "epoch:  29600 train_loss: 0.4103836715221405 val_loss: 1.9614639282226562\n",
      "epoch:  29700 train_loss: 0.41188308596611023 val_loss: 2.0353965759277344\n",
      "epoch:  29800 train_loss: 0.38981595635414124 val_loss: 2.008394241333008\n",
      "epoch:  29900 train_loss: 0.36759212613105774 val_loss: 2.0108799934387207\n",
      "epoch:  30000 train_loss: 0.3655335307121277 val_loss: 2.0275447368621826\n",
      "epoch:  30100 train_loss: 0.359063059091568 val_loss: 2.0275299549102783\n",
      "epoch:  30200 train_loss: 0.37451303005218506 val_loss: 2.044111728668213\n",
      "epoch:  30300 train_loss: 0.4088020324707031 val_loss: 2.094212055206299\n",
      "epoch:  30400 train_loss: 0.34299564361572266 val_loss: 2.050281524658203\n",
      "epoch:  30500 train_loss: 0.3415936231613159 val_loss: 2.0549702644348145\n",
      "epoch:  30600 train_loss: 0.4652416408061981 val_loss: 2.1916744709014893\n",
      "epoch:  30700 train_loss: 0.3625399172306061 val_loss: 2.0837490558624268\n",
      "epoch:  30800 train_loss: 0.3361205458641052 val_loss: 2.105926513671875\n",
      "epoch:  30900 train_loss: 0.37569281458854675 val_loss: 2.1468377113342285\n",
      "epoch:  31000 train_loss: 0.3225935995578766 val_loss: 2.125361919403076\n",
      "epoch:  31100 train_loss: 0.3176287114620209 val_loss: 2.097719430923462\n",
      "epoch:  31200 train_loss: 0.3125298321247101 val_loss: 2.1257221698760986\n",
      "epoch:  31300 train_loss: 0.33184272050857544 val_loss: 2.1774842739105225\n",
      "epoch:  31400 train_loss: 0.3067342936992645 val_loss: 2.141295909881592\n",
      "epoch:  31500 train_loss: 0.3226161003112793 val_loss: 2.1910457611083984\n",
      "epoch:  31600 train_loss: 0.30948540568351746 val_loss: 2.1568970680236816\n",
      "epoch:  31700 train_loss: 0.3044198751449585 val_loss: 2.171262502670288\n",
      "epoch:  31800 train_loss: 0.2918669581413269 val_loss: 2.1755430698394775\n",
      "epoch:  31900 train_loss: 0.3501851558685303 val_loss: 2.210637331008911\n",
      "epoch:  32000 train_loss: 0.29810798168182373 val_loss: 2.231260299682617\n",
      "epoch:  32100 train_loss: 0.2824016213417053 val_loss: 2.1905362606048584\n",
      "epoch:  32200 train_loss: 0.2716878652572632 val_loss: 2.2147133350372314\n",
      "epoch:  32300 train_loss: 0.27544328570365906 val_loss: 2.2189676761627197\n",
      "epoch:  32400 train_loss: 0.2967536151409149 val_loss: 2.2668538093566895\n",
      "epoch:  32500 train_loss: 0.2724480926990509 val_loss: 2.248520612716675\n",
      "epoch:  32600 train_loss: 0.29322823882102966 val_loss: 2.2657742500305176\n",
      "epoch:  32700 train_loss: 0.2580145001411438 val_loss: 2.265575647354126\n",
      "epoch:  32800 train_loss: 0.25339949131011963 val_loss: 2.2414112091064453\n",
      "epoch:  32900 train_loss: 0.29470115900039673 val_loss: 2.2626700401306152\n",
      "epoch:  33000 train_loss: 0.2563382685184479 val_loss: 2.3019402027130127\n",
      "epoch:  33100 train_loss: 0.24240417778491974 val_loss: 2.3039069175720215\n",
      "epoch:  33200 train_loss: 0.24823829531669617 val_loss: 2.269181728363037\n",
      "epoch:  33300 train_loss: 0.2300676554441452 val_loss: 2.309480667114258\n",
      "epoch:  33400 train_loss: 0.2335493415594101 val_loss: 2.3385226726531982\n",
      "epoch:  33500 train_loss: 0.23202939331531525 val_loss: 2.3141727447509766\n",
      "epoch:  33600 train_loss: 0.225322887301445 val_loss: 2.322803258895874\n",
      "epoch:  33700 train_loss: 0.3978888988494873 val_loss: 2.3866472244262695\n",
      "epoch:  33800 train_loss: 0.21585792303085327 val_loss: 2.331005811691284\n",
      "epoch:  33900 train_loss: 0.24124230444431305 val_loss: 2.384160041809082\n",
      "epoch:  34000 train_loss: 0.23389722406864166 val_loss: 2.3702471256256104\n",
      "epoch:  34100 train_loss: 0.21112293004989624 val_loss: 2.3628244400024414\n",
      "epoch:  34200 train_loss: 0.2154538333415985 val_loss: 2.389685869216919\n",
      "epoch:  34300 train_loss: 0.2042657881975174 val_loss: 2.392157793045044\n",
      "epoch:  34400 train_loss: 0.20753327012062073 val_loss: 2.4046883583068848\n",
      "epoch:  34500 train_loss: 0.29591289162635803 val_loss: 2.4473395347595215\n",
      "epoch:  34600 train_loss: 0.2042442262172699 val_loss: 2.4217381477355957\n",
      "epoch:  34700 train_loss: 0.2015209197998047 val_loss: 2.420103073120117\n",
      "epoch:  34800 train_loss: 0.19230462610721588 val_loss: 2.4522340297698975\n",
      "epoch:  34900 train_loss: 0.18965569138526917 val_loss: 2.4717161655426025\n",
      "epoch:  35000 train_loss: 0.20206353068351746 val_loss: 2.455495834350586\n",
      "epoch:  35100 train_loss: 0.1981848180294037 val_loss: 2.5255751609802246\n",
      "epoch:  35200 train_loss: 0.18645019829273224 val_loss: 2.4592795372009277\n",
      "epoch:  35300 train_loss: 0.18115468323230743 val_loss: 2.5053083896636963\n",
      "epoch:  35400 train_loss: 0.18787938356399536 val_loss: 2.5076725482940674\n",
      "epoch:  35500 train_loss: 0.26173320412635803 val_loss: 2.485605239868164\n",
      "epoch:  35600 train_loss: 0.17483024299144745 val_loss: 2.5418319702148438\n",
      "epoch:  35700 train_loss: 0.17676293849945068 val_loss: 2.5093278884887695\n",
      "epoch:  35800 train_loss: 0.1687738597393036 val_loss: 2.534992218017578\n",
      "epoch:  35900 train_loss: 0.2129868119955063 val_loss: 2.5268852710723877\n",
      "sigma: 1.9 RMSE:  tensor(2.0544, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Generate the dataset with noise N(0, sigma)\n",
    "i = 0\n",
    "sigma = 1.9\n",
    "my_dataset = []\n",
    "for ud in UDs:\n",
    "    example = []\n",
    "    for an in ANs:\n",
    "        noise = np.random.normal(0,sigma)\n",
    "        # 0 is mean\n",
    "        # sigma is the deviation of the normal distribution\n",
    "        d = compute_3d_distance(ud, an) + noise\n",
    "        example.append(d)\n",
    "    \n",
    "    # append x, y, z as col#10, #11, #12\n",
    "    example.append(ud[0])\n",
    "    example.append(ud[1])\n",
    "    example.append(ud[2])\n",
    "    \n",
    "    # append 1x13 example row into my_dataset\n",
    "    my_dataset.append(example)  # expected to be 3000x13  \n",
    "    \n",
    "# Load dataset\n",
    "exercise5_dataset = Exercise5Dataset(list_dataset = my_dataset, shuffle=True)\n",
    "\n",
    "#Split dataset by 0.8: 0.1: 0.1\n",
    "train_examples, train_labels = exercise5_dataset[:int(3000*0.8)]  # (2400, 10)   # (2400, 3)\n",
    "val_examples, val_labels = exercise5_dataset[int(3000*0.8):int(3000*0.9)]    # (300, 10)   #(300, 3)\n",
    "test_examples, test_labels = exercise5_dataset[int(3000*0.9):]     #(300, 10)   # (300, 3)\n",
    "\n",
    "###Define model, loss function and optimizer\n",
    "# if we have GPU, then use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define model\n",
    "#model = Net(x_dim = train_examples.shape[1], y_dim = train_labels.shape[1]).to(device)\n",
    "input_dim = 1     #input dim is 1, seq_len = 10\n",
    "hidden_dim = 64   #hidden state dim is 64\n",
    "n_layers = 3             #3-layered LSTM\n",
    "model = MYLSTM(input_dim, hidden_dim, n_layers).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Correct the input/output shape for LSTM\n",
    "train_inputs = torch.unsqueeze(train_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "train_inputs = train_inputs.to(device) \n",
    "\n",
    "val_inputs = torch.unsqueeze(val_examples, dim=-1)   # (N, 10) -> (N, 10, 1)\n",
    "val_inputs = val_inputs.to(device) \n",
    "\n",
    "train_labels = train_labels.to(device)   #(N, 3)\n",
    "val_labels = val_labels.to(device)          #(N, 3)\n",
    "\n",
    "\n",
    "# Define the loss threshold, if the current train loss is lower than the threshold, we will begin to save the model\n",
    "best_loss = 100.0\n",
    "\n",
    "# Define the model filename for model.save()\n",
    "MODEL_FILENAME = \"best.pth\"\n",
    "\n",
    "# set model to Training mode\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "NUM_OF_EPOCH = 36000\n",
    "\n",
    "# Train\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    y_pred = model(train_inputs)\n",
    "    loss = loss_fn(y_pred, train_labels).cpu()\n",
    "    #print(t, loss.item())\n",
    "    train_losses.append(loss.item())\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    # BGD\n",
    "    optimizer.step()\n",
    "    \n",
    "    # evaluate validation loss\n",
    "    val_pred = model(val_inputs)\n",
    "    loss = loss_fn(val_pred, val_labels)\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "\n",
    "\n",
    "    if (epoch % 100) == 0:\n",
    "        print(\"epoch: \", epoch, \"train_loss:\", train_losses[-1], \"val_loss:\", val_losses[-1])\n",
    "        # check if we got better loss\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n",
    "        \n",
    "# Load the best model on previous step\n",
    "model.load_state_dict(torch.load(\"best.pth\"))\n",
    "\n",
    "# Inference all testing examples and compute RMSE\n",
    "def square_error(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  square_error= loss_fn(a, b)\n",
    "  return square_error\n",
    "\n",
    "model.eval() # inference mode\n",
    "test_inputs = torch.unsqueeze(test_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "test_inputs = test_inputs.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "\n",
    "test_preds = model(test_inputs)\n",
    "#print(\"example: \", test_example.cpu())\n",
    "#print(\"========================================\")\n",
    "#print(\"ground_truth:\", test_label.cpu())\n",
    "#print(\"prediction:\", test_pred.cpu())\n",
    "#print(\"========================================\")\n",
    "\n",
    "\n",
    "total_errors = 0.0\n",
    "for idx in range(len(test_inputs)):\n",
    "    total_errors += square_error(test_preds[idx], test_labels[idx])\n",
    "    \n",
    "RMSE = torch.sqrt(total_errors / len(test_inputs))\n",
    "print(\"sigma:\", sigma, \"RMSE: \",  RMSE)\n",
    "\n",
    "sigmas.append(sigma)\n",
    "RMSEs.append(RMSE.cpu().detach().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigma = 2.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffle = True!\n",
      "epoch:  0 train_loss: 7318.8310546875 val_loss: 7423.31982421875\n",
      "epoch:  100 train_loss: 5998.41455078125 val_loss: 6087.52587890625\n",
      "epoch:  200 train_loss: 5108.8525390625 val_loss: 5194.3125\n",
      "epoch:  300 train_loss: 4366.9404296875 val_loss: 4447.64111328125\n",
      "epoch:  400 train_loss: 3707.647216796875 val_loss: 3784.12451171875\n",
      "epoch:  500 train_loss: 3151.73779296875 val_loss: 3223.748779296875\n",
      "epoch:  600 train_loss: 2674.996826171875 val_loss: 2742.5009765625\n",
      "epoch:  700 train_loss: 2243.298095703125 val_loss: 2305.486083984375\n",
      "epoch:  800 train_loss: 1879.8555908203125 val_loss: 1937.37646484375\n",
      "epoch:  900 train_loss: 1572.6953125 val_loss: 1625.40283203125\n",
      "epoch:  1000 train_loss: 1312.2440185546875 val_loss: 1360.2550048828125\n",
      "epoch:  1100 train_loss: 1092.172119140625 val_loss: 1135.5645751953125\n",
      "epoch:  1200 train_loss: 907.1878662109375 val_loss: 946.393798828125\n",
      "epoch:  1300 train_loss: 753.3662719726562 val_loss: 788.2512817382812\n",
      "epoch:  1400 train_loss: 626.2091674804688 val_loss: 657.3273315429688\n",
      "epoch:  1500 train_loss: 522.6104125976562 val_loss: 550.1114501953125\n",
      "epoch:  1600 train_loss: 438.9588317871094 val_loss: 463.1780090332031\n",
      "epoch:  1700 train_loss: 372.53057861328125 val_loss: 393.57611083984375\n",
      "epoch:  1800 train_loss: 320.32318115234375 val_loss: 338.49951171875\n",
      "epoch:  1900 train_loss: 280.0230407714844 val_loss: 295.6859130859375\n",
      "epoch:  2000 train_loss: 249.3685302734375 val_loss: 262.7597351074219\n",
      "epoch:  2100 train_loss: 226.55841064453125 val_loss: 237.79103088378906\n",
      "epoch:  2200 train_loss: 209.81515502929688 val_loss: 219.2566375732422\n",
      "epoch:  2300 train_loss: 197.80032348632812 val_loss: 205.69712829589844\n",
      "epoch:  2400 train_loss: 189.37709045410156 val_loss: 195.85035705566406\n",
      "epoch:  2500 train_loss: 183.5782012939453 val_loss: 188.8776397705078\n",
      "epoch:  2600 train_loss: 179.71080017089844 val_loss: 184.0180206298828\n",
      "epoch:  2700 train_loss: 177.15724182128906 val_loss: 180.6727294921875\n",
      "epoch:  2800 train_loss: 175.5597381591797 val_loss: 178.39044189453125\n",
      "epoch:  2900 train_loss: 174.55990600585938 val_loss: 176.85491943359375\n",
      "epoch:  3000 train_loss: 173.96331787109375 val_loss: 175.83607482910156\n",
      "epoch:  3100 train_loss: 173.6124725341797 val_loss: 175.14230346679688\n",
      "epoch:  3200 train_loss: 173.41958618164062 val_loss: 174.69021606445312\n",
      "epoch:  3300 train_loss: 173.3106231689453 val_loss: 174.37940979003906\n",
      "epoch:  3400 train_loss: 173.25599670410156 val_loss: 174.1795654296875\n",
      "epoch:  3500 train_loss: 173.22955322265625 val_loss: 174.04847717285156\n",
      "epoch:  3600 train_loss: 173.21603393554688 val_loss: 173.9590301513672\n",
      "epoch:  3700 train_loss: 173.2091827392578 val_loss: 173.8965606689453\n",
      "epoch:  3800 train_loss: 173.2064666748047 val_loss: 173.85816955566406\n",
      "epoch:  3900 train_loss: 173.2052764892578 val_loss: 173.83258056640625\n",
      "epoch:  4000 train_loss: 173.20477294921875 val_loss: 173.81610107421875\n",
      "epoch:  4100 train_loss: 173.20465087890625 val_loss: 173.80709838867188\n",
      "epoch:  4200 train_loss: 173.20462036132812 val_loss: 173.8009490966797\n",
      "epoch:  4300 train_loss: 173.20457458496094 val_loss: 173.79908752441406\n",
      "epoch:  4400 train_loss: 173.20455932617188 val_loss: 173.7959442138672\n",
      "epoch:  4500 train_loss: 173.20455932617188 val_loss: 173.7939910888672\n",
      "epoch:  4600 train_loss: 173.20455932617188 val_loss: 173.7931671142578\n",
      "epoch:  4700 train_loss: 173.20455932617188 val_loss: 173.79306030273438\n",
      "epoch:  4800 train_loss: 173.20455932617188 val_loss: 173.79306030273438\n",
      "epoch:  4900 train_loss: 173.20455932617188 val_loss: 173.79306030273438\n",
      "epoch:  5000 train_loss: 173.20455932617188 val_loss: 173.79306030273438\n",
      "epoch:  5100 train_loss: 173.20455932617188 val_loss: 173.7931671142578\n",
      "epoch:  5200 train_loss: 173.20455932617188 val_loss: 173.7931671142578\n",
      "epoch:  5300 train_loss: 173.20455932617188 val_loss: 173.79306030273438\n",
      "epoch:  5400 train_loss: 173.20455932617188 val_loss: 173.7931671142578\n",
      "epoch:  5500 train_loss: 173.20455932617188 val_loss: 173.79306030273438\n",
      "epoch:  5600 train_loss: 173.20455932617188 val_loss: 173.7931671142578\n",
      "epoch:  5700 train_loss: 173.20455932617188 val_loss: 173.7931671142578\n",
      "epoch:  5800 train_loss: 173.20455932617188 val_loss: 173.79306030273438\n",
      "epoch:  5900 train_loss: 173.20455932617188 val_loss: 173.7931671142578\n",
      "epoch:  6000 train_loss: 173.20455932617188 val_loss: 173.79306030273438\n",
      "epoch:  6100 train_loss: 173.20455932617188 val_loss: 173.79306030273438\n",
      "epoch:  6200 train_loss: 173.20455932617188 val_loss: 173.79306030273438\n",
      "epoch:  6300 train_loss: 173.20455932617188 val_loss: 173.7931671142578\n",
      "epoch:  6400 train_loss: 173.20455932617188 val_loss: 173.79306030273438\n",
      "epoch:  6500 train_loss: 173.20455932617188 val_loss: 173.79306030273438\n",
      "epoch:  6600 train_loss: 173.20455932617188 val_loss: 173.7931671142578\n",
      "epoch:  6700 train_loss: 173.20455932617188 val_loss: 173.79295349121094\n",
      "epoch:  6800 train_loss: 173.20455932617188 val_loss: 173.7931671142578\n",
      "epoch:  6900 train_loss: 173.20455932617188 val_loss: 173.79295349121094\n",
      "epoch:  7000 train_loss: 173.20455932617188 val_loss: 173.7931671142578\n",
      "epoch:  7100 train_loss: 173.20455932617188 val_loss: 173.7931671142578\n",
      "epoch:  7200 train_loss: 173.20455932617188 val_loss: 173.7931671142578\n",
      "epoch:  7300 train_loss: 173.20455932617188 val_loss: 173.79296875\n",
      "epoch:  7400 train_loss: 173.20455932617188 val_loss: 173.7931671142578\n",
      "epoch:  7500 train_loss: 166.5316925048828 val_loss: 168.4694366455078\n",
      "epoch:  7600 train_loss: 128.5873260498047 val_loss: 129.08599853515625\n",
      "epoch:  7700 train_loss: 102.46607208251953 val_loss: 102.87630462646484\n",
      "epoch:  7800 train_loss: 84.515625 val_loss: 85.29005432128906\n",
      "epoch:  7900 train_loss: 69.29270935058594 val_loss: 70.22509765625\n",
      "epoch:  8000 train_loss: 55.917686462402344 val_loss: 56.76805877685547\n",
      "epoch:  8100 train_loss: 44.288368225097656 val_loss: 44.941429138183594\n",
      "epoch:  8200 train_loss: 34.529911041259766 val_loss: 35.18510437011719\n",
      "epoch:  8300 train_loss: 26.6870059967041 val_loss: 27.29631233215332\n",
      "epoch:  8400 train_loss: 20.593856811523438 val_loss: 21.175872802734375\n",
      "epoch:  8500 train_loss: 15.97242259979248 val_loss: 16.466379165649414\n",
      "epoch:  8600 train_loss: 12.42185115814209 val_loss: 12.901169776916504\n",
      "epoch:  8700 train_loss: 9.733381271362305 val_loss: 10.187657356262207\n",
      "epoch:  8800 train_loss: 7.540732383728027 val_loss: 7.996598720550537\n",
      "epoch:  8900 train_loss: 5.7727766036987305 val_loss: 6.263891220092773\n",
      "epoch:  9000 train_loss: 4.838085651397705 val_loss: 5.358298301696777\n",
      "epoch:  9100 train_loss: 4.137020111083984 val_loss: 4.744338035583496\n",
      "epoch:  9200 train_loss: 3.6135153770446777 val_loss: 4.3085551261901855\n",
      "epoch:  9300 train_loss: 3.2404019832611084 val_loss: 3.9676177501678467\n",
      "epoch:  9400 train_loss: 2.9365158081054688 val_loss: 3.75636625289917\n",
      "epoch:  9500 train_loss: 2.722744941711426 val_loss: 3.578787088394165\n",
      "epoch:  9600 train_loss: 2.5362184047698975 val_loss: 3.4588887691497803\n",
      "epoch:  9700 train_loss: 2.39579701423645 val_loss: 3.386378765106201\n",
      "epoch:  9800 train_loss: 2.2576558589935303 val_loss: 3.347954750061035\n",
      "epoch:  9900 train_loss: 2.1549277305603027 val_loss: 3.3011512756347656\n",
      "epoch:  10000 train_loss: 2.0837554931640625 val_loss: 3.3473031520843506\n",
      "epoch:  10100 train_loss: 1.9598605632781982 val_loss: 3.2931575775146484\n",
      "epoch:  10200 train_loss: 1.9216680526733398 val_loss: 3.347759246826172\n",
      "epoch:  10300 train_loss: 1.798323154449463 val_loss: 3.2715322971343994\n",
      "epoch:  10400 train_loss: 1.7324105501174927 val_loss: 3.2674808502197266\n",
      "epoch:  10500 train_loss: 1.662855625152588 val_loss: 3.340955972671509\n",
      "epoch:  10600 train_loss: 1.588004469871521 val_loss: 3.306715250015259\n",
      "epoch:  10700 train_loss: 1.54069185256958 val_loss: 3.3438498973846436\n",
      "epoch:  10800 train_loss: 1.4628483057022095 val_loss: 3.348677158355713\n",
      "epoch:  10900 train_loss: 1.403369426727295 val_loss: 3.3975071907043457\n",
      "epoch:  11000 train_loss: 1.3793598413467407 val_loss: 3.522031307220459\n",
      "epoch:  11100 train_loss: 1.297609567642212 val_loss: 3.483126163482666\n",
      "epoch:  11200 train_loss: 1.254184365272522 val_loss: 3.5246360301971436\n",
      "epoch:  11300 train_loss: 1.2273701429367065 val_loss: 3.573033571243286\n",
      "epoch:  11400 train_loss: 1.2143367528915405 val_loss: 3.625756025314331\n",
      "epoch:  11500 train_loss: 1.135434627532959 val_loss: 3.6929819583892822\n",
      "epoch:  11600 train_loss: 1.1144448518753052 val_loss: 3.646819829940796\n",
      "epoch:  11700 train_loss: 1.04753839969635 val_loss: 3.678032875061035\n",
      "epoch:  11800 train_loss: 1.0063344240188599 val_loss: 3.7456765174865723\n",
      "epoch:  11900 train_loss: 0.9815801978111267 val_loss: 3.757796287536621\n",
      "epoch:  12000 train_loss: 0.9452976584434509 val_loss: 3.8495147228240967\n",
      "epoch:  12100 train_loss: 0.9124548435211182 val_loss: 3.823474645614624\n",
      "epoch:  12200 train_loss: 0.8668481111526489 val_loss: 3.9128212928771973\n",
      "epoch:  12300 train_loss: 0.8409028053283691 val_loss: 4.000236511230469\n",
      "epoch:  12400 train_loss: 0.8147813081741333 val_loss: 4.036908149719238\n",
      "epoch:  12500 train_loss: 0.8247351050376892 val_loss: 4.118709087371826\n",
      "epoch:  12600 train_loss: 0.7591419816017151 val_loss: 4.119184494018555\n",
      "epoch:  12700 train_loss: 0.7337733507156372 val_loss: 4.075736999511719\n",
      "epoch:  12800 train_loss: 0.7325152158737183 val_loss: 4.206432342529297\n",
      "epoch:  12900 train_loss: 0.6738383769989014 val_loss: 4.20177698135376\n",
      "epoch:  13000 train_loss: 0.6486334204673767 val_loss: 4.240286350250244\n",
      "epoch:  13100 train_loss: 0.6334511637687683 val_loss: 4.2125163078308105\n",
      "epoch:  13200 train_loss: 0.6209825277328491 val_loss: 4.284118175506592\n",
      "epoch:  13300 train_loss: 0.5799568891525269 val_loss: 4.354893684387207\n",
      "epoch:  13400 train_loss: 0.5950784087181091 val_loss: 4.425251483917236\n",
      "epoch:  13500 train_loss: 0.5467488169670105 val_loss: 4.446288585662842\n",
      "epoch:  13600 train_loss: 0.523173987865448 val_loss: 4.461507320404053\n",
      "epoch:  13700 train_loss: 0.5163805484771729 val_loss: 4.5158843994140625\n",
      "epoch:  13800 train_loss: 0.49625930190086365 val_loss: 4.477035045623779\n",
      "epoch:  13900 train_loss: 0.46887609362602234 val_loss: 4.574222087860107\n",
      "epoch:  14000 train_loss: 0.48881158232688904 val_loss: 4.594130039215088\n",
      "epoch:  14100 train_loss: 0.4416535794734955 val_loss: 4.650811672210693\n",
      "epoch:  14200 train_loss: 0.4388478696346283 val_loss: 4.683828353881836\n",
      "epoch:  14300 train_loss: 0.4224316477775574 val_loss: 4.790414810180664\n",
      "epoch:  14400 train_loss: 0.40640631318092346 val_loss: 4.761541843414307\n",
      "epoch:  14500 train_loss: 0.3956475853919983 val_loss: 4.760397911071777\n",
      "epoch:  14600 train_loss: 0.36956116557121277 val_loss: 4.8163275718688965\n",
      "epoch:  14700 train_loss: 0.39230406284332275 val_loss: 4.947427272796631\n",
      "epoch:  14800 train_loss: 0.35107314586639404 val_loss: 4.927990436553955\n",
      "epoch:  14900 train_loss: 0.3294578194618225 val_loss: 4.900341510772705\n",
      "epoch:  15000 train_loss: 0.3154202699661255 val_loss: 4.9561052322387695\n",
      "epoch:  15100 train_loss: 0.32579800486564636 val_loss: 4.965691089630127\n",
      "epoch:  15200 train_loss: 0.2939581274986267 val_loss: 5.028654098510742\n",
      "epoch:  15300 train_loss: 0.28755322098731995 val_loss: 5.015056610107422\n",
      "epoch:  15400 train_loss: 0.27585944533348083 val_loss: 5.057269096374512\n",
      "epoch:  15500 train_loss: 0.26444146037101746 val_loss: 5.138132095336914\n",
      "epoch:  15600 train_loss: 0.26784059405326843 val_loss: 5.124093055725098\n",
      "epoch:  15700 train_loss: 0.25413158535957336 val_loss: 5.198264122009277\n",
      "epoch:  15800 train_loss: 0.30429816246032715 val_loss: 5.15302848815918\n",
      "epoch:  15900 train_loss: 0.2290303260087967 val_loss: 5.228896617889404\n",
      "epoch:  16000 train_loss: 0.2499821037054062 val_loss: 5.3307671546936035\n",
      "epoch:  16100 train_loss: 0.21659207344055176 val_loss: 5.296626567840576\n",
      "epoch:  16200 train_loss: 0.22975187003612518 val_loss: 5.371208667755127\n",
      "epoch:  16300 train_loss: 0.20275108516216278 val_loss: 5.409256935119629\n",
      "epoch:  16400 train_loss: 0.2634378671646118 val_loss: 5.450545310974121\n",
      "epoch:  16500 train_loss: 0.21693694591522217 val_loss: 5.337435245513916\n",
      "epoch:  16600 train_loss: 0.1856660395860672 val_loss: 5.498022079467773\n",
      "epoch:  16700 train_loss: 0.2492624670267105 val_loss: 5.541623592376709\n",
      "epoch:  16800 train_loss: 0.17239348590373993 val_loss: 5.463809490203857\n",
      "epoch:  16900 train_loss: 0.1812916398048401 val_loss: 5.492339611053467\n",
      "epoch:  17000 train_loss: 0.2219116985797882 val_loss: 5.5519843101501465\n",
      "epoch:  17100 train_loss: 0.1811789870262146 val_loss: 5.532721996307373\n",
      "epoch:  17200 train_loss: 0.16180559992790222 val_loss: 5.633751392364502\n",
      "epoch:  17300 train_loss: 0.14678636193275452 val_loss: 5.5694098472595215\n",
      "epoch:  17400 train_loss: 0.14578057825565338 val_loss: 5.64155387878418\n",
      "epoch:  17500 train_loss: 0.1459375023841858 val_loss: 5.6775946617126465\n",
      "epoch:  17600 train_loss: 0.1557716727256775 val_loss: 5.7269606590271\n",
      "epoch:  17700 train_loss: 0.14580966532230377 val_loss: 5.7573137283325195\n",
      "epoch:  17800 train_loss: 0.13439300656318665 val_loss: 5.725617408752441\n",
      "epoch:  17900 train_loss: 0.122353695333004 val_loss: 5.762193202972412\n",
      "epoch:  18000 train_loss: 0.12070545554161072 val_loss: 5.759133338928223\n",
      "epoch:  18100 train_loss: 0.12471029907464981 val_loss: 5.781583309173584\n",
      "epoch:  18200 train_loss: 0.10761186480522156 val_loss: 5.775089263916016\n",
      "epoch:  18300 train_loss: 0.15902064740657806 val_loss: 5.780898571014404\n",
      "epoch:  18400 train_loss: 0.10196264088153839 val_loss: 5.847236633300781\n",
      "epoch:  18500 train_loss: 0.11720356345176697 val_loss: 5.888776779174805\n",
      "epoch:  18600 train_loss: 0.17618252336978912 val_loss: 5.96544075012207\n",
      "epoch:  18700 train_loss: 0.10715484619140625 val_loss: 5.815708160400391\n",
      "epoch:  18800 train_loss: 0.09307613968849182 val_loss: 5.900461196899414\n",
      "epoch:  18900 train_loss: 0.09862557798624039 val_loss: 5.892298698425293\n",
      "epoch:  19000 train_loss: 0.1084764301776886 val_loss: 5.9199652671813965\n",
      "epoch:  19100 train_loss: 0.08988981693983078 val_loss: 5.937661647796631\n",
      "epoch:  19200 train_loss: 0.09115487337112427 val_loss: 5.980724334716797\n",
      "epoch:  19300 train_loss: 0.09356463700532913 val_loss: 5.941691875457764\n",
      "epoch:  19400 train_loss: 0.07993833720684052 val_loss: 5.970923900604248\n",
      "epoch:  19500 train_loss: 0.07702966034412384 val_loss: 5.974857807159424\n",
      "epoch:  19600 train_loss: 0.10459542274475098 val_loss: 5.996607780456543\n",
      "epoch:  19700 train_loss: 0.07552438974380493 val_loss: 6.0161285400390625\n",
      "epoch:  19800 train_loss: 0.07414978742599487 val_loss: 6.023908615112305\n",
      "epoch:  19900 train_loss: 0.09672797471284866 val_loss: 6.013696670532227\n",
      "epoch:  20000 train_loss: 0.07004265487194061 val_loss: 6.052787780761719\n",
      "epoch:  20100 train_loss: 0.06064538285136223 val_loss: 6.06484317779541\n",
      "epoch:  20200 train_loss: 0.07635999470949173 val_loss: 6.0889387130737305\n",
      "epoch:  20300 train_loss: 0.059573695063591 val_loss: 6.063600540161133\n",
      "epoch:  20400 train_loss: 0.05846661329269409 val_loss: 6.056959629058838\n",
      "epoch:  20500 train_loss: 0.05568314716219902 val_loss: 6.062008380889893\n",
      "epoch:  20600 train_loss: 0.06363548338413239 val_loss: 6.134973049163818\n",
      "epoch:  20700 train_loss: 0.07051841914653778 val_loss: 6.107407569885254\n",
      "epoch:  20800 train_loss: 0.05643784627318382 val_loss: 6.06607723236084\n",
      "epoch:  20900 train_loss: 0.05025899037718773 val_loss: 6.139889240264893\n",
      "epoch:  21000 train_loss: 0.054213717579841614 val_loss: 6.120797634124756\n",
      "epoch:  21100 train_loss: 0.06027498096227646 val_loss: 6.146373748779297\n",
      "epoch:  21200 train_loss: 0.05557597801089287 val_loss: 6.135385513305664\n",
      "epoch:  21300 train_loss: 0.05108679085969925 val_loss: 6.123320579528809\n",
      "epoch:  21400 train_loss: 0.057001955807209015 val_loss: 6.112401962280273\n",
      "epoch:  21500 train_loss: 0.04531390964984894 val_loss: 6.175950050354004\n",
      "epoch:  21600 train_loss: 0.058278996497392654 val_loss: 6.1353864669799805\n",
      "epoch:  21700 train_loss: 0.043234992772340775 val_loss: 6.131329536437988\n",
      "epoch:  21800 train_loss: 0.04314460605382919 val_loss: 6.1752238273620605\n",
      "epoch:  21900 train_loss: 0.06763079762458801 val_loss: 6.1401143074035645\n",
      "epoch:  22000 train_loss: 0.051405057311058044 val_loss: 6.179821968078613\n",
      "epoch:  22100 train_loss: 0.04560969024896622 val_loss: 6.189622402191162\n",
      "epoch:  22200 train_loss: 0.09415336698293686 val_loss: 6.268219947814941\n",
      "epoch:  22300 train_loss: 0.06032199412584305 val_loss: 6.183798313140869\n",
      "epoch:  22400 train_loss: 0.043020814657211304 val_loss: 6.210723876953125\n",
      "epoch:  22500 train_loss: 0.04210015386343002 val_loss: 6.183681011199951\n",
      "epoch:  22600 train_loss: 0.04403907060623169 val_loss: 6.163887977600098\n",
      "epoch:  22700 train_loss: 0.044108256697654724 val_loss: 6.159506320953369\n",
      "epoch:  22800 train_loss: 0.042604174464941025 val_loss: 6.213032245635986\n",
      "epoch:  22900 train_loss: 0.038842570036649704 val_loss: 6.253530502319336\n",
      "epoch:  23000 train_loss: 0.03475838899612427 val_loss: 6.172445774078369\n",
      "epoch:  23100 train_loss: 0.0480940155684948 val_loss: 6.130712985992432\n",
      "epoch:  23200 train_loss: 0.0324644111096859 val_loss: 6.221151351928711\n",
      "epoch:  23300 train_loss: 0.0525219552218914 val_loss: 6.191967487335205\n",
      "epoch:  23400 train_loss: 0.04356792941689491 val_loss: 6.268496036529541\n",
      "epoch:  23500 train_loss: 0.03035694546997547 val_loss: 6.167888641357422\n",
      "epoch:  23600 train_loss: 0.03064427338540554 val_loss: 6.229893684387207\n",
      "epoch:  23700 train_loss: 0.05481493100523949 val_loss: 6.186245441436768\n",
      "epoch:  23800 train_loss: 0.03518825024366379 val_loss: 6.170586585998535\n",
      "epoch:  23900 train_loss: 0.04144826531410217 val_loss: 6.302019119262695\n",
      "epoch:  24000 train_loss: 0.03323705866932869 val_loss: 6.178743839263916\n",
      "epoch:  24100 train_loss: 0.028755439445376396 val_loss: 6.158613204956055\n",
      "epoch:  24200 train_loss: 0.02659909427165985 val_loss: 6.169520378112793\n",
      "epoch:  24300 train_loss: 0.0283054206520319 val_loss: 6.211145401000977\n",
      "epoch:  24400 train_loss: 0.04308483749628067 val_loss: 6.285321235656738\n",
      "epoch:  24500 train_loss: 0.03385866805911064 val_loss: 6.147176742553711\n",
      "epoch:  24600 train_loss: 0.03304128721356392 val_loss: 6.171727657318115\n",
      "epoch:  24700 train_loss: 0.025323012843728065 val_loss: 6.187720775604248\n",
      "epoch:  24800 train_loss: 0.022791434079408646 val_loss: 6.1913161277771\n",
      "epoch:  24900 train_loss: 0.03322151303291321 val_loss: 6.284159183502197\n",
      "epoch:  25000 train_loss: 0.041149090975522995 val_loss: 6.296270847320557\n",
      "epoch:  25100 train_loss: 0.027028216049075127 val_loss: 6.216131687164307\n",
      "epoch:  25200 train_loss: 0.04075576364994049 val_loss: 6.186720848083496\n",
      "epoch:  25300 train_loss: 0.03923840820789337 val_loss: 6.191956996917725\n",
      "epoch:  25400 train_loss: 0.02277299016714096 val_loss: 6.183073997497559\n",
      "epoch:  25500 train_loss: 0.021457668393850327 val_loss: 6.189596176147461\n",
      "epoch:  25600 train_loss: 0.0264749638736248 val_loss: 6.164045333862305\n",
      "epoch:  25700 train_loss: 0.021319231018424034 val_loss: 6.197785377502441\n",
      "epoch:  25800 train_loss: 0.05396109074354172 val_loss: 6.2714128494262695\n",
      "epoch:  25900 train_loss: 0.04216601327061653 val_loss: 6.226970195770264\n",
      "epoch:  26000 train_loss: 0.018597116693854332 val_loss: 6.199166297912598\n",
      "epoch:  26100 train_loss: 0.023267339915037155 val_loss: 6.234920024871826\n",
      "epoch:  26200 train_loss: 0.023255161941051483 val_loss: 6.236203670501709\n",
      "epoch:  26300 train_loss: 0.02464684657752514 val_loss: 6.133649826049805\n",
      "epoch:  26400 train_loss: 0.039019059389829636 val_loss: 6.11643123626709\n",
      "epoch:  26500 train_loss: 0.01939278282225132 val_loss: 6.190234184265137\n",
      "epoch:  26600 train_loss: 0.05372067168354988 val_loss: 6.1596856117248535\n",
      "epoch:  26700 train_loss: 0.024884575977921486 val_loss: 6.186166763305664\n",
      "epoch:  26800 train_loss: 0.01878441497683525 val_loss: 6.153585910797119\n",
      "epoch:  26900 train_loss: 0.021593572571873665 val_loss: 6.1198883056640625\n",
      "epoch:  27000 train_loss: 0.01886862702667713 val_loss: 6.215938568115234\n",
      "epoch:  27100 train_loss: 0.03733287379145622 val_loss: 6.208622455596924\n",
      "epoch:  27200 train_loss: 0.037760235369205475 val_loss: 6.14594841003418\n",
      "epoch:  27300 train_loss: 0.02811770886182785 val_loss: 6.187689304351807\n",
      "epoch:  27400 train_loss: 0.022353816777467728 val_loss: 6.15518856048584\n",
      "epoch:  27500 train_loss: 0.02968796342611313 val_loss: 6.201748371124268\n",
      "epoch:  27600 train_loss: 0.019312238320708275 val_loss: 6.172369956970215\n",
      "epoch:  27700 train_loss: 0.023425055667757988 val_loss: 6.065033435821533\n",
      "epoch:  27800 train_loss: 0.019085807725787163 val_loss: 6.116449356079102\n",
      "epoch:  27900 train_loss: 0.027501976117491722 val_loss: 6.141094207763672\n",
      "epoch:  28000 train_loss: 0.023524686694145203 val_loss: 6.097891807556152\n",
      "epoch:  28100 train_loss: 0.011604278348386288 val_loss: 6.134432315826416\n",
      "epoch:  28200 train_loss: 0.019676361232995987 val_loss: 6.149967670440674\n",
      "epoch:  28300 train_loss: 0.014191810041666031 val_loss: 6.087073802947998\n",
      "epoch:  28400 train_loss: 0.0231766514480114 val_loss: 6.114022731781006\n",
      "epoch:  28500 train_loss: 0.015790564939379692 val_loss: 6.149213790893555\n",
      "epoch:  28600 train_loss: 0.024102812632918358 val_loss: 6.200320720672607\n",
      "epoch:  28700 train_loss: 0.022849654778838158 val_loss: 6.1105241775512695\n",
      "epoch:  28800 train_loss: 0.0139125632122159 val_loss: 6.103348731994629\n",
      "epoch:  28900 train_loss: 0.02386963739991188 val_loss: 6.066648006439209\n",
      "epoch:  29000 train_loss: 0.019858673214912415 val_loss: 6.135014057159424\n",
      "epoch:  29100 train_loss: 0.017192503437399864 val_loss: 6.066805839538574\n",
      "epoch:  29200 train_loss: 0.014055512845516205 val_loss: 6.134574890136719\n",
      "epoch:  29300 train_loss: 0.018357109278440475 val_loss: 6.1461639404296875\n",
      "epoch:  29400 train_loss: 0.029132220894098282 val_loss: 6.193600177764893\n",
      "epoch:  29500 train_loss: 0.010223819874227047 val_loss: 6.096099376678467\n",
      "epoch:  29600 train_loss: 0.016344865784049034 val_loss: 6.115687847137451\n",
      "epoch:  29700 train_loss: 0.013801723718643188 val_loss: 6.103761196136475\n",
      "epoch:  29800 train_loss: 0.02353767491877079 val_loss: 6.177178382873535\n",
      "epoch:  29900 train_loss: 0.01745513081550598 val_loss: 6.016805648803711\n",
      "epoch:  30000 train_loss: 0.017537059262394905 val_loss: 6.091548442840576\n",
      "epoch:  30100 train_loss: 0.027226535603404045 val_loss: 6.074822425842285\n",
      "epoch:  30200 train_loss: 0.01174991950392723 val_loss: 6.097982883453369\n",
      "epoch:  30300 train_loss: 0.015359320677816868 val_loss: 6.121820449829102\n",
      "epoch:  30400 train_loss: 0.011765329167246819 val_loss: 6.081753730773926\n",
      "epoch:  30500 train_loss: 0.013174555264413357 val_loss: 6.048950672149658\n",
      "epoch:  30600 train_loss: 0.017078574746847153 val_loss: 6.10487174987793\n",
      "epoch:  30700 train_loss: 0.01990325190126896 val_loss: 6.1242146492004395\n",
      "epoch:  30800 train_loss: 0.016889631748199463 val_loss: 6.027961730957031\n",
      "epoch:  30900 train_loss: 0.014236805960536003 val_loss: 6.0877203941345215\n",
      "epoch:  31000 train_loss: 0.010985581204295158 val_loss: 6.06569242477417\n",
      "epoch:  31100 train_loss: 0.016892779618501663 val_loss: 6.105020999908447\n",
      "epoch:  31200 train_loss: 0.017593756318092346 val_loss: 6.1020331382751465\n",
      "epoch:  31300 train_loss: 0.015094242058694363 val_loss: 5.988521099090576\n",
      "epoch:  31400 train_loss: 0.016681542620062828 val_loss: 5.979236125946045\n",
      "epoch:  31500 train_loss: 0.009470785968005657 val_loss: 6.076982021331787\n",
      "epoch:  31600 train_loss: 0.03166092932224274 val_loss: 6.089321613311768\n",
      "epoch:  31700 train_loss: 0.03340177237987518 val_loss: 6.056522369384766\n",
      "epoch:  31800 train_loss: 0.022559750825166702 val_loss: 6.077016353607178\n",
      "epoch:  31900 train_loss: 0.010979264974594116 val_loss: 6.006895542144775\n",
      "epoch:  32000 train_loss: 0.013441542163491249 val_loss: 6.015352725982666\n",
      "epoch:  32100 train_loss: 0.014768090099096298 val_loss: 5.980610370635986\n",
      "epoch:  32200 train_loss: 0.011656145565211773 val_loss: 6.036916255950928\n",
      "epoch:  32300 train_loss: 0.014487610198557377 val_loss: 6.0249528884887695\n",
      "epoch:  32400 train_loss: 0.009101121686398983 val_loss: 5.985205173492432\n",
      "epoch:  32500 train_loss: 0.01093241386115551 val_loss: 5.99176549911499\n",
      "epoch:  32600 train_loss: 0.011617753654718399 val_loss: 6.042156219482422\n",
      "epoch:  32700 train_loss: 0.015242084860801697 val_loss: 5.943316459655762\n",
      "epoch:  32800 train_loss: 0.008761974051594734 val_loss: 6.007183074951172\n",
      "epoch:  32900 train_loss: 0.013256549835205078 val_loss: 5.9580183029174805\n",
      "epoch:  33000 train_loss: 0.020847346633672714 val_loss: 6.065236568450928\n",
      "epoch:  33100 train_loss: 0.01715894229710102 val_loss: 5.9837822914123535\n",
      "epoch:  33200 train_loss: 0.018800562247633934 val_loss: 5.976690769195557\n",
      "epoch:  33300 train_loss: 0.010507694445550442 val_loss: 5.947540283203125\n",
      "epoch:  33400 train_loss: 0.013486041687428951 val_loss: 5.9745097160339355\n",
      "epoch:  33500 train_loss: 0.012936819344758987 val_loss: 5.940910339355469\n",
      "epoch:  33600 train_loss: 0.01178005151450634 val_loss: 5.9764790534973145\n",
      "epoch:  33700 train_loss: 0.014077053405344486 val_loss: 5.943631649017334\n",
      "epoch:  33800 train_loss: 0.006614552345126867 val_loss: 5.963754653930664\n",
      "epoch:  33900 train_loss: 0.006725880783051252 val_loss: 5.988476753234863\n",
      "epoch:  34000 train_loss: 0.00856775138527155 val_loss: 6.015833377838135\n",
      "epoch:  34100 train_loss: 0.005913757719099522 val_loss: 5.955719470977783\n",
      "epoch:  34200 train_loss: 0.010832545347511768 val_loss: 5.929429054260254\n",
      "epoch:  34300 train_loss: 0.013571027666330338 val_loss: 5.900515556335449\n",
      "epoch:  34400 train_loss: 0.007308174390345812 val_loss: 5.982824802398682\n",
      "epoch:  34500 train_loss: 0.0080742621794343 val_loss: 5.941459655761719\n",
      "epoch:  34600 train_loss: 0.009404434822499752 val_loss: 5.973212718963623\n",
      "epoch:  34700 train_loss: 0.010288020595908165 val_loss: 5.995616436004639\n",
      "epoch:  34800 train_loss: 0.011415163986384869 val_loss: 5.914329528808594\n",
      "epoch:  34900 train_loss: 0.008377011865377426 val_loss: 5.961071491241455\n",
      "epoch:  35000 train_loss: 0.008607335388660431 val_loss: 5.927748203277588\n",
      "epoch:  35100 train_loss: 0.013163602910935879 val_loss: 5.96872091293335\n",
      "epoch:  35200 train_loss: 0.010893228463828564 val_loss: 5.884042263031006\n",
      "epoch:  35300 train_loss: 0.00934003759175539 val_loss: 5.95780086517334\n",
      "epoch:  35400 train_loss: 0.01083617564290762 val_loss: 5.9905829429626465\n",
      "epoch:  35500 train_loss: 0.014761277474462986 val_loss: 5.94966983795166\n",
      "epoch:  35600 train_loss: 0.014892524108290672 val_loss: 5.947728157043457\n",
      "epoch:  35700 train_loss: 0.013146444223821163 val_loss: 5.940911769866943\n",
      "epoch:  35800 train_loss: 0.007567480206489563 val_loss: 5.9339165687561035\n",
      "epoch:  35900 train_loss: 0.011990503408014774 val_loss: 5.911980628967285\n",
      "sigma: 2.8 RMSE:  tensor(3.1730, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Generate the dataset with noise N(0, sigma)\n",
    "i = 0\n",
    "sigma = 2.8\n",
    "my_dataset = []\n",
    "for ud in UDs:\n",
    "    example = []\n",
    "    for an in ANs:\n",
    "        noise = np.random.normal(0,sigma)\n",
    "        # 0 is mean\n",
    "        # sigma is the deviation of the normal distribution\n",
    "        d = compute_3d_distance(ud, an) + noise\n",
    "        example.append(d)\n",
    "    \n",
    "    # append x, y, z as col#10, #11, #12\n",
    "    example.append(ud[0])\n",
    "    example.append(ud[1])\n",
    "    example.append(ud[2])\n",
    "    \n",
    "    # append 1x13 example row into my_dataset\n",
    "    my_dataset.append(example)  # expected to be 3000x13  \n",
    "    \n",
    "# Load dataset\n",
    "exercise5_dataset = Exercise5Dataset(list_dataset = my_dataset, shuffle=True)\n",
    "\n",
    "#Split dataset by 0.8: 0.1: 0.1\n",
    "train_examples, train_labels = exercise5_dataset[:int(3000*0.8)]  # (2400, 10)   # (2400, 3)\n",
    "val_examples, val_labels = exercise5_dataset[int(3000*0.8):int(3000*0.9)]    # (300, 10)   #(300, 3)\n",
    "test_examples, test_labels = exercise5_dataset[int(3000*0.9):]     #(300, 10)   # (300, 3)\n",
    "\n",
    "###Define model, loss function and optimizer\n",
    "# if we have GPU, then use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define model\n",
    "#model = Net(x_dim = train_examples.shape[1], y_dim = train_labels.shape[1]).to(device)\n",
    "input_dim = 1     #input dim is 1, seq_len = 10\n",
    "hidden_dim = 64   #hidden state dim is 64\n",
    "n_layers = 3             #3-layered LSTM\n",
    "model = MYLSTM(input_dim, hidden_dim, n_layers).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Correct the input/output shape for LSTM\n",
    "train_inputs = torch.unsqueeze(train_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "train_inputs = train_inputs.to(device) \n",
    "\n",
    "val_inputs = torch.unsqueeze(val_examples, dim=-1)   # (N, 10) -> (N, 10, 1)\n",
    "val_inputs = val_inputs.to(device) \n",
    "\n",
    "train_labels = train_labels.to(device)   #(N, 3)\n",
    "val_labels = val_labels.to(device)          #(N, 3)\n",
    "\n",
    "\n",
    "# Define the loss threshold, if the current train loss is lower than the threshold, we will begin to save the model\n",
    "best_loss = 100.0\n",
    "\n",
    "# Define the model filename for model.save()\n",
    "MODEL_FILENAME = \"best.pth\"\n",
    "\n",
    "# set model to Training mode\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "NUM_OF_EPOCH = 36000\n",
    "\n",
    "# Train\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    y_pred = model(train_inputs)\n",
    "    loss = loss_fn(y_pred, train_labels).cpu()\n",
    "    #print(t, loss.item())\n",
    "    train_losses.append(loss.item())\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    # BGD\n",
    "    optimizer.step()\n",
    "    \n",
    "    # evaluate validation loss\n",
    "    val_pred = model(val_inputs)\n",
    "    loss = loss_fn(val_pred, val_labels)\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "\n",
    "\n",
    "    if (epoch % 100) == 0:\n",
    "        print(\"epoch: \", epoch, \"train_loss:\", train_losses[-1], \"val_loss:\", val_losses[-1])\n",
    "        # check if we got better loss\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n",
    "        \n",
    "# Load the best model on previous step\n",
    "model.load_state_dict(torch.load(\"best.pth\"))\n",
    "\n",
    "# Inference all testing examples and compute RMSE\n",
    "def square_error(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  square_error= loss_fn(a, b)\n",
    "  return square_error\n",
    "\n",
    "model.eval() # inference mode\n",
    "test_inputs = torch.unsqueeze(test_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "test_inputs = test_inputs.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "\n",
    "test_preds = model(test_inputs)\n",
    "#print(\"example: \", test_example.cpu())\n",
    "#print(\"========================================\")\n",
    "#print(\"ground_truth:\", test_label.cpu())\n",
    "#print(\"prediction:\", test_pred.cpu())\n",
    "#print(\"========================================\")\n",
    "\n",
    "\n",
    "total_errors = 0.0\n",
    "for idx in range(len(test_inputs)):\n",
    "    total_errors += square_error(test_preds[idx], test_labels[idx])\n",
    "    \n",
    "RMSE = torch.sqrt(total_errors / len(test_inputs))\n",
    "print(\"sigma:\", sigma, \"RMSE: \",  RMSE)\n",
    "\n",
    "sigmas.append(sigma)\n",
    "RMSEs.append(RMSE.cpu().detach().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigma = 3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffle = True!\n",
      "epoch:  0 train_loss: 7335.892578125 val_loss: 7412.7822265625\n",
      "epoch:  100 train_loss: 5926.85791015625 val_loss: 5990.75439453125\n",
      "epoch:  200 train_loss: 5024.87890625 val_loss: 5087.6845703125\n",
      "epoch:  300 train_loss: 4278.263671875 val_loss: 4339.1533203125\n",
      "epoch:  400 train_loss: 3641.87841796875 val_loss: 3700.428466796875\n",
      "epoch:  500 train_loss: 3095.662841796875 val_loss: 3151.4921875\n",
      "epoch:  600 train_loss: 2625.489501953125 val_loss: 2678.5478515625\n",
      "epoch:  700 train_loss: 2220.937744140625 val_loss: 2270.500244140625\n",
      "epoch:  800 train_loss: 1872.672119140625 val_loss: 1919.08740234375\n",
      "epoch:  900 train_loss: 1573.9222412109375 val_loss: 1616.776123046875\n",
      "epoch:  1000 train_loss: 1318.5897216796875 val_loss: 1357.95751953125\n",
      "epoch:  1100 train_loss: 1101.4368896484375 val_loss: 1137.4305419921875\n",
      "epoch:  1200 train_loss: 918.3193359375 val_loss: 950.5076904296875\n",
      "epoch:  1300 train_loss: 764.8369750976562 val_loss: 793.851318359375\n",
      "epoch:  1400 train_loss: 637.5634765625 val_loss: 663.5165405273438\n",
      "epoch:  1500 train_loss: 533.157958984375 val_loss: 556.1099853515625\n",
      "epoch:  1600 train_loss: 448.6478576660156 val_loss: 468.63653564453125\n",
      "epoch:  1700 train_loss: 380.9460144042969 val_loss: 398.38897705078125\n",
      "epoch:  1800 train_loss: 327.4950866699219 val_loss: 342.52606201171875\n",
      "epoch:  1900 train_loss: 285.9460754394531 val_loss: 298.84503173828125\n",
      "epoch:  2000 train_loss: 254.19967651367188 val_loss: 264.98089599609375\n",
      "epoch:  2100 train_loss: 230.25694274902344 val_loss: 239.36068725585938\n",
      "epoch:  2200 train_loss: 212.6285858154297 val_loss: 220.12864685058594\n",
      "epoch:  2300 train_loss: 199.9224853515625 val_loss: 205.98902893066406\n",
      "epoch:  2400 train_loss: 190.8753662109375 val_loss: 195.7631072998047\n",
      "epoch:  2500 train_loss: 184.58663940429688 val_loss: 188.47645568847656\n",
      "epoch:  2600 train_loss: 180.3518829345703 val_loss: 183.3321990966797\n",
      "epoch:  2700 train_loss: 177.54405212402344 val_loss: 179.80909729003906\n",
      "epoch:  2800 train_loss: 175.74855041503906 val_loss: 177.3930206298828\n",
      "epoch:  2900 train_loss: 174.6165313720703 val_loss: 175.77906799316406\n",
      "epoch:  3000 train_loss: 173.93197631835938 val_loss: 174.70260620117188\n",
      "epoch:  3100 train_loss: 173.53192138671875 val_loss: 173.98336791992188\n",
      "epoch:  3200 train_loss: 173.30078125 val_loss: 173.50680541992188\n",
      "epoch:  3300 train_loss: 173.17449951171875 val_loss: 173.1953887939453\n",
      "epoch:  3400 train_loss: 173.1069793701172 val_loss: 172.99073791503906\n",
      "epoch:  3500 train_loss: 173.0725555419922 val_loss: 172.856201171875\n",
      "epoch:  3600 train_loss: 173.05564880371094 val_loss: 172.7617950439453\n",
      "epoch:  3700 train_loss: 173.04795837402344 val_loss: 172.7068634033203\n",
      "epoch:  3800 train_loss: 173.0441436767578 val_loss: 172.66326904296875\n",
      "epoch:  3900 train_loss: 173.04270935058594 val_loss: 172.6439666748047\n",
      "epoch:  4000 train_loss: 173.0419464111328 val_loss: 172.6195068359375\n",
      "epoch:  4100 train_loss: 173.04177856445312 val_loss: 172.61087036132812\n",
      "epoch:  4200 train_loss: 173.04168701171875 val_loss: 172.60223388671875\n",
      "epoch:  4300 train_loss: 173.0416717529297 val_loss: 172.60025024414062\n",
      "epoch:  4400 train_loss: 173.04165649414062 val_loss: 172.6007843017578\n",
      "epoch:  4500 train_loss: 173.04164123535156 val_loss: 172.5997314453125\n",
      "epoch:  4600 train_loss: 173.04164123535156 val_loss: 172.5975341796875\n",
      "epoch:  4700 train_loss: 173.04164123535156 val_loss: 172.5963592529297\n",
      "epoch:  4800 train_loss: 173.04164123535156 val_loss: 172.5963592529297\n",
      "epoch:  4900 train_loss: 173.04164123535156 val_loss: 172.5963592529297\n",
      "epoch:  5000 train_loss: 173.04164123535156 val_loss: 172.5963592529297\n",
      "epoch:  5100 train_loss: 173.04164123535156 val_loss: 172.59622192382812\n",
      "epoch:  5200 train_loss: 173.04164123535156 val_loss: 172.59622192382812\n",
      "epoch:  5300 train_loss: 173.04164123535156 val_loss: 172.59622192382812\n",
      "epoch:  5400 train_loss: 173.04164123535156 val_loss: 172.5963592529297\n",
      "epoch:  5500 train_loss: 173.04164123535156 val_loss: 172.5963592529297\n",
      "epoch:  5600 train_loss: 173.04164123535156 val_loss: 172.5963592529297\n",
      "epoch:  5700 train_loss: 173.04164123535156 val_loss: 172.5963592529297\n",
      "epoch:  5800 train_loss: 173.04164123535156 val_loss: 172.5963592529297\n",
      "epoch:  5900 train_loss: 173.04164123535156 val_loss: 172.5963592529297\n",
      "epoch:  6000 train_loss: 173.04164123535156 val_loss: 172.5963592529297\n",
      "epoch:  6100 train_loss: 173.04164123535156 val_loss: 172.5963592529297\n",
      "epoch:  6200 train_loss: 173.04164123535156 val_loss: 172.5963592529297\n",
      "epoch:  6300 train_loss: 173.04164123535156 val_loss: 172.5963592529297\n",
      "epoch:  6400 train_loss: 173.04164123535156 val_loss: 172.5963592529297\n",
      "epoch:  6500 train_loss: 173.04164123535156 val_loss: 172.59649658203125\n",
      "epoch:  6600 train_loss: 173.04164123535156 val_loss: 172.5963592529297\n",
      "epoch:  6700 train_loss: 173.04164123535156 val_loss: 172.5963592529297\n",
      "epoch:  6800 train_loss: 172.61097717285156 val_loss: 172.4920654296875\n",
      "epoch:  6900 train_loss: 124.17198944091797 val_loss: 124.73825073242188\n",
      "epoch:  7000 train_loss: 101.1666030883789 val_loss: 101.32521057128906\n",
      "epoch:  7100 train_loss: 88.49816131591797 val_loss: 88.49058532714844\n",
      "epoch:  7200 train_loss: 78.17053985595703 val_loss: 78.39836883544922\n",
      "epoch:  7300 train_loss: 68.43128967285156 val_loss: 67.82994079589844\n",
      "epoch:  7400 train_loss: 57.4451789855957 val_loss: 56.7434196472168\n",
      "epoch:  7500 train_loss: 46.96248245239258 val_loss: 46.25346374511719\n",
      "epoch:  7600 train_loss: 37.28319549560547 val_loss: 36.89506149291992\n",
      "epoch:  7700 train_loss: 28.849184036254883 val_loss: 29.423187255859375\n",
      "epoch:  7800 train_loss: 23.109983444213867 val_loss: 23.70809555053711\n",
      "epoch:  7900 train_loss: 18.54214859008789 val_loss: 19.16449737548828\n",
      "epoch:  8000 train_loss: 15.196155548095703 val_loss: 15.651265144348145\n",
      "epoch:  8100 train_loss: 12.536700248718262 val_loss: 13.024731636047363\n",
      "epoch:  8200 train_loss: 10.599333763122559 val_loss: 11.051691055297852\n",
      "epoch:  8300 train_loss: 9.124027252197266 val_loss: 9.634729385375977\n",
      "epoch:  8400 train_loss: 8.036547660827637 val_loss: 8.686015129089355\n",
      "epoch:  8500 train_loss: 7.236188888549805 val_loss: 8.00080680847168\n",
      "epoch:  8600 train_loss: 6.66115665435791 val_loss: 7.608139514923096\n",
      "epoch:  8700 train_loss: 5.923707962036133 val_loss: 6.68596076965332\n",
      "epoch:  8800 train_loss: 5.720734596252441 val_loss: 6.516918659210205\n",
      "epoch:  8900 train_loss: 5.1521077156066895 val_loss: 6.074352264404297\n",
      "epoch:  9000 train_loss: 4.969691753387451 val_loss: 5.891746997833252\n",
      "epoch:  9100 train_loss: 4.744339466094971 val_loss: 5.8477678298950195\n",
      "epoch:  9200 train_loss: 4.53481912612915 val_loss: 5.656778335571289\n",
      "epoch:  9300 train_loss: 5.071197032928467 val_loss: 5.703399181365967\n",
      "epoch:  9400 train_loss: 4.248769283294678 val_loss: 5.448538780212402\n",
      "epoch:  9500 train_loss: 4.206305980682373 val_loss: 5.347308158874512\n",
      "epoch:  9600 train_loss: 4.057790756225586 val_loss: 5.401890277862549\n",
      "epoch:  9700 train_loss: 4.061394691467285 val_loss: 5.478030681610107\n",
      "epoch:  9800 train_loss: 3.912991523742676 val_loss: 5.3582963943481445\n",
      "epoch:  9900 train_loss: 3.8185911178588867 val_loss: 5.230242729187012\n",
      "epoch:  10000 train_loss: 3.760253667831421 val_loss: 5.218427658081055\n",
      "epoch:  10100 train_loss: 3.8004674911499023 val_loss: 5.265222549438477\n",
      "epoch:  10200 train_loss: 3.658458709716797 val_loss: 5.221423149108887\n",
      "epoch:  10300 train_loss: 3.6897361278533936 val_loss: 5.19520378112793\n",
      "epoch:  10400 train_loss: 3.6009790897369385 val_loss: 5.222823619842529\n",
      "epoch:  10500 train_loss: 3.666682720184326 val_loss: 5.338625907897949\n",
      "epoch:  10600 train_loss: 3.501492500305176 val_loss: 5.105045318603516\n",
      "epoch:  10700 train_loss: 3.6085855960845947 val_loss: 5.471144676208496\n",
      "epoch:  10800 train_loss: 3.460629940032959 val_loss: 5.3193359375\n",
      "epoch:  10900 train_loss: 3.6811158657073975 val_loss: 5.876895427703857\n",
      "epoch:  11000 train_loss: 3.33927845954895 val_loss: 5.218588829040527\n",
      "epoch:  11100 train_loss: 3.3389031887054443 val_loss: 5.219478130340576\n",
      "epoch:  11200 train_loss: 3.2662880420684814 val_loss: 5.167474269866943\n",
      "epoch:  11300 train_loss: 3.3324334621429443 val_loss: 5.1640191078186035\n",
      "epoch:  11400 train_loss: 3.1836085319519043 val_loss: 5.203873634338379\n",
      "epoch:  11500 train_loss: 3.1661481857299805 val_loss: 5.199950218200684\n",
      "epoch:  11600 train_loss: 3.160747766494751 val_loss: 5.328216075897217\n",
      "epoch:  11700 train_loss: 3.0725748538970947 val_loss: 5.281911849975586\n",
      "epoch:  11800 train_loss: 3.2523839473724365 val_loss: 5.494478702545166\n",
      "epoch:  11900 train_loss: 3.0219452381134033 val_loss: 5.367652416229248\n",
      "epoch:  12000 train_loss: 2.9815025329589844 val_loss: 5.3245463371276855\n",
      "epoch:  12100 train_loss: 2.9847028255462646 val_loss: 5.50213098526001\n",
      "epoch:  12200 train_loss: 3.07358455657959 val_loss: 5.372143745422363\n",
      "epoch:  12300 train_loss: 2.990952253341675 val_loss: 5.34620475769043\n",
      "epoch:  12400 train_loss: 2.8248438835144043 val_loss: 5.445535659790039\n",
      "epoch:  12500 train_loss: 2.806706666946411 val_loss: 5.508917331695557\n",
      "epoch:  12600 train_loss: 2.7633919715881348 val_loss: 5.527885437011719\n",
      "epoch:  12700 train_loss: 2.7970473766326904 val_loss: 5.559885025024414\n",
      "epoch:  12800 train_loss: 2.7271902561187744 val_loss: 5.835052013397217\n",
      "epoch:  12900 train_loss: 2.7284114360809326 val_loss: 5.814521312713623\n",
      "epoch:  13000 train_loss: 2.686755657196045 val_loss: 5.916614532470703\n",
      "epoch:  13100 train_loss: 2.659115791320801 val_loss: 5.919563293457031\n",
      "epoch:  13200 train_loss: 2.5968048572540283 val_loss: 5.90511417388916\n",
      "epoch:  13300 train_loss: 2.550924301147461 val_loss: 6.033236026763916\n",
      "epoch:  13400 train_loss: 2.496349811553955 val_loss: 6.052194118499756\n",
      "epoch:  13500 train_loss: 2.4784305095672607 val_loss: 6.188722133636475\n",
      "epoch:  13600 train_loss: 2.4348816871643066 val_loss: 6.211737155914307\n",
      "epoch:  13700 train_loss: 2.4107980728149414 val_loss: 6.167886257171631\n",
      "epoch:  13800 train_loss: 2.3791699409484863 val_loss: 6.205018043518066\n",
      "epoch:  13900 train_loss: 2.321918487548828 val_loss: 6.341535568237305\n",
      "epoch:  14000 train_loss: 2.3416683673858643 val_loss: 6.2820000648498535\n",
      "epoch:  14100 train_loss: 2.350914239883423 val_loss: 6.340042591094971\n",
      "epoch:  14200 train_loss: 2.2875776290893555 val_loss: 6.572407245635986\n",
      "epoch:  14300 train_loss: 2.361715316772461 val_loss: 6.700843334197998\n",
      "epoch:  14400 train_loss: 2.1764934062957764 val_loss: 6.553346633911133\n",
      "epoch:  14500 train_loss: 2.148209571838379 val_loss: 6.592897891998291\n",
      "epoch:  14600 train_loss: 2.129182815551758 val_loss: 6.6996846199035645\n",
      "epoch:  14700 train_loss: 2.088026523590088 val_loss: 6.657209396362305\n",
      "epoch:  14800 train_loss: 2.1220741271972656 val_loss: 6.551145076751709\n",
      "epoch:  14900 train_loss: 2.369009017944336 val_loss: 7.022302150726318\n",
      "epoch:  15000 train_loss: 2.0294504165649414 val_loss: 6.679660320281982\n",
      "epoch:  15100 train_loss: 1.9713523387908936 val_loss: 6.820287227630615\n",
      "epoch:  15200 train_loss: 1.9754348993301392 val_loss: 6.7838263511657715\n",
      "epoch:  15300 train_loss: 2.14180850982666 val_loss: 7.141055583953857\n",
      "epoch:  15400 train_loss: 1.905450463294983 val_loss: 6.839321136474609\n",
      "epoch:  15500 train_loss: 1.8906277418136597 val_loss: 7.0806965827941895\n",
      "epoch:  15600 train_loss: 2.191683053970337 val_loss: 6.946361064910889\n",
      "epoch:  15700 train_loss: 1.836922526359558 val_loss: 7.104348182678223\n",
      "epoch:  15800 train_loss: 1.7797514200210571 val_loss: 6.959394931793213\n",
      "epoch:  15900 train_loss: 1.7773345708847046 val_loss: 7.073178768157959\n",
      "epoch:  16000 train_loss: 1.8186429738998413 val_loss: 7.125442981719971\n",
      "epoch:  16100 train_loss: 1.9095673561096191 val_loss: 7.435210704803467\n",
      "epoch:  16200 train_loss: 1.738732099533081 val_loss: 7.086026668548584\n",
      "epoch:  16300 train_loss: 1.652759075164795 val_loss: 7.254823684692383\n",
      "epoch:  16400 train_loss: 1.9075125455856323 val_loss: 7.193313121795654\n",
      "epoch:  16500 train_loss: 1.6532232761383057 val_loss: 7.3428778648376465\n",
      "epoch:  16600 train_loss: 1.5805187225341797 val_loss: 7.346452713012695\n",
      "epoch:  16700 train_loss: 1.662967562675476 val_loss: 7.393001556396484\n",
      "epoch:  16800 train_loss: 1.6847971677780151 val_loss: 7.322909832000732\n",
      "epoch:  16900 train_loss: 1.6626986265182495 val_loss: 7.630403518676758\n",
      "epoch:  17000 train_loss: 1.5298725366592407 val_loss: 7.502967357635498\n",
      "epoch:  17100 train_loss: 1.566514015197754 val_loss: 7.458404064178467\n",
      "epoch:  17200 train_loss: 1.5266731977462769 val_loss: 7.570856094360352\n",
      "epoch:  17300 train_loss: 1.4184805154800415 val_loss: 7.6082563400268555\n",
      "epoch:  17400 train_loss: 1.4909793138504028 val_loss: 7.794554233551025\n",
      "epoch:  17500 train_loss: 1.4011107683181763 val_loss: 7.689016342163086\n",
      "epoch:  17600 train_loss: 1.4360016584396362 val_loss: 7.715346813201904\n",
      "epoch:  17700 train_loss: 1.3492354154586792 val_loss: 7.777896881103516\n",
      "epoch:  17800 train_loss: 1.376954197883606 val_loss: 7.733730792999268\n",
      "epoch:  17900 train_loss: 1.3057305812835693 val_loss: 7.793166637420654\n",
      "epoch:  18000 train_loss: 1.3809326887130737 val_loss: 7.829347133636475\n",
      "epoch:  18100 train_loss: 1.2838104963302612 val_loss: 7.809532642364502\n",
      "epoch:  18200 train_loss: 1.3751115798950195 val_loss: 7.775160789489746\n",
      "epoch:  18300 train_loss: 1.2256227731704712 val_loss: 7.879243850708008\n",
      "epoch:  18400 train_loss: 1.2476826906204224 val_loss: 7.914453506469727\n",
      "epoch:  18500 train_loss: 1.2206648588180542 val_loss: 7.892622947692871\n",
      "epoch:  18600 train_loss: 1.1524889469146729 val_loss: 7.8538818359375\n",
      "epoch:  18700 train_loss: 1.2553927898406982 val_loss: 7.935002326965332\n",
      "epoch:  18800 train_loss: 1.1556273698806763 val_loss: 7.967527389526367\n",
      "epoch:  18900 train_loss: 1.2349517345428467 val_loss: 8.007416725158691\n",
      "epoch:  19000 train_loss: 1.0804415941238403 val_loss: 7.985660076141357\n",
      "epoch:  19100 train_loss: 1.1253958940505981 val_loss: 8.093249320983887\n",
      "epoch:  19200 train_loss: 1.1213597059249878 val_loss: 8.051387786865234\n",
      "epoch:  19300 train_loss: 1.0107955932617188 val_loss: 8.029315948486328\n",
      "epoch:  19400 train_loss: 1.0390452146530151 val_loss: 8.097111701965332\n",
      "epoch:  19500 train_loss: 1.0015422105789185 val_loss: 8.064434051513672\n",
      "epoch:  19600 train_loss: 1.0492119789123535 val_loss: 8.185697555541992\n",
      "epoch:  19700 train_loss: 0.9956585764884949 val_loss: 8.035656929016113\n",
      "epoch:  19800 train_loss: 1.0401768684387207 val_loss: 8.143026351928711\n",
      "epoch:  19900 train_loss: 0.9072351455688477 val_loss: 8.162923812866211\n",
      "epoch:  20000 train_loss: 0.9701679348945618 val_loss: 8.154423713684082\n",
      "epoch:  20100 train_loss: 0.9328553080558777 val_loss: 8.214540481567383\n",
      "epoch:  20200 train_loss: 0.9056810140609741 val_loss: 8.289173126220703\n",
      "epoch:  20300 train_loss: 1.0685443878173828 val_loss: 8.217863082885742\n",
      "epoch:  20400 train_loss: 0.8924850821495056 val_loss: 8.345166206359863\n",
      "epoch:  20500 train_loss: 0.8421455025672913 val_loss: 8.390016555786133\n",
      "epoch:  20600 train_loss: 0.8364939093589783 val_loss: 8.419088363647461\n",
      "epoch:  20700 train_loss: 0.8144404888153076 val_loss: 8.484883308410645\n",
      "epoch:  20800 train_loss: 0.798150360584259 val_loss: 8.452391624450684\n",
      "epoch:  20900 train_loss: 0.7673737406730652 val_loss: 8.507794380187988\n",
      "epoch:  21000 train_loss: 0.8251056671142578 val_loss: 8.391766548156738\n",
      "epoch:  21100 train_loss: 0.8126570582389832 val_loss: 8.523558616638184\n",
      "epoch:  21200 train_loss: 0.9745333790779114 val_loss: 8.575567245483398\n",
      "epoch:  21300 train_loss: 0.7770582437515259 val_loss: 8.616479873657227\n",
      "epoch:  21400 train_loss: 0.7384613752365112 val_loss: 8.738321304321289\n",
      "epoch:  21500 train_loss: 0.7167001366615295 val_loss: 8.758095741271973\n",
      "epoch:  21600 train_loss: 0.7887033820152283 val_loss: 8.682929992675781\n",
      "epoch:  21700 train_loss: 0.7366011738777161 val_loss: 8.768095970153809\n",
      "epoch:  21800 train_loss: 0.6897048354148865 val_loss: 8.813048362731934\n",
      "epoch:  21900 train_loss: 0.6573394536972046 val_loss: 8.831775665283203\n",
      "epoch:  22000 train_loss: 0.6520529389381409 val_loss: 8.894684791564941\n",
      "epoch:  22100 train_loss: 0.6808252334594727 val_loss: 8.86794662475586\n",
      "epoch:  22200 train_loss: 0.664097011089325 val_loss: 8.869751930236816\n",
      "epoch:  22300 train_loss: 0.631886899471283 val_loss: 8.910861015319824\n",
      "epoch:  22400 train_loss: 0.6521126627922058 val_loss: 8.927963256835938\n",
      "epoch:  22500 train_loss: 0.6184338331222534 val_loss: 8.998941421508789\n",
      "epoch:  22600 train_loss: 0.7954229116439819 val_loss: 9.063084602355957\n",
      "epoch:  22700 train_loss: 0.6074533462524414 val_loss: 9.113521575927734\n",
      "epoch:  22800 train_loss: 0.5793927907943726 val_loss: 8.98725700378418\n",
      "epoch:  22900 train_loss: 0.577686607837677 val_loss: 9.02683162689209\n",
      "epoch:  23000 train_loss: 0.5598806738853455 val_loss: 9.057585716247559\n",
      "epoch:  23100 train_loss: 0.7581565976142883 val_loss: 9.424103736877441\n",
      "epoch:  23200 train_loss: 0.5700669288635254 val_loss: 9.09119987487793\n",
      "epoch:  23300 train_loss: 0.5428536534309387 val_loss: 9.09543514251709\n",
      "epoch:  23400 train_loss: 0.5560603141784668 val_loss: 9.07946491241455\n",
      "epoch:  23500 train_loss: 0.5746344327926636 val_loss: 9.144811630249023\n",
      "epoch:  23600 train_loss: 0.5410977602005005 val_loss: 9.108049392700195\n",
      "epoch:  23700 train_loss: 0.5660533308982849 val_loss: 8.964966773986816\n",
      "epoch:  23800 train_loss: 0.5533519387245178 val_loss: 9.132207870483398\n",
      "epoch:  23900 train_loss: 0.5197570323944092 val_loss: 9.209668159484863\n",
      "epoch:  24000 train_loss: 0.7633466720581055 val_loss: 9.409199714660645\n",
      "epoch:  24100 train_loss: 0.5199353098869324 val_loss: 9.251677513122559\n",
      "epoch:  24200 train_loss: 0.6052526235580444 val_loss: 9.168715476989746\n",
      "epoch:  24300 train_loss: 0.7618303894996643 val_loss: 9.311091423034668\n",
      "epoch:  24400 train_loss: 0.46773701906204224 val_loss: 9.213315963745117\n",
      "epoch:  24500 train_loss: 0.4487805664539337 val_loss: 9.302448272705078\n",
      "epoch:  24600 train_loss: 0.44502463936805725 val_loss: 9.234002113342285\n",
      "epoch:  24700 train_loss: 0.49865710735321045 val_loss: 9.39090347290039\n",
      "epoch:  24800 train_loss: 0.5304067730903625 val_loss: 9.20763874053955\n",
      "epoch:  24900 train_loss: 0.44660884141921997 val_loss: 9.349142074584961\n",
      "epoch:  25000 train_loss: 0.44972777366638184 val_loss: 9.290228843688965\n",
      "epoch:  25100 train_loss: 0.4489057958126068 val_loss: 9.336729049682617\n",
      "epoch:  25200 train_loss: 0.39719581604003906 val_loss: 9.300658226013184\n",
      "epoch:  25300 train_loss: 0.4260399043560028 val_loss: 9.284884452819824\n",
      "epoch:  25400 train_loss: 0.5076048970222473 val_loss: 9.125507354736328\n",
      "epoch:  25500 train_loss: 0.43238165974617004 val_loss: 9.476511001586914\n",
      "epoch:  25600 train_loss: 0.4341573119163513 val_loss: 9.289436340332031\n",
      "epoch:  25700 train_loss: 0.405099093914032 val_loss: 9.455046653747559\n",
      "epoch:  25800 train_loss: 0.37866613268852234 val_loss: 9.399824142456055\n",
      "epoch:  25900 train_loss: 0.44922900199890137 val_loss: 9.24189281463623\n",
      "epoch:  26000 train_loss: 0.36841532588005066 val_loss: 9.441720962524414\n",
      "epoch:  26100 train_loss: 0.3552038371562958 val_loss: 9.423270225524902\n",
      "epoch:  26200 train_loss: 0.3869391977787018 val_loss: 9.426475524902344\n",
      "epoch:  26300 train_loss: 0.37618890404701233 val_loss: 9.52426528930664\n",
      "epoch:  26400 train_loss: 0.3717016577720642 val_loss: 9.4176025390625\n",
      "epoch:  26500 train_loss: 0.3796961307525635 val_loss: 9.448437690734863\n",
      "epoch:  26600 train_loss: 0.3498714864253998 val_loss: 9.518244743347168\n",
      "epoch:  26700 train_loss: 0.49329638481140137 val_loss: 9.755064964294434\n",
      "epoch:  26800 train_loss: 0.3910992443561554 val_loss: 9.48717212677002\n",
      "epoch:  26900 train_loss: 0.34951192140579224 val_loss: 9.569609642028809\n",
      "epoch:  27000 train_loss: 0.3801175355911255 val_loss: 9.51330852508545\n",
      "epoch:  27100 train_loss: 0.39392176270484924 val_loss: 9.603806495666504\n",
      "epoch:  27200 train_loss: 0.31233060359954834 val_loss: 9.556987762451172\n",
      "epoch:  27300 train_loss: 0.3095913827419281 val_loss: 9.64367389678955\n",
      "epoch:  27400 train_loss: 0.3210626244544983 val_loss: 9.613550186157227\n",
      "epoch:  27500 train_loss: 0.3080825209617615 val_loss: 9.554274559020996\n",
      "epoch:  27600 train_loss: 0.37035828828811646 val_loss: 9.63952350616455\n",
      "epoch:  27700 train_loss: 0.3114396333694458 val_loss: 9.623689651489258\n",
      "epoch:  27800 train_loss: 0.2965318560600281 val_loss: 9.751260757446289\n",
      "epoch:  27900 train_loss: 0.3155241012573242 val_loss: 9.652778625488281\n",
      "epoch:  28000 train_loss: 0.2844228446483612 val_loss: 9.716221809387207\n",
      "epoch:  28100 train_loss: 0.3058038353919983 val_loss: 9.657038688659668\n",
      "epoch:  28200 train_loss: 0.2941123843193054 val_loss: 9.635425567626953\n",
      "epoch:  28300 train_loss: 0.2692481577396393 val_loss: 9.763669967651367\n",
      "epoch:  28400 train_loss: 0.294033408164978 val_loss: 9.62751579284668\n",
      "epoch:  28500 train_loss: 0.31896427273750305 val_loss: 9.724937438964844\n",
      "epoch:  28600 train_loss: 0.2798931300640106 val_loss: 9.82309341430664\n",
      "epoch:  28700 train_loss: 0.3193880617618561 val_loss: 9.730579376220703\n",
      "epoch:  28800 train_loss: 0.24957112967967987 val_loss: 9.797611236572266\n",
      "epoch:  28900 train_loss: 0.2773842513561249 val_loss: 9.861896514892578\n",
      "epoch:  29000 train_loss: 0.24431782960891724 val_loss: 9.816399574279785\n",
      "epoch:  29100 train_loss: 0.28364434838294983 val_loss: 9.810965538024902\n",
      "epoch:  29200 train_loss: 0.24907226860523224 val_loss: 9.88068675994873\n",
      "epoch:  29300 train_loss: 0.2645614743232727 val_loss: 9.899871826171875\n",
      "epoch:  29400 train_loss: 0.26016056537628174 val_loss: 9.957383155822754\n",
      "epoch:  29500 train_loss: 0.2818240225315094 val_loss: 9.790853500366211\n",
      "epoch:  29600 train_loss: 0.24122460186481476 val_loss: 9.921701431274414\n",
      "epoch:  29700 train_loss: 0.2344871461391449 val_loss: 9.937623977661133\n",
      "epoch:  29800 train_loss: 0.29835930466651917 val_loss: 10.050902366638184\n",
      "epoch:  29900 train_loss: 0.6658479571342468 val_loss: 10.064114570617676\n",
      "epoch:  30000 train_loss: 0.23077671229839325 val_loss: 9.928991317749023\n",
      "epoch:  30100 train_loss: 0.2343233972787857 val_loss: 10.037013053894043\n",
      "epoch:  30200 train_loss: 0.2674591839313507 val_loss: 10.089402198791504\n",
      "epoch:  30300 train_loss: 0.21052290499210358 val_loss: 9.956380844116211\n",
      "epoch:  30400 train_loss: 0.22561009228229523 val_loss: 10.074329376220703\n",
      "epoch:  30500 train_loss: 0.28487271070480347 val_loss: 9.868172645568848\n",
      "epoch:  30600 train_loss: 0.2819388806819916 val_loss: 9.868014335632324\n",
      "epoch:  30700 train_loss: 0.19896624982357025 val_loss: 10.061274528503418\n",
      "epoch:  30800 train_loss: 0.2147178202867508 val_loss: 10.06937313079834\n",
      "epoch:  30900 train_loss: 0.21701809763908386 val_loss: 9.996057510375977\n",
      "epoch:  31000 train_loss: 0.18183451890945435 val_loss: 10.040213584899902\n",
      "epoch:  31100 train_loss: 0.18750354647636414 val_loss: 10.037132263183594\n",
      "epoch:  31200 train_loss: 0.21643687784671783 val_loss: 10.144865036010742\n",
      "epoch:  31300 train_loss: 0.19018079340457916 val_loss: 10.123906135559082\n",
      "epoch:  31400 train_loss: 0.16914011538028717 val_loss: 10.023303031921387\n",
      "epoch:  31500 train_loss: 0.21695706248283386 val_loss: 10.059532165527344\n",
      "epoch:  31600 train_loss: 0.22197569906711578 val_loss: 10.106966018676758\n",
      "epoch:  31700 train_loss: 0.18510094285011292 val_loss: 10.136518478393555\n",
      "epoch:  31800 train_loss: 0.22904999554157257 val_loss: 10.2160062789917\n",
      "epoch:  31900 train_loss: 0.1790931522846222 val_loss: 10.109079360961914\n",
      "epoch:  32000 train_loss: 0.277860552072525 val_loss: 10.108413696289062\n",
      "epoch:  32100 train_loss: 0.24227145314216614 val_loss: 10.036649703979492\n",
      "epoch:  32200 train_loss: 0.15570469200611115 val_loss: 10.193422317504883\n",
      "epoch:  32300 train_loss: 0.2707028090953827 val_loss: 10.291633605957031\n",
      "epoch:  32400 train_loss: 0.15919816493988037 val_loss: 10.180054664611816\n",
      "epoch:  32500 train_loss: 0.17473606765270233 val_loss: 10.175016403198242\n",
      "epoch:  32600 train_loss: 0.17724475264549255 val_loss: 10.337335586547852\n",
      "epoch:  32700 train_loss: 0.2018175572156906 val_loss: 10.243522644042969\n",
      "epoch:  32800 train_loss: 0.17611925303936005 val_loss: 10.229419708251953\n",
      "epoch:  32900 train_loss: 0.14612632989883423 val_loss: 10.323356628417969\n",
      "epoch:  33000 train_loss: 0.18992750346660614 val_loss: 10.271737098693848\n",
      "epoch:  33100 train_loss: 0.14698326587677002 val_loss: 10.265820503234863\n",
      "epoch:  33200 train_loss: 0.19777323305606842 val_loss: 10.283987045288086\n",
      "epoch:  33300 train_loss: 0.16530923545360565 val_loss: 10.303592681884766\n",
      "epoch:  33400 train_loss: 0.1532551497220993 val_loss: 10.260454177856445\n",
      "epoch:  33500 train_loss: 0.16145658493041992 val_loss: 10.33846378326416\n",
      "epoch:  33600 train_loss: 0.2746553122997284 val_loss: 10.193405151367188\n",
      "epoch:  33700 train_loss: 0.18482957780361176 val_loss: 10.348370552062988\n",
      "epoch:  33800 train_loss: 0.13409103453159332 val_loss: 10.264009475708008\n",
      "epoch:  33900 train_loss: 0.16833378374576569 val_loss: 10.245109558105469\n",
      "epoch:  34000 train_loss: 0.1601712703704834 val_loss: 10.408463478088379\n",
      "epoch:  34100 train_loss: 0.13608352839946747 val_loss: 10.36958122253418\n",
      "epoch:  34200 train_loss: 0.1611020565032959 val_loss: 10.229503631591797\n",
      "epoch:  34300 train_loss: 0.16570180654525757 val_loss: 10.229812622070312\n",
      "epoch:  34400 train_loss: 0.22060933709144592 val_loss: 10.306828498840332\n",
      "epoch:  34500 train_loss: 0.15647394955158234 val_loss: 10.33488655090332\n",
      "epoch:  34600 train_loss: 0.14767852425575256 val_loss: 10.31576156616211\n",
      "epoch:  34700 train_loss: 0.1171959638595581 val_loss: 10.332310676574707\n",
      "epoch:  34800 train_loss: 0.1368303745985031 val_loss: 10.377202033996582\n",
      "epoch:  34900 train_loss: 0.12701667845249176 val_loss: 10.331512451171875\n",
      "epoch:  35000 train_loss: 0.12241187691688538 val_loss: 10.424203872680664\n",
      "epoch:  35100 train_loss: 0.18319013714790344 val_loss: 10.414695739746094\n",
      "epoch:  35200 train_loss: 0.18967245519161224 val_loss: 10.527371406555176\n",
      "epoch:  35300 train_loss: 0.2952778935432434 val_loss: 10.423989295959473\n",
      "epoch:  35400 train_loss: 0.11434852331876755 val_loss: 10.293787002563477\n",
      "epoch:  35500 train_loss: 0.15266497433185577 val_loss: 10.467243194580078\n",
      "epoch:  35600 train_loss: 0.13001269102096558 val_loss: 10.383320808410645\n",
      "epoch:  35700 train_loss: 0.13443420827388763 val_loss: 10.468574523925781\n",
      "epoch:  35800 train_loss: 0.13951967656612396 val_loss: 10.474303245544434\n",
      "epoch:  35900 train_loss: 0.09294832497835159 val_loss: 10.358221054077148\n",
      "sigma: 3.7 RMSE:  tensor(4.0515, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Generate the dataset with noise N(0, sigma)\n",
    "i = 0\n",
    "sigma = 3.7\n",
    "my_dataset = []\n",
    "for ud in UDs:\n",
    "    example = []\n",
    "    for an in ANs:\n",
    "        noise = np.random.normal(0,sigma)\n",
    "        # 0 is mean\n",
    "        # sigma is the deviation of the normal distribution\n",
    "        d = compute_3d_distance(ud, an) + noise\n",
    "        example.append(d)\n",
    "    \n",
    "    # append x, y, z as col#10, #11, #12\n",
    "    example.append(ud[0])\n",
    "    example.append(ud[1])\n",
    "    example.append(ud[2])\n",
    "    \n",
    "    # append 1x13 example row into my_dataset\n",
    "    my_dataset.append(example)  # expected to be 3000x13  \n",
    "    \n",
    "# Load dataset\n",
    "exercise5_dataset = Exercise5Dataset(list_dataset = my_dataset, shuffle=True)\n",
    "\n",
    "#Split dataset by 0.8: 0.1: 0.1\n",
    "train_examples, train_labels = exercise5_dataset[:int(3000*0.8)]  # (2400, 10)   # (2400, 3)\n",
    "val_examples, val_labels = exercise5_dataset[int(3000*0.8):int(3000*0.9)]    # (300, 10)   #(300, 3)\n",
    "test_examples, test_labels = exercise5_dataset[int(3000*0.9):]     #(300, 10)   # (300, 3)\n",
    "\n",
    "###Define model, loss function and optimizer\n",
    "# if we have GPU, then use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define model\n",
    "#model = Net(x_dim = train_examples.shape[1], y_dim = train_labels.shape[1]).to(device)\n",
    "input_dim = 1     #input dim is 1, seq_len = 10\n",
    "hidden_dim = 64   #hidden state dim is 64\n",
    "n_layers = 3             #3-layered LSTM\n",
    "model = MYLSTM(input_dim, hidden_dim, n_layers).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Correct the input/output shape for LSTM\n",
    "train_inputs = torch.unsqueeze(train_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "train_inputs = train_inputs.to(device) \n",
    "\n",
    "val_inputs = torch.unsqueeze(val_examples, dim=-1)   # (N, 10) -> (N, 10, 1)\n",
    "val_inputs = val_inputs.to(device) \n",
    "\n",
    "train_labels = train_labels.to(device)   #(N, 3)\n",
    "val_labels = val_labels.to(device)          #(N, 3)\n",
    "\n",
    "\n",
    "# Define the loss threshold, if the current train loss is lower than the threshold, we will begin to save the model\n",
    "best_loss = 100.0\n",
    "\n",
    "# Define the model filename for model.save()\n",
    "MODEL_FILENAME = \"best.pth\"\n",
    "\n",
    "# set model to Training mode\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "NUM_OF_EPOCH = 36000\n",
    "\n",
    "# Train\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    y_pred = model(train_inputs)\n",
    "    loss = loss_fn(y_pred, train_labels).cpu()\n",
    "    #print(t, loss.item())\n",
    "    train_losses.append(loss.item())\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    # BGD\n",
    "    optimizer.step()\n",
    "    \n",
    "    # evaluate validation loss\n",
    "    val_pred = model(val_inputs)\n",
    "    loss = loss_fn(val_pred, val_labels)\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "\n",
    "\n",
    "    if (epoch % 100) == 0:\n",
    "        print(\"epoch: \", epoch, \"train_loss:\", train_losses[-1], \"val_loss:\", val_losses[-1])\n",
    "        # check if we got better loss\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n",
    "        \n",
    "# Load the best model on previous step\n",
    "model.load_state_dict(torch.load(\"best.pth\"))\n",
    "\n",
    "# Inference all testing examples and compute RMSE\n",
    "def square_error(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  square_error= loss_fn(a, b)\n",
    "  return square_error\n",
    "\n",
    "model.eval() # inference mode\n",
    "test_inputs = torch.unsqueeze(test_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "test_inputs = test_inputs.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "\n",
    "test_preds = model(test_inputs)\n",
    "#print(\"example: \", test_example.cpu())\n",
    "#print(\"========================================\")\n",
    "#print(\"ground_truth:\", test_label.cpu())\n",
    "#print(\"prediction:\", test_pred.cpu())\n",
    "#print(\"========================================\")\n",
    "\n",
    "\n",
    "total_errors = 0.0\n",
    "for idx in range(len(test_inputs)):\n",
    "    total_errors += square_error(test_preds[idx], test_labels[idx])\n",
    "    \n",
    "RMSE = torch.sqrt(total_errors / len(test_inputs))\n",
    "print(\"sigma:\", sigma, \"RMSE: \",  RMSE)\n",
    "\n",
    "sigmas.append(sigma)\n",
    "RMSEs.append(RMSE.cpu().detach().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigma = 4.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffle = True!\n",
      "epoch:  0 train_loss: 7339.33056640625 val_loss: 7317.88232421875\n",
      "epoch:  100 train_loss: 5976.46630859375 val_loss: 5953.708984375\n",
      "epoch:  200 train_loss: 5072.2099609375 val_loss: 5055.4306640625\n",
      "epoch:  300 train_loss: 4316.51806640625 val_loss: 4304.58251953125\n",
      "epoch:  400 train_loss: 3663.818359375 val_loss: 3655.4150390625\n",
      "epoch:  500 train_loss: 3095.794677734375 val_loss: 3090.764892578125\n",
      "epoch:  600 train_loss: 2615.93994140625 val_loss: 2613.494140625\n",
      "epoch:  700 train_loss: 2205.67529296875 val_loss: 2205.3017578125\n",
      "epoch:  800 train_loss: 1854.2872314453125 val_loss: 1855.2181396484375\n",
      "epoch:  900 train_loss: 1553.71240234375 val_loss: 1555.5379638671875\n",
      "epoch:  1000 train_loss: 1297.595458984375 val_loss: 1300.1630859375\n",
      "epoch:  1100 train_loss: 1080.6861572265625 val_loss: 1083.454833984375\n",
      "epoch:  1200 train_loss: 898.1596069335938 val_loss: 901.1116333007812\n",
      "epoch:  1300 train_loss: 746.0665893554688 val_loss: 748.9627075195312\n",
      "epoch:  1400 train_loss: 620.4445190429688 val_loss: 623.3976440429688\n",
      "epoch:  1500 train_loss: 518.0565185546875 val_loss: 520.7032470703125\n",
      "epoch:  1600 train_loss: 435.4077453613281 val_loss: 437.9765319824219\n",
      "epoch:  1700 train_loss: 369.61041259765625 val_loss: 372.0858459472656\n",
      "epoch:  1800 train_loss: 318.0855712890625 val_loss: 320.3432312011719\n",
      "epoch:  1900 train_loss: 278.2038269042969 val_loss: 280.35089111328125\n",
      "epoch:  2000 train_loss: 247.98423767089844 val_loss: 249.93975830078125\n",
      "epoch:  2100 train_loss: 225.43031311035156 val_loss: 227.25306701660156\n",
      "epoch:  2200 train_loss: 208.88580322265625 val_loss: 210.5777130126953\n",
      "epoch:  2300 train_loss: 197.06764221191406 val_loss: 198.6189422607422\n",
      "epoch:  2400 train_loss: 188.72329711914062 val_loss: 190.19732666015625\n",
      "epoch:  2500 train_loss: 183.02554321289062 val_loss: 184.3917999267578\n",
      "epoch:  2600 train_loss: 179.23028564453125 val_loss: 180.4878387451172\n",
      "epoch:  2700 train_loss: 176.72384643554688 val_loss: 177.9070587158203\n",
      "epoch:  2800 train_loss: 175.15576171875 val_loss: 176.2638702392578\n",
      "epoch:  2900 train_loss: 174.17584228515625 val_loss: 175.23382568359375\n",
      "epoch:  3000 train_loss: 173.59608459472656 val_loss: 174.60984802246094\n",
      "epoch:  3100 train_loss: 173.24942016601562 val_loss: 174.22525024414062\n",
      "epoch:  3200 train_loss: 173.06124877929688 val_loss: 174.0112762451172\n",
      "epoch:  3300 train_loss: 172.95755004882812 val_loss: 173.88345336914062\n",
      "epoch:  3400 train_loss: 172.90333557128906 val_loss: 173.81219482421875\n",
      "epoch:  3500 train_loss: 172.87705993652344 val_loss: 173.77528381347656\n",
      "epoch:  3600 train_loss: 172.86338806152344 val_loss: 173.7519073486328\n",
      "epoch:  3700 train_loss: 172.85647583007812 val_loss: 173.7382354736328\n",
      "epoch:  3800 train_loss: 172.8541717529297 val_loss: 173.7313232421875\n",
      "epoch:  3900 train_loss: 172.85284423828125 val_loss: 173.7294464111328\n",
      "epoch:  4000 train_loss: 172.85240173339844 val_loss: 173.72486877441406\n",
      "epoch:  4100 train_loss: 172.85232543945312 val_loss: 173.72535705566406\n",
      "epoch:  4200 train_loss: 172.85226440429688 val_loss: 173.72410583496094\n",
      "epoch:  4300 train_loss: 172.85220336914062 val_loss: 173.7226104736328\n",
      "epoch:  4400 train_loss: 172.85220336914062 val_loss: 173.7218475341797\n",
      "epoch:  4500 train_loss: 172.85218811035156 val_loss: 173.72247314453125\n",
      "epoch:  4600 train_loss: 172.85218811035156 val_loss: 173.72267150878906\n",
      "epoch:  4700 train_loss: 172.85218811035156 val_loss: 173.72286987304688\n",
      "epoch:  4800 train_loss: 172.85218811035156 val_loss: 173.72286987304688\n",
      "epoch:  4900 train_loss: 172.85218811035156 val_loss: 173.72308349609375\n",
      "epoch:  5000 train_loss: 172.85218811035156 val_loss: 173.72286987304688\n",
      "epoch:  5100 train_loss: 172.85218811035156 val_loss: 173.72286987304688\n",
      "epoch:  5200 train_loss: 172.85218811035156 val_loss: 173.72286987304688\n",
      "epoch:  5300 train_loss: 172.85218811035156 val_loss: 173.7225341796875\n",
      "epoch:  5400 train_loss: 172.85218811035156 val_loss: 173.7225341796875\n",
      "epoch:  5500 train_loss: 172.85218811035156 val_loss: 173.72286987304688\n",
      "epoch:  5600 train_loss: 172.85218811035156 val_loss: 173.72254943847656\n",
      "epoch:  5700 train_loss: 172.85218811035156 val_loss: 173.72254943847656\n",
      "epoch:  5800 train_loss: 172.85218811035156 val_loss: 173.72235107421875\n",
      "epoch:  5900 train_loss: 172.85218811035156 val_loss: 173.72254943847656\n",
      "epoch:  6000 train_loss: 172.85218811035156 val_loss: 173.72286987304688\n",
      "epoch:  6100 train_loss: 172.85218811035156 val_loss: 173.72286987304688\n",
      "epoch:  6200 train_loss: 172.85218811035156 val_loss: 173.72267150878906\n",
      "epoch:  6300 train_loss: 172.85218811035156 val_loss: 173.72286987304688\n",
      "epoch:  6400 train_loss: 172.85218811035156 val_loss: 173.72254943847656\n",
      "epoch:  6500 train_loss: 172.85218811035156 val_loss: 173.72308349609375\n",
      "epoch:  6600 train_loss: 172.85218811035156 val_loss: 173.72267150878906\n",
      "epoch:  6700 train_loss: 172.85218811035156 val_loss: 173.72235107421875\n",
      "epoch:  6800 train_loss: 172.85218811035156 val_loss: 173.72286987304688\n",
      "epoch:  6900 train_loss: 172.85218811035156 val_loss: 173.72286987304688\n",
      "epoch:  7000 train_loss: 172.85218811035156 val_loss: 173.72235107421875\n",
      "epoch:  7100 train_loss: 172.85218811035156 val_loss: 173.72286987304688\n",
      "epoch:  7200 train_loss: 172.85218811035156 val_loss: 173.72286987304688\n",
      "epoch:  7300 train_loss: 172.85218811035156 val_loss: 173.72235107421875\n",
      "epoch:  7400 train_loss: 171.78750610351562 val_loss: 172.31382751464844\n",
      "epoch:  7500 train_loss: 127.6448745727539 val_loss: 128.5567169189453\n",
      "epoch:  7600 train_loss: 114.6114273071289 val_loss: 116.12144470214844\n",
      "epoch:  7700 train_loss: 103.76687622070312 val_loss: 106.37332916259766\n",
      "epoch:  7800 train_loss: 93.43116760253906 val_loss: 96.46475982666016\n",
      "epoch:  7900 train_loss: 82.06414794921875 val_loss: 84.76785278320312\n",
      "epoch:  8000 train_loss: 70.5938949584961 val_loss: 73.4658203125\n",
      "epoch:  8100 train_loss: 58.9962158203125 val_loss: 61.45351791381836\n",
      "epoch:  8200 train_loss: 46.35643768310547 val_loss: 48.27054977416992\n",
      "epoch:  8300 train_loss: 35.58832550048828 val_loss: 37.46611022949219\n",
      "epoch:  8400 train_loss: 28.126962661743164 val_loss: 29.910799026489258\n",
      "epoch:  8500 train_loss: 24.070831298828125 val_loss: 25.809906005859375\n",
      "epoch:  8600 train_loss: 17.76811981201172 val_loss: 19.359375\n",
      "epoch:  8700 train_loss: 14.74024772644043 val_loss: 16.132722854614258\n",
      "epoch:  8800 train_loss: 12.518058776855469 val_loss: 13.802117347717285\n",
      "epoch:  8900 train_loss: 11.0211820602417 val_loss: 12.22333812713623\n",
      "epoch:  9000 train_loss: 9.975783348083496 val_loss: 11.245121002197266\n",
      "epoch:  9100 train_loss: 9.169516563415527 val_loss: 10.451061248779297\n",
      "epoch:  9200 train_loss: 8.633273124694824 val_loss: 9.923612594604492\n",
      "epoch:  9300 train_loss: 8.167372703552246 val_loss: 9.538485527038574\n",
      "epoch:  9400 train_loss: 8.25588607788086 val_loss: 9.753249168395996\n",
      "epoch:  9500 train_loss: 7.483431339263916 val_loss: 8.86562442779541\n",
      "epoch:  9600 train_loss: 7.34882926940918 val_loss: 8.739721298217773\n",
      "epoch:  9700 train_loss: 7.044491291046143 val_loss: 8.557695388793945\n",
      "epoch:  9800 train_loss: 8.267200469970703 val_loss: 9.576593399047852\n",
      "epoch:  9900 train_loss: 6.838870525360107 val_loss: 8.523468017578125\n",
      "epoch:  10000 train_loss: 6.558706760406494 val_loss: 8.235230445861816\n",
      "epoch:  10100 train_loss: 6.437807083129883 val_loss: 8.19616413116455\n",
      "epoch:  10200 train_loss: 6.307544708251953 val_loss: 8.107197761535645\n",
      "epoch:  10300 train_loss: 6.402769088745117 val_loss: 8.20189380645752\n",
      "epoch:  10400 train_loss: 6.110567569732666 val_loss: 8.046365737915039\n",
      "epoch:  10500 train_loss: 5.989528179168701 val_loss: 7.944839954376221\n",
      "epoch:  10600 train_loss: 5.944874286651611 val_loss: 7.98217248916626\n",
      "epoch:  10700 train_loss: 5.805927753448486 val_loss: 7.8715362548828125\n",
      "epoch:  10800 train_loss: 5.720019340515137 val_loss: 7.868977069854736\n",
      "epoch:  10900 train_loss: 5.872804164886475 val_loss: 7.94977331161499\n",
      "epoch:  11000 train_loss: 5.571532726287842 val_loss: 7.887820243835449\n",
      "epoch:  11100 train_loss: 5.470444679260254 val_loss: 7.816329479217529\n",
      "epoch:  11200 train_loss: 5.779549598693848 val_loss: 7.875983715057373\n",
      "epoch:  11300 train_loss: 5.372507572174072 val_loss: 7.881197929382324\n",
      "epoch:  11400 train_loss: 5.249862194061279 val_loss: 7.85118293762207\n",
      "epoch:  11500 train_loss: 5.242897033691406 val_loss: 7.860621452331543\n",
      "epoch:  11600 train_loss: 5.115776062011719 val_loss: 7.892829895019531\n",
      "epoch:  11700 train_loss: 5.105782508850098 val_loss: 7.922211170196533\n",
      "epoch:  11800 train_loss: 4.989631175994873 val_loss: 7.929511547088623\n",
      "epoch:  11900 train_loss: 4.920019149780273 val_loss: 7.951369762420654\n",
      "epoch:  12000 train_loss: 4.86463737487793 val_loss: 7.971001625061035\n",
      "epoch:  12100 train_loss: 4.7924418449401855 val_loss: 7.986361980438232\n",
      "epoch:  12200 train_loss: 4.735140323638916 val_loss: 8.012537002563477\n",
      "epoch:  12300 train_loss: 4.7101922035217285 val_loss: 8.039594650268555\n",
      "epoch:  12400 train_loss: 4.635792255401611 val_loss: 8.136899948120117\n",
      "epoch:  12500 train_loss: 4.659529209136963 val_loss: 8.236343383789062\n",
      "epoch:  12600 train_loss: 4.528535842895508 val_loss: 8.144159317016602\n",
      "epoch:  12700 train_loss: 4.386514186859131 val_loss: 8.241663932800293\n",
      "epoch:  12800 train_loss: 4.509805679321289 val_loss: 8.391887664794922\n",
      "epoch:  12900 train_loss: 4.412263870239258 val_loss: 8.490058898925781\n",
      "epoch:  13000 train_loss: 4.189988136291504 val_loss: 8.397756576538086\n",
      "epoch:  13100 train_loss: 4.120289325714111 val_loss: 8.42634391784668\n",
      "epoch:  13200 train_loss: 4.067610740661621 val_loss: 8.4785795211792\n",
      "epoch:  13300 train_loss: 4.02489709854126 val_loss: 8.588358879089355\n",
      "epoch:  13400 train_loss: 4.1719970703125 val_loss: 8.818394660949707\n",
      "epoch:  13500 train_loss: 3.8776628971099854 val_loss: 8.655256271362305\n",
      "epoch:  13600 train_loss: 4.235001087188721 val_loss: 9.00328254699707\n",
      "epoch:  13700 train_loss: 3.7905333042144775 val_loss: 8.792494773864746\n",
      "epoch:  13800 train_loss: 3.696681499481201 val_loss: 8.939757347106934\n",
      "epoch:  13900 train_loss: 3.7191922664642334 val_loss: 9.076714515686035\n",
      "epoch:  14000 train_loss: 3.6238961219787598 val_loss: 9.084907531738281\n",
      "epoch:  14100 train_loss: 3.5030648708343506 val_loss: 9.112274169921875\n",
      "epoch:  14200 train_loss: 3.5404481887817383 val_loss: 9.289012908935547\n",
      "epoch:  14300 train_loss: 3.484485387802124 val_loss: 9.261417388916016\n",
      "epoch:  14400 train_loss: 3.4485514163970947 val_loss: 9.549614906311035\n",
      "epoch:  14500 train_loss: 3.363185405731201 val_loss: 9.684168815612793\n",
      "epoch:  14600 train_loss: 3.5699100494384766 val_loss: 9.962776184082031\n",
      "epoch:  14700 train_loss: 3.130324125289917 val_loss: 9.739728927612305\n",
      "epoch:  14800 train_loss: 3.0634090900421143 val_loss: 9.798195838928223\n",
      "epoch:  14900 train_loss: 3.008484125137329 val_loss: 9.941838264465332\n",
      "epoch:  15000 train_loss: 3.003797769546509 val_loss: 9.982532501220703\n",
      "epoch:  15100 train_loss: 2.868673086166382 val_loss: 10.086139678955078\n",
      "epoch:  15200 train_loss: 3.004080295562744 val_loss: 10.271965026855469\n",
      "epoch:  15300 train_loss: 2.958925485610962 val_loss: 10.389854431152344\n",
      "epoch:  15400 train_loss: 3.0462114810943604 val_loss: 10.445253372192383\n",
      "epoch:  15500 train_loss: 2.8309006690979004 val_loss: 10.484976768493652\n",
      "epoch:  15600 train_loss: 2.6458239555358887 val_loss: 10.541196823120117\n",
      "epoch:  15700 train_loss: 2.6950621604919434 val_loss: 10.659165382385254\n",
      "epoch:  15800 train_loss: 2.515040159225464 val_loss: 10.642468452453613\n",
      "epoch:  15900 train_loss: 2.5775017738342285 val_loss: 10.81085205078125\n",
      "epoch:  16000 train_loss: 2.6098780632019043 val_loss: 10.843710899353027\n",
      "epoch:  16100 train_loss: 2.4807682037353516 val_loss: 10.884241104125977\n",
      "epoch:  16200 train_loss: 2.5358541011810303 val_loss: 10.973159790039062\n",
      "epoch:  16300 train_loss: 2.393397331237793 val_loss: 11.139317512512207\n",
      "epoch:  16400 train_loss: 2.269765853881836 val_loss: 11.146074295043945\n",
      "epoch:  16500 train_loss: 2.294935703277588 val_loss: 11.214292526245117\n",
      "epoch:  16600 train_loss: 2.24347186088562 val_loss: 11.30366039276123\n",
      "epoch:  16700 train_loss: 2.125142812728882 val_loss: 11.454569816589355\n",
      "epoch:  16800 train_loss: 2.1147568225860596 val_loss: 11.519694328308105\n",
      "epoch:  16900 train_loss: 2.045098066329956 val_loss: 11.658626556396484\n",
      "epoch:  17000 train_loss: 2.148282051086426 val_loss: 11.685233116149902\n",
      "epoch:  17100 train_loss: 2.1036667823791504 val_loss: 11.791658401489258\n",
      "epoch:  17200 train_loss: 1.9502228498458862 val_loss: 11.857294082641602\n",
      "epoch:  17300 train_loss: 1.9680548906326294 val_loss: 11.971549034118652\n",
      "epoch:  17400 train_loss: 1.949162483215332 val_loss: 12.186568260192871\n",
      "epoch:  17500 train_loss: 1.9279834032058716 val_loss: 12.103196144104004\n",
      "epoch:  17600 train_loss: 1.8088181018829346 val_loss: 12.296185493469238\n",
      "epoch:  17700 train_loss: 1.9078844785690308 val_loss: 12.42039966583252\n",
      "epoch:  17800 train_loss: 1.7856173515319824 val_loss: 12.417667388916016\n",
      "epoch:  17900 train_loss: 1.8552409410476685 val_loss: 12.579670906066895\n",
      "epoch:  18000 train_loss: 1.7142964601516724 val_loss: 12.637537956237793\n",
      "epoch:  18100 train_loss: 1.7071791887283325 val_loss: 12.590787887573242\n",
      "epoch:  18200 train_loss: 1.6610431671142578 val_loss: 12.802903175354004\n",
      "epoch:  18300 train_loss: 1.7367866039276123 val_loss: 12.716044425964355\n",
      "epoch:  18400 train_loss: 1.5967485904693604 val_loss: 12.943500518798828\n",
      "epoch:  18500 train_loss: 1.5326833724975586 val_loss: 12.924492835998535\n",
      "epoch:  18600 train_loss: 1.5447275638580322 val_loss: 12.992852210998535\n",
      "epoch:  18700 train_loss: 1.5308884382247925 val_loss: 13.056447982788086\n",
      "epoch:  18800 train_loss: 1.5372384786605835 val_loss: 13.256282806396484\n",
      "epoch:  18900 train_loss: 1.4310251474380493 val_loss: 13.248745918273926\n",
      "epoch:  19000 train_loss: 1.4754499197006226 val_loss: 13.328924179077148\n",
      "epoch:  19100 train_loss: 1.496681571006775 val_loss: 13.431838035583496\n",
      "epoch:  19200 train_loss: 1.705276608467102 val_loss: 13.411148071289062\n",
      "epoch:  19300 train_loss: 1.3502389192581177 val_loss: 13.591909408569336\n",
      "epoch:  19400 train_loss: 1.354857325553894 val_loss: 13.504866600036621\n",
      "epoch:  19500 train_loss: 1.3817046880722046 val_loss: 13.528524398803711\n",
      "epoch:  19600 train_loss: 1.3820874691009521 val_loss: 13.645828247070312\n",
      "epoch:  19700 train_loss: 1.3476064205169678 val_loss: 13.809897422790527\n",
      "epoch:  19800 train_loss: 1.251114010810852 val_loss: 13.768503189086914\n",
      "epoch:  19900 train_loss: 1.2794837951660156 val_loss: 13.733247756958008\n",
      "epoch:  20000 train_loss: 1.2310287952423096 val_loss: 13.96094799041748\n",
      "epoch:  20100 train_loss: 1.194836139678955 val_loss: 13.928731918334961\n",
      "epoch:  20200 train_loss: 1.2175281047821045 val_loss: 14.160664558410645\n",
      "epoch:  20300 train_loss: 1.1953940391540527 val_loss: 14.145158767700195\n",
      "epoch:  20400 train_loss: 1.1420198678970337 val_loss: 14.113537788391113\n",
      "epoch:  20500 train_loss: 1.1158688068389893 val_loss: 14.316751480102539\n",
      "epoch:  20600 train_loss: 1.1141963005065918 val_loss: 14.162029266357422\n",
      "epoch:  20700 train_loss: 1.4053430557250977 val_loss: 14.590925216674805\n",
      "epoch:  20800 train_loss: 1.2525781393051147 val_loss: 14.29412841796875\n",
      "epoch:  20900 train_loss: 1.0795159339904785 val_loss: 14.274685859680176\n",
      "epoch:  21000 train_loss: 1.2718584537506104 val_loss: 14.756258964538574\n",
      "epoch:  21100 train_loss: 1.1235769987106323 val_loss: 14.495640754699707\n",
      "epoch:  21200 train_loss: 1.012658715248108 val_loss: 14.459540367126465\n",
      "epoch:  21300 train_loss: 1.1249243021011353 val_loss: 14.649110794067383\n",
      "epoch:  21400 train_loss: 0.9694589972496033 val_loss: 14.521164894104004\n",
      "epoch:  21500 train_loss: 0.9144618511199951 val_loss: 14.758368492126465\n",
      "epoch:  21600 train_loss: 0.9317434430122375 val_loss: 14.558165550231934\n",
      "epoch:  21700 train_loss: 0.9170430898666382 val_loss: 14.791069984436035\n",
      "epoch:  21800 train_loss: 0.951574981212616 val_loss: 14.911675453186035\n",
      "epoch:  21900 train_loss: 1.0896975994110107 val_loss: 14.88757610321045\n",
      "epoch:  22000 train_loss: 0.8667239546775818 val_loss: 14.946758270263672\n",
      "epoch:  22100 train_loss: 1.3627958297729492 val_loss: 14.77509593963623\n",
      "epoch:  22200 train_loss: 0.9006468653678894 val_loss: 14.91976261138916\n",
      "epoch:  22300 train_loss: 0.8541737794876099 val_loss: 15.097501754760742\n",
      "epoch:  22400 train_loss: 0.8163303732872009 val_loss: 15.005428314208984\n",
      "epoch:  22500 train_loss: 0.8114197254180908 val_loss: 15.154776573181152\n",
      "epoch:  22600 train_loss: 0.908000648021698 val_loss: 15.220778465270996\n",
      "epoch:  22700 train_loss: 0.7877825498580933 val_loss: 15.093953132629395\n",
      "epoch:  22800 train_loss: 0.8280072212219238 val_loss: 15.137419700622559\n",
      "epoch:  22900 train_loss: 0.9764143824577332 val_loss: 15.197502136230469\n",
      "epoch:  23000 train_loss: 0.8364293575286865 val_loss: 15.41504192352295\n",
      "epoch:  23100 train_loss: 0.8269798755645752 val_loss: 15.474879264831543\n",
      "epoch:  23200 train_loss: 0.7041375637054443 val_loss: 15.309731483459473\n",
      "epoch:  23300 train_loss: 0.9707354307174683 val_loss: 15.52011775970459\n",
      "epoch:  23400 train_loss: 0.7412614226341248 val_loss: 15.283867835998535\n",
      "epoch:  23500 train_loss: 0.7007116079330444 val_loss: 15.48043155670166\n",
      "epoch:  23600 train_loss: 0.6821796298027039 val_loss: 15.45405387878418\n",
      "epoch:  23700 train_loss: 0.7490226030349731 val_loss: 15.491291999816895\n",
      "epoch:  23800 train_loss: 0.6673839092254639 val_loss: 15.393574714660645\n",
      "epoch:  23900 train_loss: 0.7044249176979065 val_loss: 15.55246353149414\n",
      "epoch:  24000 train_loss: 0.6597195863723755 val_loss: 15.43386459350586\n",
      "epoch:  24100 train_loss: 0.8106682896614075 val_loss: 15.393901824951172\n",
      "epoch:  24200 train_loss: 0.6837959885597229 val_loss: 15.54694652557373\n",
      "epoch:  24300 train_loss: 0.6811969876289368 val_loss: 15.587669372558594\n",
      "epoch:  24400 train_loss: 0.7531951665878296 val_loss: 15.727205276489258\n",
      "epoch:  24500 train_loss: 0.6672168970108032 val_loss: 15.567995071411133\n",
      "epoch:  24600 train_loss: 0.6221727132797241 val_loss: 15.586609840393066\n",
      "epoch:  24700 train_loss: 0.6582057476043701 val_loss: 15.580940246582031\n",
      "epoch:  24800 train_loss: 0.547305166721344 val_loss: 15.651790618896484\n",
      "epoch:  24900 train_loss: 0.6587632894515991 val_loss: 15.608467102050781\n",
      "epoch:  25000 train_loss: 0.5337547659873962 val_loss: 15.743066787719727\n",
      "epoch:  25100 train_loss: 0.5403451919555664 val_loss: 15.663897514343262\n",
      "epoch:  25200 train_loss: 0.6530284881591797 val_loss: 15.802264213562012\n",
      "epoch:  25300 train_loss: 0.5576711893081665 val_loss: 15.867475509643555\n",
      "epoch:  25400 train_loss: 0.49164944887161255 val_loss: 15.81201457977295\n",
      "epoch:  25500 train_loss: 0.6076622605323792 val_loss: 15.835784912109375\n",
      "epoch:  25600 train_loss: 0.573401927947998 val_loss: 15.914383888244629\n",
      "epoch:  25700 train_loss: 0.5111441016197205 val_loss: 15.69514274597168\n",
      "epoch:  25800 train_loss: 0.6117280125617981 val_loss: 15.770511627197266\n",
      "epoch:  25900 train_loss: 0.5133455395698547 val_loss: 15.676186561584473\n",
      "epoch:  26000 train_loss: 0.4829764664173126 val_loss: 15.836228370666504\n",
      "epoch:  26100 train_loss: 0.48404133319854736 val_loss: 15.906255722045898\n",
      "epoch:  26200 train_loss: 0.4630703628063202 val_loss: 15.937960624694824\n",
      "epoch:  26300 train_loss: 0.518334686756134 val_loss: 15.996254920959473\n",
      "epoch:  26400 train_loss: 0.4869542419910431 val_loss: 15.781829833984375\n",
      "epoch:  26500 train_loss: 0.46456530690193176 val_loss: 15.903554916381836\n",
      "epoch:  26600 train_loss: 0.43092605471611023 val_loss: 15.889095306396484\n",
      "epoch:  26700 train_loss: 0.45052558183670044 val_loss: 15.861836433410645\n",
      "epoch:  26800 train_loss: 0.42190003395080566 val_loss: 16.024229049682617\n",
      "epoch:  26900 train_loss: 0.4139188826084137 val_loss: 16.01814079284668\n",
      "epoch:  27000 train_loss: 0.4339248836040497 val_loss: 15.99575138092041\n",
      "epoch:  27100 train_loss: 0.4328860938549042 val_loss: 15.902771949768066\n",
      "epoch:  27200 train_loss: 0.39790651202201843 val_loss: 15.894213676452637\n",
      "epoch:  27300 train_loss: 0.3844141960144043 val_loss: 16.080238342285156\n",
      "epoch:  27400 train_loss: 0.3956492841243744 val_loss: 15.941970825195312\n",
      "epoch:  27500 train_loss: 0.5928856134414673 val_loss: 15.880575180053711\n",
      "epoch:  27600 train_loss: 0.38333168625831604 val_loss: 16.127384185791016\n",
      "epoch:  27700 train_loss: 0.3599891662597656 val_loss: 16.156496047973633\n",
      "epoch:  27800 train_loss: 0.3649691641330719 val_loss: 16.14756965637207\n",
      "epoch:  27900 train_loss: 0.6924721002578735 val_loss: 16.465818405151367\n",
      "epoch:  28000 train_loss: 0.5916764736175537 val_loss: 15.967984199523926\n",
      "epoch:  28100 train_loss: 0.3456738293170929 val_loss: 16.080739974975586\n",
      "epoch:  28200 train_loss: 0.3668276071548462 val_loss: 16.2061767578125\n",
      "epoch:  28300 train_loss: 0.5448936820030212 val_loss: 15.955215454101562\n",
      "epoch:  28400 train_loss: 0.4109771251678467 val_loss: 16.304214477539062\n",
      "epoch:  28500 train_loss: 0.3985018730163574 val_loss: 16.031362533569336\n",
      "epoch:  28600 train_loss: 0.39174899458885193 val_loss: 16.30287742614746\n",
      "epoch:  28700 train_loss: 0.3449662923812866 val_loss: 16.108203887939453\n",
      "epoch:  28800 train_loss: 0.31175798177719116 val_loss: 16.115896224975586\n",
      "epoch:  28900 train_loss: 0.31144091486930847 val_loss: 16.111976623535156\n",
      "epoch:  29000 train_loss: 0.3113058805465698 val_loss: 16.158334732055664\n",
      "epoch:  29100 train_loss: 0.3083256185054779 val_loss: 16.188032150268555\n",
      "epoch:  29200 train_loss: 0.3231477737426758 val_loss: 16.040443420410156\n",
      "epoch:  29300 train_loss: 0.31206533312797546 val_loss: 16.138885498046875\n",
      "epoch:  29400 train_loss: 0.30599677562713623 val_loss: 16.025161743164062\n",
      "epoch:  29500 train_loss: 0.38366082310676575 val_loss: 16.11747169494629\n",
      "epoch:  29600 train_loss: 0.33300939202308655 val_loss: 16.223299026489258\n",
      "epoch:  29700 train_loss: 0.36367982625961304 val_loss: 16.298208236694336\n",
      "epoch:  29800 train_loss: 0.31468120217323303 val_loss: 16.03273582458496\n",
      "epoch:  29900 train_loss: 0.493717223405838 val_loss: 16.507421493530273\n",
      "epoch:  30000 train_loss: 0.288039892911911 val_loss: 16.238439559936523\n",
      "epoch:  30100 train_loss: 0.5919401049613953 val_loss: 16.055524826049805\n",
      "epoch:  30200 train_loss: 0.2674749195575714 val_loss: 16.337825775146484\n",
      "epoch:  30300 train_loss: 0.24382486939430237 val_loss: 16.272132873535156\n",
      "epoch:  30400 train_loss: 0.2609264850616455 val_loss: 16.192480087280273\n",
      "epoch:  30500 train_loss: 0.2659527659416199 val_loss: 16.197429656982422\n",
      "epoch:  30600 train_loss: 0.265935480594635 val_loss: 16.361425399780273\n",
      "epoch:  30700 train_loss: 0.24923408031463623 val_loss: 16.212995529174805\n",
      "epoch:  30800 train_loss: 0.26480191946029663 val_loss: 16.2230281829834\n",
      "epoch:  30900 train_loss: 0.2541549503803253 val_loss: 16.191856384277344\n",
      "epoch:  31000 train_loss: 0.254307359457016 val_loss: 16.203453063964844\n",
      "epoch:  31100 train_loss: 0.29004865884780884 val_loss: 16.28316307067871\n",
      "epoch:  31200 train_loss: 0.2374744862318039 val_loss: 16.287147521972656\n",
      "epoch:  31300 train_loss: 0.2545461356639862 val_loss: 16.287790298461914\n",
      "epoch:  31400 train_loss: 0.25810685753822327 val_loss: 16.2641658782959\n",
      "epoch:  31500 train_loss: 0.24194574356079102 val_loss: 16.200393676757812\n",
      "epoch:  31600 train_loss: 0.27547672390937805 val_loss: 16.207460403442383\n",
      "epoch:  31700 train_loss: 0.24521394073963165 val_loss: 16.295629501342773\n",
      "epoch:  31800 train_loss: 0.26977524161338806 val_loss: 16.284143447875977\n",
      "epoch:  31900 train_loss: 0.2098725438117981 val_loss: 16.205354690551758\n",
      "epoch:  32000 train_loss: 0.43899667263031006 val_loss: 16.43720245361328\n",
      "epoch:  32100 train_loss: 0.25277677178382874 val_loss: 16.39832878112793\n",
      "epoch:  32200 train_loss: 0.1945696771144867 val_loss: 16.270893096923828\n",
      "epoch:  32300 train_loss: 0.244421124458313 val_loss: 16.33077049255371\n",
      "epoch:  32400 train_loss: 0.1946830004453659 val_loss: 16.39242172241211\n",
      "epoch:  32500 train_loss: 0.2714823782444 val_loss: 16.373516082763672\n",
      "epoch:  32600 train_loss: 0.27395376563072205 val_loss: 16.595666885375977\n",
      "epoch:  32700 train_loss: 0.42818617820739746 val_loss: 16.125043869018555\n",
      "epoch:  32800 train_loss: 0.23715443909168243 val_loss: 16.495635986328125\n",
      "epoch:  32900 train_loss: 0.2093983292579651 val_loss: 16.32477378845215\n",
      "epoch:  33000 train_loss: 0.1929415464401245 val_loss: 16.41996192932129\n",
      "epoch:  33100 train_loss: 0.2354729324579239 val_loss: 16.547765731811523\n",
      "epoch:  33200 train_loss: 0.22699473798274994 val_loss: 16.28082275390625\n",
      "epoch:  33300 train_loss: 0.20489628612995148 val_loss: 16.431543350219727\n",
      "epoch:  33400 train_loss: 0.18119128048419952 val_loss: 16.333921432495117\n",
      "epoch:  33500 train_loss: 0.20939888060092926 val_loss: 16.26534080505371\n",
      "epoch:  33600 train_loss: 0.16141967475414276 val_loss: 16.386348724365234\n",
      "epoch:  33700 train_loss: 0.17054186761379242 val_loss: 16.48431396484375\n",
      "epoch:  33800 train_loss: 0.17857205867767334 val_loss: 16.37333106994629\n",
      "epoch:  33900 train_loss: 0.1929009109735489 val_loss: 16.3528995513916\n",
      "epoch:  34000 train_loss: 0.36757245659828186 val_loss: 16.80852508544922\n",
      "epoch:  34100 train_loss: 0.15636339783668518 val_loss: 16.362363815307617\n",
      "epoch:  34200 train_loss: 0.21347831189632416 val_loss: 16.582780838012695\n",
      "epoch:  34300 train_loss: 0.4030408561229706 val_loss: 16.626245498657227\n",
      "epoch:  34400 train_loss: 0.42198270559310913 val_loss: 16.674976348876953\n",
      "epoch:  34500 train_loss: 0.17526045441627502 val_loss: 16.528684616088867\n",
      "epoch:  34600 train_loss: 0.5955243706703186 val_loss: 16.794458389282227\n",
      "epoch:  34700 train_loss: 0.17595890164375305 val_loss: 16.425506591796875\n",
      "epoch:  34800 train_loss: 0.17161798477172852 val_loss: 16.453275680541992\n",
      "epoch:  34900 train_loss: 0.19565361738204956 val_loss: 16.595552444458008\n",
      "epoch:  35000 train_loss: 0.20489665865898132 val_loss: 16.325895309448242\n",
      "epoch:  35100 train_loss: 0.19006139039993286 val_loss: 16.461576461791992\n",
      "epoch:  35200 train_loss: 0.30474990606307983 val_loss: 16.735742568969727\n",
      "epoch:  35300 train_loss: 0.13962726294994354 val_loss: 16.434467315673828\n",
      "epoch:  35400 train_loss: 0.1889190524816513 val_loss: 16.506622314453125\n",
      "epoch:  35500 train_loss: 0.16295906901359558 val_loss: 16.383831024169922\n",
      "epoch:  35600 train_loss: 0.3845723569393158 val_loss: 16.334875106811523\n",
      "epoch:  35700 train_loss: 0.14422181248664856 val_loss: 16.49700164794922\n",
      "epoch:  35800 train_loss: 0.1298455148935318 val_loss: 16.495128631591797\n",
      "epoch:  35900 train_loss: 0.14814138412475586 val_loss: 16.440942764282227\n",
      "sigma: 4.6 RMSE:  tensor(5.0541, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Generate the dataset with noise N(0, sigma)\n",
    "i = 0\n",
    "sigma = 4.6\n",
    "my_dataset = []\n",
    "for ud in UDs:\n",
    "    example = []\n",
    "    for an in ANs:\n",
    "        noise = np.random.normal(0,sigma)\n",
    "        # 0 is mean\n",
    "        # sigma is the deviation of the normal distribution\n",
    "        d = compute_3d_distance(ud, an) + noise\n",
    "        example.append(d)\n",
    "    \n",
    "    # append x, y, z as col#10, #11, #12\n",
    "    example.append(ud[0])\n",
    "    example.append(ud[1])\n",
    "    example.append(ud[2])\n",
    "    \n",
    "    # append 1x13 example row into my_dataset\n",
    "    my_dataset.append(example)  # expected to be 3000x13  \n",
    "    \n",
    "# Load dataset\n",
    "exercise5_dataset = Exercise5Dataset(list_dataset = my_dataset, shuffle=True)\n",
    "\n",
    "#Split dataset by 0.8: 0.1: 0.1\n",
    "train_examples, train_labels = exercise5_dataset[:int(3000*0.8)]  # (2400, 10)   # (2400, 3)\n",
    "val_examples, val_labels = exercise5_dataset[int(3000*0.8):int(3000*0.9)]    # (300, 10)   #(300, 3)\n",
    "test_examples, test_labels = exercise5_dataset[int(3000*0.9):]     #(300, 10)   # (300, 3)\n",
    "\n",
    "###Define model, loss function and optimizer\n",
    "# if we have GPU, then use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define model\n",
    "#model = Net(x_dim = train_examples.shape[1], y_dim = train_labels.shape[1]).to(device)\n",
    "input_dim = 1     #input dim is 1, seq_len = 10\n",
    "hidden_dim = 64   #hidden state dim is 64\n",
    "n_layers = 3             #3-layered LSTM\n",
    "model = MYLSTM(input_dim, hidden_dim, n_layers).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Correct the input/output shape for LSTM\n",
    "train_inputs = torch.unsqueeze(train_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "train_inputs = train_inputs.to(device) \n",
    "\n",
    "val_inputs = torch.unsqueeze(val_examples, dim=-1)   # (N, 10) -> (N, 10, 1)\n",
    "val_inputs = val_inputs.to(device) \n",
    "\n",
    "train_labels = train_labels.to(device)   #(N, 3)\n",
    "val_labels = val_labels.to(device)          #(N, 3)\n",
    "\n",
    "\n",
    "# Define the loss threshold, if the current train loss is lower than the threshold, we will begin to save the model\n",
    "best_loss = 100.0\n",
    "\n",
    "# Define the model filename for model.save()\n",
    "MODEL_FILENAME = \"best.pth\"\n",
    "\n",
    "# set model to Training mode\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "NUM_OF_EPOCH = 36000\n",
    "\n",
    "# Train\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    y_pred = model(train_inputs)\n",
    "    loss = loss_fn(y_pred, train_labels).cpu()\n",
    "    #print(t, loss.item())\n",
    "    train_losses.append(loss.item())\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    # BGD\n",
    "    optimizer.step()\n",
    "    \n",
    "    # evaluate validation loss\n",
    "    val_pred = model(val_inputs)\n",
    "    loss = loss_fn(val_pred, val_labels)\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "\n",
    "\n",
    "    if (epoch % 100) == 0:\n",
    "        print(\"epoch: \", epoch, \"train_loss:\", train_losses[-1], \"val_loss:\", val_losses[-1])\n",
    "        # check if we got better loss\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n",
    "        \n",
    "# Load the best model on previous step\n",
    "model.load_state_dict(torch.load(\"best.pth\"))\n",
    "\n",
    "# Inference all testing examples and compute RMSE\n",
    "def square_error(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  square_error= loss_fn(a, b)\n",
    "  return square_error\n",
    "\n",
    "model.eval() # inference mode\n",
    "test_inputs = torch.unsqueeze(test_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "test_inputs = test_inputs.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "\n",
    "test_preds = model(test_inputs)\n",
    "#print(\"example: \", test_example.cpu())\n",
    "#print(\"========================================\")\n",
    "#print(\"ground_truth:\", test_label.cpu())\n",
    "#print(\"prediction:\", test_pred.cpu())\n",
    "#print(\"========================================\")\n",
    "\n",
    "\n",
    "total_errors = 0.0\n",
    "for idx in range(len(test_inputs)):\n",
    "    total_errors += square_error(test_preds[idx], test_labels[idx])\n",
    "    \n",
    "RMSE = torch.sqrt(total_errors / len(test_inputs))\n",
    "print(\"sigma:\", sigma, \"RMSE: \",  RMSE)\n",
    "\n",
    "sigmas.append(sigma)\n",
    "RMSEs.append(RMSE.cpu().detach().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigma = 5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffle = True!\n",
      "epoch:  0 train_loss: 7324.1953125 val_loss: 7262.0947265625\n",
      "epoch:  100 train_loss: 5908.982421875 val_loss: 5844.51904296875\n",
      "epoch:  200 train_loss: 5002.35546875 val_loss: 4942.93359375\n",
      "epoch:  300 train_loss: 4250.24560546875 val_loss: 4195.173828125\n",
      "epoch:  400 train_loss: 3609.9189453125 val_loss: 3558.659912109375\n",
      "epoch:  500 train_loss: 3061.1982421875 val_loss: 3013.77197265625\n",
      "epoch:  600 train_loss: 2589.735595703125 val_loss: 2546.04052734375\n",
      "epoch:  700 train_loss: 2184.65966796875 val_loss: 2144.5830078125\n",
      "epoch:  800 train_loss: 1837.078369140625 val_loss: 1800.4219970703125\n",
      "epoch:  900 train_loss: 1539.584228515625 val_loss: 1506.341552734375\n",
      "epoch:  1000 train_loss: 1285.9447021484375 val_loss: 1255.906982421875\n",
      "epoch:  1100 train_loss: 1071.103759765625 val_loss: 1044.1871337890625\n",
      "epoch:  1200 train_loss: 890.3026733398438 val_loss: 866.4234008789062\n",
      "epoch:  1300 train_loss: 739.5667114257812 val_loss: 718.6979370117188\n",
      "epoch:  1400 train_loss: 615.2669067382812 val_loss: 596.8386840820312\n",
      "epoch:  1500 train_loss: 513.84228515625 val_loss: 497.78765869140625\n",
      "epoch:  1600 train_loss: 432.0450744628906 val_loss: 418.19244384765625\n",
      "epoch:  1700 train_loss: 366.9175109863281 val_loss: 355.1311340332031\n",
      "epoch:  1800 train_loss: 315.86407470703125 val_loss: 305.986328125\n",
      "epoch:  1900 train_loss: 276.488037109375 val_loss: 268.2655334472656\n",
      "epoch:  2000 train_loss: 246.591552734375 val_loss: 239.8023223876953\n",
      "epoch:  2100 train_loss: 224.28179931640625 val_loss: 218.83226013183594\n",
      "epoch:  2200 train_loss: 207.9962158203125 val_loss: 203.65330505371094\n",
      "epoch:  2300 train_loss: 196.31910705566406 val_loss: 192.96414184570312\n",
      "epoch:  2400 train_loss: 188.11874389648438 val_loss: 185.61631774902344\n",
      "epoch:  2500 train_loss: 182.5135498046875 val_loss: 180.69822692871094\n",
      "epoch:  2600 train_loss: 178.75306701660156 val_loss: 177.5431365966797\n",
      "epoch:  2700 train_loss: 176.2948760986328 val_loss: 175.58261108398438\n",
      "epoch:  2800 train_loss: 174.74317932128906 val_loss: 174.4362030029297\n",
      "epoch:  2900 train_loss: 173.7855987548828 val_loss: 173.79852294921875\n",
      "epoch:  3000 train_loss: 173.21389770507812 val_loss: 173.47837829589844\n",
      "epoch:  3100 train_loss: 172.88128662109375 val_loss: 173.3501739501953\n",
      "epoch:  3200 train_loss: 172.69677734375 val_loss: 173.31707763671875\n",
      "epoch:  3300 train_loss: 172.59375 val_loss: 173.33010864257812\n",
      "epoch:  3400 train_loss: 172.54112243652344 val_loss: 173.36354064941406\n",
      "epoch:  3500 train_loss: 172.51608276367188 val_loss: 173.3976287841797\n",
      "epoch:  3600 train_loss: 172.50332641601562 val_loss: 173.42898559570312\n",
      "epoch:  3700 train_loss: 172.49703979492188 val_loss: 173.45603942871094\n",
      "epoch:  3800 train_loss: 172.49472045898438 val_loss: 173.4736785888672\n",
      "epoch:  3900 train_loss: 172.4935760498047 val_loss: 173.48802185058594\n",
      "epoch:  4000 train_loss: 172.4930877685547 val_loss: 173.49697875976562\n",
      "epoch:  4100 train_loss: 172.492919921875 val_loss: 173.50250244140625\n",
      "epoch:  4200 train_loss: 172.49288940429688 val_loss: 173.50418090820312\n",
      "epoch:  4300 train_loss: 172.4928741455078 val_loss: 173.50851440429688\n",
      "epoch:  4400 train_loss: 172.4928741455078 val_loss: 173.50808715820312\n",
      "epoch:  4500 train_loss: 172.4928741455078 val_loss: 173.50901794433594\n",
      "epoch:  4600 train_loss: 172.4928741455078 val_loss: 173.50991821289062\n",
      "epoch:  4700 train_loss: 172.4928741455078 val_loss: 173.50991821289062\n",
      "epoch:  4800 train_loss: 172.4928741455078 val_loss: 173.50990295410156\n",
      "epoch:  4900 train_loss: 172.4928741455078 val_loss: 173.50990295410156\n",
      "epoch:  5000 train_loss: 172.4928741455078 val_loss: 173.5096893310547\n",
      "epoch:  5100 train_loss: 172.4928741455078 val_loss: 173.5096893310547\n",
      "epoch:  5200 train_loss: 172.49285888671875 val_loss: 173.50949096679688\n",
      "epoch:  5300 train_loss: 172.49285888671875 val_loss: 173.50949096679688\n",
      "epoch:  5400 train_loss: 172.4928741455078 val_loss: 173.5096893310547\n",
      "epoch:  5500 train_loss: 172.49285888671875 val_loss: 173.50949096679688\n",
      "epoch:  5600 train_loss: 172.4928741455078 val_loss: 173.5096893310547\n",
      "epoch:  5700 train_loss: 172.4928741455078 val_loss: 173.5096893310547\n",
      "epoch:  5800 train_loss: 172.4928741455078 val_loss: 173.5096893310547\n",
      "epoch:  5900 train_loss: 172.49285888671875 val_loss: 173.50949096679688\n",
      "epoch:  6000 train_loss: 172.4928741455078 val_loss: 173.5096893310547\n",
      "epoch:  6100 train_loss: 172.49285888671875 val_loss: 173.5096893310547\n",
      "epoch:  6200 train_loss: 172.4928741455078 val_loss: 173.5096893310547\n",
      "epoch:  6300 train_loss: 172.4928741455078 val_loss: 173.5096893310547\n",
      "epoch:  6400 train_loss: 172.49285888671875 val_loss: 173.50949096679688\n",
      "epoch:  6500 train_loss: 172.49285888671875 val_loss: 173.50949096679688\n",
      "epoch:  6600 train_loss: 172.49285888671875 val_loss: 173.50949096679688\n",
      "epoch:  6700 train_loss: 172.4928741455078 val_loss: 173.5096893310547\n",
      "epoch:  6800 train_loss: 172.49285888671875 val_loss: 173.50949096679688\n",
      "epoch:  6900 train_loss: 172.49285888671875 val_loss: 173.50949096679688\n",
      "epoch:  7000 train_loss: 172.48992919921875 val_loss: 173.49903869628906\n",
      "epoch:  7100 train_loss: 149.05010986328125 val_loss: 146.7725372314453\n",
      "epoch:  7200 train_loss: 112.4671630859375 val_loss: 111.74781799316406\n",
      "epoch:  7300 train_loss: 101.77456665039062 val_loss: 101.21184539794922\n",
      "epoch:  7400 train_loss: 89.51583862304688 val_loss: 89.62574768066406\n",
      "epoch:  7500 train_loss: 74.33064270019531 val_loss: 74.4185791015625\n",
      "epoch:  7600 train_loss: 59.95256042480469 val_loss: 59.9241943359375\n",
      "epoch:  7700 train_loss: 47.698673248291016 val_loss: 48.34967041015625\n",
      "epoch:  7800 train_loss: 37.769168853759766 val_loss: 38.8325080871582\n",
      "epoch:  7900 train_loss: 29.92274284362793 val_loss: 31.471485137939453\n",
      "epoch:  8000 train_loss: 24.001007080078125 val_loss: 25.90928840637207\n",
      "epoch:  8100 train_loss: 19.469261169433594 val_loss: 21.761194229125977\n",
      "epoch:  8200 train_loss: 16.127408981323242 val_loss: 18.85694694519043\n",
      "epoch:  8300 train_loss: 13.694473266601562 val_loss: 16.844135284423828\n",
      "epoch:  8400 train_loss: 11.887734413146973 val_loss: 15.224859237670898\n",
      "epoch:  8500 train_loss: 10.503578186035156 val_loss: 14.223522186279297\n",
      "epoch:  8600 train_loss: 9.523553848266602 val_loss: 13.664249420166016\n",
      "epoch:  8700 train_loss: 8.565464973449707 val_loss: 13.288945198059082\n",
      "epoch:  8800 train_loss: 7.910629749298096 val_loss: 13.135316848754883\n",
      "epoch:  8900 train_loss: 7.3833184242248535 val_loss: 13.00883960723877\n",
      "epoch:  9000 train_loss: 7.074405193328857 val_loss: 13.073748588562012\n",
      "epoch:  9100 train_loss: 6.513190746307373 val_loss: 13.202383041381836\n",
      "epoch:  9200 train_loss: 6.210355281829834 val_loss: 13.160263061523438\n",
      "epoch:  9300 train_loss: 5.861763954162598 val_loss: 13.401041984558105\n",
      "epoch:  9400 train_loss: 5.618391990661621 val_loss: 13.571666717529297\n",
      "epoch:  9500 train_loss: 5.286850929260254 val_loss: 13.810102462768555\n",
      "epoch:  9600 train_loss: 5.061488628387451 val_loss: 13.93054485321045\n",
      "epoch:  9700 train_loss: 5.133788108825684 val_loss: 14.263739585876465\n",
      "epoch:  9800 train_loss: 4.567983150482178 val_loss: 14.319005966186523\n",
      "epoch:  9900 train_loss: 4.324119567871094 val_loss: 14.597332954406738\n",
      "epoch:  10000 train_loss: 4.132040023803711 val_loss: 15.055083274841309\n",
      "epoch:  10100 train_loss: 4.076646327972412 val_loss: 15.231322288513184\n",
      "epoch:  10200 train_loss: 3.6712114810943604 val_loss: 15.331860542297363\n",
      "epoch:  10300 train_loss: 3.4945716857910156 val_loss: 15.278894424438477\n",
      "epoch:  10400 train_loss: 3.2897424697875977 val_loss: 15.526726722717285\n",
      "epoch:  10500 train_loss: 3.2372846603393555 val_loss: 15.580327033996582\n",
      "epoch:  10600 train_loss: 2.969911575317383 val_loss: 15.696343421936035\n",
      "epoch:  10700 train_loss: 2.9740374088287354 val_loss: 15.811543464660645\n",
      "epoch:  10800 train_loss: 2.727311611175537 val_loss: 15.928483009338379\n",
      "epoch:  10900 train_loss: 2.5481810569763184 val_loss: 16.050113677978516\n",
      "epoch:  11000 train_loss: 2.475048303604126 val_loss: 16.263458251953125\n",
      "epoch:  11100 train_loss: 2.3670594692230225 val_loss: 16.326309204101562\n",
      "epoch:  11200 train_loss: 2.2382264137268066 val_loss: 16.45733642578125\n",
      "epoch:  11300 train_loss: 2.143327236175537 val_loss: 16.68466567993164\n",
      "epoch:  11400 train_loss: 2.0678951740264893 val_loss: 16.63691520690918\n",
      "epoch:  11500 train_loss: 1.9521921873092651 val_loss: 16.57046890258789\n",
      "epoch:  11600 train_loss: 1.8942434787750244 val_loss: 16.72437286376953\n",
      "epoch:  11700 train_loss: 1.7812104225158691 val_loss: 16.852628707885742\n",
      "epoch:  11800 train_loss: 1.7584190368652344 val_loss: 17.06270408630371\n",
      "epoch:  11900 train_loss: 1.7129501104354858 val_loss: 17.17264747619629\n",
      "epoch:  12000 train_loss: 1.6055105924606323 val_loss: 17.16705894470215\n",
      "epoch:  12100 train_loss: 1.519134283065796 val_loss: 17.310665130615234\n",
      "epoch:  12200 train_loss: 1.5142472982406616 val_loss: 17.438861846923828\n",
      "epoch:  12300 train_loss: 1.4235801696777344 val_loss: 17.410938262939453\n",
      "epoch:  12400 train_loss: 1.4167860746383667 val_loss: 17.6488094329834\n",
      "epoch:  12500 train_loss: 1.4744775295257568 val_loss: 17.77760887145996\n",
      "epoch:  12600 train_loss: 1.3014566898345947 val_loss: 17.89093017578125\n",
      "epoch:  12700 train_loss: 1.2406964302062988 val_loss: 18.039955139160156\n",
      "epoch:  12800 train_loss: 1.1882566213607788 val_loss: 18.133411407470703\n",
      "epoch:  12900 train_loss: 1.1520414352416992 val_loss: 18.142257690429688\n",
      "epoch:  13000 train_loss: 1.1240144968032837 val_loss: 18.316417694091797\n",
      "epoch:  13100 train_loss: 1.0990183353424072 val_loss: 18.454740524291992\n",
      "epoch:  13200 train_loss: 1.0331470966339111 val_loss: 18.614213943481445\n",
      "epoch:  13300 train_loss: 0.9998812079429626 val_loss: 18.585498809814453\n",
      "epoch:  13400 train_loss: 0.9952487945556641 val_loss: 18.852909088134766\n",
      "epoch:  13500 train_loss: 1.0728036165237427 val_loss: 18.920202255249023\n",
      "epoch:  13600 train_loss: 0.9529691338539124 val_loss: 18.939279556274414\n",
      "epoch:  13700 train_loss: 0.870187520980835 val_loss: 19.000072479248047\n",
      "epoch:  13800 train_loss: 0.8469433188438416 val_loss: 19.055816650390625\n",
      "epoch:  13900 train_loss: 0.8124862909317017 val_loss: 19.232383728027344\n",
      "epoch:  14000 train_loss: 0.7823309898376465 val_loss: 19.391942977905273\n",
      "epoch:  14100 train_loss: 0.803648829460144 val_loss: 19.365684509277344\n",
      "epoch:  14200 train_loss: 0.8268458843231201 val_loss: 19.31413459777832\n",
      "epoch:  14300 train_loss: 0.7211710214614868 val_loss: 19.56241798400879\n",
      "epoch:  14400 train_loss: 0.7057332396507263 val_loss: 19.593647003173828\n",
      "epoch:  14500 train_loss: 0.7627508640289307 val_loss: 19.77399444580078\n",
      "epoch:  14600 train_loss: 0.6635868549346924 val_loss: 19.743083953857422\n",
      "epoch:  14700 train_loss: 0.6466988325119019 val_loss: 19.86860466003418\n",
      "epoch:  14800 train_loss: 0.6590942740440369 val_loss: 19.931243896484375\n",
      "epoch:  14900 train_loss: 0.5944865345954895 val_loss: 20.03299331665039\n",
      "epoch:  15000 train_loss: 0.6233245730400085 val_loss: 20.270475387573242\n",
      "epoch:  15100 train_loss: 0.5394218564033508 val_loss: 20.218658447265625\n",
      "epoch:  15200 train_loss: 0.5316038727760315 val_loss: 20.279361724853516\n",
      "epoch:  15300 train_loss: 0.5276257395744324 val_loss: 20.384794235229492\n",
      "epoch:  15400 train_loss: 0.5112974643707275 val_loss: 20.379722595214844\n",
      "epoch:  15500 train_loss: 0.4861831068992615 val_loss: 20.469745635986328\n",
      "epoch:  15600 train_loss: 0.528691828250885 val_loss: 20.43973159790039\n",
      "epoch:  15700 train_loss: 0.49259209632873535 val_loss: 20.52926254272461\n",
      "epoch:  15800 train_loss: 0.5141292214393616 val_loss: 20.584033966064453\n",
      "epoch:  15900 train_loss: 0.48251500725746155 val_loss: 20.694196701049805\n",
      "epoch:  16000 train_loss: 0.4452421963214874 val_loss: 20.76968765258789\n",
      "epoch:  16100 train_loss: 0.48646682500839233 val_loss: 20.83502197265625\n",
      "epoch:  16200 train_loss: 0.39315611124038696 val_loss: 20.83521270751953\n",
      "epoch:  16300 train_loss: 0.39393603801727295 val_loss: 20.920543670654297\n",
      "epoch:  16400 train_loss: 0.42596596479415894 val_loss: 20.90756607055664\n",
      "epoch:  16500 train_loss: 0.3954075872898102 val_loss: 20.952125549316406\n",
      "epoch:  16600 train_loss: 0.38137540221214294 val_loss: 21.003446578979492\n",
      "epoch:  16700 train_loss: 0.4063667356967926 val_loss: 21.014738082885742\n",
      "epoch:  16800 train_loss: 0.3660733997821808 val_loss: 20.977235794067383\n",
      "epoch:  16900 train_loss: 0.3648383617401123 val_loss: 21.153390884399414\n",
      "epoch:  17000 train_loss: 0.32560813426971436 val_loss: 21.035978317260742\n",
      "epoch:  17100 train_loss: 0.52437424659729 val_loss: 21.190929412841797\n",
      "epoch:  17200 train_loss: 0.6305953860282898 val_loss: 21.248355865478516\n",
      "epoch:  17300 train_loss: 0.31156209111213684 val_loss: 21.18638038635254\n",
      "epoch:  17400 train_loss: 0.31151944398880005 val_loss: 21.244518280029297\n",
      "epoch:  17500 train_loss: 0.2939026653766632 val_loss: 21.284832000732422\n",
      "epoch:  17600 train_loss: 0.3222884237766266 val_loss: 21.308242797851562\n",
      "epoch:  17700 train_loss: 0.3600754141807556 val_loss: 21.363203048706055\n",
      "epoch:  17800 train_loss: 0.32268181443214417 val_loss: 21.318927764892578\n",
      "epoch:  17900 train_loss: 0.2713357210159302 val_loss: 21.361042022705078\n",
      "epoch:  18000 train_loss: 0.2865608036518097 val_loss: 21.505308151245117\n",
      "epoch:  18100 train_loss: 0.4118581712245941 val_loss: 21.53312110900879\n",
      "epoch:  18200 train_loss: 0.25283125042915344 val_loss: 21.430259704589844\n",
      "epoch:  18300 train_loss: 0.27536317706108093 val_loss: 21.5490665435791\n",
      "epoch:  18400 train_loss: 0.260755717754364 val_loss: 21.48512077331543\n",
      "epoch:  18500 train_loss: 0.2501254081726074 val_loss: 21.565109252929688\n",
      "epoch:  18600 train_loss: 0.2687004804611206 val_loss: 21.633832931518555\n",
      "epoch:  18700 train_loss: 0.2260821908712387 val_loss: 21.608064651489258\n",
      "epoch:  18800 train_loss: 0.23927901685237885 val_loss: 21.604162216186523\n",
      "epoch:  18900 train_loss: 0.21535658836364746 val_loss: 21.67201042175293\n",
      "epoch:  19000 train_loss: 0.26943549513816833 val_loss: 21.695018768310547\n",
      "epoch:  19100 train_loss: 0.21735432744026184 val_loss: 21.729694366455078\n",
      "epoch:  19200 train_loss: 0.24012556672096252 val_loss: 21.756311416625977\n",
      "epoch:  19300 train_loss: 0.2393072098493576 val_loss: 21.73431968688965\n",
      "epoch:  19400 train_loss: 0.26898178458213806 val_loss: 21.874643325805664\n",
      "epoch:  19500 train_loss: 0.25283360481262207 val_loss: 21.835607528686523\n",
      "epoch:  19600 train_loss: 0.25069302320480347 val_loss: 21.812564849853516\n",
      "epoch:  19700 train_loss: 0.20092077553272247 val_loss: 21.83665657043457\n",
      "epoch:  19800 train_loss: 0.20601560175418854 val_loss: 21.922359466552734\n",
      "epoch:  19900 train_loss: 0.1864614188671112 val_loss: 21.937358856201172\n",
      "epoch:  20000 train_loss: 0.19523648917675018 val_loss: 21.998830795288086\n",
      "epoch:  20100 train_loss: 0.22562415897846222 val_loss: 21.941810607910156\n",
      "epoch:  20200 train_loss: 0.149516299366951 val_loss: 21.962806701660156\n",
      "epoch:  20300 train_loss: 0.2776075601577759 val_loss: 22.151121139526367\n",
      "epoch:  20400 train_loss: 0.18174418807029724 val_loss: 22.086122512817383\n",
      "epoch:  20500 train_loss: 0.24947011470794678 val_loss: 21.973716735839844\n",
      "epoch:  20600 train_loss: 0.13809722661972046 val_loss: 22.06527328491211\n",
      "epoch:  20700 train_loss: 0.15894022583961487 val_loss: 22.192848205566406\n",
      "epoch:  20800 train_loss: 0.1667236089706421 val_loss: 22.19252586364746\n",
      "epoch:  20900 train_loss: 0.13684670627117157 val_loss: 22.107402801513672\n",
      "epoch:  21000 train_loss: 0.23868991434574127 val_loss: 22.216102600097656\n",
      "epoch:  21100 train_loss: 0.12887687981128693 val_loss: 22.189228057861328\n",
      "epoch:  21200 train_loss: 0.15567699074745178 val_loss: 22.237329483032227\n",
      "epoch:  21300 train_loss: 0.13591629266738892 val_loss: 22.217119216918945\n",
      "epoch:  21400 train_loss: 0.1441950798034668 val_loss: 22.231412887573242\n",
      "epoch:  21500 train_loss: 0.13151632249355316 val_loss: 22.224441528320312\n",
      "epoch:  21600 train_loss: 0.19437426328659058 val_loss: 22.24418830871582\n",
      "epoch:  21700 train_loss: 0.13326609134674072 val_loss: 22.352720260620117\n",
      "epoch:  21800 train_loss: 0.12286561727523804 val_loss: 22.314668655395508\n",
      "epoch:  21900 train_loss: 0.12068819999694824 val_loss: 22.311176300048828\n",
      "epoch:  22000 train_loss: 0.13547800481319427 val_loss: 22.311344146728516\n",
      "epoch:  22100 train_loss: 0.15460604429244995 val_loss: 22.333465576171875\n",
      "epoch:  22200 train_loss: 0.17707383632659912 val_loss: 22.3289737701416\n",
      "epoch:  22300 train_loss: 0.11209864914417267 val_loss: 22.351781845092773\n",
      "epoch:  22400 train_loss: 0.11526181548833847 val_loss: 22.3962459564209\n",
      "epoch:  22500 train_loss: 0.17815782129764557 val_loss: 22.41331672668457\n",
      "epoch:  22600 train_loss: 0.11373624950647354 val_loss: 22.383291244506836\n",
      "epoch:  22700 train_loss: 0.10397220402956009 val_loss: 22.36822509765625\n",
      "epoch:  22800 train_loss: 0.10504647344350815 val_loss: 22.375205993652344\n",
      "epoch:  22900 train_loss: 0.09539644420146942 val_loss: 22.42371940612793\n",
      "epoch:  23000 train_loss: 0.09821582585573196 val_loss: 22.43688201904297\n",
      "epoch:  23100 train_loss: 0.16001203656196594 val_loss: 22.393775939941406\n",
      "epoch:  23200 train_loss: 0.15139459073543549 val_loss: 22.463464736938477\n",
      "epoch:  23300 train_loss: 0.1001218631863594 val_loss: 22.41240119934082\n",
      "epoch:  23400 train_loss: 0.09498944133520126 val_loss: 22.439739227294922\n",
      "epoch:  23500 train_loss: 0.14773815870285034 val_loss: 22.49142074584961\n",
      "epoch:  23600 train_loss: 0.09710840880870819 val_loss: 22.518230438232422\n",
      "epoch:  23700 train_loss: 0.13460974395275116 val_loss: 22.493412017822266\n",
      "epoch:  23800 train_loss: 0.13952851295471191 val_loss: 22.45884895324707\n",
      "epoch:  23900 train_loss: 0.10502729564905167 val_loss: 22.479455947875977\n",
      "epoch:  24000 train_loss: 0.08846193552017212 val_loss: 22.48732566833496\n",
      "epoch:  24100 train_loss: 0.08805377781391144 val_loss: 22.510622024536133\n",
      "epoch:  24200 train_loss: 0.0898655503988266 val_loss: 22.506113052368164\n",
      "epoch:  24300 train_loss: 0.07424796372652054 val_loss: 22.52968406677246\n",
      "epoch:  24400 train_loss: 0.09188603609800339 val_loss: 22.50836944580078\n",
      "epoch:  24500 train_loss: 0.0883110910654068 val_loss: 22.471765518188477\n",
      "epoch:  24600 train_loss: 0.10384561866521835 val_loss: 22.536544799804688\n",
      "epoch:  24700 train_loss: 0.07104677706956863 val_loss: 22.56078338623047\n",
      "epoch:  24800 train_loss: 0.10819148272275925 val_loss: 22.58393096923828\n",
      "epoch:  24900 train_loss: 0.14423848688602448 val_loss: 22.58275604248047\n",
      "epoch:  25000 train_loss: 0.2511121928691864 val_loss: 22.682371139526367\n",
      "epoch:  25100 train_loss: 0.0622703954577446 val_loss: 22.568754196166992\n",
      "epoch:  25200 train_loss: 0.3178418278694153 val_loss: 22.422901153564453\n",
      "epoch:  25300 train_loss: 0.06980237364768982 val_loss: 22.543590545654297\n",
      "epoch:  25400 train_loss: 0.07931144535541534 val_loss: 22.6064453125\n",
      "epoch:  25500 train_loss: 0.06448541581630707 val_loss: 22.607582092285156\n",
      "epoch:  25600 train_loss: 0.08536690473556519 val_loss: 22.567153930664062\n",
      "epoch:  25700 train_loss: 0.10550800710916519 val_loss: 22.62482261657715\n",
      "epoch:  25800 train_loss: 0.10664776712656021 val_loss: 22.62405776977539\n",
      "epoch:  25900 train_loss: 0.06374282389879227 val_loss: 22.592262268066406\n",
      "epoch:  26000 train_loss: 0.0721408948302269 val_loss: 22.590274810791016\n",
      "epoch:  26100 train_loss: 0.07696163654327393 val_loss: 22.592348098754883\n",
      "epoch:  26200 train_loss: 0.08987221121788025 val_loss: 22.63925552368164\n",
      "epoch:  26300 train_loss: 0.05582568794488907 val_loss: 22.577701568603516\n",
      "epoch:  26400 train_loss: 0.10028698295354843 val_loss: 22.62791633605957\n",
      "epoch:  26500 train_loss: 0.10609017312526703 val_loss: 22.62583351135254\n",
      "epoch:  26600 train_loss: 0.07875609397888184 val_loss: 22.631229400634766\n",
      "epoch:  26700 train_loss: 0.07841498404741287 val_loss: 22.566320419311523\n",
      "epoch:  26800 train_loss: 0.06987648457288742 val_loss: 22.594209671020508\n",
      "epoch:  26900 train_loss: 0.07158487290143967 val_loss: 22.621501922607422\n",
      "epoch:  27000 train_loss: 0.062430351972579956 val_loss: 22.60538673400879\n",
      "epoch:  27100 train_loss: 0.09832700341939926 val_loss: 22.614227294921875\n",
      "epoch:  27200 train_loss: 0.07285928726196289 val_loss: 22.637531280517578\n",
      "epoch:  27300 train_loss: 0.07086438685655594 val_loss: 22.609214782714844\n",
      "epoch:  27400 train_loss: 0.05113222450017929 val_loss: 22.615697860717773\n",
      "epoch:  27500 train_loss: 0.07340540736913681 val_loss: 22.665185928344727\n",
      "epoch:  27600 train_loss: 0.048164088279008865 val_loss: 22.602031707763672\n",
      "epoch:  27700 train_loss: 0.10351363569498062 val_loss: 22.687660217285156\n",
      "epoch:  27800 train_loss: 0.04906238242983818 val_loss: 22.618425369262695\n",
      "epoch:  27900 train_loss: 0.09217467159032822 val_loss: 22.62331199645996\n",
      "epoch:  28000 train_loss: 0.08670523762702942 val_loss: 22.654483795166016\n",
      "epoch:  28100 train_loss: 0.08792794495820999 val_loss: 22.59151840209961\n",
      "epoch:  28200 train_loss: 0.07469736039638519 val_loss: 22.665103912353516\n",
      "epoch:  28300 train_loss: 0.07275046408176422 val_loss: 22.58401107788086\n",
      "epoch:  28400 train_loss: 0.08501425385475159 val_loss: 22.574975967407227\n",
      "epoch:  28500 train_loss: 0.08290978521108627 val_loss: 22.573902130126953\n",
      "epoch:  28600 train_loss: 0.046603139489889145 val_loss: 22.575376510620117\n",
      "epoch:  28700 train_loss: 0.05676113814115524 val_loss: 22.606342315673828\n",
      "epoch:  28800 train_loss: 0.04341474547982216 val_loss: 22.551410675048828\n",
      "epoch:  28900 train_loss: 0.03683764114975929 val_loss: 22.584388732910156\n",
      "epoch:  29000 train_loss: 0.06595075875520706 val_loss: 22.59599494934082\n",
      "epoch:  29100 train_loss: 0.06726288795471191 val_loss: 22.590198516845703\n",
      "epoch:  29200 train_loss: 0.050027430057525635 val_loss: 22.57638931274414\n",
      "epoch:  29300 train_loss: 0.043143562972545624 val_loss: 22.555500030517578\n",
      "epoch:  29400 train_loss: 0.030694982036948204 val_loss: 22.544963836669922\n",
      "epoch:  29500 train_loss: 0.057494863867759705 val_loss: 22.54224395751953\n",
      "epoch:  29600 train_loss: 0.04272734001278877 val_loss: 22.544254302978516\n",
      "epoch:  29700 train_loss: 0.053713638335466385 val_loss: 22.55789566040039\n",
      "epoch:  29800 train_loss: 0.05645003542304039 val_loss: 22.487255096435547\n",
      "epoch:  29900 train_loss: 0.06097446009516716 val_loss: 22.531803131103516\n",
      "epoch:  30000 train_loss: 0.045584168285131454 val_loss: 22.539392471313477\n",
      "epoch:  30100 train_loss: 0.06126381456851959 val_loss: 22.52174949645996\n",
      "epoch:  30200 train_loss: 0.03367229923605919 val_loss: 22.544328689575195\n",
      "epoch:  30300 train_loss: 0.03634166345000267 val_loss: 22.480825424194336\n",
      "epoch:  30400 train_loss: 0.11861325800418854 val_loss: 22.44003677368164\n",
      "epoch:  30500 train_loss: 0.04711366072297096 val_loss: 22.480342864990234\n",
      "epoch:  30600 train_loss: 0.03407711163163185 val_loss: 22.502412796020508\n",
      "epoch:  30700 train_loss: 0.04444387927651405 val_loss: 22.46770668029785\n",
      "epoch:  30800 train_loss: 0.03590918704867363 val_loss: 22.51097297668457\n",
      "epoch:  30900 train_loss: 0.061964474618434906 val_loss: 22.454654693603516\n",
      "epoch:  31000 train_loss: 0.032425206154584885 val_loss: 22.46772575378418\n",
      "epoch:  31100 train_loss: 0.027815675362944603 val_loss: 22.512216567993164\n",
      "epoch:  31200 train_loss: 0.08452046662569046 val_loss: 22.502342224121094\n",
      "epoch:  31300 train_loss: 0.034199442714452744 val_loss: 22.455135345458984\n",
      "epoch:  31400 train_loss: 0.02468828484416008 val_loss: 22.48699188232422\n",
      "epoch:  31500 train_loss: 0.03940742462873459 val_loss: 22.462223052978516\n",
      "epoch:  31600 train_loss: 0.038129713386297226 val_loss: 22.4502010345459\n",
      "epoch:  31700 train_loss: 0.0446285679936409 val_loss: 22.42369842529297\n",
      "epoch:  31800 train_loss: 0.05228148400783539 val_loss: 22.446697235107422\n",
      "epoch:  31900 train_loss: 0.032451558858156204 val_loss: 22.47051239013672\n",
      "epoch:  32000 train_loss: 0.050728000700473785 val_loss: 22.387548446655273\n",
      "epoch:  32100 train_loss: 0.07386753708124161 val_loss: 22.448776245117188\n",
      "epoch:  32200 train_loss: 0.03270311281085014 val_loss: 22.38972282409668\n",
      "epoch:  32300 train_loss: 0.03210633620619774 val_loss: 22.427778244018555\n",
      "epoch:  32400 train_loss: 0.03094320185482502 val_loss: 22.404878616333008\n",
      "epoch:  32500 train_loss: 0.038162726908922195 val_loss: 22.414182662963867\n",
      "epoch:  32600 train_loss: 0.042025815695524216 val_loss: 22.392358779907227\n",
      "epoch:  32700 train_loss: 0.05164056643843651 val_loss: 22.382400512695312\n",
      "epoch:  32800 train_loss: 0.042236194014549255 val_loss: 22.306119918823242\n",
      "epoch:  32900 train_loss: 0.06201181188225746 val_loss: 22.373088836669922\n",
      "epoch:  33000 train_loss: 0.045985184609889984 val_loss: 22.35889434814453\n",
      "epoch:  33100 train_loss: 0.04604531452059746 val_loss: 22.330278396606445\n",
      "epoch:  33200 train_loss: 0.05603986978530884 val_loss: 22.415889739990234\n",
      "epoch:  33300 train_loss: 0.04828345403075218 val_loss: 22.365713119506836\n",
      "epoch:  33400 train_loss: 0.027585890144109726 val_loss: 22.326950073242188\n",
      "epoch:  33500 train_loss: 0.019190609455108643 val_loss: 22.35579490661621\n",
      "epoch:  33600 train_loss: 0.023297693580389023 val_loss: 22.32759666442871\n",
      "epoch:  33700 train_loss: 0.03004758246243 val_loss: 22.33530044555664\n",
      "epoch:  33800 train_loss: 0.024921439588069916 val_loss: 22.335407257080078\n",
      "epoch:  33900 train_loss: 0.034702058881521225 val_loss: 22.30750274658203\n",
      "epoch:  34000 train_loss: 0.08017154783010483 val_loss: 22.353269577026367\n",
      "epoch:  34100 train_loss: 0.03195128217339516 val_loss: 22.34006118774414\n",
      "epoch:  34200 train_loss: 0.01904950849711895 val_loss: 22.24534034729004\n",
      "epoch:  34300 train_loss: 0.04421837255358696 val_loss: 22.335372924804688\n",
      "epoch:  34400 train_loss: 0.02041570283472538 val_loss: 22.31378746032715\n",
      "epoch:  34500 train_loss: 0.02276184968650341 val_loss: 22.237760543823242\n",
      "epoch:  34600 train_loss: 0.03666609153151512 val_loss: 22.26553726196289\n",
      "epoch:  34700 train_loss: 0.031633879989385605 val_loss: 22.336076736450195\n",
      "epoch:  34800 train_loss: 0.04679218679666519 val_loss: 22.286949157714844\n",
      "epoch:  34900 train_loss: 0.03753533214330673 val_loss: 22.273494720458984\n",
      "epoch:  35000 train_loss: 0.04446449130773544 val_loss: 22.230602264404297\n",
      "epoch:  35100 train_loss: 0.03165310248732567 val_loss: 22.225868225097656\n",
      "epoch:  35200 train_loss: 0.0518573597073555 val_loss: 22.25519371032715\n",
      "epoch:  35300 train_loss: 0.02043127827346325 val_loss: 22.21981430053711\n",
      "epoch:  35400 train_loss: 0.02655554935336113 val_loss: 22.141944885253906\n",
      "epoch:  35500 train_loss: 0.03973613306879997 val_loss: 22.21683120727539\n",
      "epoch:  35600 train_loss: 0.04327874258160591 val_loss: 22.20121955871582\n",
      "epoch:  35700 train_loss: 0.029587959870696068 val_loss: 22.238418579101562\n",
      "epoch:  35800 train_loss: 0.049400024116039276 val_loss: 22.24893569946289\n",
      "epoch:  35900 train_loss: 0.040096741169691086 val_loss: 22.144847869873047\n",
      "sigma: 5.5 RMSE:  tensor(6.1152, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Generate the dataset with noise N(0, sigma)\n",
    "i = 0\n",
    "sigma = 5.5\n",
    "my_dataset = []\n",
    "for ud in UDs:\n",
    "    example = []\n",
    "    for an in ANs:\n",
    "        noise = np.random.normal(0,sigma)\n",
    "        # 0 is mean\n",
    "        # sigma is the deviation of the normal distribution\n",
    "        d = compute_3d_distance(ud, an) + noise\n",
    "        example.append(d)\n",
    "    \n",
    "    # append x, y, z as col#10, #11, #12\n",
    "    example.append(ud[0])\n",
    "    example.append(ud[1])\n",
    "    example.append(ud[2])\n",
    "    \n",
    "    # append 1x13 example row into my_dataset\n",
    "    my_dataset.append(example)  # expected to be 3000x13  \n",
    "    \n",
    "# Load dataset\n",
    "exercise5_dataset = Exercise5Dataset(list_dataset = my_dataset, shuffle=True)\n",
    "\n",
    "#Split dataset by 0.8: 0.1: 0.1\n",
    "train_examples, train_labels = exercise5_dataset[:int(3000*0.8)]  # (2400, 10)   # (2400, 3)\n",
    "val_examples, val_labels = exercise5_dataset[int(3000*0.8):int(3000*0.9)]    # (300, 10)   #(300, 3)\n",
    "test_examples, test_labels = exercise5_dataset[int(3000*0.9):]     #(300, 10)   # (300, 3)\n",
    "\n",
    "###Define model, loss function and optimizer\n",
    "# if we have GPU, then use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define model\n",
    "#model = Net(x_dim = train_examples.shape[1], y_dim = train_labels.shape[1]).to(device)\n",
    "input_dim = 1     #input dim is 1, seq_len = 10\n",
    "hidden_dim = 64   #hidden state dim is 64\n",
    "n_layers = 3             #3-layered LSTM\n",
    "model = MYLSTM(input_dim, hidden_dim, n_layers).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Correct the input/output shape for LSTM\n",
    "train_inputs = torch.unsqueeze(train_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "train_inputs = train_inputs.to(device) \n",
    "\n",
    "val_inputs = torch.unsqueeze(val_examples, dim=-1)   # (N, 10) -> (N, 10, 1)\n",
    "val_inputs = val_inputs.to(device) \n",
    "\n",
    "train_labels = train_labels.to(device)   #(N, 3)\n",
    "val_labels = val_labels.to(device)          #(N, 3)\n",
    "\n",
    "\n",
    "# Define the loss threshold, if the current train loss is lower than the threshold, we will begin to save the model\n",
    "best_loss = 100.0\n",
    "\n",
    "# Define the model filename for model.save()\n",
    "MODEL_FILENAME = \"best.pth\"\n",
    "\n",
    "# set model to Training mode\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "NUM_OF_EPOCH = 36000\n",
    "\n",
    "# Train\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    y_pred = model(train_inputs)\n",
    "    loss = loss_fn(y_pred, train_labels).cpu()\n",
    "    #print(t, loss.item())\n",
    "    train_losses.append(loss.item())\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    # BGD\n",
    "    optimizer.step()\n",
    "    \n",
    "    # evaluate validation loss\n",
    "    val_pred = model(val_inputs)\n",
    "    loss = loss_fn(val_pred, val_labels)\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "\n",
    "\n",
    "    if (epoch % 100) == 0:\n",
    "        print(\"epoch: \", epoch, \"train_loss:\", train_losses[-1], \"val_loss:\", val_losses[-1])\n",
    "        # check if we got better loss\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n",
    "        \n",
    "# Load the best model on previous step\n",
    "model.load_state_dict(torch.load(\"best.pth\"))\n",
    "\n",
    "# Inference all testing examples and compute RMSE\n",
    "def square_error(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  square_error= loss_fn(a, b)\n",
    "  return square_error\n",
    "\n",
    "model.eval() # inference mode\n",
    "test_inputs = torch.unsqueeze(test_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "test_inputs = test_inputs.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "\n",
    "test_preds = model(test_inputs)\n",
    "#print(\"example: \", test_example.cpu())\n",
    "#print(\"========================================\")\n",
    "#print(\"ground_truth:\", test_label.cpu())\n",
    "#print(\"prediction:\", test_pred.cpu())\n",
    "#print(\"========================================\")\n",
    "\n",
    "\n",
    "total_errors = 0.0\n",
    "for idx in range(len(test_inputs)):\n",
    "    total_errors += square_error(test_preds[idx], test_labels[idx])\n",
    "    \n",
    "RMSE = torch.sqrt(total_errors / len(test_inputs))\n",
    "print(\"sigma:\", sigma, \"RMSE: \",  RMSE)\n",
    "\n",
    "sigmas.append(sigma)\n",
    "RMSEs.append(RMSE.cpu().detach().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigma = 6.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffle = True!\n",
      "epoch:  0 train_loss: 7337.568359375 val_loss: 7340.720703125\n",
      "epoch:  100 train_loss: 5922.626953125 val_loss: 5915.2412109375\n",
      "epoch:  200 train_loss: 5020.3935546875 val_loss: 5012.02587890625\n",
      "epoch:  300 train_loss: 4269.97216796875 val_loss: 4260.5947265625\n",
      "epoch:  400 train_loss: 3630.572265625 val_loss: 3620.152587890625\n",
      "epoch:  500 train_loss: 3081.640625 val_loss: 3070.71240234375\n",
      "epoch:  600 train_loss: 2609.52978515625 val_loss: 2598.3212890625\n",
      "epoch:  700 train_loss: 2203.5263671875 val_loss: 2192.05078125\n",
      "epoch:  800 train_loss: 1854.544189453125 val_loss: 1843.240966796875\n",
      "epoch:  900 train_loss: 1555.429443359375 val_loss: 1544.628173828125\n",
      "epoch:  1000 train_loss: 1300.189697265625 val_loss: 1289.852294921875\n",
      "epoch:  1100 train_loss: 1083.6239013671875 val_loss: 1074.0250244140625\n",
      "epoch:  1200 train_loss: 901.3701782226562 val_loss: 892.45556640625\n",
      "epoch:  1300 train_loss: 749.2096557617188 val_loss: 740.92578125\n",
      "epoch:  1400 train_loss: 623.389892578125 val_loss: 616.0098266601562\n",
      "epoch:  1500 train_loss: 520.6508178710938 val_loss: 513.9630126953125\n",
      "epoch:  1600 train_loss: 437.81494140625 val_loss: 431.62457275390625\n",
      "epoch:  1700 train_loss: 371.664306640625 val_loss: 366.2053527832031\n",
      "epoch:  1800 train_loss: 319.7698059082031 val_loss: 314.8080749511719\n",
      "epoch:  1900 train_loss: 279.68994140625 val_loss: 275.15789794921875\n",
      "epoch:  2000 train_loss: 249.1982421875 val_loss: 245.0296630859375\n",
      "epoch:  2100 train_loss: 226.35643005371094 val_loss: 222.61083984375\n",
      "epoch:  2200 train_loss: 209.6683349609375 val_loss: 206.19329833984375\n",
      "epoch:  2300 train_loss: 197.67684936523438 val_loss: 194.4562225341797\n",
      "epoch:  2400 train_loss: 189.21925354003906 val_loss: 186.2528839111328\n",
      "epoch:  2500 train_loss: 183.43406677246094 val_loss: 180.6172332763672\n",
      "epoch:  2600 train_loss: 179.5457000732422 val_loss: 176.87686157226562\n",
      "epoch:  2700 train_loss: 176.99465942382812 val_loss: 174.46226501464844\n",
      "epoch:  2800 train_loss: 175.3786163330078 val_loss: 172.94113159179688\n",
      "epoch:  2900 train_loss: 174.37513732910156 val_loss: 172.01309204101562\n",
      "epoch:  3000 train_loss: 173.76791381835938 val_loss: 171.4695587158203\n",
      "epoch:  3100 train_loss: 173.41847229003906 val_loss: 171.1677703857422\n",
      "epoch:  3200 train_loss: 173.2227783203125 val_loss: 171.0079803466797\n",
      "epoch:  3300 train_loss: 173.11451721191406 val_loss: 170.9268035888672\n",
      "epoch:  3400 train_loss: 173.05833435058594 val_loss: 170.88980102539062\n",
      "epoch:  3500 train_loss: 173.02857971191406 val_loss: 170.8758087158203\n",
      "epoch:  3600 train_loss: 173.01531982421875 val_loss: 170.87246704101562\n",
      "epoch:  3700 train_loss: 173.0099334716797 val_loss: 170.87159729003906\n",
      "epoch:  3800 train_loss: 173.00625610351562 val_loss: 170.87538146972656\n",
      "epoch:  3900 train_loss: 173.00523376464844 val_loss: 170.87632751464844\n",
      "epoch:  4000 train_loss: 173.00479125976562 val_loss: 170.8773651123047\n",
      "epoch:  4100 train_loss: 173.00454711914062 val_loss: 170.87889099121094\n",
      "epoch:  4200 train_loss: 173.00448608398438 val_loss: 170.87997436523438\n",
      "epoch:  4300 train_loss: 173.00445556640625 val_loss: 170.88063049316406\n",
      "epoch:  4400 train_loss: 173.00445556640625 val_loss: 170.8804931640625\n",
      "epoch:  4500 train_loss: 173.00445556640625 val_loss: 170.88063049316406\n",
      "epoch:  4600 train_loss: 173.00445556640625 val_loss: 170.88064575195312\n",
      "epoch:  4700 train_loss: 173.00445556640625 val_loss: 170.88064575195312\n",
      "epoch:  4800 train_loss: 173.00445556640625 val_loss: 170.88064575195312\n",
      "epoch:  4900 train_loss: 173.00445556640625 val_loss: 170.88064575195312\n",
      "epoch:  5000 train_loss: 173.00445556640625 val_loss: 170.8806610107422\n",
      "epoch:  5100 train_loss: 173.00445556640625 val_loss: 170.8809814453125\n",
      "epoch:  5200 train_loss: 173.00445556640625 val_loss: 170.8806610107422\n",
      "epoch:  5300 train_loss: 173.00445556640625 val_loss: 170.88079833984375\n",
      "epoch:  5400 train_loss: 173.0044708251953 val_loss: 170.8808135986328\n",
      "epoch:  5500 train_loss: 173.00445556640625 val_loss: 170.88079833984375\n",
      "epoch:  5600 train_loss: 173.0044708251953 val_loss: 170.8808135986328\n",
      "epoch:  5700 train_loss: 173.00445556640625 val_loss: 170.8809814453125\n",
      "epoch:  5800 train_loss: 173.0044708251953 val_loss: 170.8808135986328\n",
      "epoch:  5900 train_loss: 173.00445556640625 val_loss: 170.8806610107422\n",
      "epoch:  6000 train_loss: 173.00445556640625 val_loss: 170.8809814453125\n",
      "epoch:  6100 train_loss: 173.0044708251953 val_loss: 170.8808135986328\n",
      "epoch:  6200 train_loss: 173.00445556640625 val_loss: 170.8808135986328\n",
      "epoch:  6300 train_loss: 173.00445556640625 val_loss: 170.88079833984375\n",
      "epoch:  6400 train_loss: 173.0044708251953 val_loss: 170.8808135986328\n",
      "epoch:  6500 train_loss: 173.00445556640625 val_loss: 170.8808135986328\n",
      "epoch:  6600 train_loss: 173.00445556640625 val_loss: 170.8809814453125\n",
      "epoch:  6700 train_loss: 173.00445556640625 val_loss: 170.88096618652344\n",
      "epoch:  6800 train_loss: 173.00445556640625 val_loss: 170.8806610107422\n",
      "epoch:  6900 train_loss: 173.00445556640625 val_loss: 170.8806610107422\n",
      "epoch:  7000 train_loss: 173.00445556640625 val_loss: 170.8806610107422\n",
      "epoch:  7100 train_loss: 173.00445556640625 val_loss: 170.88079833984375\n",
      "epoch:  7200 train_loss: 173.00445556640625 val_loss: 170.88079833984375\n",
      "epoch:  7300 train_loss: 173.00445556640625 val_loss: 170.8806610107422\n",
      "epoch:  7400 train_loss: 173.0045928955078 val_loss: 170.88540649414062\n",
      "epoch:  7500 train_loss: 167.08364868164062 val_loss: 162.69419860839844\n",
      "epoch:  7600 train_loss: 120.75887298583984 val_loss: 119.11878204345703\n",
      "epoch:  7700 train_loss: 106.64835357666016 val_loss: 105.64854431152344\n",
      "epoch:  7800 train_loss: 95.74432373046875 val_loss: 94.88138580322266\n",
      "epoch:  7900 train_loss: 85.13314819335938 val_loss: 84.66709899902344\n",
      "epoch:  8000 train_loss: 75.21646881103516 val_loss: 75.01738739013672\n",
      "epoch:  8100 train_loss: 64.63622283935547 val_loss: 64.77982330322266\n",
      "epoch:  8200 train_loss: 53.29429626464844 val_loss: 53.035545349121094\n",
      "epoch:  8300 train_loss: 42.408172607421875 val_loss: 42.482826232910156\n",
      "epoch:  8400 train_loss: 34.02543640136719 val_loss: 34.85463333129883\n",
      "epoch:  8500 train_loss: 27.69548225402832 val_loss: 28.66915512084961\n",
      "epoch:  8600 train_loss: 23.290006637573242 val_loss: 24.613245010375977\n",
      "epoch:  8700 train_loss: 20.7193546295166 val_loss: 22.975421905517578\n",
      "epoch:  8800 train_loss: 17.512569427490234 val_loss: 19.659223556518555\n",
      "epoch:  8900 train_loss: 15.562074661254883 val_loss: 18.250513076782227\n",
      "epoch:  9000 train_loss: 14.117734909057617 val_loss: 17.35103988647461\n",
      "epoch:  9100 train_loss: 13.165122985839844 val_loss: 17.099040985107422\n",
      "epoch:  9200 train_loss: 12.319021224975586 val_loss: 16.727632522583008\n",
      "epoch:  9300 train_loss: 11.6795015335083 val_loss: 16.66152572631836\n",
      "epoch:  9400 train_loss: 11.166573524475098 val_loss: 16.733612060546875\n",
      "epoch:  9500 train_loss: 10.771443367004395 val_loss: 16.735166549682617\n",
      "epoch:  9600 train_loss: 10.469502449035645 val_loss: 16.739765167236328\n",
      "epoch:  9700 train_loss: 11.441771507263184 val_loss: 17.756492614746094\n",
      "epoch:  9800 train_loss: 9.658476829528809 val_loss: 17.133405685424805\n",
      "epoch:  9900 train_loss: 9.435733795166016 val_loss: 17.22718048095703\n",
      "epoch:  10000 train_loss: 9.065842628479004 val_loss: 17.439287185668945\n",
      "epoch:  10100 train_loss: 9.107637405395508 val_loss: 18.232585906982422\n",
      "epoch:  10200 train_loss: 8.540773391723633 val_loss: 17.88059425354004\n",
      "epoch:  10300 train_loss: 8.375518798828125 val_loss: 17.990915298461914\n",
      "epoch:  10400 train_loss: 8.139719009399414 val_loss: 18.449371337890625\n",
      "epoch:  10500 train_loss: 7.9443745613098145 val_loss: 18.38654899597168\n",
      "epoch:  10600 train_loss: 7.675118446350098 val_loss: 18.68952178955078\n",
      "epoch:  10700 train_loss: 7.652256965637207 val_loss: 18.26160430908203\n",
      "epoch:  10800 train_loss: 7.26567268371582 val_loss: 18.918771743774414\n",
      "epoch:  10900 train_loss: 7.151192665100098 val_loss: 18.80610466003418\n",
      "epoch:  11000 train_loss: 7.219717979431152 val_loss: 19.04529571533203\n",
      "epoch:  11100 train_loss: 6.690898418426514 val_loss: 19.162296295166016\n",
      "epoch:  11200 train_loss: 6.588747024536133 val_loss: 19.550661087036133\n",
      "epoch:  11300 train_loss: 6.631584167480469 val_loss: 19.689525604248047\n",
      "epoch:  11400 train_loss: 6.311174392700195 val_loss: 19.781272888183594\n",
      "epoch:  11500 train_loss: 6.176470756530762 val_loss: 19.94852638244629\n",
      "epoch:  11600 train_loss: 6.058248519897461 val_loss: 20.50585174560547\n",
      "epoch:  11700 train_loss: 5.751269817352295 val_loss: 20.420774459838867\n",
      "epoch:  11800 train_loss: 5.604817867279053 val_loss: 20.6876163482666\n",
      "epoch:  11900 train_loss: 5.469302654266357 val_loss: 20.765274047851562\n",
      "epoch:  12000 train_loss: 5.23900842666626 val_loss: 21.10293197631836\n",
      "epoch:  12100 train_loss: 5.197930812835693 val_loss: 21.16152000427246\n",
      "epoch:  12200 train_loss: 5.104358673095703 val_loss: 21.297502517700195\n",
      "epoch:  12300 train_loss: 4.894494533538818 val_loss: 21.69420051574707\n",
      "epoch:  12400 train_loss: 4.755149841308594 val_loss: 21.734880447387695\n",
      "epoch:  12500 train_loss: 4.859254360198975 val_loss: 22.28519058227539\n",
      "epoch:  12600 train_loss: 4.527990341186523 val_loss: 22.171180725097656\n",
      "epoch:  12700 train_loss: 4.544682502746582 val_loss: 22.27179718017578\n",
      "epoch:  12800 train_loss: 4.3361358642578125 val_loss: 22.345844268798828\n",
      "epoch:  12900 train_loss: 4.2567243576049805 val_loss: 22.573299407958984\n",
      "epoch:  13000 train_loss: 4.092912197113037 val_loss: 23.20677947998047\n",
      "epoch:  13100 train_loss: 4.2586140632629395 val_loss: 23.409353256225586\n",
      "epoch:  13200 train_loss: 4.065431118011475 val_loss: 23.408294677734375\n",
      "epoch:  13300 train_loss: 3.800239324569702 val_loss: 23.12684440612793\n",
      "epoch:  13400 train_loss: 4.034950256347656 val_loss: 23.35993766784668\n",
      "epoch:  13500 train_loss: 3.5947680473327637 val_loss: 23.685070037841797\n",
      "epoch:  13600 train_loss: 3.455808162689209 val_loss: 23.762020111083984\n",
      "epoch:  13700 train_loss: 3.64518666267395 val_loss: 24.18100929260254\n",
      "epoch:  13800 train_loss: 3.2691140174865723 val_loss: 23.898181915283203\n",
      "epoch:  13900 train_loss: 3.2273266315460205 val_loss: 24.155086517333984\n",
      "epoch:  14000 train_loss: 3.120638608932495 val_loss: 23.89504623413086\n",
      "epoch:  14100 train_loss: 3.044837236404419 val_loss: 24.2020320892334\n",
      "epoch:  14200 train_loss: 3.3860440254211426 val_loss: 24.748659133911133\n",
      "epoch:  14300 train_loss: 3.061204433441162 val_loss: 24.527799606323242\n",
      "epoch:  14400 train_loss: 2.918943166732788 val_loss: 24.51331901550293\n",
      "epoch:  14500 train_loss: 2.889385938644409 val_loss: 24.138347625732422\n",
      "epoch:  14600 train_loss: 2.7490501403808594 val_loss: 24.233436584472656\n",
      "epoch:  14700 train_loss: 2.7697460651397705 val_loss: 23.974206924438477\n",
      "epoch:  14800 train_loss: 2.960740089416504 val_loss: 24.786251068115234\n",
      "epoch:  14900 train_loss: 2.5754475593566895 val_loss: 24.373870849609375\n",
      "epoch:  15000 train_loss: 2.571474075317383 val_loss: 24.35668182373047\n",
      "epoch:  15100 train_loss: 2.42814040184021 val_loss: 24.571504592895508\n",
      "epoch:  15200 train_loss: 2.4253346920013428 val_loss: 24.576480865478516\n",
      "epoch:  15300 train_loss: 2.446676015853882 val_loss: 24.639949798583984\n",
      "epoch:  15400 train_loss: 2.427460193634033 val_loss: 24.732955932617188\n",
      "epoch:  15500 train_loss: 2.3439512252807617 val_loss: 24.733694076538086\n",
      "epoch:  15600 train_loss: 2.326626777648926 val_loss: 24.968780517578125\n",
      "epoch:  15700 train_loss: 2.190392255783081 val_loss: 24.55189323425293\n",
      "epoch:  15800 train_loss: 2.2195019721984863 val_loss: 24.714475631713867\n",
      "epoch:  15900 train_loss: 2.083463668823242 val_loss: 24.960649490356445\n",
      "epoch:  16000 train_loss: 2.128915548324585 val_loss: 25.47746467590332\n",
      "epoch:  16100 train_loss: 2.1637959480285645 val_loss: 24.8846378326416\n",
      "epoch:  16200 train_loss: 1.9734253883361816 val_loss: 25.15572738647461\n",
      "epoch:  16300 train_loss: 1.8985897302627563 val_loss: 25.12627601623535\n",
      "epoch:  16400 train_loss: 2.3090364933013916 val_loss: 25.292945861816406\n",
      "epoch:  16500 train_loss: 1.8325798511505127 val_loss: 25.31237030029297\n",
      "epoch:  16600 train_loss: 1.8429595232009888 val_loss: 25.42197036743164\n",
      "epoch:  16700 train_loss: 1.8138967752456665 val_loss: 25.665590286254883\n",
      "epoch:  16800 train_loss: 1.767098307609558 val_loss: 25.520030975341797\n",
      "epoch:  16900 train_loss: 1.766340970993042 val_loss: 25.58006477355957\n",
      "epoch:  17000 train_loss: 1.8908861875534058 val_loss: 25.81056785583496\n",
      "epoch:  17100 train_loss: 1.6615594625473022 val_loss: 26.21586799621582\n",
      "epoch:  17200 train_loss: 1.7855675220489502 val_loss: 26.012277603149414\n",
      "epoch:  17300 train_loss: 1.5655651092529297 val_loss: 26.071365356445312\n",
      "epoch:  17400 train_loss: 1.637954831123352 val_loss: 26.17534828186035\n",
      "epoch:  17500 train_loss: 1.5743392705917358 val_loss: 26.043264389038086\n",
      "epoch:  17600 train_loss: 1.4900768995285034 val_loss: 26.35726547241211\n",
      "epoch:  17700 train_loss: 1.5173299312591553 val_loss: 26.502389907836914\n",
      "epoch:  17800 train_loss: 1.503662109375 val_loss: 26.519285202026367\n",
      "epoch:  17900 train_loss: 1.518821358680725 val_loss: 26.85009002685547\n",
      "epoch:  18000 train_loss: 1.4929050207138062 val_loss: 26.515682220458984\n",
      "epoch:  18100 train_loss: 1.493748664855957 val_loss: 26.455421447753906\n",
      "epoch:  18200 train_loss: 1.364754557609558 val_loss: 26.90733528137207\n",
      "epoch:  18300 train_loss: 1.3562278747558594 val_loss: 26.86404800415039\n",
      "epoch:  18400 train_loss: 1.3447167873382568 val_loss: 27.11537742614746\n",
      "epoch:  18500 train_loss: 1.3864449262619019 val_loss: 26.85051727294922\n",
      "epoch:  18600 train_loss: 1.5188981294631958 val_loss: 27.019367218017578\n",
      "epoch:  18700 train_loss: 1.7995822429656982 val_loss: 27.37282371520996\n",
      "epoch:  18800 train_loss: 2.05100679397583 val_loss: 27.63003921508789\n",
      "epoch:  18900 train_loss: 1.3751811981201172 val_loss: 27.46603775024414\n",
      "epoch:  19000 train_loss: 1.3752154111862183 val_loss: 27.573129653930664\n",
      "epoch:  19100 train_loss: 1.237388014793396 val_loss: 27.406396865844727\n",
      "epoch:  19200 train_loss: 1.1804600954055786 val_loss: 27.64767074584961\n",
      "epoch:  19300 train_loss: 1.1764215230941772 val_loss: 27.34868049621582\n",
      "epoch:  19400 train_loss: 1.2191553115844727 val_loss: 27.380550384521484\n",
      "epoch:  19500 train_loss: 1.3480510711669922 val_loss: 27.65757942199707\n",
      "epoch:  19600 train_loss: 1.106349229812622 val_loss: 27.54487419128418\n",
      "epoch:  19700 train_loss: 1.1185462474822998 val_loss: 27.766359329223633\n",
      "epoch:  19800 train_loss: 1.2089178562164307 val_loss: 28.13773536682129\n",
      "epoch:  19900 train_loss: 1.0129156112670898 val_loss: 27.871849060058594\n",
      "epoch:  20000 train_loss: 1.088550090789795 val_loss: 27.813446044921875\n",
      "epoch:  20100 train_loss: 1.1036386489868164 val_loss: 28.10472297668457\n",
      "epoch:  20200 train_loss: 1.1191198825836182 val_loss: 28.331541061401367\n",
      "epoch:  20300 train_loss: 0.9797661900520325 val_loss: 28.134117126464844\n",
      "epoch:  20400 train_loss: 1.024939775466919 val_loss: 28.389719009399414\n",
      "epoch:  20500 train_loss: 0.9234904646873474 val_loss: 28.21888542175293\n",
      "epoch:  20600 train_loss: 0.9571457505226135 val_loss: 28.077110290527344\n",
      "epoch:  20700 train_loss: 0.9756069779396057 val_loss: 28.263307571411133\n",
      "epoch:  20800 train_loss: 1.0952470302581787 val_loss: 28.483285903930664\n",
      "epoch:  20900 train_loss: 0.9749600291252136 val_loss: 28.561138153076172\n",
      "epoch:  21000 train_loss: 0.9061801433563232 val_loss: 28.424264907836914\n",
      "epoch:  21100 train_loss: 1.0270341634750366 val_loss: 28.351806640625\n",
      "epoch:  21200 train_loss: 0.9567562341690063 val_loss: 28.582656860351562\n",
      "epoch:  21300 train_loss: 0.8357868790626526 val_loss: 28.639175415039062\n",
      "epoch:  21400 train_loss: 0.8137034773826599 val_loss: 28.701324462890625\n",
      "epoch:  21500 train_loss: 0.7992671728134155 val_loss: 28.464981079101562\n",
      "epoch:  21600 train_loss: 0.9470158815383911 val_loss: 29.002300262451172\n",
      "epoch:  21700 train_loss: 0.7708979249000549 val_loss: 28.671567916870117\n",
      "epoch:  21800 train_loss: 0.8979461193084717 val_loss: 28.643186569213867\n",
      "epoch:  21900 train_loss: 0.8691453337669373 val_loss: 28.549137115478516\n",
      "epoch:  22000 train_loss: 0.7401836514472961 val_loss: 28.91218376159668\n",
      "epoch:  22100 train_loss: 0.8564823865890503 val_loss: 28.80791664123535\n",
      "epoch:  22200 train_loss: 0.7329527735710144 val_loss: 28.764543533325195\n",
      "epoch:  22300 train_loss: 0.7834663391113281 val_loss: 28.9820499420166\n",
      "epoch:  22400 train_loss: 0.7089422941207886 val_loss: 28.98472785949707\n",
      "epoch:  22500 train_loss: 0.7431865930557251 val_loss: 29.029376983642578\n",
      "epoch:  22600 train_loss: 0.7627355456352234 val_loss: 28.883920669555664\n",
      "epoch:  22700 train_loss: 0.7644174695014954 val_loss: 29.32843780517578\n",
      "epoch:  22800 train_loss: 0.708178699016571 val_loss: 28.996267318725586\n",
      "epoch:  22900 train_loss: 1.0174657106399536 val_loss: 29.642093658447266\n",
      "epoch:  23000 train_loss: 0.6769927740097046 val_loss: 29.433443069458008\n",
      "epoch:  23100 train_loss: 0.6506813168525696 val_loss: 29.28144645690918\n",
      "epoch:  23200 train_loss: 0.9354103803634644 val_loss: 29.35072898864746\n",
      "epoch:  23300 train_loss: 0.8461172580718994 val_loss: 29.462135314941406\n",
      "epoch:  23400 train_loss: 0.6946178674697876 val_loss: 29.582651138305664\n",
      "epoch:  23500 train_loss: 0.676694393157959 val_loss: 29.490564346313477\n",
      "epoch:  23600 train_loss: 0.6808398365974426 val_loss: 29.286510467529297\n",
      "epoch:  23700 train_loss: 0.7509133815765381 val_loss: 29.99778938293457\n",
      "epoch:  23800 train_loss: 0.6335996389389038 val_loss: 29.467926025390625\n",
      "epoch:  23900 train_loss: 0.5617598295211792 val_loss: 29.609966278076172\n",
      "epoch:  24000 train_loss: 0.8034492135047913 val_loss: 29.421281814575195\n",
      "epoch:  24100 train_loss: 0.5669184327125549 val_loss: 29.716136932373047\n",
      "epoch:  24200 train_loss: 0.5403112769126892 val_loss: 29.652301788330078\n",
      "epoch:  24300 train_loss: 0.5594736933708191 val_loss: 29.50973892211914\n",
      "epoch:  24400 train_loss: 0.8496870994567871 val_loss: 29.755334854125977\n",
      "epoch:  24500 train_loss: 0.5280906558036804 val_loss: 29.744895935058594\n",
      "epoch:  24600 train_loss: 0.5402681827545166 val_loss: 29.803369522094727\n",
      "epoch:  24700 train_loss: 0.5100501179695129 val_loss: 29.690532684326172\n",
      "epoch:  24800 train_loss: 0.6761725544929504 val_loss: 30.0416202545166\n",
      "epoch:  24900 train_loss: 0.5073736310005188 val_loss: 29.944995880126953\n",
      "epoch:  25000 train_loss: 0.49029698967933655 val_loss: 29.78072166442871\n",
      "epoch:  25100 train_loss: 0.5640490055084229 val_loss: 29.80109405517578\n",
      "epoch:  25200 train_loss: 0.6011132001876831 val_loss: 29.89297103881836\n",
      "epoch:  25300 train_loss: 0.5222451090812683 val_loss: 29.712127685546875\n",
      "epoch:  25400 train_loss: 0.5487320423126221 val_loss: 29.861549377441406\n",
      "epoch:  25500 train_loss: 0.7271663546562195 val_loss: 30.115633010864258\n",
      "epoch:  25600 train_loss: 0.5107935667037964 val_loss: 30.18743324279785\n",
      "epoch:  25700 train_loss: 0.7276162505149841 val_loss: 29.791276931762695\n",
      "epoch:  25800 train_loss: 0.5929753184318542 val_loss: 30.127946853637695\n",
      "epoch:  25900 train_loss: 0.4617408812046051 val_loss: 29.886560440063477\n",
      "epoch:  26000 train_loss: 0.4826907217502594 val_loss: 30.061796188354492\n",
      "epoch:  26100 train_loss: 0.4910649359226227 val_loss: 30.243234634399414\n",
      "epoch:  26200 train_loss: 0.4825827479362488 val_loss: 29.93449592590332\n",
      "epoch:  26300 train_loss: 0.4952227473258972 val_loss: 30.251541137695312\n",
      "epoch:  26400 train_loss: 0.4419386684894562 val_loss: 30.07183837890625\n",
      "epoch:  26500 train_loss: 0.44898566603660583 val_loss: 30.12090301513672\n",
      "epoch:  26600 train_loss: 0.5317370295524597 val_loss: 30.258419036865234\n",
      "epoch:  26700 train_loss: 0.4223767817020416 val_loss: 30.18341064453125\n",
      "epoch:  26800 train_loss: 0.4027918875217438 val_loss: 30.16036033630371\n",
      "epoch:  26900 train_loss: 0.43182429671287537 val_loss: 30.418495178222656\n",
      "epoch:  27000 train_loss: 0.582157552242279 val_loss: 30.452728271484375\n",
      "epoch:  27100 train_loss: 0.4925479590892792 val_loss: 30.370908737182617\n",
      "epoch:  27200 train_loss: 0.4501553773880005 val_loss: 30.298416137695312\n",
      "epoch:  27300 train_loss: 0.4162813723087311 val_loss: 30.46428680419922\n",
      "epoch:  27400 train_loss: 0.5279550552368164 val_loss: 30.545494079589844\n",
      "epoch:  27500 train_loss: 0.4096876382827759 val_loss: 30.311437606811523\n",
      "epoch:  27600 train_loss: 0.4314544200897217 val_loss: 30.4908447265625\n",
      "epoch:  27700 train_loss: 0.4071711301803589 val_loss: 30.538633346557617\n",
      "epoch:  27800 train_loss: 0.4845937192440033 val_loss: 30.871274948120117\n",
      "epoch:  27900 train_loss: 0.4619060456752777 val_loss: 30.31680679321289\n",
      "epoch:  28000 train_loss: 0.5011634230613708 val_loss: 30.54987144470215\n",
      "epoch:  28100 train_loss: 0.3617227375507355 val_loss: 30.587297439575195\n",
      "epoch:  28200 train_loss: 0.4314228892326355 val_loss: 30.6302547454834\n",
      "epoch:  28300 train_loss: 0.4177924394607544 val_loss: 30.718120574951172\n",
      "epoch:  28400 train_loss: 0.4717857539653778 val_loss: 30.87131118774414\n",
      "epoch:  28500 train_loss: 0.4218578636646271 val_loss: 30.625076293945312\n",
      "epoch:  28600 train_loss: 0.3367934226989746 val_loss: 30.806001663208008\n",
      "epoch:  28700 train_loss: 0.5002362728118896 val_loss: 30.81761360168457\n",
      "epoch:  28800 train_loss: 0.3788756728172302 val_loss: 30.886133193969727\n",
      "epoch:  28900 train_loss: 0.3421654999256134 val_loss: 30.845478057861328\n",
      "epoch:  29000 train_loss: 0.4543485641479492 val_loss: 31.06728172302246\n",
      "epoch:  29100 train_loss: 0.32328400015830994 val_loss: 30.914106369018555\n",
      "epoch:  29200 train_loss: 0.3908868432044983 val_loss: 30.724124908447266\n",
      "epoch:  29300 train_loss: 0.32969850301742554 val_loss: 30.933616638183594\n",
      "epoch:  29400 train_loss: 0.5103711485862732 val_loss: 30.793832778930664\n",
      "epoch:  29500 train_loss: 0.4031316637992859 val_loss: 30.74870491027832\n",
      "epoch:  29600 train_loss: 0.38608765602111816 val_loss: 31.22239875793457\n",
      "epoch:  29700 train_loss: 0.7180886268615723 val_loss: 30.74601173400879\n",
      "epoch:  29800 train_loss: 0.3405213952064514 val_loss: 31.281206130981445\n",
      "epoch:  29900 train_loss: 0.3487390875816345 val_loss: 31.14964485168457\n",
      "epoch:  30000 train_loss: 0.28353357315063477 val_loss: 31.07429313659668\n",
      "epoch:  30100 train_loss: 0.3256109654903412 val_loss: 31.11001968383789\n",
      "epoch:  30200 train_loss: 0.3323071300983429 val_loss: 31.126873016357422\n",
      "epoch:  30300 train_loss: 0.28702113032341003 val_loss: 31.098527908325195\n",
      "epoch:  30400 train_loss: 0.29751843214035034 val_loss: 31.104175567626953\n",
      "epoch:  30500 train_loss: 0.28054600954055786 val_loss: 31.09977912902832\n",
      "epoch:  30600 train_loss: 0.4778877794742584 val_loss: 31.17925453186035\n",
      "epoch:  30700 train_loss: 0.34828582406044006 val_loss: 31.302162170410156\n",
      "epoch:  30800 train_loss: 0.591423511505127 val_loss: 31.340850830078125\n",
      "epoch:  30900 train_loss: 0.30661872029304504 val_loss: 31.1553955078125\n",
      "epoch:  31000 train_loss: 0.2574482560157776 val_loss: 31.149202346801758\n",
      "epoch:  31100 train_loss: 0.37907496094703674 val_loss: 31.280860900878906\n",
      "epoch:  31200 train_loss: 0.2960537374019623 val_loss: 31.22176742553711\n",
      "epoch:  31300 train_loss: 0.2508067786693573 val_loss: 31.024980545043945\n",
      "epoch:  31400 train_loss: 0.25578126311302185 val_loss: 31.196636199951172\n",
      "epoch:  31500 train_loss: 0.3362160921096802 val_loss: 31.129146575927734\n",
      "epoch:  31600 train_loss: 0.29822292923927307 val_loss: 31.129987716674805\n",
      "epoch:  31700 train_loss: 0.29228639602661133 val_loss: 31.30541229248047\n",
      "epoch:  31800 train_loss: 0.3651043176651001 val_loss: 31.293153762817383\n",
      "epoch:  31900 train_loss: 0.24501533806324005 val_loss: 31.056354522705078\n",
      "epoch:  32000 train_loss: 0.2706224024295807 val_loss: 31.230318069458008\n",
      "epoch:  32100 train_loss: 0.254376620054245 val_loss: 31.084163665771484\n",
      "epoch:  32200 train_loss: 0.34014058113098145 val_loss: 31.22423553466797\n",
      "epoch:  32300 train_loss: 0.301800400018692 val_loss: 31.109792709350586\n",
      "epoch:  32400 train_loss: 0.2154257446527481 val_loss: 31.067811965942383\n",
      "epoch:  32500 train_loss: 0.30769211053848267 val_loss: 30.92819595336914\n",
      "epoch:  32600 train_loss: 0.23170119524002075 val_loss: 31.081077575683594\n",
      "epoch:  32700 train_loss: 0.35536155104637146 val_loss: 31.11032485961914\n",
      "epoch:  32800 train_loss: 0.34755271673202515 val_loss: 31.07344627380371\n",
      "epoch:  32900 train_loss: 0.23961810767650604 val_loss: 31.08818244934082\n",
      "epoch:  33000 train_loss: 0.2573946714401245 val_loss: 31.226531982421875\n",
      "epoch:  33100 train_loss: 0.22148315608501434 val_loss: 31.0498104095459\n",
      "epoch:  33200 train_loss: 0.2319507896900177 val_loss: 31.193967819213867\n",
      "epoch:  33300 train_loss: 0.2460378259420395 val_loss: 31.145896911621094\n",
      "epoch:  33400 train_loss: 0.3284345865249634 val_loss: 31.184133529663086\n",
      "epoch:  33500 train_loss: 0.22456695139408112 val_loss: 31.06285285949707\n",
      "epoch:  33600 train_loss: 0.18455879390239716 val_loss: 31.07735824584961\n",
      "epoch:  33700 train_loss: 0.29477444291114807 val_loss: 30.79785919189453\n",
      "epoch:  33800 train_loss: 0.19626133143901825 val_loss: 31.039297103881836\n",
      "epoch:  33900 train_loss: 0.4780787527561188 val_loss: 31.140270233154297\n",
      "epoch:  34000 train_loss: 0.2026565968990326 val_loss: 31.08618927001953\n",
      "epoch:  34100 train_loss: 0.2505405843257904 val_loss: 31.135499954223633\n",
      "epoch:  34200 train_loss: 0.2622673511505127 val_loss: 31.04404067993164\n",
      "epoch:  34300 train_loss: 0.253070592880249 val_loss: 30.972930908203125\n",
      "epoch:  34400 train_loss: 0.20104721188545227 val_loss: 31.114416122436523\n",
      "epoch:  34500 train_loss: 0.34811246395111084 val_loss: 30.90263557434082\n",
      "epoch:  34600 train_loss: 0.18182383477687836 val_loss: 31.063974380493164\n",
      "epoch:  34700 train_loss: 0.1809369921684265 val_loss: 30.94011116027832\n",
      "epoch:  34800 train_loss: 0.2516717314720154 val_loss: 30.925037384033203\n",
      "epoch:  34900 train_loss: 0.2022113800048828 val_loss: 30.98284339904785\n",
      "epoch:  35000 train_loss: 0.15837997198104858 val_loss: 31.010860443115234\n",
      "epoch:  35100 train_loss: 0.2724761366844177 val_loss: 31.038850784301758\n",
      "epoch:  35200 train_loss: 0.21422356367111206 val_loss: 31.01747703552246\n",
      "epoch:  35300 train_loss: 0.2079167366027832 val_loss: 30.949148178100586\n",
      "epoch:  35400 train_loss: 0.20676246285438538 val_loss: 30.97477149963379\n",
      "epoch:  35500 train_loss: 0.17856928706169128 val_loss: 30.976964950561523\n",
      "epoch:  35600 train_loss: 0.32122209668159485 val_loss: 31.06575584411621\n",
      "epoch:  35700 train_loss: 0.1888747215270996 val_loss: 30.90323257446289\n",
      "epoch:  35800 train_loss: 0.1797022819519043 val_loss: 30.904563903808594\n",
      "epoch:  35900 train_loss: 0.17205916345119476 val_loss: 31.003271102905273\n",
      "sigma: 6.4 RMSE:  tensor(6.7785, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Generate the dataset with noise N(0, sigma)\n",
    "i = 0\n",
    "sigma = 6.4\n",
    "my_dataset = []\n",
    "for ud in UDs:\n",
    "    example = []\n",
    "    for an in ANs:\n",
    "        noise = np.random.normal(0,sigma)\n",
    "        # 0 is mean\n",
    "        # sigma is the deviation of the normal distribution\n",
    "        d = compute_3d_distance(ud, an) + noise\n",
    "        example.append(d)\n",
    "    \n",
    "    # append x, y, z as col#10, #11, #12\n",
    "    example.append(ud[0])\n",
    "    example.append(ud[1])\n",
    "    example.append(ud[2])\n",
    "    \n",
    "    # append 1x13 example row into my_dataset\n",
    "    my_dataset.append(example)  # expected to be 3000x13  \n",
    "    \n",
    "# Load dataset\n",
    "exercise5_dataset = Exercise5Dataset(list_dataset = my_dataset, shuffle=True)\n",
    "\n",
    "#Split dataset by 0.8: 0.1: 0.1\n",
    "train_examples, train_labels = exercise5_dataset[:int(3000*0.8)]  # (2400, 10)   # (2400, 3)\n",
    "val_examples, val_labels = exercise5_dataset[int(3000*0.8):int(3000*0.9)]    # (300, 10)   #(300, 3)\n",
    "test_examples, test_labels = exercise5_dataset[int(3000*0.9):]     #(300, 10)   # (300, 3)\n",
    "\n",
    "###Define model, loss function and optimizer\n",
    "# if we have GPU, then use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define model\n",
    "#model = Net(x_dim = train_examples.shape[1], y_dim = train_labels.shape[1]).to(device)\n",
    "input_dim = 1     #input dim is 1, seq_len = 10\n",
    "hidden_dim = 64   #hidden state dim is 64\n",
    "n_layers = 3             #3-layered LSTM\n",
    "model = MYLSTM(input_dim, hidden_dim, n_layers).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Correct the input/output shape for LSTM\n",
    "train_inputs = torch.unsqueeze(train_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "train_inputs = train_inputs.to(device) \n",
    "\n",
    "val_inputs = torch.unsqueeze(val_examples, dim=-1)   # (N, 10) -> (N, 10, 1)\n",
    "val_inputs = val_inputs.to(device) \n",
    "\n",
    "train_labels = train_labels.to(device)   #(N, 3)\n",
    "val_labels = val_labels.to(device)          #(N, 3)\n",
    "\n",
    "\n",
    "# Define the loss threshold, if the current train loss is lower than the threshold, we will begin to save the model\n",
    "best_loss = 100.0\n",
    "\n",
    "# Define the model filename for model.save()\n",
    "MODEL_FILENAME = \"best.pth\"\n",
    "\n",
    "# set model to Training mode\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "NUM_OF_EPOCH = 36000\n",
    "\n",
    "# Train\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    y_pred = model(train_inputs)\n",
    "    loss = loss_fn(y_pred, train_labels).cpu()\n",
    "    #print(t, loss.item())\n",
    "    train_losses.append(loss.item())\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    # BGD\n",
    "    optimizer.step()\n",
    "    \n",
    "    # evaluate validation loss\n",
    "    val_pred = model(val_inputs)\n",
    "    loss = loss_fn(val_pred, val_labels)\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "\n",
    "\n",
    "    if (epoch % 100) == 0:\n",
    "        print(\"epoch: \", epoch, \"train_loss:\", train_losses[-1], \"val_loss:\", val_losses[-1])\n",
    "        # check if we got better loss\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n",
    "        \n",
    "# Load the best model on previous step\n",
    "model.load_state_dict(torch.load(\"best.pth\"))\n",
    "\n",
    "# Inference all testing examples and compute RMSE\n",
    "def square_error(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  square_error= loss_fn(a, b)\n",
    "  return square_error\n",
    "\n",
    "model.eval() # inference mode\n",
    "test_inputs = torch.unsqueeze(test_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "test_inputs = test_inputs.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "\n",
    "test_preds = model(test_inputs)\n",
    "#print(\"example: \", test_example.cpu())\n",
    "#print(\"========================================\")\n",
    "#print(\"ground_truth:\", test_label.cpu())\n",
    "#print(\"prediction:\", test_pred.cpu())\n",
    "#print(\"========================================\")\n",
    "\n",
    "\n",
    "total_errors = 0.0\n",
    "for idx in range(len(test_inputs)):\n",
    "    total_errors += square_error(test_preds[idx], test_labels[idx])\n",
    "    \n",
    "RMSE = torch.sqrt(total_errors / len(test_inputs))\n",
    "print(\"sigma:\", sigma, \"RMSE: \",  RMSE)\n",
    "\n",
    "sigmas.append(sigma)\n",
    "RMSEs.append(RMSE.cpu().detach().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigma = 7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffle = True!\n",
      "epoch:  0 train_loss: 7343.42919921875 val_loss: 7287.8662109375\n",
      "epoch:  100 train_loss: 5976.57568359375 val_loss: 5918.86328125\n",
      "epoch:  200 train_loss: 5042.6083984375 val_loss: 4992.001953125\n",
      "epoch:  300 train_loss: 4280.9482421875 val_loss: 4235.93798828125\n",
      "epoch:  400 train_loss: 3635.251708984375 val_loss: 3594.9833984375\n",
      "epoch:  500 train_loss: 3082.718994140625 val_loss: 3046.69287109375\n",
      "epoch:  600 train_loss: 2608.20556640625 val_loss: 2576.18310546875\n",
      "epoch:  700 train_loss: 2200.729736328125 val_loss: 2172.138427734375\n",
      "epoch:  800 train_loss: 1850.9842529296875 val_loss: 1825.4766845703125\n",
      "epoch:  900 train_loss: 1551.6112060546875 val_loss: 1528.791748046875\n",
      "epoch:  1000 train_loss: 1296.4017333984375 val_loss: 1275.90869140625\n",
      "epoch:  1100 train_loss: 1079.931396484375 val_loss: 1061.7158203125\n",
      "epoch:  1200 train_loss: 897.868408203125 val_loss: 881.6083374023438\n",
      "epoch:  1300 train_loss: 746.0778198242188 val_loss: 731.5398559570312\n",
      "epoch:  1400 train_loss: 620.5810546875 val_loss: 607.8233642578125\n",
      "epoch:  1500 train_loss: 518.2791748046875 val_loss: 506.8273010253906\n",
      "epoch:  1600 train_loss: 435.76812744140625 val_loss: 425.5513000488281\n",
      "epoch:  1700 train_loss: 369.9903564453125 val_loss: 361.0372619628906\n",
      "epoch:  1800 train_loss: 318.3086242675781 val_loss: 310.5836181640625\n",
      "epoch:  1900 train_loss: 278.5335388183594 val_loss: 271.58868408203125\n",
      "epoch:  2000 train_loss: 248.299560546875 val_loss: 242.19334411621094\n",
      "epoch:  2100 train_loss: 225.67515563964844 val_loss: 220.39723205566406\n",
      "epoch:  2200 train_loss: 209.14439392089844 val_loss: 204.4677276611328\n",
      "epoch:  2300 train_loss: 197.2568817138672 val_loss: 193.14791870117188\n",
      "epoch:  2400 train_loss: 188.90618896484375 val_loss: 185.31854248046875\n",
      "epoch:  2500 train_loss: 183.21194458007812 val_loss: 180.0128173828125\n",
      "epoch:  2600 train_loss: 179.37249755859375 val_loss: 176.5097198486328\n",
      "epoch:  2700 train_loss: 176.87924194335938 val_loss: 174.3022918701172\n",
      "epoch:  2800 train_loss: 175.28402709960938 val_loss: 172.94229125976562\n",
      "epoch:  2900 train_loss: 174.2959442138672 val_loss: 172.14205932617188\n",
      "epoch:  3000 train_loss: 173.70989990234375 val_loss: 171.70758056640625\n",
      "epoch:  3100 train_loss: 173.36398315429688 val_loss: 171.48104858398438\n",
      "epoch:  3200 train_loss: 173.17454528808594 val_loss: 171.37599182128906\n",
      "epoch:  3300 train_loss: 173.06829833984375 val_loss: 171.3418731689453\n",
      "epoch:  3400 train_loss: 173.0133514404297 val_loss: 171.33743286132812\n",
      "epoch:  3500 train_loss: 172.9875030517578 val_loss: 171.34658813476562\n",
      "epoch:  3600 train_loss: 172.97372436523438 val_loss: 171.36123657226562\n",
      "epoch:  3700 train_loss: 172.9674072265625 val_loss: 171.3704071044922\n",
      "epoch:  3800 train_loss: 172.96473693847656 val_loss: 171.38699340820312\n",
      "epoch:  3900 train_loss: 172.9635467529297 val_loss: 171.391845703125\n",
      "epoch:  4000 train_loss: 172.96316528320312 val_loss: 171.3956298828125\n",
      "epoch:  4100 train_loss: 172.96290588378906 val_loss: 171.3976593017578\n",
      "epoch:  4200 train_loss: 172.96282958984375 val_loss: 171.4027099609375\n",
      "epoch:  4300 train_loss: 172.9628143310547 val_loss: 171.40382385253906\n",
      "epoch:  4400 train_loss: 172.9628143310547 val_loss: 171.40447998046875\n",
      "epoch:  4500 train_loss: 172.9628143310547 val_loss: 171.4044952392578\n",
      "epoch:  4600 train_loss: 172.9628143310547 val_loss: 171.40420532226562\n",
      "epoch:  4700 train_loss: 172.9628143310547 val_loss: 171.40487670898438\n",
      "epoch:  4800 train_loss: 172.9628143310547 val_loss: 171.40524291992188\n",
      "epoch:  4900 train_loss: 172.9628143310547 val_loss: 171.40524291992188\n",
      "epoch:  5000 train_loss: 172.9628143310547 val_loss: 171.40524291992188\n",
      "epoch:  5100 train_loss: 172.9628143310547 val_loss: 171.40524291992188\n",
      "epoch:  5200 train_loss: 172.9628143310547 val_loss: 171.40524291992188\n",
      "epoch:  5300 train_loss: 172.9628143310547 val_loss: 171.40524291992188\n",
      "epoch:  5400 train_loss: 172.9628143310547 val_loss: 171.40524291992188\n",
      "epoch:  5500 train_loss: 172.9628143310547 val_loss: 171.40524291992188\n",
      "epoch:  5600 train_loss: 172.9628143310547 val_loss: 171.40524291992188\n",
      "epoch:  5700 train_loss: 172.9628143310547 val_loss: 171.40524291992188\n",
      "epoch:  5800 train_loss: 172.9628143310547 val_loss: 171.40524291992188\n",
      "epoch:  5900 train_loss: 172.9628143310547 val_loss: 171.40524291992188\n",
      "epoch:  6000 train_loss: 172.9628143310547 val_loss: 171.40524291992188\n",
      "epoch:  6100 train_loss: 172.9628143310547 val_loss: 171.40524291992188\n",
      "epoch:  6200 train_loss: 172.9628143310547 val_loss: 171.40524291992188\n",
      "epoch:  6300 train_loss: 172.9628143310547 val_loss: 171.40524291992188\n",
      "epoch:  6400 train_loss: 172.9628143310547 val_loss: 171.40524291992188\n",
      "epoch:  6500 train_loss: 172.9628143310547 val_loss: 171.4044952392578\n",
      "epoch:  6600 train_loss: 172.9628143310547 val_loss: 171.40524291992188\n",
      "epoch:  6700 train_loss: 172.9628143310547 val_loss: 171.40524291992188\n",
      "epoch:  6800 train_loss: 172.9628143310547 val_loss: 171.40524291992188\n",
      "epoch:  6900 train_loss: 172.9628143310547 val_loss: 171.40524291992188\n",
      "epoch:  7000 train_loss: 172.96282958984375 val_loss: 171.40524291992188\n",
      "epoch:  7100 train_loss: 170.76429748535156 val_loss: 168.37806701660156\n",
      "epoch:  7200 train_loss: 123.64733123779297 val_loss: 122.42770385742188\n",
      "epoch:  7300 train_loss: 112.9012451171875 val_loss: 112.4496841430664\n",
      "epoch:  7400 train_loss: 104.65696716308594 val_loss: 104.00137329101562\n",
      "epoch:  7500 train_loss: 97.5482177734375 val_loss: 103.85279846191406\n",
      "epoch:  7600 train_loss: 85.6150894165039 val_loss: 85.23989868164062\n",
      "epoch:  7700 train_loss: 77.0682373046875 val_loss: 76.4522705078125\n",
      "epoch:  7800 train_loss: 69.5269775390625 val_loss: 68.0347671508789\n",
      "epoch:  7900 train_loss: 62.39906311035156 val_loss: 61.35996627807617\n",
      "epoch:  8000 train_loss: 54.739501953125 val_loss: 53.84075927734375\n",
      "epoch:  8100 train_loss: 45.71307373046875 val_loss: 45.506900787353516\n",
      "epoch:  8200 train_loss: 37.46946334838867 val_loss: 37.5970458984375\n",
      "epoch:  8300 train_loss: 31.378570556640625 val_loss: 32.33077621459961\n",
      "epoch:  8400 train_loss: 27.57578468322754 val_loss: 29.052053451538086\n",
      "epoch:  8500 train_loss: 24.32075309753418 val_loss: 26.440326690673828\n",
      "epoch:  8600 train_loss: 22.218521118164062 val_loss: 24.874670028686523\n",
      "epoch:  8700 train_loss: 20.629955291748047 val_loss: 23.400144577026367\n",
      "epoch:  8800 train_loss: 19.380130767822266 val_loss: 22.371606826782227\n",
      "epoch:  8900 train_loss: 18.5892276763916 val_loss: 21.702604293823242\n",
      "epoch:  9000 train_loss: 18.21282958984375 val_loss: 21.622495651245117\n",
      "epoch:  9100 train_loss: 17.331581115722656 val_loss: 20.82293701171875\n",
      "epoch:  9200 train_loss: 16.96040916442871 val_loss: 20.565332412719727\n",
      "epoch:  9300 train_loss: 16.636024475097656 val_loss: 20.384075164794922\n",
      "epoch:  9400 train_loss: 16.288232803344727 val_loss: 20.777076721191406\n",
      "epoch:  9500 train_loss: 16.184457778930664 val_loss: 20.02227020263672\n",
      "epoch:  9600 train_loss: 15.705137252807617 val_loss: 20.099794387817383\n",
      "epoch:  9700 train_loss: 15.294872283935547 val_loss: 19.934301376342773\n",
      "epoch:  9800 train_loss: 15.077485084533691 val_loss: 19.58914566040039\n",
      "epoch:  9900 train_loss: 14.872777938842773 val_loss: 19.64305305480957\n",
      "epoch:  10000 train_loss: 14.962701797485352 val_loss: 19.793106079101562\n",
      "epoch:  10100 train_loss: 14.547768592834473 val_loss: 19.832103729248047\n",
      "epoch:  10200 train_loss: 14.326419830322266 val_loss: 19.60643768310547\n",
      "epoch:  10300 train_loss: 14.332152366638184 val_loss: 20.293338775634766\n",
      "epoch:  10400 train_loss: 13.93608570098877 val_loss: 20.080894470214844\n",
      "epoch:  10500 train_loss: 13.905304908752441 val_loss: 20.036527633666992\n",
      "epoch:  10600 train_loss: 13.549509048461914 val_loss: 20.141407012939453\n",
      "epoch:  10700 train_loss: 13.449027061462402 val_loss: 20.24812126159668\n",
      "epoch:  10800 train_loss: 13.254535675048828 val_loss: 20.81757354736328\n",
      "epoch:  10900 train_loss: 13.052403450012207 val_loss: 20.710771560668945\n",
      "epoch:  11000 train_loss: 12.796586036682129 val_loss: 20.788240432739258\n",
      "epoch:  11100 train_loss: 12.609464645385742 val_loss: 21.147977828979492\n",
      "epoch:  11200 train_loss: 12.4595308303833 val_loss: 21.217727661132812\n",
      "epoch:  11300 train_loss: 12.122199058532715 val_loss: 21.36281394958496\n",
      "epoch:  11400 train_loss: 11.929576873779297 val_loss: 21.877016067504883\n",
      "epoch:  11500 train_loss: 11.780950546264648 val_loss: 22.104358673095703\n",
      "epoch:  11600 train_loss: 11.617091178894043 val_loss: 22.254684448242188\n",
      "epoch:  11700 train_loss: 11.354528427124023 val_loss: 22.432769775390625\n",
      "epoch:  11800 train_loss: 11.284262657165527 val_loss: 22.85761833190918\n",
      "epoch:  11900 train_loss: 10.989118576049805 val_loss: 22.762405395507812\n",
      "epoch:  12000 train_loss: 10.657293319702148 val_loss: 22.678529739379883\n",
      "epoch:  12100 train_loss: 11.130505561828613 val_loss: 23.015474319458008\n",
      "epoch:  12200 train_loss: 10.454909324645996 val_loss: 23.14457893371582\n",
      "epoch:  12300 train_loss: 10.5778169631958 val_loss: 23.385143280029297\n",
      "epoch:  12400 train_loss: 9.989616394042969 val_loss: 23.17719268798828\n",
      "epoch:  12500 train_loss: 9.806139945983887 val_loss: 23.45210838317871\n",
      "epoch:  12600 train_loss: 9.819005966186523 val_loss: 23.864295959472656\n",
      "epoch:  12700 train_loss: 9.466702461242676 val_loss: 23.7264461517334\n",
      "epoch:  12800 train_loss: 9.322918891906738 val_loss: 23.93796157836914\n",
      "epoch:  12900 train_loss: 9.165304183959961 val_loss: 24.060176849365234\n",
      "epoch:  13000 train_loss: 9.009310722351074 val_loss: 24.268850326538086\n",
      "epoch:  13100 train_loss: 9.248133659362793 val_loss: 24.44231414794922\n",
      "epoch:  13200 train_loss: 8.740365982055664 val_loss: 24.424163818359375\n",
      "epoch:  13300 train_loss: 8.585375785827637 val_loss: 24.568798065185547\n",
      "epoch:  13400 train_loss: 8.55196762084961 val_loss: 24.955934524536133\n",
      "epoch:  13500 train_loss: 8.46615982055664 val_loss: 24.718177795410156\n",
      "epoch:  13600 train_loss: 8.293732643127441 val_loss: 24.954959869384766\n",
      "epoch:  13700 train_loss: 8.105907440185547 val_loss: 24.76202392578125\n",
      "epoch:  13800 train_loss: 8.177889823913574 val_loss: 25.342191696166992\n",
      "epoch:  13900 train_loss: 8.004810333251953 val_loss: 25.568429946899414\n",
      "epoch:  14000 train_loss: 7.827244281768799 val_loss: 25.014631271362305\n",
      "epoch:  14100 train_loss: 7.7062153816223145 val_loss: 25.147735595703125\n",
      "epoch:  14200 train_loss: 7.978229522705078 val_loss: 25.211389541625977\n",
      "epoch:  14300 train_loss: 7.446101665496826 val_loss: 25.693702697753906\n",
      "epoch:  14400 train_loss: 7.566070556640625 val_loss: 25.53746223449707\n",
      "epoch:  14500 train_loss: 7.278465747833252 val_loss: 26.163238525390625\n",
      "epoch:  14600 train_loss: 7.119823455810547 val_loss: 26.52521514892578\n",
      "epoch:  14700 train_loss: 7.210081577301025 val_loss: 26.381122589111328\n",
      "epoch:  14800 train_loss: 7.168407917022705 val_loss: 26.56309700012207\n",
      "epoch:  14900 train_loss: 6.838206768035889 val_loss: 27.011184692382812\n",
      "epoch:  15000 train_loss: 7.471559524536133 val_loss: 28.357032775878906\n",
      "epoch:  15100 train_loss: 6.806334972381592 val_loss: 27.336620330810547\n",
      "epoch:  15200 train_loss: 6.598842620849609 val_loss: 27.613916397094727\n",
      "epoch:  15300 train_loss: 6.584062576293945 val_loss: 27.672636032104492\n",
      "epoch:  15400 train_loss: 7.149358749389648 val_loss: 28.776744842529297\n",
      "epoch:  15500 train_loss: 6.439494609832764 val_loss: 28.264957427978516\n",
      "epoch:  15600 train_loss: 6.418197154998779 val_loss: 27.908018112182617\n",
      "epoch:  15700 train_loss: 6.457676410675049 val_loss: 28.807968139648438\n",
      "epoch:  15800 train_loss: 6.154141902923584 val_loss: 27.986112594604492\n",
      "epoch:  15900 train_loss: 5.9123687744140625 val_loss: 27.989519119262695\n",
      "epoch:  16000 train_loss: 6.079991340637207 val_loss: 28.52996826171875\n",
      "epoch:  16100 train_loss: 5.730417728424072 val_loss: 28.373226165771484\n",
      "epoch:  16200 train_loss: 5.9854960441589355 val_loss: 28.56122398376465\n",
      "epoch:  16300 train_loss: 5.607400417327881 val_loss: 28.483932495117188\n",
      "epoch:  16400 train_loss: 5.476993083953857 val_loss: 28.74335479736328\n",
      "epoch:  16500 train_loss: 5.593319892883301 val_loss: 28.604625701904297\n",
      "epoch:  16600 train_loss: 5.456439971923828 val_loss: 28.977397918701172\n",
      "epoch:  16700 train_loss: 5.277925491333008 val_loss: 28.951026916503906\n",
      "epoch:  16800 train_loss: 5.228094577789307 val_loss: 29.330156326293945\n",
      "epoch:  16900 train_loss: 5.028015613555908 val_loss: 29.334657669067383\n",
      "epoch:  17000 train_loss: 5.088017463684082 val_loss: 29.3422794342041\n",
      "epoch:  17100 train_loss: 5.13124418258667 val_loss: 29.89004898071289\n",
      "epoch:  17200 train_loss: 5.107752799987793 val_loss: 29.722665786743164\n",
      "epoch:  17300 train_loss: 5.116165637969971 val_loss: 29.473529815673828\n",
      "epoch:  17400 train_loss: 4.809640407562256 val_loss: 29.537704467773438\n",
      "epoch:  17500 train_loss: 4.772117614746094 val_loss: 29.64359474182129\n",
      "epoch:  17600 train_loss: 4.560471534729004 val_loss: 29.973230361938477\n",
      "epoch:  17700 train_loss: 4.648438930511475 val_loss: 30.236324310302734\n",
      "epoch:  17800 train_loss: 4.705108642578125 val_loss: 30.240686416625977\n",
      "epoch:  17900 train_loss: 5.419716835021973 val_loss: 30.671293258666992\n",
      "epoch:  18000 train_loss: 4.466979026794434 val_loss: 30.72837257385254\n",
      "epoch:  18100 train_loss: 4.502334117889404 val_loss: 30.592805862426758\n",
      "epoch:  18200 train_loss: 5.119412422180176 val_loss: 30.096574783325195\n",
      "epoch:  18300 train_loss: 4.429038047790527 val_loss: 31.093637466430664\n",
      "epoch:  18400 train_loss: 4.4877753257751465 val_loss: 30.98076820373535\n",
      "epoch:  18500 train_loss: 4.411702632904053 val_loss: 31.266216278076172\n",
      "epoch:  18600 train_loss: 4.078935623168945 val_loss: 31.08719253540039\n",
      "epoch:  18700 train_loss: 4.101884365081787 val_loss: 30.762725830078125\n",
      "epoch:  18800 train_loss: 4.069037437438965 val_loss: 31.265565872192383\n",
      "epoch:  18900 train_loss: 3.886369466781616 val_loss: 31.164649963378906\n",
      "epoch:  19000 train_loss: 3.9256813526153564 val_loss: 31.090614318847656\n",
      "epoch:  19100 train_loss: 3.7955172061920166 val_loss: 31.191850662231445\n",
      "epoch:  19200 train_loss: 4.088736534118652 val_loss: 31.69003677368164\n",
      "epoch:  19300 train_loss: 3.837398052215576 val_loss: 31.724977493286133\n",
      "epoch:  19400 train_loss: 3.6111605167388916 val_loss: 31.570938110351562\n",
      "epoch:  19500 train_loss: 3.8408098220825195 val_loss: 31.98712921142578\n",
      "epoch:  19600 train_loss: 3.7454140186309814 val_loss: 31.66962242126465\n",
      "epoch:  19700 train_loss: 3.5606470108032227 val_loss: 31.74374008178711\n",
      "epoch:  19800 train_loss: 3.5990450382232666 val_loss: 31.84750747680664\n",
      "epoch:  19900 train_loss: 3.4198715686798096 val_loss: 31.860300064086914\n",
      "epoch:  20000 train_loss: 3.4914844036102295 val_loss: 32.147682189941406\n",
      "epoch:  20100 train_loss: 3.3055708408355713 val_loss: 32.15449905395508\n",
      "epoch:  20200 train_loss: 3.281431198120117 val_loss: 32.27284240722656\n",
      "epoch:  20300 train_loss: 3.5855844020843506 val_loss: 32.44872283935547\n",
      "epoch:  20400 train_loss: 3.6911849975585938 val_loss: 33.00277328491211\n",
      "epoch:  20500 train_loss: 3.757808208465576 val_loss: 32.747276306152344\n",
      "epoch:  20600 train_loss: 3.2041499614715576 val_loss: 32.13514709472656\n",
      "epoch:  20700 train_loss: 3.10534405708313 val_loss: 32.500144958496094\n",
      "epoch:  20800 train_loss: 3.674682140350342 val_loss: 33.00328826904297\n",
      "epoch:  20900 train_loss: 3.178593873977661 val_loss: 32.83135986328125\n",
      "epoch:  21000 train_loss: 3.0647642612457275 val_loss: 33.038692474365234\n",
      "epoch:  21100 train_loss: 2.9556891918182373 val_loss: 33.22592544555664\n",
      "epoch:  21200 train_loss: 3.2013049125671387 val_loss: 33.531959533691406\n",
      "epoch:  21300 train_loss: 2.8402626514434814 val_loss: 33.05506896972656\n",
      "epoch:  21400 train_loss: 3.001471996307373 val_loss: 33.69901657104492\n",
      "epoch:  21500 train_loss: 2.79775071144104 val_loss: 33.5982551574707\n",
      "epoch:  21600 train_loss: 2.9429407119750977 val_loss: 33.75688934326172\n",
      "epoch:  21700 train_loss: 2.8496856689453125 val_loss: 33.73887634277344\n",
      "epoch:  21800 train_loss: 3.1288840770721436 val_loss: 33.22793960571289\n",
      "epoch:  21900 train_loss: 2.740385055541992 val_loss: 34.01289367675781\n",
      "epoch:  22000 train_loss: 2.78865122795105 val_loss: 34.185157775878906\n",
      "epoch:  22100 train_loss: 2.6207075119018555 val_loss: 33.98126983642578\n",
      "epoch:  22200 train_loss: 2.592194080352783 val_loss: 34.13311004638672\n",
      "epoch:  22300 train_loss: 2.6300528049468994 val_loss: 34.30675506591797\n",
      "epoch:  22400 train_loss: 2.5625126361846924 val_loss: 34.35094451904297\n",
      "epoch:  22500 train_loss: 2.5756731033325195 val_loss: 34.95336151123047\n",
      "epoch:  22600 train_loss: 2.454197883605957 val_loss: 34.26824188232422\n",
      "epoch:  22700 train_loss: 2.9194552898406982 val_loss: 35.10205841064453\n",
      "epoch:  22800 train_loss: 2.565162181854248 val_loss: 35.044368743896484\n",
      "epoch:  22900 train_loss: 2.4136998653411865 val_loss: 34.79608917236328\n",
      "epoch:  23000 train_loss: 2.289520263671875 val_loss: 35.06816864013672\n",
      "epoch:  23100 train_loss: 2.8480942249298096 val_loss: 35.28429412841797\n",
      "epoch:  23200 train_loss: 3.060924530029297 val_loss: 35.63235855102539\n",
      "epoch:  23300 train_loss: 2.2802894115448 val_loss: 35.46925354003906\n",
      "epoch:  23400 train_loss: 2.2895121574401855 val_loss: 35.690757751464844\n",
      "epoch:  23500 train_loss: 2.2001662254333496 val_loss: 35.620113372802734\n",
      "epoch:  23600 train_loss: 2.1942741870880127 val_loss: 35.83777618408203\n",
      "epoch:  23700 train_loss: 2.400341033935547 val_loss: 36.0633544921875\n",
      "epoch:  23800 train_loss: 2.172365188598633 val_loss: 36.05467224121094\n",
      "epoch:  23900 train_loss: 2.4411580562591553 val_loss: 36.50863265991211\n",
      "epoch:  24000 train_loss: 2.368722677230835 val_loss: 36.02397155761719\n",
      "epoch:  24100 train_loss: 1.9958844184875488 val_loss: 36.492271423339844\n",
      "epoch:  24200 train_loss: 2.364043951034546 val_loss: 36.799522399902344\n",
      "epoch:  24300 train_loss: 2.0070440769195557 val_loss: 36.68378448486328\n",
      "epoch:  24400 train_loss: 2.0679914951324463 val_loss: 36.64140701293945\n",
      "epoch:  24500 train_loss: 2.0055625438690186 val_loss: 36.751094818115234\n",
      "epoch:  24600 train_loss: 1.9568253755569458 val_loss: 37.119049072265625\n",
      "epoch:  24700 train_loss: 2.5437355041503906 val_loss: 37.34436798095703\n",
      "epoch:  24800 train_loss: 1.9369982481002808 val_loss: 37.125850677490234\n",
      "epoch:  24900 train_loss: 2.1654303073883057 val_loss: 37.290828704833984\n",
      "epoch:  25000 train_loss: 2.4002301692962646 val_loss: 37.23928451538086\n",
      "epoch:  25100 train_loss: 2.071597099304199 val_loss: 37.34743118286133\n",
      "epoch:  25200 train_loss: 1.8888628482818604 val_loss: 37.49702453613281\n",
      "epoch:  25300 train_loss: 1.8356338739395142 val_loss: 37.51704788208008\n",
      "epoch:  25400 train_loss: 2.0829267501831055 val_loss: 37.539085388183594\n",
      "epoch:  25500 train_loss: 1.81264066696167 val_loss: 37.527496337890625\n",
      "epoch:  25600 train_loss: 1.9487049579620361 val_loss: 37.5175895690918\n",
      "epoch:  25700 train_loss: 1.8777340650558472 val_loss: 37.69980239868164\n",
      "epoch:  25800 train_loss: 1.7233314514160156 val_loss: 37.8521728515625\n",
      "epoch:  25900 train_loss: 1.8823283910751343 val_loss: 37.96561813354492\n",
      "epoch:  26000 train_loss: 1.9592448472976685 val_loss: 37.97993850708008\n",
      "epoch:  26100 train_loss: 1.6219748258590698 val_loss: 38.14506530761719\n",
      "epoch:  26200 train_loss: 1.7042014598846436 val_loss: 38.132877349853516\n",
      "epoch:  26300 train_loss: 1.7188260555267334 val_loss: 38.013179779052734\n",
      "epoch:  26400 train_loss: 1.6748650074005127 val_loss: 38.12828826904297\n",
      "epoch:  26500 train_loss: 1.5221856832504272 val_loss: 38.22296905517578\n",
      "epoch:  26600 train_loss: 1.8242841958999634 val_loss: 38.315834045410156\n",
      "epoch:  26700 train_loss: 1.711861252784729 val_loss: 38.52027893066406\n",
      "epoch:  26800 train_loss: 1.7991360425949097 val_loss: 38.54733657836914\n",
      "epoch:  26900 train_loss: 1.5022493600845337 val_loss: 38.49087142944336\n",
      "epoch:  27000 train_loss: 1.5781725645065308 val_loss: 38.581275939941406\n",
      "epoch:  27100 train_loss: 1.5423904657363892 val_loss: 38.61491394042969\n",
      "epoch:  27200 train_loss: 1.7541414499282837 val_loss: 38.541683197021484\n",
      "epoch:  27300 train_loss: 1.4979116916656494 val_loss: 38.575042724609375\n",
      "epoch:  27400 train_loss: 1.574026107788086 val_loss: 38.74454116821289\n",
      "epoch:  27500 train_loss: 1.7107294797897339 val_loss: 38.64434051513672\n",
      "epoch:  27600 train_loss: 1.503143310546875 val_loss: 38.95539855957031\n",
      "epoch:  27700 train_loss: 1.3469206094741821 val_loss: 38.72069549560547\n",
      "epoch:  27800 train_loss: 1.4274688959121704 val_loss: 38.8657112121582\n",
      "epoch:  27900 train_loss: 1.3340240716934204 val_loss: 38.76231002807617\n",
      "epoch:  28000 train_loss: 1.3567882776260376 val_loss: 38.8103141784668\n",
      "epoch:  28100 train_loss: 1.380911946296692 val_loss: 38.872718811035156\n",
      "epoch:  28200 train_loss: 1.3184418678283691 val_loss: 38.96510696411133\n",
      "epoch:  28300 train_loss: 1.4900401830673218 val_loss: 38.97690963745117\n",
      "epoch:  28400 train_loss: 1.4022479057312012 val_loss: 39.093326568603516\n",
      "epoch:  28500 train_loss: 1.2508010864257812 val_loss: 38.86842727661133\n",
      "epoch:  28600 train_loss: 1.3206931352615356 val_loss: 38.76642608642578\n",
      "epoch:  28700 train_loss: 1.4251171350479126 val_loss: 38.944923400878906\n",
      "epoch:  28800 train_loss: 1.3320527076721191 val_loss: 39.022430419921875\n",
      "epoch:  28900 train_loss: 1.2868937253952026 val_loss: 39.3504753112793\n",
      "epoch:  29000 train_loss: 1.37471604347229 val_loss: 39.254119873046875\n",
      "epoch:  29100 train_loss: 1.4969444274902344 val_loss: 39.28434371948242\n",
      "epoch:  29200 train_loss: 1.184720754623413 val_loss: 39.08778381347656\n",
      "epoch:  29300 train_loss: 1.170490026473999 val_loss: 39.28601837158203\n",
      "epoch:  29400 train_loss: 1.4149961471557617 val_loss: 39.32271957397461\n",
      "epoch:  29500 train_loss: 1.3548280000686646 val_loss: 39.30161666870117\n",
      "epoch:  29600 train_loss: 1.3176732063293457 val_loss: 38.95914077758789\n",
      "epoch:  29700 train_loss: 1.5020464658737183 val_loss: 39.49826431274414\n",
      "epoch:  29800 train_loss: 1.385837197303772 val_loss: 39.2244987487793\n",
      "epoch:  29900 train_loss: 1.1925941705703735 val_loss: 39.294944763183594\n",
      "epoch:  30000 train_loss: 1.0731126070022583 val_loss: 39.30180358886719\n",
      "epoch:  30100 train_loss: 1.2628329992294312 val_loss: 39.38935089111328\n",
      "epoch:  30200 train_loss: 1.1299891471862793 val_loss: 39.292747497558594\n",
      "epoch:  30300 train_loss: 1.0500041246414185 val_loss: 39.37810516357422\n",
      "epoch:  30400 train_loss: 1.0690627098083496 val_loss: 39.529720306396484\n",
      "epoch:  30500 train_loss: 1.1376993656158447 val_loss: 39.2895393371582\n",
      "epoch:  30600 train_loss: 1.2662378549575806 val_loss: 39.37847137451172\n",
      "epoch:  30700 train_loss: 1.1633304357528687 val_loss: 39.43548583984375\n",
      "epoch:  30800 train_loss: 0.9769497513771057 val_loss: 39.30414962768555\n",
      "epoch:  30900 train_loss: 1.4481796026229858 val_loss: 39.60026168823242\n",
      "epoch:  31000 train_loss: 1.144213080406189 val_loss: 39.308292388916016\n",
      "epoch:  31100 train_loss: 1.1515283584594727 val_loss: 39.5894660949707\n",
      "epoch:  31200 train_loss: 1.0362228155136108 val_loss: 39.46324920654297\n",
      "epoch:  31300 train_loss: 1.035959243774414 val_loss: 39.530601501464844\n",
      "epoch:  31400 train_loss: 1.0944080352783203 val_loss: 39.45521545410156\n",
      "epoch:  31500 train_loss: 1.1130387783050537 val_loss: 39.56608963012695\n",
      "epoch:  31600 train_loss: 0.9252645373344421 val_loss: 39.70478820800781\n",
      "epoch:  31700 train_loss: 0.8950901627540588 val_loss: 39.65607833862305\n",
      "epoch:  31800 train_loss: 0.9126669764518738 val_loss: 39.63520050048828\n",
      "epoch:  31900 train_loss: 0.9618554711341858 val_loss: 39.821102142333984\n",
      "epoch:  32000 train_loss: 0.939795970916748 val_loss: 39.687461853027344\n",
      "epoch:  32100 train_loss: 0.9325714111328125 val_loss: 39.645835876464844\n",
      "epoch:  32200 train_loss: 2.119332790374756 val_loss: 39.873870849609375\n",
      "epoch:  32300 train_loss: 0.8526881337165833 val_loss: 39.64419937133789\n",
      "epoch:  32400 train_loss: 1.1532573699951172 val_loss: 39.75334548950195\n",
      "epoch:  32500 train_loss: 1.063429594039917 val_loss: 39.75064468383789\n",
      "epoch:  32600 train_loss: 0.8748930096626282 val_loss: 39.72101593017578\n",
      "epoch:  32700 train_loss: 0.9526371955871582 val_loss: 39.662837982177734\n",
      "epoch:  32800 train_loss: 0.9216635227203369 val_loss: 40.033172607421875\n",
      "epoch:  32900 train_loss: 0.8676514625549316 val_loss: 40.07918167114258\n",
      "epoch:  33000 train_loss: 0.8325341939926147 val_loss: 40.01729202270508\n",
      "epoch:  33100 train_loss: 0.8356871604919434 val_loss: 39.920772552490234\n",
      "epoch:  33200 train_loss: 0.8233060240745544 val_loss: 40.01080322265625\n",
      "epoch:  33300 train_loss: 0.9476054310798645 val_loss: 40.029354095458984\n",
      "epoch:  33400 train_loss: 0.9287068843841553 val_loss: 39.83578109741211\n",
      "epoch:  33500 train_loss: 0.892771303653717 val_loss: 40.059974670410156\n",
      "epoch:  33600 train_loss: 0.7323882579803467 val_loss: 40.13043212890625\n",
      "epoch:  33700 train_loss: 0.9695103764533997 val_loss: 39.795936584472656\n",
      "epoch:  33800 train_loss: 0.8065710067749023 val_loss: 40.32004928588867\n",
      "epoch:  33900 train_loss: 0.8861363530158997 val_loss: 40.134246826171875\n",
      "epoch:  34000 train_loss: 0.788801372051239 val_loss: 40.07875061035156\n",
      "epoch:  34100 train_loss: 0.7586271166801453 val_loss: 40.187232971191406\n",
      "epoch:  34200 train_loss: 0.7671910524368286 val_loss: 40.256900787353516\n",
      "epoch:  34300 train_loss: 0.8157764077186584 val_loss: 39.8039665222168\n",
      "epoch:  34400 train_loss: 0.7060970067977905 val_loss: 40.2433967590332\n",
      "epoch:  34500 train_loss: 0.7327411770820618 val_loss: 40.37955093383789\n",
      "epoch:  34600 train_loss: 0.7354803085327148 val_loss: 40.47272491455078\n",
      "epoch:  34700 train_loss: 0.7899690270423889 val_loss: 40.36082077026367\n",
      "epoch:  34800 train_loss: 0.836762011051178 val_loss: 40.33395004272461\n",
      "epoch:  34900 train_loss: 0.6638210415840149 val_loss: 40.3154182434082\n",
      "epoch:  35000 train_loss: 0.9720214605331421 val_loss: 40.55152130126953\n",
      "epoch:  35100 train_loss: 0.8282415270805359 val_loss: 40.52014923095703\n",
      "epoch:  35200 train_loss: 0.7387689352035522 val_loss: 40.48471450805664\n",
      "epoch:  35300 train_loss: 0.7273402214050293 val_loss: 40.11532211303711\n",
      "epoch:  35400 train_loss: 0.6413570046424866 val_loss: 40.57474899291992\n",
      "epoch:  35500 train_loss: 0.7520690560340881 val_loss: 40.40966796875\n",
      "epoch:  35600 train_loss: 0.9707549214363098 val_loss: 40.87111282348633\n",
      "epoch:  35700 train_loss: 0.6636075973510742 val_loss: 40.696495056152344\n",
      "epoch:  35800 train_loss: 0.6842450499534607 val_loss: 40.65684127807617\n",
      "epoch:  35900 train_loss: 0.8532836437225342 val_loss: 40.74214553833008\n",
      "sigma: 7.3 RMSE:  tensor(7.4122, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Generate the dataset with noise N(0, sigma)\n",
    "i = 0\n",
    "sigma = 7.3\n",
    "my_dataset = []\n",
    "for ud in UDs:\n",
    "    example = []\n",
    "    for an in ANs:\n",
    "        noise = np.random.normal(0,sigma)\n",
    "        # 0 is mean\n",
    "        # sigma is the deviation of the normal distribution\n",
    "        d = compute_3d_distance(ud, an) + noise\n",
    "        example.append(d)\n",
    "    \n",
    "    # append x, y, z as col#10, #11, #12\n",
    "    example.append(ud[0])\n",
    "    example.append(ud[1])\n",
    "    example.append(ud[2])\n",
    "    \n",
    "    # append 1x13 example row into my_dataset\n",
    "    my_dataset.append(example)  # expected to be 3000x13  \n",
    "    \n",
    "# Load dataset\n",
    "exercise5_dataset = Exercise5Dataset(list_dataset = my_dataset, shuffle=True)\n",
    "\n",
    "#Split dataset by 0.8: 0.1: 0.1\n",
    "train_examples, train_labels = exercise5_dataset[:int(3000*0.8)]  # (2400, 10)   # (2400, 3)\n",
    "val_examples, val_labels = exercise5_dataset[int(3000*0.8):int(3000*0.9)]    # (300, 10)   #(300, 3)\n",
    "test_examples, test_labels = exercise5_dataset[int(3000*0.9):]     #(300, 10)   # (300, 3)\n",
    "\n",
    "###Define model, loss function and optimizer\n",
    "# if we have GPU, then use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define model\n",
    "#model = Net(x_dim = train_examples.shape[1], y_dim = train_labels.shape[1]).to(device)\n",
    "input_dim = 1     #input dim is 1, seq_len = 10\n",
    "hidden_dim = 64   #hidden state dim is 64\n",
    "n_layers = 3             #3-layered LSTM\n",
    "model = MYLSTM(input_dim, hidden_dim, n_layers).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Correct the input/output shape for LSTM\n",
    "train_inputs = torch.unsqueeze(train_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "train_inputs = train_inputs.to(device) \n",
    "\n",
    "val_inputs = torch.unsqueeze(val_examples, dim=-1)   # (N, 10) -> (N, 10, 1)\n",
    "val_inputs = val_inputs.to(device) \n",
    "\n",
    "train_labels = train_labels.to(device)   #(N, 3)\n",
    "val_labels = val_labels.to(device)          #(N, 3)\n",
    "\n",
    "\n",
    "# Define the loss threshold, if the current train loss is lower than the threshold, we will begin to save the model\n",
    "best_loss = 100.0\n",
    "\n",
    "# Define the model filename for model.save()\n",
    "MODEL_FILENAME = \"best.pth\"\n",
    "\n",
    "# set model to Training mode\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "NUM_OF_EPOCH = 36000\n",
    "\n",
    "# Train\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    y_pred = model(train_inputs)\n",
    "    loss = loss_fn(y_pred, train_labels).cpu()\n",
    "    #print(t, loss.item())\n",
    "    train_losses.append(loss.item())\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    # BGD\n",
    "    optimizer.step()\n",
    "    \n",
    "    # evaluate validation loss\n",
    "    val_pred = model(val_inputs)\n",
    "    loss = loss_fn(val_pred, val_labels)\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "\n",
    "\n",
    "    if (epoch % 100) == 0:\n",
    "        print(\"epoch: \", epoch, \"train_loss:\", train_losses[-1], \"val_loss:\", val_losses[-1])\n",
    "        # check if we got better loss\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n",
    "        \n",
    "# Load the best model on previous step\n",
    "model.load_state_dict(torch.load(\"best.pth\"))\n",
    "\n",
    "# Inference all testing examples and compute RMSE\n",
    "def square_error(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  square_error= loss_fn(a, b)\n",
    "  return square_error\n",
    "\n",
    "model.eval() # inference mode\n",
    "test_inputs = torch.unsqueeze(test_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "test_inputs = test_inputs.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "\n",
    "test_preds = model(test_inputs)\n",
    "#print(\"example: \", test_example.cpu())\n",
    "#print(\"========================================\")\n",
    "#print(\"ground_truth:\", test_label.cpu())\n",
    "#print(\"prediction:\", test_pred.cpu())\n",
    "#print(\"========================================\")\n",
    "\n",
    "\n",
    "total_errors = 0.0\n",
    "for idx in range(len(test_inputs)):\n",
    "    total_errors += square_error(test_preds[idx], test_labels[idx])\n",
    "    \n",
    "RMSE = torch.sqrt(total_errors / len(test_inputs))\n",
    "print(\"sigma:\", sigma, \"RMSE: \",  RMSE)\n",
    "\n",
    "sigmas.append(sigma)\n",
    "RMSEs.append(RMSE.cpu().detach().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigma = 8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffle = True!\n",
      "epoch:  0 train_loss: 7349.2734375 val_loss: 7329.3701171875\n",
      "epoch:  100 train_loss: 5890.2734375 val_loss: 5864.9521484375\n",
      "epoch:  200 train_loss: 4980.46240234375 val_loss: 4958.20556640625\n",
      "epoch:  300 train_loss: 4228.64208984375 val_loss: 4208.484375\n",
      "epoch:  400 train_loss: 3589.34033203125 val_loss: 3570.928955078125\n",
      "epoch:  500 train_loss: 3041.875 val_loss: 3024.947509765625\n",
      "epoch:  600 train_loss: 2571.98779296875 val_loss: 2556.7509765625\n",
      "epoch:  700 train_loss: 2168.476318359375 val_loss: 2154.805908203125\n",
      "epoch:  800 train_loss: 1822.559814453125 val_loss: 1810.1375732421875\n",
      "epoch:  900 train_loss: 1526.5711669921875 val_loss: 1515.5179443359375\n",
      "epoch:  1000 train_loss: 1274.52783203125 val_loss: 1264.7197265625\n",
      "epoch:  1100 train_loss: 1061.159423828125 val_loss: 1052.4232177734375\n",
      "epoch:  1200 train_loss: 881.7615966796875 val_loss: 874.14013671875\n",
      "epoch:  1300 train_loss: 732.418212890625 val_loss: 725.6917114257812\n",
      "epoch:  1400 train_loss: 609.0609741210938 val_loss: 603.4324340820312\n",
      "epoch:  1500 train_loss: 508.8247375488281 val_loss: 503.863037109375\n",
      "epoch:  1600 train_loss: 427.8980407714844 val_loss: 423.6811828613281\n",
      "epoch:  1700 train_loss: 363.5975646972656 val_loss: 360.1307067871094\n",
      "epoch:  1800 train_loss: 313.3355712890625 val_loss: 310.43310546875\n",
      "epoch:  1900 train_loss: 274.54296875 val_loss: 272.1566467285156\n",
      "epoch:  2000 train_loss: 245.12608337402344 val_loss: 243.27769470214844\n",
      "epoch:  2100 train_loss: 223.2740478515625 val_loss: 221.79788208007812\n",
      "epoch:  2200 train_loss: 207.3077850341797 val_loss: 206.16041564941406\n",
      "epoch:  2300 train_loss: 195.86843872070312 val_loss: 195.0635223388672\n",
      "epoch:  2400 train_loss: 187.85861206054688 val_loss: 187.30226135253906\n",
      "epoch:  2500 train_loss: 182.39247131347656 val_loss: 182.0445556640625\n",
      "epoch:  2600 train_loss: 178.76568603515625 val_loss: 178.56927490234375\n",
      "epoch:  2700 train_loss: 176.38096618652344 val_loss: 176.34588623046875\n",
      "epoch:  2800 train_loss: 174.88780212402344 val_loss: 174.954833984375\n",
      "epoch:  2900 train_loss: 173.9612579345703 val_loss: 174.12684631347656\n",
      "epoch:  3000 train_loss: 173.41041564941406 val_loss: 173.6480255126953\n",
      "epoch:  3100 train_loss: 173.0949249267578 val_loss: 173.38754272460938\n",
      "epoch:  3200 train_loss: 172.9155731201172 val_loss: 173.2513427734375\n",
      "epoch:  3300 train_loss: 172.8199005126953 val_loss: 173.18785095214844\n",
      "epoch:  3400 train_loss: 172.76995849609375 val_loss: 173.1612548828125\n",
      "epoch:  3500 train_loss: 172.74557495117188 val_loss: 173.15377807617188\n",
      "epoch:  3600 train_loss: 172.7335968017578 val_loss: 173.15374755859375\n",
      "epoch:  3700 train_loss: 172.7279510498047 val_loss: 173.1560516357422\n",
      "epoch:  3800 train_loss: 172.7253875732422 val_loss: 173.15975952148438\n",
      "epoch:  3900 train_loss: 172.7244110107422 val_loss: 173.16209411621094\n",
      "epoch:  4000 train_loss: 172.7239990234375 val_loss: 173.16427612304688\n",
      "epoch:  4100 train_loss: 172.7238311767578 val_loss: 173.1658172607422\n",
      "epoch:  4200 train_loss: 172.72378540039062 val_loss: 173.16702270507812\n",
      "epoch:  4300 train_loss: 172.72377014160156 val_loss: 173.16746520996094\n",
      "epoch:  4400 train_loss: 172.7237548828125 val_loss: 173.1676788330078\n",
      "epoch:  4500 train_loss: 172.7237548828125 val_loss: 173.1678009033203\n",
      "epoch:  4600 train_loss: 172.7237548828125 val_loss: 173.1678009033203\n",
      "epoch:  4700 train_loss: 172.72377014160156 val_loss: 173.1678924560547\n",
      "epoch:  4800 train_loss: 172.7237548828125 val_loss: 173.1678924560547\n",
      "epoch:  4900 train_loss: 172.7237548828125 val_loss: 173.16786193847656\n",
      "epoch:  5000 train_loss: 172.7237548828125 val_loss: 173.16795349121094\n",
      "epoch:  5100 train_loss: 172.7237548828125 val_loss: 173.1679229736328\n",
      "epoch:  5200 train_loss: 172.7237548828125 val_loss: 173.1679229736328\n",
      "epoch:  5300 train_loss: 172.7237548828125 val_loss: 173.1679229736328\n",
      "epoch:  5400 train_loss: 172.7237548828125 val_loss: 173.16795349121094\n",
      "epoch:  5500 train_loss: 172.7237548828125 val_loss: 173.1679229736328\n",
      "epoch:  5600 train_loss: 172.7237548828125 val_loss: 173.16795349121094\n",
      "epoch:  5700 train_loss: 172.7237548828125 val_loss: 173.16795349121094\n",
      "epoch:  5800 train_loss: 172.7237548828125 val_loss: 173.1679229736328\n",
      "epoch:  5900 train_loss: 172.7237548828125 val_loss: 173.16795349121094\n",
      "epoch:  6000 train_loss: 172.7237548828125 val_loss: 173.1679229736328\n",
      "epoch:  6100 train_loss: 172.7237548828125 val_loss: 173.16795349121094\n",
      "epoch:  6200 train_loss: 172.7237548828125 val_loss: 173.16795349121094\n",
      "epoch:  6300 train_loss: 172.7237548828125 val_loss: 173.1679229736328\n",
      "epoch:  6400 train_loss: 172.7237548828125 val_loss: 173.16795349121094\n",
      "epoch:  6500 train_loss: 172.7237548828125 val_loss: 173.16795349121094\n",
      "epoch:  6600 train_loss: 172.7237548828125 val_loss: 173.16795349121094\n",
      "epoch:  6700 train_loss: 172.7237548828125 val_loss: 173.16795349121094\n",
      "epoch:  6800 train_loss: 172.7237548828125 val_loss: 173.16786193847656\n",
      "epoch:  6900 train_loss: 172.7237548828125 val_loss: 173.1679229736328\n",
      "epoch:  7000 train_loss: 172.7237548828125 val_loss: 173.1679229736328\n",
      "epoch:  7100 train_loss: 172.7237548828125 val_loss: 173.1679229736328\n",
      "epoch:  7200 train_loss: 172.7237548828125 val_loss: 173.16786193847656\n",
      "epoch:  7300 train_loss: 172.7237548828125 val_loss: 173.1679229736328\n",
      "epoch:  7400 train_loss: 168.06072998046875 val_loss: 166.58343505859375\n",
      "epoch:  7500 train_loss: 126.05120849609375 val_loss: 124.4942398071289\n",
      "epoch:  7600 train_loss: 111.38941192626953 val_loss: 109.6934585571289\n",
      "epoch:  7700 train_loss: 100.44933319091797 val_loss: 99.27315521240234\n",
      "epoch:  7800 train_loss: 89.83265686035156 val_loss: 89.57967376708984\n",
      "epoch:  7900 train_loss: 81.01133728027344 val_loss: 81.92993927001953\n",
      "epoch:  8000 train_loss: 73.02725219726562 val_loss: 74.63927459716797\n",
      "epoch:  8100 train_loss: 65.2258529663086 val_loss: 66.09449005126953\n",
      "epoch:  8200 train_loss: 60.26769256591797 val_loss: 62.179176330566406\n",
      "epoch:  8300 train_loss: 56.1341438293457 val_loss: 58.55224609375\n",
      "epoch:  8400 train_loss: 51.98015213012695 val_loss: 54.37870788574219\n",
      "epoch:  8500 train_loss: 45.80154800415039 val_loss: 47.96144485473633\n",
      "epoch:  8600 train_loss: 37.17534255981445 val_loss: 39.78295135498047\n",
      "epoch:  8700 train_loss: 32.53121566772461 val_loss: 34.49491500854492\n",
      "epoch:  8800 train_loss: 27.70536994934082 val_loss: 30.945161819458008\n",
      "epoch:  8900 train_loss: 25.257802963256836 val_loss: 28.99239158630371\n",
      "epoch:  9000 train_loss: 23.925846099853516 val_loss: 27.89864158630371\n",
      "epoch:  9100 train_loss: 23.11399269104004 val_loss: 27.151273727416992\n",
      "epoch:  9200 train_loss: 22.629575729370117 val_loss: 27.148426055908203\n",
      "epoch:  9300 train_loss: 21.734167098999023 val_loss: 25.5435733795166\n",
      "epoch:  9400 train_loss: 20.940235137939453 val_loss: 25.219125747680664\n",
      "epoch:  9500 train_loss: 21.01279067993164 val_loss: 25.024484634399414\n",
      "epoch:  9600 train_loss: 20.18852996826172 val_loss: 24.62717056274414\n",
      "epoch:  9700 train_loss: 19.91288948059082 val_loss: 24.504281997680664\n",
      "epoch:  9800 train_loss: 20.227340698242188 val_loss: 24.634384155273438\n",
      "epoch:  9900 train_loss: 19.283329010009766 val_loss: 23.79374885559082\n",
      "epoch:  10000 train_loss: 19.065879821777344 val_loss: 23.711345672607422\n",
      "epoch:  10100 train_loss: 18.997787475585938 val_loss: 23.795312881469727\n",
      "epoch:  10200 train_loss: 18.58941078186035 val_loss: 23.648822784423828\n",
      "epoch:  10300 train_loss: 18.53244400024414 val_loss: 23.709705352783203\n",
      "epoch:  10400 train_loss: 18.354700088500977 val_loss: 23.779958724975586\n",
      "epoch:  10500 train_loss: 18.13828468322754 val_loss: 23.936281204223633\n",
      "epoch:  10600 train_loss: 17.781635284423828 val_loss: 23.866058349609375\n",
      "epoch:  10700 train_loss: 17.588598251342773 val_loss: 23.865144729614258\n",
      "epoch:  10800 train_loss: 17.342121124267578 val_loss: 23.97481346130371\n",
      "epoch:  10900 train_loss: 17.435501098632812 val_loss: 24.462398529052734\n",
      "epoch:  11000 train_loss: 16.98017120361328 val_loss: 24.05194664001465\n",
      "epoch:  11100 train_loss: 16.76214599609375 val_loss: 24.260435104370117\n",
      "epoch:  11200 train_loss: 16.677467346191406 val_loss: 24.167678833007812\n",
      "epoch:  11300 train_loss: 16.422067642211914 val_loss: 24.401880264282227\n",
      "epoch:  11400 train_loss: 16.507902145385742 val_loss: 24.786840438842773\n",
      "epoch:  11500 train_loss: 16.178077697753906 val_loss: 24.893524169921875\n",
      "epoch:  11600 train_loss: 16.164796829223633 val_loss: 24.97547721862793\n",
      "epoch:  11700 train_loss: 15.503260612487793 val_loss: 24.670625686645508\n",
      "epoch:  11800 train_loss: 15.494357109069824 val_loss: 25.20119857788086\n",
      "epoch:  11900 train_loss: 15.290849685668945 val_loss: 25.353910446166992\n",
      "epoch:  12000 train_loss: 15.036367416381836 val_loss: 25.404163360595703\n",
      "epoch:  12100 train_loss: 14.73353099822998 val_loss: 25.54374122619629\n",
      "epoch:  12200 train_loss: 14.485901832580566 val_loss: 25.772367477416992\n",
      "epoch:  12300 train_loss: 14.411761283874512 val_loss: 25.89795684814453\n",
      "epoch:  12400 train_loss: 14.118127822875977 val_loss: 26.17152214050293\n",
      "epoch:  12500 train_loss: 13.989778518676758 val_loss: 26.477807998657227\n",
      "epoch:  12600 train_loss: 13.807482719421387 val_loss: 26.82282829284668\n",
      "epoch:  12700 train_loss: 13.365764617919922 val_loss: 26.722326278686523\n",
      "epoch:  12800 train_loss: 13.596085548400879 val_loss: 27.250934600830078\n",
      "epoch:  12900 train_loss: 12.962828636169434 val_loss: 27.019207000732422\n",
      "epoch:  13000 train_loss: 13.360882759094238 val_loss: 27.604141235351562\n",
      "epoch:  13100 train_loss: 12.670315742492676 val_loss: 27.15106773376465\n",
      "epoch:  13200 train_loss: 12.39580249786377 val_loss: 27.627370834350586\n",
      "epoch:  13300 train_loss: 12.745038032531738 val_loss: 28.213911056518555\n",
      "epoch:  13400 train_loss: 12.252278327941895 val_loss: 27.809059143066406\n",
      "epoch:  13500 train_loss: 12.071601867675781 val_loss: 28.059925079345703\n",
      "epoch:  13600 train_loss: 12.573628425598145 val_loss: 28.551334381103516\n",
      "epoch:  13700 train_loss: 11.801937103271484 val_loss: 28.06084442138672\n",
      "epoch:  13800 train_loss: 11.545550346374512 val_loss: 28.515369415283203\n",
      "epoch:  13900 train_loss: 11.356117248535156 val_loss: 28.45463752746582\n",
      "epoch:  14000 train_loss: 11.004651069641113 val_loss: 28.49374771118164\n",
      "epoch:  14100 train_loss: 10.893231391906738 val_loss: 28.763437271118164\n",
      "epoch:  14200 train_loss: 10.485627174377441 val_loss: 28.88673210144043\n",
      "epoch:  14300 train_loss: 10.448182106018066 val_loss: 29.37556266784668\n",
      "epoch:  14400 train_loss: 10.46424674987793 val_loss: 29.439783096313477\n",
      "epoch:  14500 train_loss: 10.116734504699707 val_loss: 29.38375473022461\n",
      "epoch:  14600 train_loss: 10.153518676757812 val_loss: 29.895238876342773\n",
      "epoch:  14700 train_loss: 10.203319549560547 val_loss: 30.087907791137695\n",
      "epoch:  14800 train_loss: 9.553071975708008 val_loss: 29.95879364013672\n",
      "epoch:  14900 train_loss: 9.625359535217285 val_loss: 30.588516235351562\n",
      "epoch:  15000 train_loss: 9.362166404724121 val_loss: 30.58888053894043\n",
      "epoch:  15100 train_loss: 9.921597480773926 val_loss: 30.440860748291016\n",
      "epoch:  15200 train_loss: 9.451729774475098 val_loss: 30.743736267089844\n",
      "epoch:  15300 train_loss: 9.672513008117676 val_loss: 30.381195068359375\n",
      "epoch:  15400 train_loss: 9.129494667053223 val_loss: 30.737951278686523\n",
      "epoch:  15500 train_loss: 8.726807594299316 val_loss: 30.90978240966797\n",
      "epoch:  15600 train_loss: 8.477644920349121 val_loss: 31.167158126831055\n",
      "epoch:  15700 train_loss: 8.39542007446289 val_loss: 31.436429977416992\n",
      "epoch:  15800 train_loss: 9.036980628967285 val_loss: 31.188207626342773\n",
      "epoch:  15900 train_loss: 8.342549324035645 val_loss: 32.067138671875\n",
      "epoch:  16000 train_loss: 8.053261756896973 val_loss: 31.607023239135742\n",
      "epoch:  16100 train_loss: 7.781887054443359 val_loss: 32.07331848144531\n",
      "epoch:  16200 train_loss: 8.221324920654297 val_loss: 31.80120277404785\n",
      "epoch:  16300 train_loss: 7.641464710235596 val_loss: 32.422000885009766\n",
      "epoch:  16400 train_loss: 7.540070056915283 val_loss: 32.925987243652344\n",
      "epoch:  16500 train_loss: 7.675734043121338 val_loss: 33.148643493652344\n",
      "epoch:  16600 train_loss: 7.381028175354004 val_loss: 32.599884033203125\n",
      "epoch:  16700 train_loss: 7.32648229598999 val_loss: 33.1020622253418\n",
      "epoch:  16800 train_loss: 7.078641891479492 val_loss: 33.605918884277344\n",
      "epoch:  16900 train_loss: 7.314365386962891 val_loss: 33.619667053222656\n",
      "epoch:  17000 train_loss: 7.285439491271973 val_loss: 33.855587005615234\n",
      "epoch:  17100 train_loss: 6.928358554840088 val_loss: 33.6102409362793\n",
      "epoch:  17200 train_loss: 6.730751991271973 val_loss: 33.849422454833984\n",
      "epoch:  17300 train_loss: 6.581038475036621 val_loss: 34.2101936340332\n",
      "epoch:  17400 train_loss: 6.708587169647217 val_loss: 34.56983184814453\n",
      "epoch:  17500 train_loss: 6.98071813583374 val_loss: 34.552860260009766\n",
      "epoch:  17600 train_loss: 6.321717739105225 val_loss: 34.3453254699707\n",
      "epoch:  17700 train_loss: 6.387835502624512 val_loss: 35.167903900146484\n",
      "epoch:  17800 train_loss: 6.209484577178955 val_loss: 34.917808532714844\n",
      "epoch:  17900 train_loss: 6.017928600311279 val_loss: 35.004981994628906\n",
      "epoch:  18000 train_loss: 6.2121992111206055 val_loss: 34.75046920776367\n",
      "epoch:  18100 train_loss: 6.617051124572754 val_loss: 34.25693130493164\n",
      "epoch:  18200 train_loss: 6.116057872772217 val_loss: 35.72001266479492\n",
      "epoch:  18300 train_loss: 6.013408184051514 val_loss: 35.87657928466797\n",
      "epoch:  18400 train_loss: 5.68210506439209 val_loss: 35.628910064697266\n",
      "epoch:  18500 train_loss: 5.633091926574707 val_loss: 35.446067810058594\n",
      "epoch:  18600 train_loss: 9.063907623291016 val_loss: 35.447608947753906\n",
      "epoch:  18700 train_loss: 5.531078815460205 val_loss: 35.71550369262695\n",
      "epoch:  18800 train_loss: 7.181441783905029 val_loss: 37.83201599121094\n",
      "epoch:  18900 train_loss: 5.561861991882324 val_loss: 36.362152099609375\n",
      "epoch:  19000 train_loss: 5.3408098220825195 val_loss: 35.51020812988281\n",
      "epoch:  19100 train_loss: 5.222829341888428 val_loss: 36.086402893066406\n",
      "epoch:  19200 train_loss: 5.158443927764893 val_loss: 35.949729919433594\n",
      "epoch:  19300 train_loss: 5.139630317687988 val_loss: 36.576416015625\n",
      "epoch:  19400 train_loss: 5.355005741119385 val_loss: 36.14030456542969\n",
      "epoch:  19500 train_loss: 5.090826034545898 val_loss: 37.02658462524414\n",
      "epoch:  19600 train_loss: 5.570539474487305 val_loss: 37.527713775634766\n",
      "epoch:  19700 train_loss: 4.8198957443237305 val_loss: 36.52922439575195\n",
      "epoch:  19800 train_loss: 4.750114440917969 val_loss: 37.20504379272461\n",
      "epoch:  19900 train_loss: 4.5633015632629395 val_loss: 37.30451583862305\n",
      "epoch:  20000 train_loss: 4.60407018661499 val_loss: 37.19472885131836\n",
      "epoch:  20100 train_loss: 4.994215965270996 val_loss: 37.48883056640625\n",
      "epoch:  20200 train_loss: 4.6419854164123535 val_loss: 37.52457046508789\n",
      "epoch:  20300 train_loss: 4.39614200592041 val_loss: 37.36930465698242\n",
      "epoch:  20400 train_loss: 4.9014811515808105 val_loss: 36.65825653076172\n",
      "epoch:  20500 train_loss: 4.512486934661865 val_loss: 37.31243896484375\n",
      "epoch:  20600 train_loss: 4.620706558227539 val_loss: 37.52669906616211\n",
      "epoch:  20700 train_loss: 4.616549015045166 val_loss: 38.17619705200195\n",
      "epoch:  20800 train_loss: 4.157036304473877 val_loss: 37.91582107543945\n",
      "epoch:  20900 train_loss: 4.141028881072998 val_loss: 37.430458068847656\n",
      "epoch:  21000 train_loss: 4.605419158935547 val_loss: 37.154170989990234\n",
      "epoch:  21100 train_loss: 4.006182670593262 val_loss: 38.1942024230957\n",
      "epoch:  21200 train_loss: 4.164310455322266 val_loss: 37.935157775878906\n",
      "epoch:  21300 train_loss: 3.905393362045288 val_loss: 37.79420852661133\n",
      "epoch:  21400 train_loss: 4.236153602600098 val_loss: 37.759010314941406\n",
      "epoch:  21500 train_loss: 7.929893970489502 val_loss: 38.69831848144531\n",
      "epoch:  21600 train_loss: 3.8205697536468506 val_loss: 37.74089431762695\n",
      "epoch:  21700 train_loss: 3.710272789001465 val_loss: 38.176918029785156\n",
      "epoch:  21800 train_loss: 3.8316190242767334 val_loss: 38.90174865722656\n",
      "epoch:  21900 train_loss: 3.800647020339966 val_loss: 38.09736633300781\n",
      "epoch:  22000 train_loss: 3.5817506313323975 val_loss: 38.05268478393555\n",
      "epoch:  22100 train_loss: 3.650869607925415 val_loss: 37.82706832885742\n",
      "epoch:  22200 train_loss: 3.6196930408477783 val_loss: 38.22196960449219\n",
      "epoch:  22300 train_loss: 3.6139349937438965 val_loss: 38.79825973510742\n",
      "epoch:  22400 train_loss: 4.118842124938965 val_loss: 39.27326965332031\n",
      "epoch:  22500 train_loss: 3.3508715629577637 val_loss: 38.298343658447266\n",
      "epoch:  22600 train_loss: 3.3062257766723633 val_loss: 37.99803161621094\n",
      "epoch:  22700 train_loss: 3.2529096603393555 val_loss: 38.33405303955078\n",
      "epoch:  22800 train_loss: 3.271716356277466 val_loss: 38.30842208862305\n",
      "epoch:  22900 train_loss: 3.2227084636688232 val_loss: 38.36561584472656\n",
      "epoch:  23000 train_loss: 3.129690647125244 val_loss: 38.86539077758789\n",
      "epoch:  23100 train_loss: 3.5899698734283447 val_loss: 38.79951477050781\n",
      "epoch:  23200 train_loss: 3.1753177642822266 val_loss: 38.737789154052734\n",
      "epoch:  23300 train_loss: 3.202000379562378 val_loss: 38.96984100341797\n",
      "epoch:  23400 train_loss: 3.295657157897949 val_loss: 38.49787521362305\n",
      "epoch:  23500 train_loss: 4.405635833740234 val_loss: 39.45777130126953\n",
      "epoch:  23600 train_loss: 3.093693971633911 val_loss: 39.028472900390625\n",
      "epoch:  23700 train_loss: 3.011936664581299 val_loss: 38.814151763916016\n",
      "epoch:  23800 train_loss: 3.1622488498687744 val_loss: 39.58481979370117\n",
      "epoch:  23900 train_loss: 2.9167747497558594 val_loss: 39.05418395996094\n",
      "epoch:  24000 train_loss: 3.1285479068756104 val_loss: 39.12258529663086\n",
      "epoch:  24100 train_loss: 3.10916805267334 val_loss: 39.592288970947266\n",
      "epoch:  24200 train_loss: 3.22357439994812 val_loss: 38.89089584350586\n",
      "epoch:  24300 train_loss: 3.532546281814575 val_loss: 39.95081329345703\n",
      "epoch:  24400 train_loss: 2.7219021320343018 val_loss: 39.84751892089844\n",
      "epoch:  24500 train_loss: 2.743811845779419 val_loss: 39.721370697021484\n",
      "epoch:  24600 train_loss: 2.7303245067596436 val_loss: 39.62501907348633\n",
      "epoch:  24700 train_loss: 4.151135444641113 val_loss: 39.090126037597656\n",
      "epoch:  24800 train_loss: 2.768695116043091 val_loss: 40.045860290527344\n",
      "epoch:  24900 train_loss: 2.937415361404419 val_loss: 39.40003204345703\n",
      "epoch:  25000 train_loss: 2.653059244155884 val_loss: 39.74074935913086\n",
      "epoch:  25100 train_loss: 2.621680736541748 val_loss: 39.88530349731445\n",
      "epoch:  25200 train_loss: 2.527971029281616 val_loss: 40.52262496948242\n",
      "epoch:  25300 train_loss: 2.843888759613037 val_loss: 39.88728332519531\n",
      "epoch:  25400 train_loss: 2.414231777191162 val_loss: 40.2564582824707\n",
      "epoch:  25500 train_loss: 3.548325777053833 val_loss: 40.50779342651367\n",
      "epoch:  25600 train_loss: 2.579450845718384 val_loss: 40.507389068603516\n",
      "epoch:  25700 train_loss: 2.403273820877075 val_loss: 40.53900146484375\n",
      "epoch:  25800 train_loss: 2.319063901901245 val_loss: 40.47935485839844\n",
      "epoch:  25900 train_loss: 3.0612740516662598 val_loss: 40.37862014770508\n",
      "epoch:  26000 train_loss: 2.5465776920318604 val_loss: 40.57866287231445\n",
      "epoch:  26100 train_loss: 5.495877742767334 val_loss: 39.67043685913086\n",
      "epoch:  26200 train_loss: 2.199808120727539 val_loss: 40.690738677978516\n",
      "epoch:  26300 train_loss: 2.2944247722625732 val_loss: 40.348899841308594\n",
      "epoch:  26400 train_loss: 2.2938129901885986 val_loss: 40.54388427734375\n",
      "epoch:  26500 train_loss: 2.6014041900634766 val_loss: 41.26642608642578\n",
      "epoch:  26600 train_loss: 2.1014163494110107 val_loss: 41.01296615600586\n",
      "epoch:  26700 train_loss: 2.4533581733703613 val_loss: 41.34146499633789\n",
      "epoch:  26800 train_loss: 2.1333870887756348 val_loss: 41.33679962158203\n",
      "epoch:  26900 train_loss: 5.493743419647217 val_loss: 42.99007034301758\n",
      "epoch:  27000 train_loss: 2.0696656703948975 val_loss: 41.55900573730469\n",
      "epoch:  27100 train_loss: 2.3229496479034424 val_loss: 41.62556457519531\n",
      "epoch:  27200 train_loss: 2.187077045440674 val_loss: 41.724700927734375\n",
      "epoch:  27300 train_loss: 1.915786623954773 val_loss: 41.877262115478516\n",
      "epoch:  27400 train_loss: 2.0276248455047607 val_loss: 42.26975631713867\n",
      "epoch:  27500 train_loss: 2.983391523361206 val_loss: 43.07881164550781\n",
      "epoch:  27600 train_loss: 1.9774585962295532 val_loss: 41.856563568115234\n",
      "epoch:  27700 train_loss: 1.8415416479110718 val_loss: 42.151790618896484\n",
      "epoch:  27800 train_loss: 1.8749744892120361 val_loss: 41.987117767333984\n",
      "epoch:  27900 train_loss: 1.9257291555404663 val_loss: 42.272953033447266\n",
      "epoch:  28000 train_loss: 2.9854133129119873 val_loss: 43.1183967590332\n",
      "epoch:  28100 train_loss: 1.7766481637954712 val_loss: 42.70807647705078\n",
      "epoch:  28200 train_loss: 3.481430768966675 val_loss: 43.7021369934082\n",
      "epoch:  28300 train_loss: 1.709886908531189 val_loss: 42.77096176147461\n",
      "epoch:  28400 train_loss: 1.99082350730896 val_loss: 42.58866500854492\n",
      "epoch:  28500 train_loss: 1.8436561822891235 val_loss: 42.801151275634766\n",
      "epoch:  28600 train_loss: 3.2790842056274414 val_loss: 44.18427276611328\n",
      "epoch:  28700 train_loss: 1.7129939794540405 val_loss: 42.820274353027344\n",
      "epoch:  28800 train_loss: 1.7545839548110962 val_loss: 42.79990005493164\n",
      "epoch:  28900 train_loss: 1.6722341775894165 val_loss: 42.976959228515625\n",
      "epoch:  29000 train_loss: 1.6820071935653687 val_loss: 42.92392349243164\n",
      "epoch:  29100 train_loss: 1.5690337419509888 val_loss: 43.343849182128906\n",
      "epoch:  29200 train_loss: 1.682747483253479 val_loss: 43.73352813720703\n",
      "epoch:  29300 train_loss: 1.7998812198638916 val_loss: 43.81971740722656\n",
      "epoch:  29400 train_loss: 1.5878233909606934 val_loss: 43.48728561401367\n",
      "epoch:  29500 train_loss: 1.6855665445327759 val_loss: 43.60416793823242\n",
      "epoch:  29600 train_loss: 1.543051838874817 val_loss: 43.453819274902344\n",
      "epoch:  29700 train_loss: 1.6074227094650269 val_loss: 43.839515686035156\n",
      "epoch:  29800 train_loss: 1.5905689001083374 val_loss: 43.876197814941406\n",
      "epoch:  29900 train_loss: 1.6330265998840332 val_loss: 43.59550476074219\n",
      "epoch:  30000 train_loss: 1.4369401931762695 val_loss: 43.95214080810547\n",
      "epoch:  30100 train_loss: 1.6143921613693237 val_loss: 43.764835357666016\n",
      "epoch:  30200 train_loss: 1.772886037826538 val_loss: 44.40851593017578\n",
      "epoch:  30300 train_loss: 1.5446685552597046 val_loss: 44.696781158447266\n",
      "epoch:  30400 train_loss: 1.540919542312622 val_loss: 44.31822204589844\n",
      "epoch:  30500 train_loss: 1.3892372846603394 val_loss: 44.513004302978516\n",
      "epoch:  30600 train_loss: 1.814691185951233 val_loss: 44.7255859375\n",
      "epoch:  30700 train_loss: 1.4447104930877686 val_loss: 44.52934265136719\n",
      "epoch:  30800 train_loss: 1.5908750295639038 val_loss: 44.36323165893555\n",
      "epoch:  30900 train_loss: 1.4401718378067017 val_loss: 43.76552963256836\n",
      "epoch:  31000 train_loss: 1.4559134244918823 val_loss: 44.53904724121094\n",
      "epoch:  31100 train_loss: 1.2815074920654297 val_loss: 44.93059539794922\n",
      "epoch:  31200 train_loss: 1.315271258354187 val_loss: 45.096900939941406\n",
      "epoch:  31300 train_loss: 1.2619452476501465 val_loss: 45.383750915527344\n",
      "epoch:  31400 train_loss: 1.2386265993118286 val_loss: 45.00223159790039\n",
      "epoch:  31500 train_loss: 1.2414470911026 val_loss: 45.3086051940918\n",
      "epoch:  31600 train_loss: 1.9082629680633545 val_loss: 44.96549606323242\n",
      "epoch:  31700 train_loss: 1.2324131727218628 val_loss: 45.34018325805664\n",
      "epoch:  31800 train_loss: 1.4594647884368896 val_loss: 44.584815979003906\n",
      "epoch:  31900 train_loss: 1.2727293968200684 val_loss: 45.64194869995117\n",
      "epoch:  32000 train_loss: 1.2518444061279297 val_loss: 45.64990997314453\n",
      "epoch:  32100 train_loss: 1.3728537559509277 val_loss: 45.10816955566406\n",
      "epoch:  32200 train_loss: 1.424474835395813 val_loss: 45.97523498535156\n",
      "epoch:  32300 train_loss: 1.1857435703277588 val_loss: 45.63856887817383\n",
      "epoch:  32400 train_loss: 1.4361826181411743 val_loss: 45.53437042236328\n",
      "epoch:  32500 train_loss: 1.3126837015151978 val_loss: 46.14071273803711\n",
      "epoch:  32600 train_loss: 1.469046711921692 val_loss: 46.202388763427734\n",
      "epoch:  32700 train_loss: 1.1962326765060425 val_loss: 46.16365432739258\n",
      "epoch:  32800 train_loss: 1.0820037126541138 val_loss: 45.9903564453125\n",
      "epoch:  32900 train_loss: 1.143913745880127 val_loss: 46.09272384643555\n",
      "epoch:  33000 train_loss: 1.0614675283432007 val_loss: 46.114501953125\n",
      "epoch:  33100 train_loss: 1.0863398313522339 val_loss: 46.31229782104492\n",
      "epoch:  33200 train_loss: 0.9987315535545349 val_loss: 45.794776916503906\n",
      "epoch:  33300 train_loss: 1.0481685400009155 val_loss: 46.1013298034668\n",
      "epoch:  33400 train_loss: 1.064515233039856 val_loss: 46.243595123291016\n",
      "epoch:  33500 train_loss: 1.3139996528625488 val_loss: 45.97978973388672\n",
      "epoch:  33600 train_loss: 1.1112124919891357 val_loss: 46.20564270019531\n",
      "epoch:  33700 train_loss: 1.247271180152893 val_loss: 45.946224212646484\n",
      "epoch:  33800 train_loss: 0.978971540927887 val_loss: 46.6650505065918\n",
      "epoch:  33900 train_loss: 1.00394606590271 val_loss: 46.698665618896484\n",
      "epoch:  34000 train_loss: 0.919080913066864 val_loss: 46.39750289916992\n",
      "epoch:  34100 train_loss: 1.138951063156128 val_loss: 46.824974060058594\n",
      "epoch:  34200 train_loss: 1.0002721548080444 val_loss: 46.34736251831055\n",
      "epoch:  34300 train_loss: 0.8887136578559875 val_loss: 46.46171569824219\n",
      "epoch:  34400 train_loss: 0.988255500793457 val_loss: 46.52943801879883\n",
      "epoch:  34500 train_loss: 0.9842323660850525 val_loss: 46.872650146484375\n",
      "epoch:  34600 train_loss: 0.8756725192070007 val_loss: 46.32997512817383\n",
      "epoch:  34700 train_loss: 0.9313584566116333 val_loss: 46.38246536254883\n",
      "epoch:  34800 train_loss: 0.9271156191825867 val_loss: 46.878265380859375\n",
      "epoch:  34900 train_loss: 0.9952955842018127 val_loss: 46.88864517211914\n",
      "epoch:  35000 train_loss: 0.8962648510932922 val_loss: 46.976417541503906\n",
      "epoch:  35100 train_loss: 0.9434601068496704 val_loss: 46.94942092895508\n",
      "epoch:  35200 train_loss: 1.4242557287216187 val_loss: 47.177120208740234\n",
      "epoch:  35300 train_loss: 1.172494649887085 val_loss: 46.67490005493164\n",
      "epoch:  35400 train_loss: 0.867455244064331 val_loss: 46.135902404785156\n",
      "epoch:  35500 train_loss: 0.7770248055458069 val_loss: 46.90424728393555\n",
      "epoch:  35600 train_loss: 0.7693067789077759 val_loss: 47.06692123413086\n",
      "epoch:  35700 train_loss: 0.9243990182876587 val_loss: 47.17746353149414\n",
      "epoch:  35800 train_loss: 0.8740745186805725 val_loss: 47.2657470703125\n",
      "epoch:  35900 train_loss: 0.8328360319137573 val_loss: 47.29780578613281\n",
      "sigma: 8.2 RMSE:  tensor(8.5234, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Generate the dataset with noise N(0, sigma)\n",
    "i = 0\n",
    "sigma = 8.2\n",
    "my_dataset = []\n",
    "for ud in UDs:\n",
    "    example = []\n",
    "    for an in ANs:\n",
    "        noise = np.random.normal(0,sigma)\n",
    "        # 0 is mean\n",
    "        # sigma is the deviation of the normal distribution\n",
    "        d = compute_3d_distance(ud, an) + noise\n",
    "        example.append(d)\n",
    "    \n",
    "    # append x, y, z as col#10, #11, #12\n",
    "    example.append(ud[0])\n",
    "    example.append(ud[1])\n",
    "    example.append(ud[2])\n",
    "    \n",
    "    # append 1x13 example row into my_dataset\n",
    "    my_dataset.append(example)  # expected to be 3000x13  \n",
    "    \n",
    "# Load dataset\n",
    "exercise5_dataset = Exercise5Dataset(list_dataset = my_dataset, shuffle=True)\n",
    "\n",
    "#Split dataset by 0.8: 0.1: 0.1\n",
    "train_examples, train_labels = exercise5_dataset[:int(3000*0.8)]  # (2400, 10)   # (2400, 3)\n",
    "val_examples, val_labels = exercise5_dataset[int(3000*0.8):int(3000*0.9)]    # (300, 10)   #(300, 3)\n",
    "test_examples, test_labels = exercise5_dataset[int(3000*0.9):]     #(300, 10)   # (300, 3)\n",
    "\n",
    "###Define model, loss function and optimizer\n",
    "# if we have GPU, then use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define model\n",
    "#model = Net(x_dim = train_examples.shape[1], y_dim = train_labels.shape[1]).to(device)\n",
    "input_dim = 1     #input dim is 1, seq_len = 10\n",
    "hidden_dim = 64   #hidden state dim is 64\n",
    "n_layers = 3             #3-layered LSTM\n",
    "model = MYLSTM(input_dim, hidden_dim, n_layers).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Correct the input/output shape for LSTM\n",
    "train_inputs = torch.unsqueeze(train_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "train_inputs = train_inputs.to(device) \n",
    "\n",
    "val_inputs = torch.unsqueeze(val_examples, dim=-1)   # (N, 10) -> (N, 10, 1)\n",
    "val_inputs = val_inputs.to(device) \n",
    "\n",
    "train_labels = train_labels.to(device)   #(N, 3)\n",
    "val_labels = val_labels.to(device)          #(N, 3)\n",
    "\n",
    "\n",
    "# Define the loss threshold, if the current train loss is lower than the threshold, we will begin to save the model\n",
    "best_loss = 100.0\n",
    "\n",
    "# Define the model filename for model.save()\n",
    "MODEL_FILENAME = \"best.pth\"\n",
    "\n",
    "# set model to Training mode\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "NUM_OF_EPOCH = 36000\n",
    "\n",
    "# Train\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    y_pred = model(train_inputs)\n",
    "    loss = loss_fn(y_pred, train_labels).cpu()\n",
    "    #print(t, loss.item())\n",
    "    train_losses.append(loss.item())\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    # BGD\n",
    "    optimizer.step()\n",
    "    \n",
    "    # evaluate validation loss\n",
    "    val_pred = model(val_inputs)\n",
    "    loss = loss_fn(val_pred, val_labels)\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "\n",
    "\n",
    "    if (epoch % 100) == 0:\n",
    "        print(\"epoch: \", epoch, \"train_loss:\", train_losses[-1], \"val_loss:\", val_losses[-1])\n",
    "        # check if we got better loss\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n",
    "        \n",
    "# Load the best model on previous step\n",
    "model.load_state_dict(torch.load(\"best.pth\"))\n",
    "\n",
    "# Inference all testing examples and compute RMSE\n",
    "def square_error(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  square_error= loss_fn(a, b)\n",
    "  return square_error\n",
    "\n",
    "model.eval() # inference mode\n",
    "test_inputs = torch.unsqueeze(test_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "test_inputs = test_inputs.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "\n",
    "test_preds = model(test_inputs)\n",
    "#print(\"example: \", test_example.cpu())\n",
    "#print(\"========================================\")\n",
    "#print(\"ground_truth:\", test_label.cpu())\n",
    "#print(\"prediction:\", test_pred.cpu())\n",
    "#print(\"========================================\")\n",
    "\n",
    "\n",
    "total_errors = 0.0\n",
    "for idx in range(len(test_inputs)):\n",
    "    total_errors += square_error(test_preds[idx], test_labels[idx])\n",
    "    \n",
    "RMSE = torch.sqrt(total_errors / len(test_inputs))\n",
    "print(\"sigma:\", sigma, \"RMSE: \",  RMSE)\n",
    "\n",
    "sigmas.append(sigma)\n",
    "RMSEs.append(RMSE.cpu().detach().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigma = 9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffle = True!\n",
      "epoch:  0 train_loss: 7331.41259765625 val_loss: 7341.69921875\n",
      "epoch:  100 train_loss: 5954.142578125 val_loss: 5954.005859375\n",
      "epoch:  200 train_loss: 5039.732421875 val_loss: 5038.0126953125\n",
      "epoch:  300 train_loss: 4283.04150390625 val_loss: 4279.35302734375\n",
      "epoch:  400 train_loss: 3639.01513671875 val_loss: 3633.718994140625\n",
      "epoch:  500 train_loss: 3087.030029296875 val_loss: 3080.50732421875\n",
      "epoch:  600 train_loss: 2612.580078125 val_loss: 2605.1728515625\n",
      "epoch:  700 train_loss: 2204.959716796875 val_loss: 2197.12890625\n",
      "epoch:  800 train_loss: 1854.9390869140625 val_loss: 1846.9747314453125\n",
      "epoch:  900 train_loss: 1555.193115234375 val_loss: 1547.4566650390625\n",
      "epoch:  1000 train_loss: 1299.6947021484375 val_loss: 1292.14306640625\n",
      "epoch:  1100 train_loss: 1083.014404296875 val_loss: 1075.9920654296875\n",
      "epoch:  1200 train_loss: 900.7398681640625 val_loss: 894.149658203125\n",
      "epoch:  1300 train_loss: 748.6314086914062 val_loss: 742.599365234375\n",
      "epoch:  1400 train_loss: 622.9146728515625 val_loss: 617.5206298828125\n",
      "epoch:  1500 train_loss: 520.249267578125 val_loss: 515.481689453125\n",
      "epoch:  1600 train_loss: 437.33160400390625 val_loss: 433.1990966796875\n",
      "epoch:  1700 train_loss: 371.3670959472656 val_loss: 367.7276916503906\n",
      "epoch:  1800 train_loss: 319.4945983886719 val_loss: 316.26507568359375\n",
      "epoch:  1900 train_loss: 279.5063171386719 val_loss: 276.62640380859375\n",
      "epoch:  2000 train_loss: 249.00660705566406 val_loss: 246.49658203125\n",
      "epoch:  2100 train_loss: 226.26361083984375 val_loss: 224.02520751953125\n",
      "epoch:  2200 train_loss: 209.65692138671875 val_loss: 207.6422576904297\n",
      "epoch:  2300 train_loss: 197.6217803955078 val_loss: 195.8494110107422\n",
      "epoch:  2400 train_loss: 189.25323486328125 val_loss: 187.61439514160156\n",
      "epoch:  2500 train_loss: 183.46002197265625 val_loss: 181.9862823486328\n",
      "epoch:  2600 train_loss: 179.5648651123047 val_loss: 178.1634063720703\n",
      "epoch:  2700 train_loss: 177.02809143066406 val_loss: 175.7210693359375\n",
      "epoch:  2800 train_loss: 175.4256591796875 val_loss: 174.17459106445312\n",
      "epoch:  2900 train_loss: 174.43145751953125 val_loss: 173.22998046875\n",
      "epoch:  3000 train_loss: 173.8317413330078 val_loss: 172.6614227294922\n",
      "epoch:  3100 train_loss: 173.47927856445312 val_loss: 172.33087158203125\n",
      "epoch:  3200 train_loss: 173.2845916748047 val_loss: 172.14486694335938\n",
      "epoch:  3300 train_loss: 173.1780548095703 val_loss: 172.05685424804688\n",
      "epoch:  3400 train_loss: 173.1217803955078 val_loss: 172.010009765625\n",
      "epoch:  3500 train_loss: 173.09310913085938 val_loss: 171.97767639160156\n",
      "epoch:  3600 train_loss: 173.07937622070312 val_loss: 171.96829223632812\n",
      "epoch:  3700 train_loss: 173.07293701171875 val_loss: 171.96514892578125\n",
      "epoch:  3800 train_loss: 173.070556640625 val_loss: 171.9621124267578\n",
      "epoch:  3900 train_loss: 173.06906127929688 val_loss: 171.95944213867188\n",
      "epoch:  4000 train_loss: 173.06861877441406 val_loss: 171.9606170654297\n",
      "epoch:  4100 train_loss: 173.0684051513672 val_loss: 171.9623260498047\n",
      "epoch:  4200 train_loss: 173.068359375 val_loss: 171.96044921875\n",
      "epoch:  4300 train_loss: 173.06834411621094 val_loss: 171.96226501464844\n",
      "epoch:  4400 train_loss: 173.06834411621094 val_loss: 171.96087646484375\n",
      "epoch:  4500 train_loss: 173.06834411621094 val_loss: 171.96170043945312\n",
      "epoch:  4600 train_loss: 173.06834411621094 val_loss: 171.96205139160156\n",
      "epoch:  4700 train_loss: 173.06834411621094 val_loss: 171.96067810058594\n",
      "epoch:  4800 train_loss: 173.06834411621094 val_loss: 171.96067810058594\n",
      "epoch:  4900 train_loss: 173.06834411621094 val_loss: 171.96067810058594\n",
      "epoch:  5000 train_loss: 173.06834411621094 val_loss: 171.96066284179688\n",
      "epoch:  5100 train_loss: 173.06834411621094 val_loss: 171.96029663085938\n",
      "epoch:  5200 train_loss: 173.06834411621094 val_loss: 171.9602813720703\n",
      "epoch:  5300 train_loss: 173.06834411621094 val_loss: 171.96066284179688\n",
      "epoch:  5400 train_loss: 173.06834411621094 val_loss: 171.96066284179688\n",
      "epoch:  5500 train_loss: 173.06834411621094 val_loss: 171.95999145507812\n",
      "epoch:  5600 train_loss: 173.068359375 val_loss: 171.96066284179688\n",
      "epoch:  5700 train_loss: 173.06834411621094 val_loss: 171.96066284179688\n",
      "epoch:  5800 train_loss: 173.06834411621094 val_loss: 171.96066284179688\n",
      "epoch:  5900 train_loss: 173.06834411621094 val_loss: 171.95999145507812\n",
      "epoch:  6000 train_loss: 173.068359375 val_loss: 171.9602813720703\n",
      "epoch:  6100 train_loss: 173.06834411621094 val_loss: 171.95960998535156\n",
      "epoch:  6200 train_loss: 173.06834411621094 val_loss: 171.95960998535156\n",
      "epoch:  6300 train_loss: 173.06834411621094 val_loss: 171.96066284179688\n",
      "epoch:  6400 train_loss: 173.068359375 val_loss: 171.95960998535156\n",
      "epoch:  6500 train_loss: 173.068359375 val_loss: 171.96066284179688\n",
      "epoch:  6600 train_loss: 173.06834411621094 val_loss: 171.96029663085938\n",
      "epoch:  6700 train_loss: 173.06834411621094 val_loss: 171.96067810058594\n",
      "epoch:  6800 train_loss: 173.06834411621094 val_loss: 171.96067810058594\n",
      "epoch:  6900 train_loss: 173.06834411621094 val_loss: 171.9600067138672\n",
      "epoch:  7000 train_loss: 173.06834411621094 val_loss: 171.9600067138672\n",
      "epoch:  7100 train_loss: 173.068359375 val_loss: 171.96067810058594\n",
      "epoch:  7200 train_loss: 173.06837463378906 val_loss: 171.96153259277344\n",
      "epoch:  7300 train_loss: 170.0187225341797 val_loss: 168.7321319580078\n",
      "epoch:  7400 train_loss: 128.38104248046875 val_loss: 126.55453491210938\n",
      "epoch:  7500 train_loss: 111.27410125732422 val_loss: 109.31918334960938\n",
      "epoch:  7600 train_loss: 103.77516174316406 val_loss: 101.40568542480469\n",
      "epoch:  7700 train_loss: 95.0469970703125 val_loss: 92.95142364501953\n",
      "epoch:  7800 train_loss: 83.49040985107422 val_loss: 82.74565887451172\n",
      "epoch:  7900 train_loss: 70.78069305419922 val_loss: 71.30560302734375\n",
      "epoch:  8000 train_loss: 58.12307357788086 val_loss: 59.34024429321289\n",
      "epoch:  8100 train_loss: 48.027671813964844 val_loss: 50.29461669921875\n",
      "epoch:  8200 train_loss: 39.99067687988281 val_loss: 43.2457389831543\n",
      "epoch:  8300 train_loss: 33.69353485107422 val_loss: 38.12738037109375\n",
      "epoch:  8400 train_loss: 28.899185180664062 val_loss: 34.36497116088867\n",
      "epoch:  8500 train_loss: 25.13909339904785 val_loss: 31.709402084350586\n",
      "epoch:  8600 train_loss: 22.30428695678711 val_loss: 29.898176193237305\n",
      "epoch:  8700 train_loss: 20.429183959960938 val_loss: 28.95911979675293\n",
      "epoch:  8800 train_loss: 18.403409957885742 val_loss: 28.252338409423828\n",
      "epoch:  8900 train_loss: 16.958534240722656 val_loss: 27.853609085083008\n",
      "epoch:  9000 train_loss: 15.758403778076172 val_loss: 27.56879425048828\n",
      "epoch:  9100 train_loss: 14.641928672790527 val_loss: 27.398405075073242\n",
      "epoch:  9200 train_loss: 13.896590232849121 val_loss: 27.472890853881836\n",
      "epoch:  9300 train_loss: 12.82548999786377 val_loss: 27.78925895690918\n",
      "epoch:  9400 train_loss: 12.06087875366211 val_loss: 28.330408096313477\n",
      "epoch:  9500 train_loss: 11.06076431274414 val_loss: 29.12779998779297\n",
      "epoch:  9600 train_loss: 10.308717727661133 val_loss: 29.6165828704834\n",
      "epoch:  9700 train_loss: 9.687589645385742 val_loss: 30.0546817779541\n",
      "epoch:  9800 train_loss: 9.087064743041992 val_loss: 30.55555534362793\n",
      "epoch:  9900 train_loss: 8.569276809692383 val_loss: 31.100435256958008\n",
      "epoch:  10000 train_loss: 8.061915397644043 val_loss: 31.30772590637207\n",
      "epoch:  10100 train_loss: 7.502237796783447 val_loss: 31.731338500976562\n",
      "epoch:  10200 train_loss: 7.140185832977295 val_loss: 32.182212829589844\n",
      "epoch:  10300 train_loss: 6.7144598960876465 val_loss: 32.54021453857422\n",
      "epoch:  10400 train_loss: 6.388387680053711 val_loss: 33.235103607177734\n",
      "epoch:  10500 train_loss: 5.966409683227539 val_loss: 33.549983978271484\n",
      "epoch:  10600 train_loss: 5.68068265914917 val_loss: 34.22368240356445\n",
      "epoch:  10700 train_loss: 5.373887062072754 val_loss: 34.43516159057617\n",
      "epoch:  10800 train_loss: 5.832696437835693 val_loss: 34.90928649902344\n",
      "epoch:  10900 train_loss: 4.769327163696289 val_loss: 35.31696701049805\n",
      "epoch:  11000 train_loss: 4.544071197509766 val_loss: 35.735713958740234\n",
      "epoch:  11100 train_loss: 4.4563446044921875 val_loss: 36.053958892822266\n",
      "epoch:  11200 train_loss: 4.343996524810791 val_loss: 36.897823333740234\n",
      "epoch:  11300 train_loss: 3.9710118770599365 val_loss: 37.0252685546875\n",
      "epoch:  11400 train_loss: 3.8377158641815186 val_loss: 37.285491943359375\n",
      "epoch:  11500 train_loss: 3.670976161956787 val_loss: 37.946964263916016\n",
      "epoch:  11600 train_loss: 3.511909008026123 val_loss: 38.14678192138672\n",
      "epoch:  11700 train_loss: 3.3366222381591797 val_loss: 38.51407241821289\n",
      "epoch:  11800 train_loss: 3.157778024673462 val_loss: 38.90262222290039\n",
      "epoch:  11900 train_loss: 3.049075126647949 val_loss: 39.16654586791992\n",
      "epoch:  12000 train_loss: 2.9559285640716553 val_loss: 39.5129280090332\n",
      "epoch:  12100 train_loss: 2.836106777191162 val_loss: 39.99385070800781\n",
      "epoch:  12200 train_loss: 2.565385341644287 val_loss: 40.275394439697266\n",
      "epoch:  12300 train_loss: 2.5487630367279053 val_loss: 40.60696792602539\n",
      "epoch:  12400 train_loss: 2.665192127227783 val_loss: 41.37602615356445\n",
      "epoch:  12500 train_loss: 2.326260566711426 val_loss: 41.63144302368164\n",
      "epoch:  12600 train_loss: 2.247344970703125 val_loss: 41.7328987121582\n",
      "epoch:  12700 train_loss: 2.0784752368927 val_loss: 42.284828186035156\n",
      "epoch:  12800 train_loss: 2.169194221496582 val_loss: 42.04868698120117\n",
      "epoch:  12900 train_loss: 1.8953402042388916 val_loss: 42.86611557006836\n",
      "epoch:  13000 train_loss: 1.767077922821045 val_loss: 42.92607879638672\n",
      "epoch:  13100 train_loss: 1.7459776401519775 val_loss: 43.280216217041016\n",
      "epoch:  13200 train_loss: 1.7032427787780762 val_loss: 43.23298645019531\n",
      "epoch:  13300 train_loss: 1.601271390914917 val_loss: 43.39934158325195\n",
      "epoch:  13400 train_loss: 1.7735663652420044 val_loss: 43.129756927490234\n",
      "epoch:  13500 train_loss: 1.4991862773895264 val_loss: 43.500877380371094\n",
      "epoch:  13600 train_loss: 1.4055382013320923 val_loss: 43.867218017578125\n",
      "epoch:  13700 train_loss: 1.6874284744262695 val_loss: 43.969566345214844\n",
      "epoch:  13800 train_loss: 1.429933786392212 val_loss: 44.33534240722656\n",
      "epoch:  13900 train_loss: 1.3384816646575928 val_loss: 44.28074264526367\n",
      "epoch:  14000 train_loss: 1.2101558446884155 val_loss: 44.40420150756836\n",
      "epoch:  14100 train_loss: 1.3834508657455444 val_loss: 44.46678161621094\n",
      "epoch:  14200 train_loss: 1.2341604232788086 val_loss: 44.91964340209961\n",
      "epoch:  14300 train_loss: 1.1424134969711304 val_loss: 44.888450622558594\n",
      "epoch:  14400 train_loss: 1.0724056959152222 val_loss: 44.95942687988281\n",
      "epoch:  14500 train_loss: 1.099603533744812 val_loss: 44.90227127075195\n",
      "epoch:  14600 train_loss: 0.9823868870735168 val_loss: 45.083560943603516\n",
      "epoch:  14700 train_loss: 1.1409873962402344 val_loss: 45.38563919067383\n",
      "epoch:  14800 train_loss: 0.8933808207511902 val_loss: 45.15226364135742\n",
      "epoch:  14900 train_loss: 1.0313318967819214 val_loss: 44.82417678833008\n",
      "epoch:  15000 train_loss: 0.8903532028198242 val_loss: 44.9886474609375\n",
      "epoch:  15100 train_loss: 1.1145178079605103 val_loss: 45.417076110839844\n",
      "epoch:  15200 train_loss: 0.9416317343711853 val_loss: 45.578365325927734\n",
      "epoch:  15300 train_loss: 0.7645972967147827 val_loss: 45.37550354003906\n",
      "epoch:  15400 train_loss: 0.7628105282783508 val_loss: 45.5603141784668\n",
      "epoch:  15500 train_loss: 0.7707074880599976 val_loss: 45.11616897583008\n",
      "epoch:  15600 train_loss: 0.6804869174957275 val_loss: 45.05330276489258\n",
      "epoch:  15700 train_loss: 0.6866645216941833 val_loss: 45.300907135009766\n",
      "epoch:  15800 train_loss: 0.6914539337158203 val_loss: 45.26127624511719\n",
      "epoch:  15900 train_loss: 0.6646018028259277 val_loss: 45.51347351074219\n",
      "epoch:  16000 train_loss: 0.5942102074623108 val_loss: 45.560203552246094\n",
      "epoch:  16100 train_loss: 0.5851583480834961 val_loss: 45.83423614501953\n",
      "epoch:  16200 train_loss: 0.5775307416915894 val_loss: 45.78474807739258\n",
      "epoch:  16300 train_loss: 0.5287697911262512 val_loss: 45.7936897277832\n",
      "epoch:  16400 train_loss: 0.5370458364486694 val_loss: 45.47339630126953\n",
      "epoch:  16500 train_loss: 0.7993592619895935 val_loss: 46.055747985839844\n",
      "epoch:  16600 train_loss: 0.5321811437606812 val_loss: 45.731903076171875\n",
      "epoch:  16700 train_loss: 0.5140764713287354 val_loss: 46.004905700683594\n",
      "epoch:  16800 train_loss: 0.5588513016700745 val_loss: 45.90595626831055\n",
      "epoch:  16900 train_loss: 0.4464637041091919 val_loss: 45.77585220336914\n",
      "epoch:  17000 train_loss: 0.43947917222976685 val_loss: 45.84783172607422\n",
      "epoch:  17100 train_loss: 0.4585912823677063 val_loss: 45.756961822509766\n",
      "epoch:  17200 train_loss: 0.4697914123535156 val_loss: 46.18991470336914\n",
      "epoch:  17300 train_loss: 0.4254429340362549 val_loss: 46.05179977416992\n",
      "epoch:  17400 train_loss: 0.3798917829990387 val_loss: 46.07157516479492\n",
      "epoch:  17500 train_loss: 0.5457414388656616 val_loss: 45.72670364379883\n",
      "epoch:  17600 train_loss: 0.3827868103981018 val_loss: 46.067237854003906\n",
      "epoch:  17700 train_loss: 0.3794865608215332 val_loss: 46.03538131713867\n",
      "epoch:  17800 train_loss: 0.34810611605644226 val_loss: 46.08005905151367\n",
      "epoch:  17900 train_loss: 0.4772503674030304 val_loss: 45.919097900390625\n",
      "epoch:  18000 train_loss: 0.4385978579521179 val_loss: 46.33072280883789\n",
      "epoch:  18100 train_loss: 0.5301604270935059 val_loss: 46.50957489013672\n",
      "epoch:  18200 train_loss: 0.46223369240760803 val_loss: 45.90171813964844\n",
      "epoch:  18300 train_loss: 0.36971843242645264 val_loss: 45.78169250488281\n",
      "epoch:  18400 train_loss: 0.3700703978538513 val_loss: 46.105079650878906\n",
      "epoch:  18500 train_loss: 0.46528637409210205 val_loss: 45.812320709228516\n",
      "epoch:  18600 train_loss: 0.2990975081920624 val_loss: 45.67369079589844\n",
      "epoch:  18700 train_loss: 0.24591930210590363 val_loss: 46.02706527709961\n",
      "epoch:  18800 train_loss: 0.36663731932640076 val_loss: 45.83840560913086\n",
      "epoch:  18900 train_loss: 0.2624998092651367 val_loss: 45.924808502197266\n",
      "epoch:  19000 train_loss: 0.2864782214164734 val_loss: 46.15568542480469\n",
      "epoch:  19100 train_loss: 0.2637195587158203 val_loss: 46.06132507324219\n",
      "epoch:  19200 train_loss: 0.4196188747882843 val_loss: 46.19076156616211\n",
      "epoch:  19300 train_loss: 0.3173251748085022 val_loss: 45.77581787109375\n",
      "epoch:  19400 train_loss: 0.37944459915161133 val_loss: 45.827274322509766\n",
      "epoch:  19500 train_loss: 0.2482100874185562 val_loss: 46.15983581542969\n",
      "epoch:  19600 train_loss: 0.2133166491985321 val_loss: 46.1633415222168\n",
      "epoch:  19700 train_loss: 0.22514277696609497 val_loss: 46.181312561035156\n",
      "epoch:  19800 train_loss: 0.20804084837436676 val_loss: 46.30480194091797\n",
      "epoch:  19900 train_loss: 0.2036551684141159 val_loss: 45.95450210571289\n",
      "epoch:  20000 train_loss: 0.19787384569644928 val_loss: 46.153785705566406\n",
      "epoch:  20100 train_loss: 0.1660083383321762 val_loss: 46.0643424987793\n",
      "epoch:  20200 train_loss: 0.18846659362316132 val_loss: 45.883567810058594\n",
      "epoch:  20300 train_loss: 0.2196701318025589 val_loss: 46.09395980834961\n",
      "epoch:  20400 train_loss: 0.16216889023780823 val_loss: 46.03602600097656\n",
      "epoch:  20500 train_loss: 0.1708839237689972 val_loss: 46.07280349731445\n",
      "epoch:  20600 train_loss: 0.18070726096630096 val_loss: 46.023834228515625\n",
      "epoch:  20700 train_loss: 0.48348695039749146 val_loss: 46.1259651184082\n",
      "epoch:  20800 train_loss: 0.14849558472633362 val_loss: 46.05949020385742\n",
      "epoch:  20900 train_loss: 0.23719440400600433 val_loss: 46.11736297607422\n",
      "epoch:  21000 train_loss: 0.23811472952365875 val_loss: 46.10438537597656\n",
      "epoch:  21100 train_loss: 0.16557322442531586 val_loss: 45.93504333496094\n",
      "epoch:  21200 train_loss: 0.17459598183631897 val_loss: 46.155540466308594\n",
      "epoch:  21300 train_loss: 0.199226513504982 val_loss: 45.958351135253906\n",
      "epoch:  21400 train_loss: 0.21375176310539246 val_loss: 46.04020690917969\n",
      "epoch:  21500 train_loss: 0.1665341556072235 val_loss: 46.03948974609375\n",
      "epoch:  21600 train_loss: 0.25731465220451355 val_loss: 46.28814697265625\n",
      "epoch:  21700 train_loss: 0.23179206252098083 val_loss: 46.016300201416016\n",
      "epoch:  21800 train_loss: 0.1359042227268219 val_loss: 45.79689025878906\n",
      "epoch:  21900 train_loss: 0.24108073115348816 val_loss: 46.16288375854492\n",
      "epoch:  22000 train_loss: 0.15550896525382996 val_loss: 45.587406158447266\n",
      "epoch:  22100 train_loss: 0.14548702538013458 val_loss: 45.86550521850586\n",
      "epoch:  22200 train_loss: 0.18977820873260498 val_loss: 45.73548889160156\n",
      "epoch:  22300 train_loss: 0.1457306146621704 val_loss: 45.7492790222168\n",
      "epoch:  22400 train_loss: 0.19619682431221008 val_loss: 45.832916259765625\n",
      "epoch:  22500 train_loss: 0.11251283437013626 val_loss: 45.822425842285156\n",
      "epoch:  22600 train_loss: 0.12284810841083527 val_loss: 45.881317138671875\n",
      "epoch:  22700 train_loss: 0.22892256081104279 val_loss: 46.057579040527344\n",
      "epoch:  22800 train_loss: 0.16816046833992004 val_loss: 45.67341613769531\n",
      "epoch:  22900 train_loss: 0.19522495567798615 val_loss: 45.51961135864258\n",
      "epoch:  23000 train_loss: 0.13813398778438568 val_loss: 45.68814468383789\n",
      "epoch:  23100 train_loss: 0.38619840145111084 val_loss: 45.44441223144531\n",
      "epoch:  23200 train_loss: 0.09714076668024063 val_loss: 45.6645622253418\n",
      "epoch:  23300 train_loss: 0.09841695427894592 val_loss: 45.67654800415039\n",
      "epoch:  23400 train_loss: 0.1227581799030304 val_loss: 45.41792678833008\n",
      "epoch:  23500 train_loss: 0.16105228662490845 val_loss: 45.98151397705078\n",
      "epoch:  23600 train_loss: 0.12269812822341919 val_loss: 45.59366989135742\n",
      "epoch:  23700 train_loss: 0.28859543800354004 val_loss: 45.955257415771484\n",
      "epoch:  23800 train_loss: 0.08849208801984787 val_loss: 45.34027099609375\n",
      "epoch:  23900 train_loss: 0.11857710033655167 val_loss: 45.73147964477539\n",
      "epoch:  24000 train_loss: 0.09299232065677643 val_loss: 45.462162017822266\n",
      "epoch:  24100 train_loss: 0.14425058662891388 val_loss: 45.42146682739258\n",
      "epoch:  24200 train_loss: 0.20964403450489044 val_loss: 45.406124114990234\n",
      "epoch:  24300 train_loss: 0.10013677179813385 val_loss: 45.479679107666016\n",
      "epoch:  24400 train_loss: 0.09523653239011765 val_loss: 45.54355239868164\n",
      "epoch:  24500 train_loss: 0.11865551769733429 val_loss: 45.57936477661133\n",
      "epoch:  24600 train_loss: 0.12990552186965942 val_loss: 45.435386657714844\n",
      "epoch:  24700 train_loss: 0.11816596239805222 val_loss: 45.46833419799805\n",
      "epoch:  24800 train_loss: 0.07726405560970306 val_loss: 45.419071197509766\n",
      "epoch:  24900 train_loss: 0.07751551270484924 val_loss: 45.47584915161133\n",
      "epoch:  25000 train_loss: 0.08873048424720764 val_loss: 45.483619689941406\n",
      "epoch:  25100 train_loss: 0.11420616507530212 val_loss: 45.30598068237305\n",
      "epoch:  25200 train_loss: 0.09839054197072983 val_loss: 45.36781692504883\n",
      "epoch:  25300 train_loss: 0.1709311157464981 val_loss: 45.471012115478516\n",
      "epoch:  25400 train_loss: 0.0959918424487114 val_loss: 45.293052673339844\n",
      "epoch:  25500 train_loss: 0.15921543538570404 val_loss: 45.45130157470703\n",
      "epoch:  25600 train_loss: 0.08993647992610931 val_loss: 45.4145622253418\n",
      "epoch:  25700 train_loss: 0.09301706403493881 val_loss: 45.398704528808594\n",
      "epoch:  25800 train_loss: 0.09615648537874222 val_loss: 45.52549743652344\n",
      "epoch:  25900 train_loss: 0.09393107146024704 val_loss: 45.22128677368164\n",
      "epoch:  26000 train_loss: 0.06905489414930344 val_loss: 45.34856033325195\n",
      "epoch:  26100 train_loss: 0.12114330381155014 val_loss: 45.241981506347656\n",
      "epoch:  26200 train_loss: 0.07058919966220856 val_loss: 45.37260437011719\n",
      "epoch:  26300 train_loss: 0.059668753296136856 val_loss: 45.366615295410156\n",
      "epoch:  26400 train_loss: 0.07304397970438004 val_loss: 45.338958740234375\n",
      "epoch:  26500 train_loss: 0.07441926002502441 val_loss: 45.34391784667969\n",
      "epoch:  26600 train_loss: 0.07436708360910416 val_loss: 45.18982696533203\n",
      "epoch:  26700 train_loss: 0.1024213582277298 val_loss: 45.17428970336914\n",
      "epoch:  26800 train_loss: 0.04107579588890076 val_loss: 45.254905700683594\n",
      "epoch:  26900 train_loss: 0.06487095355987549 val_loss: 45.149559020996094\n",
      "epoch:  27000 train_loss: 0.14592528343200684 val_loss: 45.42658233642578\n",
      "epoch:  27100 train_loss: 0.05984096974134445 val_loss: 45.19151306152344\n",
      "epoch:  27200 train_loss: 0.054182492196559906 val_loss: 45.172115325927734\n",
      "epoch:  27300 train_loss: 0.07820587605237961 val_loss: 45.257415771484375\n",
      "epoch:  27400 train_loss: 0.07646302133798599 val_loss: 45.37651062011719\n",
      "epoch:  27500 train_loss: 0.04471457749605179 val_loss: 45.12088394165039\n",
      "epoch:  27600 train_loss: 0.05837610736489296 val_loss: 45.026710510253906\n",
      "epoch:  27700 train_loss: 0.060884349048137665 val_loss: 45.243080139160156\n",
      "epoch:  27800 train_loss: 0.08498308062553406 val_loss: 44.99494171142578\n",
      "epoch:  27900 train_loss: 0.06670517474412918 val_loss: 45.1598014831543\n",
      "epoch:  28000 train_loss: 0.049229323863983154 val_loss: 45.18909454345703\n",
      "epoch:  28100 train_loss: 0.051954079419374466 val_loss: 45.1161003112793\n",
      "epoch:  28200 train_loss: 0.07380152493715286 val_loss: 45.16492462158203\n",
      "epoch:  28300 train_loss: 0.0656571090221405 val_loss: 45.309913635253906\n",
      "epoch:  28400 train_loss: 0.05341872200369835 val_loss: 45.15672302246094\n",
      "epoch:  28500 train_loss: 0.07291305810213089 val_loss: 45.27279281616211\n",
      "epoch:  28600 train_loss: 0.06313195079565048 val_loss: 45.26921844482422\n",
      "epoch:  28700 train_loss: 0.05451833829283714 val_loss: 45.29072570800781\n",
      "epoch:  28800 train_loss: 0.14797364175319672 val_loss: 45.513587951660156\n",
      "epoch:  28900 train_loss: 0.08255285024642944 val_loss: 45.22877883911133\n",
      "epoch:  29000 train_loss: 0.1222144290804863 val_loss: 45.403709411621094\n",
      "epoch:  29100 train_loss: 0.08015933632850647 val_loss: 44.9628791809082\n",
      "epoch:  29200 train_loss: 0.08901423215866089 val_loss: 45.03390884399414\n",
      "epoch:  29300 train_loss: 0.08994771540164948 val_loss: 44.98046112060547\n",
      "epoch:  29400 train_loss: 0.13241855800151825 val_loss: 45.05501937866211\n",
      "epoch:  29500 train_loss: 0.07257889956235886 val_loss: 45.2799072265625\n",
      "epoch:  29600 train_loss: 0.1510610729455948 val_loss: 45.35055160522461\n",
      "epoch:  29700 train_loss: 0.04596547409892082 val_loss: 45.109230041503906\n",
      "epoch:  29800 train_loss: 0.057438433170318604 val_loss: 45.24690628051758\n",
      "epoch:  29900 train_loss: 0.06137550622224808 val_loss: 45.0826301574707\n",
      "epoch:  30000 train_loss: 0.07066025584936142 val_loss: 45.117488861083984\n",
      "epoch:  30100 train_loss: 0.05758081004023552 val_loss: 45.221805572509766\n",
      "epoch:  30200 train_loss: 0.04748670011758804 val_loss: 45.171016693115234\n",
      "epoch:  30300 train_loss: 0.038854289799928665 val_loss: 44.98465347290039\n",
      "epoch:  30400 train_loss: 0.6903833150863647 val_loss: 45.94906234741211\n",
      "epoch:  30500 train_loss: 0.022863516584038734 val_loss: 45.001686096191406\n",
      "epoch:  30600 train_loss: 0.04565479978919029 val_loss: 45.2254524230957\n",
      "epoch:  30700 train_loss: 0.03579515218734741 val_loss: 45.10818862915039\n",
      "epoch:  30800 train_loss: 0.09132468700408936 val_loss: 44.823272705078125\n",
      "epoch:  30900 train_loss: 0.0770094096660614 val_loss: 44.9530143737793\n",
      "epoch:  31000 train_loss: 0.11348417401313782 val_loss: 44.79637145996094\n",
      "epoch:  31100 train_loss: 0.0290693286806345 val_loss: 45.03099822998047\n",
      "epoch:  31200 train_loss: 0.07599993795156479 val_loss: 45.360408782958984\n",
      "epoch:  31300 train_loss: 0.05535363405942917 val_loss: 45.04536437988281\n",
      "epoch:  31400 train_loss: 0.07879174500703812 val_loss: 44.97624969482422\n",
      "epoch:  31500 train_loss: 0.08394020050764084 val_loss: 45.02452850341797\n",
      "epoch:  31600 train_loss: 0.03782754763960838 val_loss: 44.888240814208984\n",
      "epoch:  31700 train_loss: 0.03932986408472061 val_loss: 45.087120056152344\n",
      "epoch:  31800 train_loss: 0.07742531597614288 val_loss: 44.898040771484375\n",
      "epoch:  31900 train_loss: 0.04170146584510803 val_loss: 45.105220794677734\n",
      "epoch:  32000 train_loss: 0.03797103464603424 val_loss: 45.149471282958984\n",
      "epoch:  32100 train_loss: 0.041276831179857254 val_loss: 45.16214370727539\n",
      "epoch:  32200 train_loss: 0.03218452259898186 val_loss: 44.868534088134766\n",
      "epoch:  32300 train_loss: 0.11778119206428528 val_loss: 45.04218673706055\n",
      "epoch:  32400 train_loss: 0.02389650233089924 val_loss: 45.074249267578125\n",
      "epoch:  32500 train_loss: 0.03249198570847511 val_loss: 45.063743591308594\n",
      "epoch:  32600 train_loss: 0.04964876174926758 val_loss: 45.03358459472656\n",
      "epoch:  32700 train_loss: 0.05719759687781334 val_loss: 45.11011505126953\n",
      "epoch:  32800 train_loss: 0.05099799856543541 val_loss: 45.207576751708984\n",
      "epoch:  32900 train_loss: 0.02875129133462906 val_loss: 44.91840744018555\n",
      "epoch:  33000 train_loss: 0.07618532329797745 val_loss: 45.150604248046875\n",
      "epoch:  33100 train_loss: 0.03408263996243477 val_loss: 44.989967346191406\n",
      "epoch:  33200 train_loss: 0.09180545806884766 val_loss: 45.16859436035156\n",
      "epoch:  33300 train_loss: 0.06906969100236893 val_loss: 45.143829345703125\n",
      "epoch:  33400 train_loss: 0.05181502923369408 val_loss: 45.01283264160156\n",
      "epoch:  33500 train_loss: 0.0432584173977375 val_loss: 44.932979583740234\n",
      "epoch:  33600 train_loss: 0.06330954283475876 val_loss: 44.801971435546875\n",
      "epoch:  33700 train_loss: 0.05375200882554054 val_loss: 44.96059036254883\n",
      "epoch:  33800 train_loss: 0.06435726583003998 val_loss: 45.02671432495117\n",
      "epoch:  33900 train_loss: 0.030721385031938553 val_loss: 44.812828063964844\n",
      "epoch:  34000 train_loss: 0.07293027639389038 val_loss: 44.82783889770508\n",
      "epoch:  34100 train_loss: 0.03757508099079132 val_loss: 44.88349914550781\n",
      "epoch:  34200 train_loss: 0.05635404586791992 val_loss: 45.033485412597656\n",
      "epoch:  34300 train_loss: 0.044747494161129 val_loss: 44.729454040527344\n",
      "epoch:  34400 train_loss: 0.032565560191869736 val_loss: 45.029541015625\n",
      "epoch:  34500 train_loss: 0.03582305461168289 val_loss: 44.97722625732422\n",
      "epoch:  34600 train_loss: 0.05224660411477089 val_loss: 44.745765686035156\n",
      "epoch:  34700 train_loss: 0.016634004190564156 val_loss: 44.977684020996094\n",
      "epoch:  34800 train_loss: 0.048043545335531235 val_loss: 44.837284088134766\n",
      "epoch:  34900 train_loss: 0.027602439746260643 val_loss: 44.817771911621094\n",
      "epoch:  35000 train_loss: 0.030830731615424156 val_loss: 44.91214370727539\n",
      "epoch:  35100 train_loss: 0.048410724848508835 val_loss: 44.93845748901367\n",
      "epoch:  35200 train_loss: 0.030753785744309425 val_loss: 44.856388092041016\n",
      "epoch:  35300 train_loss: 0.049686770886182785 val_loss: 44.93585968017578\n",
      "epoch:  35400 train_loss: 0.033915553241968155 val_loss: 44.86037063598633\n",
      "epoch:  35500 train_loss: 0.02157696709036827 val_loss: 44.82508850097656\n",
      "epoch:  35600 train_loss: 0.045809242874383926 val_loss: 44.79544448852539\n",
      "epoch:  35700 train_loss: 0.0431424081325531 val_loss: 45.043495178222656\n",
      "epoch:  35800 train_loss: 0.014902983792126179 val_loss: 44.96113204956055\n",
      "epoch:  35900 train_loss: 0.03876315429806709 val_loss: 45.02891159057617\n",
      "sigma: 9.1 RMSE:  tensor(9.6006, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Generate the dataset with noise N(0, sigma)\n",
    "i = 0\n",
    "sigma = 9.1\n",
    "my_dataset = []\n",
    "for ud in UDs:\n",
    "    example = []\n",
    "    for an in ANs:\n",
    "        noise = np.random.normal(0,sigma)\n",
    "        # 0 is mean\n",
    "        # sigma is the deviation of the normal distribution\n",
    "        d = compute_3d_distance(ud, an) + noise\n",
    "        example.append(d)\n",
    "    \n",
    "    # append x, y, z as col#10, #11, #12\n",
    "    example.append(ud[0])\n",
    "    example.append(ud[1])\n",
    "    example.append(ud[2])\n",
    "    \n",
    "    # append 1x13 example row into my_dataset\n",
    "    my_dataset.append(example)  # expected to be 3000x13  \n",
    "    \n",
    "# Load dataset\n",
    "exercise5_dataset = Exercise5Dataset(list_dataset = my_dataset, shuffle=True)\n",
    "\n",
    "#Split dataset by 0.8: 0.1: 0.1\n",
    "train_examples, train_labels = exercise5_dataset[:int(3000*0.8)]  # (2400, 10)   # (2400, 3)\n",
    "val_examples, val_labels = exercise5_dataset[int(3000*0.8):int(3000*0.9)]    # (300, 10)   #(300, 3)\n",
    "test_examples, test_labels = exercise5_dataset[int(3000*0.9):]     #(300, 10)   # (300, 3)\n",
    "\n",
    "###Define model, loss function and optimizer\n",
    "# if we have GPU, then use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define model\n",
    "#model = Net(x_dim = train_examples.shape[1], y_dim = train_labels.shape[1]).to(device)\n",
    "input_dim = 1     #input dim is 1, seq_len = 10\n",
    "hidden_dim = 64   #hidden state dim is 64\n",
    "n_layers = 3             #3-layered LSTM\n",
    "model = MYLSTM(input_dim, hidden_dim, n_layers).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Correct the input/output shape for LSTM\n",
    "train_inputs = torch.unsqueeze(train_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "train_inputs = train_inputs.to(device) \n",
    "\n",
    "val_inputs = torch.unsqueeze(val_examples, dim=-1)   # (N, 10) -> (N, 10, 1)\n",
    "val_inputs = val_inputs.to(device) \n",
    "\n",
    "train_labels = train_labels.to(device)   #(N, 3)\n",
    "val_labels = val_labels.to(device)          #(N, 3)\n",
    "\n",
    "\n",
    "# Define the loss threshold, if the current train loss is lower than the threshold, we will begin to save the model\n",
    "best_loss = 100.0\n",
    "\n",
    "# Define the model filename for model.save()\n",
    "MODEL_FILENAME = \"best.pth\"\n",
    "\n",
    "# set model to Training mode\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "NUM_OF_EPOCH = 36000\n",
    "\n",
    "# Train\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    y_pred = model(train_inputs)\n",
    "    loss = loss_fn(y_pred, train_labels).cpu()\n",
    "    #print(t, loss.item())\n",
    "    train_losses.append(loss.item())\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    # BGD\n",
    "    optimizer.step()\n",
    "    \n",
    "    # evaluate validation loss\n",
    "    val_pred = model(val_inputs)\n",
    "    loss = loss_fn(val_pred, val_labels)\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "\n",
    "\n",
    "    if (epoch % 100) == 0:\n",
    "        print(\"epoch: \", epoch, \"train_loss:\", train_losses[-1], \"val_loss:\", val_losses[-1])\n",
    "        # check if we got better loss\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n",
    "        \n",
    "# Load the best model on previous step\n",
    "model.load_state_dict(torch.load(\"best.pth\"))\n",
    "\n",
    "# Inference all testing examples and compute RMSE\n",
    "def square_error(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  square_error= loss_fn(a, b)\n",
    "  return square_error\n",
    "\n",
    "model.eval() # inference mode\n",
    "test_inputs = torch.unsqueeze(test_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "test_inputs = test_inputs.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "\n",
    "test_preds = model(test_inputs)\n",
    "#print(\"example: \", test_example.cpu())\n",
    "#print(\"========================================\")\n",
    "#print(\"ground_truth:\", test_label.cpu())\n",
    "#print(\"prediction:\", test_pred.cpu())\n",
    "#print(\"========================================\")\n",
    "\n",
    "\n",
    "total_errors = 0.0\n",
    "for idx in range(len(test_inputs)):\n",
    "    total_errors += square_error(test_preds[idx], test_labels[idx])\n",
    "    \n",
    "RMSE = torch.sqrt(total_errors / len(test_inputs))\n",
    "print(\"sigma:\", sigma, \"RMSE: \",  RMSE)\n",
    "\n",
    "sigmas.append(sigma)\n",
    "RMSEs.append(RMSE.cpu().detach().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigma = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffle = True!\n",
      "epoch:  0 train_loss: 7313.5078125 val_loss: 7412.6689453125\n",
      "epoch:  100 train_loss: 5996.3876953125 val_loss: 6079.244140625\n",
      "epoch:  200 train_loss: 5076.19384765625 val_loss: 5154.62255859375\n",
      "epoch:  300 train_loss: 4315.88720703125 val_loss: 4389.4287109375\n",
      "epoch:  400 train_loss: 3669.02294921875 val_loss: 3737.62353515625\n",
      "epoch:  500 train_loss: 3114.13330078125 val_loss: 3178.19677734375\n",
      "epoch:  600 train_loss: 2637.292236328125 val_loss: 2696.657470703125\n",
      "epoch:  700 train_loss: 2227.0234375 val_loss: 2282.11083984375\n",
      "epoch:  800 train_loss: 1874.7198486328125 val_loss: 1925.306396484375\n",
      "epoch:  900 train_loss: 1572.7000732421875 val_loss: 1619.1895751953125\n",
      "epoch:  1000 train_loss: 1314.91650390625 val_loss: 1357.4150390625\n",
      "epoch:  1100 train_loss: 1096.1214599609375 val_loss: 1134.814208984375\n",
      "epoch:  1200 train_loss: 911.943359375 val_loss: 946.9263916015625\n",
      "epoch:  1300 train_loss: 757.89892578125 val_loss: 789.6646728515625\n",
      "epoch:  1400 train_loss: 630.648193359375 val_loss: 659.13818359375\n",
      "epoch:  1500 train_loss: 526.50927734375 val_loss: 552.1170043945312\n",
      "epoch:  1600 train_loss: 442.4180603027344 val_loss: 465.17425537109375\n",
      "epoch:  1700 train_loss: 375.2566833496094 val_loss: 395.58154296875\n",
      "epoch:  1800 train_loss: 322.525634765625 val_loss: 340.52239990234375\n",
      "epoch:  1900 train_loss: 281.7197570800781 val_loss: 297.51385498046875\n",
      "epoch:  2000 train_loss: 250.58615112304688 val_loss: 264.53302001953125\n",
      "epoch:  2100 train_loss: 227.33460998535156 val_loss: 239.5615234375\n",
      "epoch:  2200 train_loss: 210.2382354736328 val_loss: 220.97930908203125\n",
      "epoch:  2300 train_loss: 197.94285583496094 val_loss: 207.33908081054688\n",
      "epoch:  2400 train_loss: 189.26220703125 val_loss: 197.51205444335938\n",
      "epoch:  2500 train_loss: 183.32716369628906 val_loss: 190.5905303955078\n",
      "epoch:  2600 train_loss: 179.296142578125 val_loss: 185.74111938476562\n",
      "epoch:  2700 train_loss: 176.66941833496094 val_loss: 182.43067932128906\n",
      "epoch:  2800 train_loss: 174.9881591796875 val_loss: 180.1870574951172\n",
      "epoch:  2900 train_loss: 173.94813537597656 val_loss: 178.68028259277344\n",
      "epoch:  3000 train_loss: 173.3238525390625 val_loss: 177.67259216308594\n",
      "epoch:  3100 train_loss: 172.96400451660156 val_loss: 177.04457092285156\n",
      "epoch:  3200 train_loss: 172.75042724609375 val_loss: 176.5941925048828\n",
      "epoch:  3300 train_loss: 172.64190673828125 val_loss: 176.32093811035156\n",
      "epoch:  3400 train_loss: 172.58253479003906 val_loss: 176.13400268554688\n",
      "epoch:  3500 train_loss: 172.55078125 val_loss: 176.00674438476562\n",
      "epoch:  3600 train_loss: 172.5365447998047 val_loss: 175.927490234375\n",
      "epoch:  3700 train_loss: 172.53028869628906 val_loss: 175.87620544433594\n",
      "epoch:  3800 train_loss: 172.5271759033203 val_loss: 175.8456268310547\n",
      "epoch:  3900 train_loss: 172.52581787109375 val_loss: 175.810546875\n",
      "epoch:  4000 train_loss: 172.5252227783203 val_loss: 175.79295349121094\n",
      "epoch:  4100 train_loss: 172.52503967285156 val_loss: 175.79092407226562\n",
      "epoch:  4200 train_loss: 172.52500915527344 val_loss: 175.78903198242188\n",
      "epoch:  4300 train_loss: 172.52499389648438 val_loss: 175.7848358154297\n",
      "epoch:  4400 train_loss: 172.52499389648438 val_loss: 175.7822265625\n",
      "epoch:  4500 train_loss: 172.52496337890625 val_loss: 175.78024291992188\n",
      "epoch:  4600 train_loss: 172.52496337890625 val_loss: 175.78021240234375\n",
      "epoch:  4700 train_loss: 172.52496337890625 val_loss: 175.77865600585938\n",
      "epoch:  4800 train_loss: 172.52496337890625 val_loss: 175.77865600585938\n",
      "epoch:  4900 train_loss: 172.52496337890625 val_loss: 175.77865600585938\n",
      "epoch:  5000 train_loss: 172.52496337890625 val_loss: 175.77923583984375\n",
      "epoch:  5100 train_loss: 172.52496337890625 val_loss: 175.77923583984375\n",
      "epoch:  5200 train_loss: 172.52499389648438 val_loss: 175.77865600585938\n",
      "epoch:  5300 train_loss: 172.52496337890625 val_loss: 175.77923583984375\n",
      "epoch:  5400 train_loss: 172.52496337890625 val_loss: 175.77923583984375\n",
      "epoch:  5500 train_loss: 172.52499389648438 val_loss: 175.77865600585938\n",
      "epoch:  5600 train_loss: 172.52496337890625 val_loss: 175.77923583984375\n",
      "epoch:  5700 train_loss: 172.52499389648438 val_loss: 175.77923583984375\n",
      "epoch:  5800 train_loss: 172.52499389648438 val_loss: 175.77923583984375\n",
      "epoch:  5900 train_loss: 172.52496337890625 val_loss: 175.77923583984375\n",
      "epoch:  6000 train_loss: 172.52499389648438 val_loss: 175.77865600585938\n",
      "epoch:  6100 train_loss: 172.52496337890625 val_loss: 175.77923583984375\n",
      "epoch:  6200 train_loss: 172.52496337890625 val_loss: 175.77923583984375\n",
      "epoch:  6300 train_loss: 172.52496337890625 val_loss: 175.77923583984375\n",
      "epoch:  6400 train_loss: 172.52499389648438 val_loss: 175.77865600585938\n",
      "epoch:  6500 train_loss: 172.52499389648438 val_loss: 175.77865600585938\n",
      "epoch:  6600 train_loss: 172.52496337890625 val_loss: 175.77862548828125\n",
      "epoch:  6700 train_loss: 172.52499389648438 val_loss: 175.7786102294922\n",
      "epoch:  6800 train_loss: 172.52499389648438 val_loss: 175.77919006347656\n",
      "epoch:  6900 train_loss: 172.52499389648438 val_loss: 175.77919006347656\n",
      "epoch:  7000 train_loss: 172.52499389648438 val_loss: 175.77919006347656\n",
      "epoch:  7100 train_loss: 172.52499389648438 val_loss: 175.7786102294922\n",
      "epoch:  7200 train_loss: 172.52496337890625 val_loss: 175.7786102294922\n",
      "epoch:  7300 train_loss: 172.52496337890625 val_loss: 175.77919006347656\n",
      "epoch:  7400 train_loss: 172.4981689453125 val_loss: 175.82278442382812\n",
      "epoch:  7500 train_loss: 137.69775390625 val_loss: 141.51809692382812\n",
      "epoch:  7600 train_loss: 112.85360717773438 val_loss: 115.0820083618164\n",
      "epoch:  7700 train_loss: 97.47215270996094 val_loss: 99.6617660522461\n",
      "epoch:  7800 train_loss: 82.35963439941406 val_loss: 84.53458404541016\n",
      "epoch:  7900 train_loss: 67.99707794189453 val_loss: 70.6719741821289\n",
      "epoch:  8000 train_loss: 55.96553039550781 val_loss: 59.64947509765625\n",
      "epoch:  8100 train_loss: 45.88330841064453 val_loss: 50.84395217895508\n",
      "epoch:  8200 train_loss: 37.934505462646484 val_loss: 44.89657974243164\n",
      "epoch:  8300 train_loss: 31.75469207763672 val_loss: 41.11677169799805\n",
      "epoch:  8400 train_loss: 26.541423797607422 val_loss: 38.38396453857422\n",
      "epoch:  8500 train_loss: 22.604507446289062 val_loss: 36.95064163208008\n",
      "epoch:  8600 train_loss: 19.506427764892578 val_loss: 36.496620178222656\n",
      "epoch:  8700 train_loss: 17.19546890258789 val_loss: 36.093719482421875\n",
      "epoch:  8800 train_loss: 15.188365936279297 val_loss: 36.1230583190918\n",
      "epoch:  8900 train_loss: 13.445147514343262 val_loss: 36.20633316040039\n",
      "epoch:  9000 train_loss: 12.040933609008789 val_loss: 37.233489990234375\n",
      "epoch:  9100 train_loss: 10.86771011352539 val_loss: 38.339351654052734\n",
      "epoch:  9200 train_loss: 9.848535537719727 val_loss: 39.58793640136719\n",
      "epoch:  9300 train_loss: 9.02400016784668 val_loss: 40.49155044555664\n",
      "epoch:  9400 train_loss: 8.267921447753906 val_loss: 40.94071960449219\n",
      "epoch:  9500 train_loss: 8.055768013000488 val_loss: 42.03646469116211\n",
      "epoch:  9600 train_loss: 7.089800834655762 val_loss: 42.06249237060547\n",
      "epoch:  9700 train_loss: 6.659539222717285 val_loss: 42.42669677734375\n",
      "epoch:  9800 train_loss: 6.1884284019470215 val_loss: 42.92329025268555\n",
      "epoch:  9900 train_loss: 5.641265392303467 val_loss: 44.08388900756836\n",
      "epoch:  10000 train_loss: 5.232295036315918 val_loss: 44.58620834350586\n",
      "epoch:  10100 train_loss: 4.888864040374756 val_loss: 45.32950210571289\n",
      "epoch:  10200 train_loss: 4.566134929656982 val_loss: 46.005104064941406\n",
      "epoch:  10300 train_loss: 4.247153282165527 val_loss: 46.7694206237793\n",
      "epoch:  10400 train_loss: 4.020730972290039 val_loss: 47.22114944458008\n",
      "epoch:  10500 train_loss: 3.736405372619629 val_loss: 48.046058654785156\n",
      "epoch:  10600 train_loss: 3.6064248085021973 val_loss: 48.759761810302734\n",
      "epoch:  10700 train_loss: 3.2845041751861572 val_loss: 49.360748291015625\n",
      "epoch:  10800 train_loss: 3.0729243755340576 val_loss: 49.862884521484375\n",
      "epoch:  10900 train_loss: 3.024232864379883 val_loss: 50.66962432861328\n",
      "epoch:  11000 train_loss: 2.9651546478271484 val_loss: 51.14475631713867\n",
      "epoch:  11100 train_loss: 2.564793348312378 val_loss: 51.610172271728516\n",
      "epoch:  11200 train_loss: 2.440558433532715 val_loss: 51.80524826049805\n",
      "epoch:  11300 train_loss: 2.290252447128296 val_loss: 52.18513488769531\n",
      "epoch:  11400 train_loss: 2.093939781188965 val_loss: 52.833457946777344\n",
      "epoch:  11500 train_loss: 1.9972317218780518 val_loss: 53.25223159790039\n",
      "epoch:  11600 train_loss: 1.8715343475341797 val_loss: 53.3691520690918\n",
      "epoch:  11700 train_loss: 1.8031189441680908 val_loss: 53.67853927612305\n",
      "epoch:  11800 train_loss: 1.7083561420440674 val_loss: 53.73342514038086\n",
      "epoch:  11900 train_loss: 1.5776538848876953 val_loss: 54.041542053222656\n",
      "epoch:  12000 train_loss: 1.6286842823028564 val_loss: 54.13736343383789\n",
      "epoch:  12100 train_loss: 1.4079598188400269 val_loss: 54.480674743652344\n",
      "epoch:  12200 train_loss: 1.4154090881347656 val_loss: 54.97273635864258\n",
      "epoch:  12300 train_loss: 1.3284101486206055 val_loss: 54.52396011352539\n",
      "epoch:  12400 train_loss: 1.3323076963424683 val_loss: 55.07052993774414\n",
      "epoch:  12500 train_loss: 1.1622016429901123 val_loss: 55.135982513427734\n",
      "epoch:  12600 train_loss: 1.1953811645507812 val_loss: 54.845401763916016\n",
      "epoch:  12700 train_loss: 1.1426944732666016 val_loss: 55.008087158203125\n",
      "epoch:  12800 train_loss: 1.3866804838180542 val_loss: 56.16212844848633\n",
      "epoch:  12900 train_loss: 1.0058211088180542 val_loss: 55.9029426574707\n",
      "epoch:  13000 train_loss: 0.9633565545082092 val_loss: 55.774654388427734\n",
      "epoch:  13100 train_loss: 0.8873757719993591 val_loss: 56.27684020996094\n",
      "epoch:  13200 train_loss: 0.8476952910423279 val_loss: 56.44795227050781\n",
      "epoch:  13300 train_loss: 0.8648946285247803 val_loss: 56.59836196899414\n",
      "epoch:  13400 train_loss: 0.8615292906761169 val_loss: 56.29323959350586\n",
      "epoch:  13500 train_loss: 0.7331565022468567 val_loss: 56.3800048828125\n",
      "epoch:  13600 train_loss: 0.7172150015830994 val_loss: 56.8044548034668\n",
      "epoch:  13700 train_loss: 0.6801988482475281 val_loss: 57.12666702270508\n",
      "epoch:  13800 train_loss: 0.7772068381309509 val_loss: 56.653934478759766\n",
      "epoch:  13900 train_loss: 0.648142397403717 val_loss: 56.85763931274414\n",
      "epoch:  14000 train_loss: 0.5891202688217163 val_loss: 57.09138870239258\n",
      "epoch:  14100 train_loss: 0.6328678131103516 val_loss: 57.34867858886719\n",
      "epoch:  14200 train_loss: 0.5463791489601135 val_loss: 57.220760345458984\n",
      "epoch:  14300 train_loss: 0.5556572079658508 val_loss: 57.19639587402344\n",
      "epoch:  14400 train_loss: 0.49673715233802795 val_loss: 57.691627502441406\n",
      "epoch:  14500 train_loss: 0.4876115620136261 val_loss: 57.70014953613281\n",
      "epoch:  14600 train_loss: 0.5413984060287476 val_loss: 57.95172119140625\n",
      "epoch:  14700 train_loss: 0.4622986316680908 val_loss: 57.83893966674805\n",
      "epoch:  14800 train_loss: 0.5529332756996155 val_loss: 58.02812576293945\n",
      "epoch:  14900 train_loss: 0.5068516135215759 val_loss: 57.89546585083008\n",
      "epoch:  15000 train_loss: 0.42890238761901855 val_loss: 58.0800895690918\n",
      "epoch:  15100 train_loss: 0.41052117943763733 val_loss: 58.018516540527344\n",
      "epoch:  15200 train_loss: 0.4064145088195801 val_loss: 57.8423957824707\n",
      "epoch:  15300 train_loss: 0.3546629250049591 val_loss: 58.2851676940918\n",
      "epoch:  15400 train_loss: 0.49611952900886536 val_loss: 58.88532257080078\n",
      "epoch:  15500 train_loss: 0.3321625590324402 val_loss: 58.335086822509766\n",
      "epoch:  15600 train_loss: 0.34089431166648865 val_loss: 58.21092224121094\n",
      "epoch:  15700 train_loss: 0.42494866251945496 val_loss: 59.05930709838867\n",
      "epoch:  15800 train_loss: 0.31254592537879944 val_loss: 58.864646911621094\n",
      "epoch:  15900 train_loss: 0.3166920840740204 val_loss: 58.59340286254883\n",
      "epoch:  16000 train_loss: 0.4391908347606659 val_loss: 58.91636276245117\n",
      "epoch:  16100 train_loss: 0.3244886100292206 val_loss: 59.06822967529297\n",
      "epoch:  16200 train_loss: 0.2531220614910126 val_loss: 58.99150466918945\n",
      "epoch:  16300 train_loss: 0.2913196086883545 val_loss: 58.991947174072266\n",
      "epoch:  16400 train_loss: 0.40799933671951294 val_loss: 59.33028793334961\n",
      "epoch:  16500 train_loss: 0.22918647527694702 val_loss: 59.13692092895508\n",
      "epoch:  16600 train_loss: 0.2216232419013977 val_loss: 58.9635009765625\n",
      "epoch:  16700 train_loss: 0.2577970325946808 val_loss: 58.81573486328125\n",
      "epoch:  16800 train_loss: 0.20603297650814056 val_loss: 58.780574798583984\n",
      "epoch:  16900 train_loss: 0.19846707582473755 val_loss: 59.081546783447266\n",
      "epoch:  17000 train_loss: 0.2618572413921356 val_loss: 59.07622146606445\n",
      "epoch:  17100 train_loss: 0.24922291934490204 val_loss: 59.12548065185547\n",
      "epoch:  17200 train_loss: 0.21463565528392792 val_loss: 59.19260025024414\n",
      "epoch:  17300 train_loss: 0.26277995109558105 val_loss: 58.88361358642578\n",
      "epoch:  17400 train_loss: 0.18040938675403595 val_loss: 59.155029296875\n",
      "epoch:  17500 train_loss: 0.20646491646766663 val_loss: 58.944297790527344\n",
      "epoch:  17600 train_loss: 0.26901838183403015 val_loss: 59.273258209228516\n",
      "epoch:  17700 train_loss: 0.19364818930625916 val_loss: 59.07310104370117\n",
      "epoch:  17800 train_loss: 0.19791634380817413 val_loss: 59.187435150146484\n",
      "epoch:  17900 train_loss: 0.17061233520507812 val_loss: 59.07206726074219\n",
      "epoch:  18000 train_loss: 0.189243882894516 val_loss: 58.95997619628906\n",
      "epoch:  18100 train_loss: 0.20868422091007233 val_loss: 59.495582580566406\n",
      "epoch:  18200 train_loss: 0.17776097357273102 val_loss: 59.27952575683594\n",
      "epoch:  18300 train_loss: 0.17318743467330933 val_loss: 59.23308181762695\n",
      "epoch:  18400 train_loss: 0.15506915748119354 val_loss: 59.16004180908203\n",
      "epoch:  18500 train_loss: 0.14548812806606293 val_loss: 59.04044723510742\n",
      "epoch:  18600 train_loss: 0.19262512028217316 val_loss: 59.43190383911133\n",
      "epoch:  18700 train_loss: 0.14990198612213135 val_loss: 59.30065155029297\n",
      "epoch:  18800 train_loss: 0.1700655221939087 val_loss: 59.50394821166992\n",
      "epoch:  18900 train_loss: 0.13888828456401825 val_loss: 59.380619049072266\n",
      "epoch:  19000 train_loss: 0.14145265519618988 val_loss: 59.1954345703125\n",
      "epoch:  19100 train_loss: 0.1383931189775467 val_loss: 59.263240814208984\n",
      "epoch:  19200 train_loss: 0.16413246095180511 val_loss: 59.12520980834961\n",
      "epoch:  19300 train_loss: 0.15593405067920685 val_loss: 59.44162368774414\n",
      "epoch:  19400 train_loss: 0.12201469391584396 val_loss: 59.35940170288086\n",
      "epoch:  19500 train_loss: 0.1480294167995453 val_loss: 59.380523681640625\n",
      "epoch:  19600 train_loss: 0.11307532340288162 val_loss: 59.53187561035156\n",
      "epoch:  19700 train_loss: 0.12069493532180786 val_loss: 59.44174575805664\n",
      "epoch:  19800 train_loss: 0.11332276463508606 val_loss: 59.41200256347656\n",
      "epoch:  19900 train_loss: 0.15507130324840546 val_loss: 59.20329284667969\n",
      "epoch:  20000 train_loss: 0.10619008541107178 val_loss: 59.48240661621094\n",
      "epoch:  20100 train_loss: 0.11292989552021027 val_loss: 59.32054138183594\n",
      "epoch:  20200 train_loss: 0.11925265938043594 val_loss: 59.50267791748047\n",
      "epoch:  20300 train_loss: 0.10796767473220825 val_loss: 59.59770965576172\n",
      "epoch:  20400 train_loss: 0.2514805793762207 val_loss: 59.52439498901367\n",
      "epoch:  20500 train_loss: 0.08668401092290878 val_loss: 59.24634552001953\n",
      "epoch:  20600 train_loss: 0.12311504781246185 val_loss: 59.426231384277344\n",
      "epoch:  20700 train_loss: 0.11774609982967377 val_loss: 59.48374557495117\n",
      "epoch:  20800 train_loss: 0.10136998444795609 val_loss: 59.37264633178711\n",
      "epoch:  20900 train_loss: 0.09052986651659012 val_loss: 59.5460205078125\n",
      "epoch:  21000 train_loss: 0.09752517193555832 val_loss: 59.624916076660156\n",
      "epoch:  21100 train_loss: 0.08256617933511734 val_loss: 59.41999816894531\n",
      "epoch:  21200 train_loss: 0.15033993124961853 val_loss: 59.53889083862305\n",
      "epoch:  21300 train_loss: 0.11704539507627487 val_loss: 59.69648742675781\n",
      "epoch:  21400 train_loss: 0.08538581430912018 val_loss: 59.61853790283203\n",
      "epoch:  21500 train_loss: 0.08226446807384491 val_loss: 59.687129974365234\n",
      "epoch:  21600 train_loss: 0.07745585590600967 val_loss: 59.463504791259766\n",
      "epoch:  21700 train_loss: 0.09989745169878006 val_loss: 59.59827423095703\n",
      "epoch:  21800 train_loss: 0.07185984402894974 val_loss: 59.589805603027344\n",
      "epoch:  21900 train_loss: 0.10443887114524841 val_loss: 59.73203659057617\n",
      "epoch:  22000 train_loss: 0.0885268822312355 val_loss: 59.57124328613281\n",
      "epoch:  22100 train_loss: 0.12665529549121857 val_loss: 59.57978439331055\n",
      "epoch:  22200 train_loss: 0.07834279537200928 val_loss: 59.528377532958984\n",
      "epoch:  22300 train_loss: 0.06035390496253967 val_loss: 59.52253341674805\n",
      "epoch:  22400 train_loss: 0.07259775698184967 val_loss: 59.556365966796875\n",
      "epoch:  22500 train_loss: 0.09141498059034348 val_loss: 59.80909729003906\n",
      "epoch:  22600 train_loss: 0.1028672456741333 val_loss: 59.679203033447266\n",
      "epoch:  22700 train_loss: 0.08721539378166199 val_loss: 59.292076110839844\n",
      "epoch:  22800 train_loss: 0.08318322896957397 val_loss: 59.61689758300781\n",
      "epoch:  22900 train_loss: 0.08459864556789398 val_loss: 59.746910095214844\n",
      "epoch:  23000 train_loss: 0.08247049897909164 val_loss: 59.57437515258789\n",
      "epoch:  23100 train_loss: 0.09817620366811752 val_loss: 59.89635467529297\n",
      "epoch:  23200 train_loss: 0.0652361586689949 val_loss: 59.6175537109375\n",
      "epoch:  23300 train_loss: 0.09027327597141266 val_loss: 59.75743103027344\n",
      "epoch:  23400 train_loss: 0.058619678020477295 val_loss: 59.6036491394043\n",
      "epoch:  23500 train_loss: 0.0750698521733284 val_loss: 59.62946319580078\n",
      "epoch:  23600 train_loss: 0.10133324563503265 val_loss: 59.38093566894531\n",
      "epoch:  23700 train_loss: 0.0626504048705101 val_loss: 59.61724090576172\n",
      "epoch:  23800 train_loss: 0.06390061229467392 val_loss: 59.499839782714844\n",
      "epoch:  23900 train_loss: 0.08128844201564789 val_loss: 59.570919036865234\n",
      "epoch:  24000 train_loss: 0.05414556711912155 val_loss: 59.6163215637207\n",
      "epoch:  24100 train_loss: 0.054835304617881775 val_loss: 59.538482666015625\n",
      "epoch:  24200 train_loss: 0.06275158375501633 val_loss: 59.553958892822266\n",
      "epoch:  24300 train_loss: 0.05808941274881363 val_loss: 59.51727294921875\n",
      "epoch:  24400 train_loss: 0.06874284148216248 val_loss: 59.6411247253418\n",
      "epoch:  24500 train_loss: 0.08992505073547363 val_loss: 59.46268844604492\n",
      "epoch:  24600 train_loss: 0.06602776050567627 val_loss: 59.4669189453125\n",
      "epoch:  24700 train_loss: 0.058622900396585464 val_loss: 59.62143325805664\n",
      "epoch:  24800 train_loss: 0.06899633258581161 val_loss: 59.769657135009766\n",
      "epoch:  24900 train_loss: 0.04214702546596527 val_loss: 59.66073989868164\n",
      "epoch:  25000 train_loss: 0.05430693179368973 val_loss: 59.66041564941406\n",
      "epoch:  25100 train_loss: 0.20606403052806854 val_loss: 59.956207275390625\n",
      "epoch:  25200 train_loss: 0.1601673811674118 val_loss: 59.706172943115234\n",
      "epoch:  25300 train_loss: 0.05770973861217499 val_loss: 59.4454460144043\n",
      "epoch:  25400 train_loss: 0.03858469799160957 val_loss: 59.560367584228516\n",
      "epoch:  25500 train_loss: 0.041608989238739014 val_loss: 59.42721939086914\n",
      "epoch:  25600 train_loss: 0.09420878440141678 val_loss: 59.532081604003906\n",
      "epoch:  25700 train_loss: 0.07697727531194687 val_loss: 59.48287582397461\n",
      "epoch:  25800 train_loss: 0.3139387369155884 val_loss: 58.61219024658203\n",
      "epoch:  25900 train_loss: 0.03398161754012108 val_loss: 58.78927230834961\n",
      "epoch:  26000 train_loss: 0.03442789241671562 val_loss: 59.031494140625\n",
      "epoch:  26100 train_loss: 0.033114295452833176 val_loss: 59.119441986083984\n",
      "epoch:  26200 train_loss: 0.045568790286779404 val_loss: 59.07365417480469\n",
      "epoch:  26300 train_loss: 0.04398059472441673 val_loss: 59.21883773803711\n",
      "epoch:  26400 train_loss: 0.04336126521229744 val_loss: 59.39550018310547\n",
      "epoch:  26500 train_loss: 0.03818150982260704 val_loss: 59.290748596191406\n",
      "epoch:  26600 train_loss: 0.04017509147524834 val_loss: 59.27302169799805\n",
      "epoch:  26700 train_loss: 0.05752255767583847 val_loss: 59.300048828125\n",
      "epoch:  26800 train_loss: 0.06307684630155563 val_loss: 59.091026306152344\n",
      "epoch:  26900 train_loss: 0.03272615000605583 val_loss: 59.23204040527344\n",
      "epoch:  27000 train_loss: 0.04429328069090843 val_loss: 59.25160598754883\n",
      "epoch:  27100 train_loss: 0.08560746908187866 val_loss: 59.0548095703125\n",
      "epoch:  27200 train_loss: 0.07001814246177673 val_loss: 59.34061050415039\n",
      "epoch:  27300 train_loss: 0.06943543255329132 val_loss: 59.33348846435547\n",
      "epoch:  27400 train_loss: 0.03365889564156532 val_loss: 59.009342193603516\n",
      "epoch:  27500 train_loss: 0.06728044152259827 val_loss: 59.32325744628906\n",
      "epoch:  27600 train_loss: 0.05044020712375641 val_loss: 59.21128463745117\n",
      "epoch:  27700 train_loss: 0.03401002660393715 val_loss: 59.26518249511719\n",
      "epoch:  27800 train_loss: 0.04530832916498184 val_loss: 59.18581008911133\n",
      "epoch:  27900 train_loss: 0.07242820411920547 val_loss: 59.04957580566406\n",
      "epoch:  28000 train_loss: 0.044024884700775146 val_loss: 59.01034164428711\n",
      "epoch:  28100 train_loss: 0.06071966513991356 val_loss: 59.06061935424805\n",
      "epoch:  28200 train_loss: 0.05046175420284271 val_loss: 59.308231353759766\n",
      "epoch:  28300 train_loss: 0.06375598162412643 val_loss: 59.35144805908203\n",
      "epoch:  28400 train_loss: 0.02906729280948639 val_loss: 59.14748001098633\n",
      "epoch:  28500 train_loss: 0.04465488716959953 val_loss: 58.95935821533203\n",
      "epoch:  28600 train_loss: 0.03375231847167015 val_loss: 59.125633239746094\n",
      "epoch:  28700 train_loss: 0.034042395651340485 val_loss: 59.064517974853516\n",
      "epoch:  28800 train_loss: 0.032807283103466034 val_loss: 57.98427200317383\n",
      "epoch:  28900 train_loss: 0.023322639986872673 val_loss: 58.416297912597656\n",
      "epoch:  29000 train_loss: 0.021919187158346176 val_loss: 58.53806686401367\n",
      "epoch:  29100 train_loss: 0.029371745884418488 val_loss: 58.57462692260742\n",
      "epoch:  29200 train_loss: 0.025322498753666878 val_loss: 58.684349060058594\n",
      "epoch:  29300 train_loss: 0.03226675093173981 val_loss: 58.65205764770508\n",
      "epoch:  29400 train_loss: 0.06409137696027756 val_loss: 58.78269958496094\n",
      "epoch:  29500 train_loss: 0.05410466715693474 val_loss: 58.66483688354492\n",
      "epoch:  29600 train_loss: 0.026952221989631653 val_loss: 58.77994155883789\n",
      "epoch:  29700 train_loss: 0.044643156230449677 val_loss: 58.821067810058594\n",
      "epoch:  29800 train_loss: 0.03974190354347229 val_loss: 58.71725082397461\n",
      "epoch:  29900 train_loss: 0.035927437245845795 val_loss: 58.702301025390625\n",
      "epoch:  30000 train_loss: 0.03692225366830826 val_loss: 58.8569450378418\n",
      "epoch:  30100 train_loss: 0.03136102482676506 val_loss: 58.642215728759766\n",
      "epoch:  30200 train_loss: 0.03778942674398422 val_loss: 58.73520278930664\n",
      "epoch:  30300 train_loss: 0.03979397192597389 val_loss: 58.846649169921875\n",
      "epoch:  30400 train_loss: 0.04268967732787132 val_loss: 58.66304397583008\n",
      "epoch:  30500 train_loss: 0.030448289588093758 val_loss: 58.62262725830078\n",
      "epoch:  30600 train_loss: 0.04480011761188507 val_loss: 58.741119384765625\n",
      "epoch:  30700 train_loss: 0.036203570663928986 val_loss: 58.76731491088867\n",
      "epoch:  30800 train_loss: 0.04790717363357544 val_loss: 58.67955780029297\n",
      "epoch:  30900 train_loss: 0.02645714022219181 val_loss: 58.7426872253418\n",
      "epoch:  31000 train_loss: 0.04444848746061325 val_loss: 58.55028533935547\n",
      "epoch:  31100 train_loss: 0.026791928336024284 val_loss: 58.718666076660156\n",
      "epoch:  31200 train_loss: 0.02120054140686989 val_loss: 58.68282699584961\n",
      "epoch:  31300 train_loss: 0.027283860370516777 val_loss: 58.80083465576172\n",
      "epoch:  31400 train_loss: 0.04878203198313713 val_loss: 58.62876510620117\n",
      "epoch:  31500 train_loss: 0.0217717457562685 val_loss: 58.80569839477539\n",
      "epoch:  31600 train_loss: 0.039018724113702774 val_loss: 58.569297790527344\n",
      "epoch:  31700 train_loss: 0.044363513588905334 val_loss: 58.61116027832031\n",
      "epoch:  31800 train_loss: 0.027602797374129295 val_loss: 58.647491455078125\n",
      "epoch:  31900 train_loss: 0.04211977869272232 val_loss: 58.7291259765625\n",
      "epoch:  32000 train_loss: 0.051119111478328705 val_loss: 58.60527801513672\n",
      "epoch:  32100 train_loss: 0.07694888859987259 val_loss: 58.689910888671875\n",
      "epoch:  32200 train_loss: 0.04258120432496071 val_loss: 58.45625686645508\n",
      "epoch:  32300 train_loss: 0.030790910124778748 val_loss: 58.32666778564453\n",
      "epoch:  32400 train_loss: 0.03236930072307587 val_loss: 58.36188507080078\n",
      "epoch:  32500 train_loss: 0.03638223186135292 val_loss: 58.58901596069336\n",
      "epoch:  32600 train_loss: 0.031233230605721474 val_loss: 58.41045379638672\n",
      "epoch:  32700 train_loss: 0.01788315735757351 val_loss: 58.509464263916016\n",
      "epoch:  32800 train_loss: 0.08480209857225418 val_loss: 58.49456024169922\n",
      "epoch:  32900 train_loss: 0.026833683252334595 val_loss: 58.48320007324219\n",
      "epoch:  33000 train_loss: 0.03091411292552948 val_loss: 58.39930725097656\n",
      "epoch:  33100 train_loss: 0.0559888631105423 val_loss: 58.20219039916992\n",
      "epoch:  33200 train_loss: 0.030815938487648964 val_loss: 58.51786422729492\n",
      "epoch:  33300 train_loss: 0.027834493666887283 val_loss: 58.29362106323242\n",
      "epoch:  33400 train_loss: 0.020838413387537003 val_loss: 58.32440948486328\n",
      "epoch:  33500 train_loss: 0.0228575412184 val_loss: 58.27021026611328\n",
      "epoch:  33600 train_loss: 0.02271164022386074 val_loss: 58.294124603271484\n",
      "epoch:  33700 train_loss: 0.034407228231430054 val_loss: 58.36543273925781\n",
      "epoch:  33800 train_loss: 0.027006641030311584 val_loss: 58.266624450683594\n",
      "epoch:  33900 train_loss: 0.018516892567276955 val_loss: 58.31290054321289\n",
      "epoch:  34000 train_loss: 0.05063893646001816 val_loss: 58.23416519165039\n",
      "epoch:  34100 train_loss: 0.05094505473971367 val_loss: 58.249168395996094\n",
      "epoch:  34200 train_loss: 0.04695276543498039 val_loss: 58.0091438293457\n",
      "epoch:  34300 train_loss: 0.03964047133922577 val_loss: 58.171268463134766\n",
      "epoch:  34400 train_loss: 0.024438610300421715 val_loss: 58.35116195678711\n",
      "epoch:  34500 train_loss: 0.03319511562585831 val_loss: 58.283077239990234\n",
      "epoch:  34600 train_loss: 0.03382410854101181 val_loss: 58.26987838745117\n",
      "epoch:  34700 train_loss: 0.038950636982917786 val_loss: 58.079994201660156\n",
      "epoch:  34800 train_loss: 0.03965485095977783 val_loss: 58.30710220336914\n",
      "epoch:  34900 train_loss: 0.02067497745156288 val_loss: 58.183223724365234\n",
      "epoch:  35000 train_loss: 0.0446929931640625 val_loss: 58.052093505859375\n",
      "epoch:  35100 train_loss: 0.03908804431557655 val_loss: 57.8807487487793\n",
      "epoch:  35200 train_loss: 0.01924826391041279 val_loss: 57.930992126464844\n",
      "epoch:  35300 train_loss: 0.026703815907239914 val_loss: 58.177146911621094\n",
      "epoch:  35400 train_loss: 0.02130955271422863 val_loss: 58.256805419921875\n",
      "epoch:  35500 train_loss: 0.015270073898136616 val_loss: 57.96759796142578\n",
      "epoch:  35600 train_loss: 0.029901165515184402 val_loss: 58.103145599365234\n",
      "epoch:  35700 train_loss: 0.022933127358555794 val_loss: 57.93682861328125\n",
      "epoch:  35800 train_loss: 0.01651778072118759 val_loss: 58.04863739013672\n",
      "epoch:  35900 train_loss: 0.02884608879685402 val_loss: 57.947471618652344\n",
      "sigma: 10.0 RMSE:  tensor(10.2957, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Generate the dataset with noise N(0, sigma)\n",
    "i = 0\n",
    "sigma = 10.0\n",
    "my_dataset = []\n",
    "for ud in UDs:\n",
    "    example = []\n",
    "    for an in ANs:\n",
    "        noise = np.random.normal(0,sigma)\n",
    "        # 0 is mean\n",
    "        # sigma is the deviation of the normal distribution\n",
    "        d = compute_3d_distance(ud, an) + noise\n",
    "        example.append(d)\n",
    "    \n",
    "    # append x, y, z as col#10, #11, #12\n",
    "    example.append(ud[0])\n",
    "    example.append(ud[1])\n",
    "    example.append(ud[2])\n",
    "    \n",
    "    # append 1x13 example row into my_dataset\n",
    "    my_dataset.append(example)  # expected to be 3000x13  \n",
    "    \n",
    "# Load dataset\n",
    "exercise5_dataset = Exercise5Dataset(list_dataset = my_dataset, shuffle=True)\n",
    "\n",
    "#Split dataset by 0.8: 0.1: 0.1\n",
    "train_examples, train_labels = exercise5_dataset[:int(3000*0.8)]  # (2400, 10)   # (2400, 3)\n",
    "val_examples, val_labels = exercise5_dataset[int(3000*0.8):int(3000*0.9)]    # (300, 10)   #(300, 3)\n",
    "test_examples, test_labels = exercise5_dataset[int(3000*0.9):]     #(300, 10)   # (300, 3)\n",
    "\n",
    "###Define model, loss function and optimizer\n",
    "# if we have GPU, then use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define model\n",
    "#model = Net(x_dim = train_examples.shape[1], y_dim = train_labels.shape[1]).to(device)\n",
    "input_dim = 1     #input dim is 1, seq_len = 10\n",
    "hidden_dim = 64   #hidden state dim is 64\n",
    "n_layers = 3             #3-layered LSTM\n",
    "model = MYLSTM(input_dim, hidden_dim, n_layers).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Correct the input/output shape for LSTM\n",
    "train_inputs = torch.unsqueeze(train_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "train_inputs = train_inputs.to(device) \n",
    "\n",
    "val_inputs = torch.unsqueeze(val_examples, dim=-1)   # (N, 10) -> (N, 10, 1)\n",
    "val_inputs = val_inputs.to(device) \n",
    "\n",
    "train_labels = train_labels.to(device)   #(N, 3)\n",
    "val_labels = val_labels.to(device)          #(N, 3)\n",
    "\n",
    "\n",
    "# Define the loss threshold, if the current train loss is lower than the threshold, we will begin to save the model\n",
    "best_loss = 100.0\n",
    "\n",
    "# Define the model filename for model.save()\n",
    "MODEL_FILENAME = \"best.pth\"\n",
    "\n",
    "# set model to Training mode\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "NUM_OF_EPOCH = 36000\n",
    "\n",
    "# Train\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    y_pred = model(train_inputs)\n",
    "    loss = loss_fn(y_pred, train_labels).cpu()\n",
    "    #print(t, loss.item())\n",
    "    train_losses.append(loss.item())\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    # BGD\n",
    "    optimizer.step()\n",
    "    \n",
    "    # evaluate validation loss\n",
    "    val_pred = model(val_inputs)\n",
    "    loss = loss_fn(val_pred, val_labels)\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "\n",
    "\n",
    "    if (epoch % 100) == 0:\n",
    "        print(\"epoch: \", epoch, \"train_loss:\", train_losses[-1], \"val_loss:\", val_losses[-1])\n",
    "        # check if we got better loss\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n",
    "        \n",
    "# Load the best model on previous step\n",
    "model.load_state_dict(torch.load(\"best.pth\"))\n",
    "\n",
    "# Inference all testing examples and compute RMSE\n",
    "def square_error(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  square_error= loss_fn(a, b)\n",
    "  return square_error\n",
    "\n",
    "model.eval() # inference mode\n",
    "test_inputs = torch.unsqueeze(test_examples, dim=-1)  #  (N, 10) -> (N, 10, 1)   \n",
    "test_inputs = test_inputs.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "\n",
    "test_preds = model(test_inputs)\n",
    "#print(\"example: \", test_example.cpu())\n",
    "#print(\"========================================\")\n",
    "#print(\"ground_truth:\", test_label.cpu())\n",
    "#print(\"prediction:\", test_pred.cpu())\n",
    "#print(\"========================================\")\n",
    "\n",
    "\n",
    "total_errors = 0.0\n",
    "for idx in range(len(test_inputs)):\n",
    "    total_errors += square_error(test_preds[idx], test_labels[idx])\n",
    "    \n",
    "RMSE = torch.sqrt(total_errors / len(test_inputs))\n",
    "print(\"sigma:\", sigma, \"RMSE: \",  RMSE)\n",
    "\n",
    "sigmas.append(sigma)\n",
    "RMSEs.append(RMSE.cpu().detach().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the RMSE by measurement noise diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sigmas = [0.1, 1.0, 1.9, 2.8, 3.7, 4.6, 5.5, 6.4, 7.3, 8.2, 9.1, 10.0]\n",
    "#RMSEs = [0.4948, 1.0454, 2.2507, 3.4022, 4.6365, 6.0840, 8.3602, 9.2469, 10.0984, 11.3101, 12.7875, 13.5534]\n",
    "plt.ylabel(\"Position RMSE(m)\")\n",
    "plt.xlabel(\"Measurement Noise sigma (m)\")\n",
    "plt.grid(True)\n",
    "plt.plot(sigmas, RMSEs, marker='o')\n",
    "\n",
    "for a, b in zip(sigmas, RMSEs):\n",
    "    plt.text(a, b+0.3, b, ha='center', va='bottom', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
