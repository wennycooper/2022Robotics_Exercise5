{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "AN_sysA = [(30, 200, 40), (100, 200, 10), (0, 0, 30), (200, 100, 20)]\n",
    "AN_sysB = [(0, 100, 10), (50, 150, 70), (100,100, 100), (200, 200, 60), (100, 0, 20), (200, 0, 30)]\n",
    "ANs = AN_sysA + AN_sysB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "UD_orig = (100, 100, 20)\n",
    "UDs = []\n",
    "r = 20.0\n",
    "PI = 3.1416\n",
    "NUM_EXAMPLES = 3000\n",
    "\n",
    "for theta in np.arange(0.0, 2*PI*6, 2*PI*6/NUM_EXAMPLES):\n",
    "    x = r * math.cos(theta) + UD_orig[0]\n",
    "    y = r * math.sin(theta) + UD_orig[1]\n",
    "    z = theta + UD_orig[2]\n",
    "    UDs.append((x, y, z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(UDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 3D scatterplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (16, 9)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.view_init(azim=235, elev=30)   # set view port according to the fig.4 in paper\n",
    "\n",
    "# plot AN points for system A\n",
    "marker = '^'\n",
    "for xs, ys, zs in AN_sysA:\n",
    "    ax.scatter(xs, ys, zs, marker=marker, c='r', s=100)\n",
    "\n",
    "# plot AN points for system B\n",
    "marker = '*'\n",
    "for xs, ys, zs in AN_sysB:\n",
    "    ax.scatter(xs, ys, zs, marker=marker, c='g', s=100)\n",
    "\n",
    "# plot UD points\n",
    "marker = '.'\n",
    "for xs, ys, zs in UDs:\n",
    "    ax.scatter(xs, ys, zs, marker=marker, c='b', s=100)\n",
    "\n",
    "    \n",
    "ax.set_xlabel('X-Axis')\n",
    "ax.set_ylabel('Y-Axis')\n",
    "ax.set_zlabel('Z-Axis')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate my_dataset by Computing the distances between UD and ANs\n",
    "# The dataset is defined to be (3000, 13) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_3d_distance(p1, p2):\n",
    "    x1 = p1[0]\n",
    "    y1 = p1[1]\n",
    "    z1 = p1[2]\n",
    "    x2 = p2[0]\n",
    "    y2 = p2[1]\n",
    "    z2 = p2[2]\n",
    "    \n",
    "    d = math.sqrt((x2 - x1)**2 + (y2 - y1)**2 + (z2 - z1)**2)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(UDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ganerate the dataset\n",
    "i = 0\n",
    "my_dataset = []\n",
    "for ud in UDs:\n",
    "    example = []\n",
    "    for an in ANs:\n",
    "        d = compute_3d_distance(ud, an)\n",
    "        example.append(d)\n",
    "    \n",
    "    # append x, y, z as col#10, #11, #12\n",
    "    example.append(ud[0])\n",
    "    example.append(ud[1])\n",
    "    example.append(ud[2])\n",
    "    \n",
    "    # append 1x13 example row into my_dataset\n",
    "    my_dataset.append(example)  # expected to be 3000x13  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to show the 1st example of my_dataset for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[136.01470508735443,\n",
       " 102.46950765959599,\n",
       " 156.52475842498527,\n",
       " 80.0,\n",
       " 120.41594578792295,\n",
       " 99.498743710662,\n",
       " 82.46211251235322,\n",
       " 134.16407864998737,\n",
       " 101.9803902718557,\n",
       " 128.4523257866513,\n",
       " 120.0,\n",
       " 100.0,\n",
       " 20.0]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Field Explaination of my_dataset\n",
    "## Example of my_dataset = [rA0, rA1, rA2, rA3, rB0, rB1,rB2, rB3, rB4, rB5, x, y, z]\n",
    "\n",
    "* rA0, rA1, rA2, rA3, rB0, rB1, ... rB5: distance between ANi to UD (in meters)\n",
    "\n",
    "*  x, y, z:  UD location (in meters, ground truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify the dataset dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array(my_dataset)   # (3000, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 13)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset loader and data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exercise5Dataset(Dataset):\n",
    "    \"\"\"Exercise5 dataset.\"\"\"\n",
    "    def __init__(self, list_dataset, shuffle=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        list_dataset (list): Directory with the dataset files.\n",
    "        shuffle (bool): Shuffle or not\n",
    "        \"\"\"\n",
    "        self.all_data = list_dataset\n",
    "\n",
    "        if shuffle:\n",
    "            random.shuffle(self.all_data)\n",
    "            print(\"Dataset shuffle = True!\")\n",
    "\n",
    "        ### Data preprocessing\n",
    "        # Compute dataset mean and std\n",
    "        examples = torch.from_numpy(np.array(self.all_data)[:, :10]).float()    \n",
    "        #print(examples.shape) # (3000, 10)\n",
    "        self.labels = torch.from_numpy(np.array(self.all_data)[:, 10:]).float()\n",
    "        #print(self.labels.shape)  #(3000, 3)\n",
    "\n",
    "        # Compute mean and std\n",
    "        mu = examples.mean(dim=0)\n",
    "        sigma = examples.std(dim=0, unbiased=False)\n",
    "\n",
    "        # Compute normalized examples:\n",
    "        x_prime = (x - mu) / sigma\n",
    "        self.normalized_examples = (examples - mu) / sigma\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.normalized_examples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        example = self.normalized_examples[idx]   #(N, 10)\n",
    "        xyz = self.labels[idx]   #(N,3)\n",
    "        return example, xyz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffle = True!\n"
     ]
    }
   ],
   "source": [
    "exercise5_dataset = Exercise5Dataset(list_dataset = my_dataset, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exercise5_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset by 0.8: 0.1: 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples, train_labels = exercise5_dataset[:int(3000*0.8)]  # (2400, 10)   # (2400, 3)\n",
    "val_examples, val_labels = exercise5_dataset[int(3000*0.8):int(3000*0.9)]    # (300, 10)   #(300, 3)\n",
    "test_examples, test_labels = exercise5_dataset[int(3000*0.9):]     #(300, 10)   # (300, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2400, 10])\n",
      "torch.Size([2400, 3])\n",
      "torch.Size([300, 10])\n",
      "torch.Size([300, 3])\n",
      "torch.Size([300, 10])\n",
      "torch.Size([300, 3])\n"
     ]
    }
   ],
   "source": [
    "print(train_examples.shape)\n",
    "print(train_labels.shape)\n",
    "print(val_examples.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_examples.shape)\n",
    "print(test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define our model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, x_dim, y_dim):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(x_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, y_dim),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear_relu_stack(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model, loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-949b51044f4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# define model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_examples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# define loss function and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    661\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    662\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 663\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure"
     ]
    }
   ],
   "source": [
    "# if we have GPU, then use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define model\n",
    "model = Net(x_dim = train_examples.shape[1], y_dim = train_labels.shape[1]).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Net(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=256, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss threshold, if the current train loss is lower than the threshold, we will begin to save the model\n",
    "best_loss = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 train_loss: 7369.17333984375 val_loss: 7192.0458984375\n",
      "epoch:  100 train_loss: 115.16506958007812 val_loss: 120.83737182617188\n",
      "epoch:  200 train_loss: 106.56716918945312 val_loss: 110.96711730957031\n",
      "epoch:  300 train_loss: 76.6618423461914 val_loss: 79.25333404541016\n",
      "epoch:  400 train_loss: 41.703182220458984 val_loss: 44.351261138916016\n",
      "epoch:  500 train_loss: 37.91929626464844 val_loss: 39.93599319458008\n",
      "epoch:  600 train_loss: 1.369756817817688 val_loss: 1.3343839645385742\n",
      "epoch:  700 train_loss: 0.41590002179145813 val_loss: 0.44995447993278503\n",
      "epoch:  800 train_loss: 0.30943313241004944 val_loss: 0.34136027097702026\n",
      "epoch:  900 train_loss: 0.2454564869403839 val_loss: 0.273266464471817\n",
      "epoch:  1000 train_loss: 0.20253215730190277 val_loss: 0.22661659121513367\n",
      "epoch:  1100 train_loss: 0.16052484512329102 val_loss: 0.18239611387252808\n",
      "epoch:  1200 train_loss: 0.13752953708171844 val_loss: 0.1573323905467987\n",
      "epoch:  1300 train_loss: 0.118495412170887 val_loss: 0.13677985966205597\n",
      "epoch:  1400 train_loss: 0.10469719767570496 val_loss: 0.12142887711524963\n",
      "epoch:  1500 train_loss: 0.09475274384021759 val_loss: 0.10994135588407516\n",
      "epoch:  1600 train_loss: 0.08608061075210571 val_loss: 0.10022992640733719\n",
      "epoch:  1700 train_loss: 0.07868514209985733 val_loss: 0.09193141013383865\n",
      "epoch:  1800 train_loss: 0.07250585407018661 val_loss: 0.08479251712560654\n",
      "epoch:  1900 train_loss: 0.06716827303171158 val_loss: 0.0785953626036644\n",
      "epoch:  2000 train_loss: 0.06242874637246132 val_loss: 0.07296593487262726\n",
      "epoch:  2100 train_loss: 0.058241408318281174 val_loss: 0.06818500906229019\n",
      "epoch:  2200 train_loss: 0.05369291082024574 val_loss: 0.06294994801282883\n",
      "epoch:  2300 train_loss: 0.05045139789581299 val_loss: 0.05927876755595207\n",
      "epoch:  2400 train_loss: 0.04756755381822586 val_loss: 0.05629287287592888\n",
      "epoch:  2500 train_loss: 0.04480747506022453 val_loss: 0.053487543016672134\n",
      "epoch:  2600 train_loss: 0.0424182303249836 val_loss: 0.05097385495901108\n",
      "epoch:  2700 train_loss: 0.04024698957800865 val_loss: 0.0485253669321537\n",
      "epoch:  2800 train_loss: 0.03824286535382271 val_loss: 0.04658550024032593\n",
      "epoch:  2900 train_loss: 0.03654973581433296 val_loss: 0.044567007571458817\n"
     ]
    }
   ],
   "source": [
    "# Training and Validation\n",
    "\n",
    "train_examples = train_examples.to(device)\n",
    "train_labels = train_labels.to(device)\n",
    "val_examples = val_examples.to(device)\n",
    "val_labels = val_labels.to(device)\n",
    "\n",
    "# Define the model filename for model.save()\n",
    "MODEL_FILENAME = \"best.pth\"\n",
    "\n",
    "# set model to Training mode\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "NUM_OF_EPOCH = 3000\n",
    "\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    y_pred = model(train_examples)\n",
    "    loss = loss_fn(y_pred, train_labels).cpu()\n",
    "    #print(t, loss.item())\n",
    "    train_losses.append(loss.item())\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    # BGD\n",
    "    optimizer.step()\n",
    "    \n",
    "    # evaluate validation loss\n",
    "    val_pred = model(val_examples)\n",
    "    loss = loss_fn(val_pred, val_labels)\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "    # check if we got better loss\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n",
    "\n",
    "    if (epoch % 100) == 0:\n",
    "        print(\"epoch: \", epoch, \"train_loss:\", train_losses[-1], \"val_loss:\", val_losses[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the Loss history for training set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_train_history(train_history, val_history):\n",
    "    plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
    "    plt.plot(np.log(train_history))\n",
    "    plt.plot(np.log(val_history))\n",
    "    plt.title(\"Train_history\")\n",
    "    plt.ylabel(\"Log(MSELoss)\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend(['train', 'val'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_train_history(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference a single testing example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example:  tensor([-1.4149, -0.5434,  0.0965,  1.2146, -0.6273, -1.9919, -1.3664, -0.0395,\n",
      "         1.1796,  1.4525])\n",
      "========================================\n",
      "ground_truth (x, y, z in meters):  tensor([ 85.4195, 113.6898,  53.8036])\n",
      "prediction (x, y, z in meters):  tensor([ 85.4193, 113.6152,  53.4346], grad_fn=<CopyBackwards>)\n",
      "========================================\n",
      "Error (euclidean distance in meters):  tensor(0.3765, grad_fn=<CopyBackwards>)\n"
     ]
    }
   ],
   "source": [
    "def euclidean_distance(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  euclidena_dist = torch.sqrt(loss_fn(a, b))\n",
    "  return euclidena_dist\n",
    "\n",
    "model.eval() # inference mode\n",
    "idx = 188\n",
    "test_examples = test_examples.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "test_example = test_examples[idx]\n",
    "test_label = test_labels[idx]\n",
    "test_pred = model(test_example)\n",
    "print(\"example: \", test_example.cpu())\n",
    "print(\"========================================\")\n",
    "print(\"ground_truth (x, y, z in meters): \", test_label.cpu())\n",
    "print(\"prediction (x, y, z in meters): \", test_pred.cpu())\n",
    "print(\"========================================\")\n",
    "\n",
    "\n",
    "#print(\"Loss: \",  loss_fn(test_pred, test_label).cpu())\n",
    "print(\"Error (euclidean distance in meters): \",  euclidean_distance(test_pred, test_label).cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference all testing examples and compute RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  tensor(0.3478, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "def square_error(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  square_error= loss_fn(a, b)\n",
    "  return square_error\n",
    "\n",
    "model.eval() # inference mode\n",
    "test_examples = test_examples.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "test_preds = model(test_examples)\n",
    "#print(\"example: \", test_example.cpu())\n",
    "#print(\"========================================\")\n",
    "#print(\"ground_truth:\", test_label.cpu())\n",
    "#print(\"prediction:\", test_pred.cpu())\n",
    "#print(\"========================================\")\n",
    "\n",
    "\n",
    "total_errors = 0.0\n",
    "for idx in range(len(test_examples)):\n",
    "    total_errors += square_error(test_preds[idx], test_labels[idx])\n",
    "    \n",
    "RMSE = torch.sqrt(total_errors / len(test_examples))\n",
    "print(\"RMSE: \",  RMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the testset prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (16, 9)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.view_init(azim=235, elev=30)   # set view port to fit the fig.4 in paper\n",
    "\n",
    "# plot AN points for system A\n",
    "marker = '^'\n",
    "for xs, ys, zs in AN_sysA:\n",
    "    ax.scatter(xs, ys, zs, marker=marker, c='r', s=100)\n",
    "\n",
    "# plot AN points for system B\n",
    "marker = '*'\n",
    "for xs, ys, zs in AN_sysB:\n",
    "    ax.scatter(xs, ys, zs, marker=marker, c='g', s=100)\n",
    "\n",
    "# plot testset prediction points\n",
    "marker = '.'\n",
    "for xs, ys, zs in test_preds.cpu().detach().numpy():\n",
    "    ax.scatter(xs, ys, zs, marker=marker, c='orange', s=100)\n",
    "\n",
    "    \n",
    "ax.set_xlabel('X-Axis')\n",
    "ax.set_ylabel('Y-Axis')\n",
    "ax.set_zlabel('Z-Axis')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOW we are going to add measurement noises into the dataset\n",
    "## Based on the paper, we will add the noise into measurements r by N(0, sigma), sigma = 0.1, 1.0, 1,9, 2.8, 3.7, 4.6, 5.5, 6.4, 7.3, 8.2, 9.1, 10.0 respectively.\n",
    "## We will trained the 12 dataset into 12 models and evaluate the RMSEs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ganerate the dataset\n",
    "i = 0\n",
    "sigma = 0.1\n",
    "my_dataset = []\n",
    "for ud in UDs:\n",
    "    example = []\n",
    "    for an in ANs:\n",
    "        noise = np.random.normal(0,sigma)\n",
    "        # 0 is mean\n",
    "        # sigma is the deviation of the normal distribution\n",
    "        d = compute_3d_distance(ud, an) + noise\n",
    "        example.append(d)\n",
    "    \n",
    "    # append x, y, z as col#10, #11, #12\n",
    "    example.append(ud[0])\n",
    "    example.append(ud[1])\n",
    "    example.append(ud[2])\n",
    "    \n",
    "    # append 1x13 example row into my_dataset\n",
    "    my_dataset.append(example)  # expected to be 3000x13  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffle = True!\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "exercise3_dataset = Exercise3Dataset(list_dataset = my_dataset, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset by 0.8: 0.1: 0.1\n",
    "train_examples, train_labels = exercise3_dataset[:int(3000*0.8)]  # (2400, 10)   # (2400, 3)\n",
    "val_examples, val_labels = exercise3_dataset[int(3000*0.8):int(3000*0.9)]    # (300, 10)   #(300, 3)\n",
    "test_examples, test_labels = exercise3_dataset[int(3000*0.9):]     #(300, 10)   # (300, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Define model, loss function and optimizer\n",
    "# if we have GPU, then use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define model\n",
    "model = Net(x_dim = train_examples.shape[1], y_dim = train_labels.shape[1]).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 train_loss: 7343.04736328125 val_loss: 7332.18017578125\n",
      "epoch:  100 train_loss: 111.82319641113281 val_loss: 114.65656280517578\n",
      "epoch:  200 train_loss: 103.675537109375 val_loss: 106.15442657470703\n",
      "epoch:  300 train_loss: 63.579750061035156 val_loss: 64.58694458007812\n",
      "epoch:  400 train_loss: 31.30756950378418 val_loss: 32.87067413330078\n",
      "epoch:  500 train_loss: 0.617013156414032 val_loss: 0.6429895162582397\n",
      "epoch:  600 train_loss: 0.396918922662735 val_loss: 0.41252031922340393\n",
      "epoch:  700 train_loss: 0.2883111834526062 val_loss: 0.31006884574890137\n",
      "epoch:  800 train_loss: 0.23190057277679443 val_loss: 0.25652313232421875\n",
      "epoch:  900 train_loss: 0.19753947854042053 val_loss: 0.22491055727005005\n",
      "epoch:  1000 train_loss: 0.1727939248085022 val_loss: 0.19933922588825226\n",
      "epoch:  1100 train_loss: 0.15528030693531036 val_loss: 0.18157744407653809\n",
      "epoch:  1200 train_loss: 0.1415184885263443 val_loss: 0.16648049652576447\n",
      "epoch:  1300 train_loss: 0.1306713968515396 val_loss: 0.154170960187912\n",
      "epoch:  1400 train_loss: 0.12186624854803085 val_loss: 0.14418195188045502\n",
      "epoch:  1500 train_loss: 0.1144435852766037 val_loss: 0.1357228010892868\n",
      "epoch:  1600 train_loss: 0.10830039530992508 val_loss: 0.1288651078939438\n",
      "epoch:  1700 train_loss: 0.10295671224594116 val_loss: 0.12241427600383759\n",
      "epoch:  1800 train_loss: 0.09867001324892044 val_loss: 0.11728415638208389\n",
      "epoch:  1900 train_loss: 0.09473889321088791 val_loss: 0.11299654096364975\n",
      "epoch:  2000 train_loss: 0.09120022505521774 val_loss: 0.10891978442668915\n",
      "epoch:  2100 train_loss: 0.0881761685013771 val_loss: 0.10565896332263947\n",
      "epoch:  2200 train_loss: 0.0854412093758583 val_loss: 0.10306846350431442\n",
      "epoch:  2300 train_loss: 0.08310651034116745 val_loss: 0.10082366317510605\n",
      "epoch:  2400 train_loss: 0.08064322918653488 val_loss: 0.0978379175066948\n",
      "epoch:  2500 train_loss: 0.0784212276339531 val_loss: 0.09525098651647568\n",
      "epoch:  2600 train_loss: 0.07664470374584198 val_loss: 0.09380995482206345\n",
      "epoch:  2700 train_loss: 0.07525302469730377 val_loss: 0.09138986468315125\n",
      "epoch:  2800 train_loss: 0.07356557250022888 val_loss: 0.09045764803886414\n",
      "epoch:  2900 train_loss: 0.07159312069416046 val_loss: 0.08859477192163467\n",
      "epoch:  3000 train_loss: 0.06953714787960052 val_loss: 0.08647430688142776\n",
      "epoch:  3100 train_loss: 0.06829410046339035 val_loss: 0.08494683355093002\n",
      "epoch:  3200 train_loss: 0.06686057150363922 val_loss: 0.08369569480419159\n",
      "epoch:  3300 train_loss: 0.06529711186885834 val_loss: 0.0819869264960289\n",
      "epoch:  3400 train_loss: 0.06413782387971878 val_loss: 0.08015580475330353\n",
      "epoch:  3500 train_loss: 0.07119938731193542 val_loss: 0.08799725770950317\n",
      "epoch:  3600 train_loss: 0.0632508173584938 val_loss: 0.07891391217708588\n",
      "epoch:  3700 train_loss: 0.06268826872110367 val_loss: 0.07830985635519028\n",
      "epoch:  3800 train_loss: 0.06061301380395889 val_loss: 0.0773983970284462\n",
      "epoch:  3900 train_loss: 0.06301769614219666 val_loss: 0.07727599143981934\n",
      "epoch:  4000 train_loss: 0.0586872436106205 val_loss: 0.0754852294921875\n",
      "epoch:  4100 train_loss: 0.06255346536636353 val_loss: 0.0803046002984047\n",
      "epoch:  4200 train_loss: 0.060288503766059875 val_loss: 0.07599663734436035\n",
      "epoch:  4300 train_loss: 0.0577385313808918 val_loss: 0.07377217710018158\n",
      "epoch:  4400 train_loss: 0.06093768775463104 val_loss: 0.0774359330534935\n",
      "epoch:  4500 train_loss: 0.06845452636480331 val_loss: 0.08062020689249039\n",
      "epoch:  4600 train_loss: 0.0625477135181427 val_loss: 0.08700315654277802\n",
      "epoch:  4700 train_loss: 0.17812445759773254 val_loss: 0.22851891815662384\n",
      "epoch:  4800 train_loss: 0.10404375195503235 val_loss: 0.11700787395238876\n",
      "epoch:  4900 train_loss: 0.13524794578552246 val_loss: 0.10796675086021423\n",
      "epoch:  5000 train_loss: 0.08216676861047745 val_loss: 0.10363874584436417\n",
      "epoch:  5100 train_loss: 0.058180902153253555 val_loss: 0.06797371804714203\n",
      "epoch:  5200 train_loss: 0.05321801081299782 val_loss: 0.07526759058237076\n",
      "epoch:  5300 train_loss: 0.04986707866191864 val_loss: 0.06690354645252228\n",
      "epoch:  5400 train_loss: 0.04901435971260071 val_loss: 0.06601979583501816\n",
      "epoch:  5500 train_loss: 0.9706993699073792 val_loss: 0.6488105654716492\n",
      "epoch:  5600 train_loss: 0.04771214351058006 val_loss: 0.06437644362449646\n",
      "epoch:  5700 train_loss: 0.04729572311043739 val_loss: 0.06506936997175217\n",
      "epoch:  5800 train_loss: 0.11695938557386398 val_loss: 0.13882505893707275\n",
      "epoch:  5900 train_loss: 0.06589770317077637 val_loss: 0.06562578678131104\n",
      "epoch:  6000 train_loss: 0.04586920514702797 val_loss: 0.06375311315059662\n",
      "epoch:  6100 train_loss: 0.046531371772289276 val_loss: 0.06397081911563873\n",
      "epoch:  6200 train_loss: 0.19698891043663025 val_loss: 0.2915339469909668\n",
      "epoch:  6300 train_loss: 0.09546799212694168 val_loss: 0.1135164424777031\n",
      "epoch:  6400 train_loss: 0.0444125197827816 val_loss: 0.06343096494674683\n",
      "epoch:  6500 train_loss: 0.057182926684617996 val_loss: 0.07457137107849121\n",
      "epoch:  6600 train_loss: 0.04499459266662598 val_loss: 0.06272643059492111\n",
      "epoch:  6700 train_loss: 0.045505136251449585 val_loss: 0.06251133233308792\n",
      "epoch:  6800 train_loss: 0.0561542846262455 val_loss: 0.0726362094283104\n",
      "epoch:  6900 train_loss: 0.0694812461733818 val_loss: 0.09516610950231552\n",
      "epoch:  7000 train_loss: 0.04740861803293228 val_loss: 0.0633203536272049\n",
      "epoch:  7100 train_loss: 0.0825808048248291 val_loss: 0.10671883821487427\n",
      "epoch:  7200 train_loss: 0.04322079196572304 val_loss: 0.06059326231479645\n",
      "epoch:  7300 train_loss: 0.05217748135328293 val_loss: 0.06995613873004913\n",
      "epoch:  7400 train_loss: 0.04276282340288162 val_loss: 0.06097911670804024\n",
      "epoch:  7500 train_loss: 0.04162085801362991 val_loss: 0.0598192922770977\n",
      "epoch:  7600 train_loss: 0.04122847318649292 val_loss: 0.05942220985889435\n",
      "epoch:  7700 train_loss: 0.25931960344314575 val_loss: 0.3241710066795349\n",
      "epoch:  7800 train_loss: 0.04360243305563927 val_loss: 0.06661194562911987\n",
      "epoch:  7900 train_loss: 0.07131315022706985 val_loss: 0.10527271032333374\n",
      "epoch:  8000 train_loss: 0.040488459169864655 val_loss: 0.05943813547492027\n",
      "epoch:  8100 train_loss: 0.09387268126010895 val_loss: 0.10968409478664398\n",
      "epoch:  8200 train_loss: 0.24072499573230743 val_loss: 0.18586787581443787\n",
      "epoch:  8300 train_loss: 0.04107970371842384 val_loss: 0.05934356153011322\n",
      "epoch:  8400 train_loss: 0.05972158908843994 val_loss: 0.08834294974803925\n",
      "epoch:  8500 train_loss: 0.0456843264400959 val_loss: 0.06521805375814438\n",
      "epoch:  8600 train_loss: 0.06273102015256882 val_loss: 0.08100803196430206\n",
      "epoch:  8700 train_loss: 0.04203064739704132 val_loss: 0.06122680380940437\n",
      "epoch:  8800 train_loss: 0.04510466381907463 val_loss: 0.06511998176574707\n",
      "epoch:  8900 train_loss: 0.05032660812139511 val_loss: 0.06063948944211006\n",
      "epoch:  9000 train_loss: 0.04035669192671776 val_loss: 0.06101444736123085\n",
      "epoch:  9100 train_loss: 0.038350556045770645 val_loss: 0.055998291820287704\n",
      "epoch:  9200 train_loss: 0.0382501557469368 val_loss: 0.05611979216337204\n",
      "epoch:  9300 train_loss: 0.06660561263561249 val_loss: 0.07902222871780396\n",
      "epoch:  9400 train_loss: 0.03888934850692749 val_loss: 0.05725904926657677\n",
      "epoch:  9500 train_loss: 0.0675983801484108 val_loss: 0.06873810291290283\n",
      "epoch:  9600 train_loss: 0.3138613998889923 val_loss: 0.3052230775356293\n",
      "epoch:  9700 train_loss: 0.06226879730820656 val_loss: 0.057885248214006424\n",
      "epoch:  9800 train_loss: 0.08599663525819778 val_loss: 0.09198057651519775\n",
      "epoch:  9900 train_loss: 0.04136704280972481 val_loss: 0.0593997985124588\n",
      "epoch:  10000 train_loss: 0.03768680989742279 val_loss: 0.05515246093273163\n",
      "epoch:  10100 train_loss: 0.1163526326417923 val_loss: 0.13017398118972778\n",
      "epoch:  10200 train_loss: 0.03686603531241417 val_loss: 0.054547104984521866\n",
      "epoch:  10300 train_loss: 0.03644511103630066 val_loss: 0.05405094847083092\n",
      "epoch:  10400 train_loss: 0.037220798432826996 val_loss: 0.05395771935582161\n",
      "epoch:  10500 train_loss: 0.07559861987829208 val_loss: 0.0951237827539444\n",
      "epoch:  10600 train_loss: 0.04833753779530525 val_loss: 0.065550796687603\n",
      "epoch:  10700 train_loss: 0.046011969447135925 val_loss: 0.06632623076438904\n",
      "epoch:  10800 train_loss: 0.0361417680978775 val_loss: 0.05265624821186066\n",
      "epoch:  10900 train_loss: 0.035444121807813644 val_loss: 0.053017206490039825\n",
      "epoch:  11000 train_loss: 0.042798835784196854 val_loss: 0.060156818479299545\n",
      "epoch:  11100 train_loss: 0.03549378737807274 val_loss: 0.052585747092962265\n",
      "epoch:  11200 train_loss: 0.03721318766474724 val_loss: 0.054404936730861664\n",
      "epoch:  11300 train_loss: 0.03763023391366005 val_loss: 0.05408085882663727\n",
      "epoch:  11400 train_loss: 0.12663838267326355 val_loss: 0.18496118485927582\n",
      "epoch:  11500 train_loss: 0.04106825590133667 val_loss: 0.06083647161722183\n",
      "epoch:  11600 train_loss: 0.05419411510229111 val_loss: 0.07581666857004166\n",
      "epoch:  11700 train_loss: 0.04034549370408058 val_loss: 0.05706818774342537\n",
      "epoch:  11800 train_loss: 0.034986600279808044 val_loss: 0.05145973339676857\n",
      "epoch:  11900 train_loss: 0.05672129988670349 val_loss: 0.08824524283409119\n",
      "epoch:  12000 train_loss: 0.034635771065950394 val_loss: 0.05363333970308304\n",
      "epoch:  12100 train_loss: 0.12228429317474365 val_loss: 0.09593084454536438\n",
      "epoch:  12200 train_loss: 0.03500121459364891 val_loss: 0.05169054493308067\n",
      "epoch:  12300 train_loss: 0.053791556507349014 val_loss: 0.050724394619464874\n",
      "epoch:  12400 train_loss: 0.041096337139606476 val_loss: 0.054786138236522675\n",
      "epoch:  12500 train_loss: 0.03358550742268562 val_loss: 0.050069864839315414\n",
      "epoch:  12600 train_loss: 0.03526993840932846 val_loss: 0.05027574300765991\n",
      "epoch:  12700 train_loss: 0.04516809433698654 val_loss: 0.06169872730970383\n",
      "epoch:  12800 train_loss: 0.03335091471672058 val_loss: 0.050310131162405014\n",
      "epoch:  12900 train_loss: 0.7851917147636414 val_loss: 0.7981685996055603\n",
      "epoch:  13000 train_loss: 0.2977290153503418 val_loss: 0.3892659544944763\n",
      "epoch:  13100 train_loss: 0.08101186156272888 val_loss: 0.09805170446634293\n",
      "epoch:  13200 train_loss: 0.03380979970097542 val_loss: 0.04957161471247673\n",
      "epoch:  13300 train_loss: 0.07377172261476517 val_loss: 0.0686308890581131\n",
      "epoch:  13400 train_loss: 0.03319351375102997 val_loss: 0.04943704605102539\n",
      "epoch:  13500 train_loss: 0.037791065871715546 val_loss: 0.05268334224820137\n",
      "epoch:  13600 train_loss: 0.04322770982980728 val_loss: 0.05606808140873909\n",
      "epoch:  13700 train_loss: 0.03256421908736229 val_loss: 0.0493210107088089\n",
      "epoch:  13800 train_loss: 0.04888385534286499 val_loss: 0.06460938602685928\n",
      "epoch:  13900 train_loss: 0.03604225069284439 val_loss: 0.04871724173426628\n",
      "epoch:  14000 train_loss: 0.032628435641527176 val_loss: 0.048909373581409454\n",
      "epoch:  14100 train_loss: 0.03649290278553963 val_loss: 0.04961344972252846\n",
      "epoch:  14200 train_loss: 0.14097480475902557 val_loss: 0.2874218821525574\n",
      "epoch:  14300 train_loss: 0.03395024314522743 val_loss: 0.05097646266222\n",
      "epoch:  14400 train_loss: 0.1523156762123108 val_loss: 0.16764818131923676\n",
      "epoch:  14500 train_loss: 0.044513244181871414 val_loss: 0.06223534792661667\n",
      "epoch:  14600 train_loss: 0.03597193956375122 val_loss: 0.05497390776872635\n",
      "epoch:  14700 train_loss: 0.07188745588064194 val_loss: 0.0987691879272461\n",
      "epoch:  14800 train_loss: 0.04235874116420746 val_loss: 0.04996141791343689\n",
      "epoch:  14900 train_loss: 0.5163931250572205 val_loss: 0.47564175724983215\n",
      "epoch:  15000 train_loss: 0.17459172010421753 val_loss: 0.15942688286304474\n",
      "epoch:  15100 train_loss: 0.5174912810325623 val_loss: 0.6961323618888855\n",
      "epoch:  15200 train_loss: 0.031931452453136444 val_loss: 0.048996374011039734\n",
      "epoch:  15300 train_loss: 0.05667107552289963 val_loss: 0.07226476818323135\n",
      "epoch:  15400 train_loss: 0.2200394570827484 val_loss: 0.29492998123168945\n",
      "epoch:  15500 train_loss: 0.2644732594490051 val_loss: 0.3308752179145813\n",
      "epoch:  15600 train_loss: 0.1722021847963333 val_loss: 0.13471868634223938\n",
      "epoch:  15700 train_loss: 0.03072579763829708 val_loss: 0.047118037939071655\n",
      "epoch:  15800 train_loss: 0.030705511569976807 val_loss: 0.047362204641103745\n",
      "epoch:  15900 train_loss: 0.07849863916635513 val_loss: 0.11447063833475113\n",
      "epoch:  16000 train_loss: 0.03060828521847725 val_loss: 0.04736340790987015\n",
      "epoch:  16100 train_loss: 0.04162777587771416 val_loss: 0.05561445280909538\n",
      "epoch:  16200 train_loss: 0.032166238874197006 val_loss: 0.04870886355638504\n",
      "epoch:  16300 train_loss: 0.16403301060199738 val_loss: 0.19477228820323944\n",
      "epoch:  16400 train_loss: 0.03168366476893425 val_loss: 0.046416524797677994\n",
      "epoch:  16500 train_loss: 0.031584884971380234 val_loss: 0.04705348610877991\n",
      "epoch:  16600 train_loss: 0.04979698732495308 val_loss: 0.059817589819431305\n",
      "epoch:  16700 train_loss: 0.0303557850420475 val_loss: 0.04681200534105301\n",
      "epoch:  16800 train_loss: 0.029919959604740143 val_loss: 0.04631023854017258\n",
      "epoch:  16900 train_loss: 0.035372816026210785 val_loss: 0.05356452986598015\n",
      "epoch:  17000 train_loss: 0.06468668580055237 val_loss: 0.08310078829526901\n",
      "epoch:  17100 train_loss: 0.03674200177192688 val_loss: 0.05300517380237579\n",
      "epoch:  17200 train_loss: 0.029629606753587723 val_loss: 0.04624422639608383\n",
      "epoch:  17300 train_loss: 0.031224802136421204 val_loss: 0.048525020480155945\n",
      "epoch:  17400 train_loss: 0.04927687719464302 val_loss: 0.0663985013961792\n",
      "epoch:  17500 train_loss: 0.07335728406906128 val_loss: 0.11504287272691727\n",
      "epoch:  17600 train_loss: 0.10189756751060486 val_loss: 0.13236509263515472\n",
      "epoch:  17700 train_loss: 0.06113750860095024 val_loss: 0.08348483592271805\n",
      "epoch:  17800 train_loss: 0.036171942949295044 val_loss: 0.048946406692266464\n",
      "epoch:  17900 train_loss: 0.14720872044563293 val_loss: 0.18410317599773407\n",
      "epoch:  18000 train_loss: 0.04424746334552765 val_loss: 0.059571195393800735\n",
      "epoch:  18100 train_loss: 0.03178158774971962 val_loss: 0.04552287608385086\n",
      "epoch:  18200 train_loss: 0.035466764122247696 val_loss: 0.05189839377999306\n",
      "epoch:  18300 train_loss: 0.030782246962189674 val_loss: 0.04931335896253586\n",
      "epoch:  18400 train_loss: 0.02997119538486004 val_loss: 0.04848025366663933\n",
      "epoch:  18500 train_loss: 0.1529521495103836 val_loss: 0.1316254585981369\n",
      "epoch:  18600 train_loss: 0.10060466080904007 val_loss: 0.16439568996429443\n",
      "epoch:  18700 train_loss: 0.16071702539920807 val_loss: 0.21815277636051178\n",
      "epoch:  18800 train_loss: 0.339253306388855 val_loss: 0.41694900393486023\n",
      "epoch:  18900 train_loss: 0.03992446884512901 val_loss: 0.055620528757572174\n",
      "epoch:  19000 train_loss: 0.029184764251112938 val_loss: 0.04553433135151863\n",
      "epoch:  19100 train_loss: 0.06623166054487228 val_loss: 0.06710708886384964\n",
      "epoch:  19200 train_loss: 0.029775572940707207 val_loss: 0.052926044911146164\n",
      "epoch:  19300 train_loss: 0.03656166419386864 val_loss: 0.056395404040813446\n",
      "epoch:  19400 train_loss: 0.11301775276660919 val_loss: 0.1437465101480484\n",
      "epoch:  19500 train_loss: 0.04099635034799576 val_loss: 0.057455308735370636\n",
      "epoch:  19600 train_loss: 0.03042597509920597 val_loss: 0.046375572681427\n",
      "epoch:  19700 train_loss: 0.030997103080153465 val_loss: 0.12015265226364136\n",
      "epoch:  19800 train_loss: 0.028753014281392097 val_loss: 0.04446187615394592\n",
      "epoch:  19900 train_loss: 0.13684464991092682 val_loss: 0.14121291041374207\n",
      "epoch:  20000 train_loss: 0.06081133335828781 val_loss: 0.07235077023506165\n",
      "epoch:  20100 train_loss: 0.028800461441278458 val_loss: 0.04377355799078941\n",
      "epoch:  20200 train_loss: 0.0361296683549881 val_loss: 0.05098475143313408\n",
      "epoch:  20300 train_loss: 0.03071235865354538 val_loss: 0.04924347996711731\n",
      "epoch:  20400 train_loss: 0.13315735757350922 val_loss: 0.1817888468503952\n",
      "epoch:  20500 train_loss: 0.08558240532875061 val_loss: 0.09267673641443253\n",
      "epoch:  20600 train_loss: 0.061324700713157654 val_loss: 0.08275792002677917\n",
      "epoch:  20700 train_loss: 0.06164294853806496 val_loss: 0.0699644610285759\n",
      "epoch:  20800 train_loss: 0.0765232965350151 val_loss: 0.06394171714782715\n",
      "epoch:  20900 train_loss: 0.03437543660402298 val_loss: 0.0553518682718277\n",
      "epoch:  21000 train_loss: 0.04255819693207741 val_loss: 0.044286709278821945\n",
      "epoch:  21100 train_loss: 0.04629926010966301 val_loss: 0.0677645280957222\n",
      "epoch:  21200 train_loss: 0.027401436120271683 val_loss: 0.04293258860707283\n",
      "epoch:  21300 train_loss: 0.11944025754928589 val_loss: 0.11094370484352112\n",
      "epoch:  21400 train_loss: 0.04577116668224335 val_loss: 0.060061752796173096\n",
      "epoch:  21500 train_loss: 0.06150750070810318 val_loss: 0.07201257348060608\n",
      "epoch:  21600 train_loss: 0.10799484699964523 val_loss: 0.13813205063343048\n",
      "epoch:  21700 train_loss: 0.029251044616103172 val_loss: 0.08187498152256012\n",
      "epoch:  21800 train_loss: 0.23820701241493225 val_loss: 0.3041699230670929\n",
      "epoch:  21900 train_loss: 0.027569903060793877 val_loss: 0.04267424717545509\n",
      "epoch:  22000 train_loss: 0.029658367857336998 val_loss: 0.044005829840898514\n",
      "epoch:  22100 train_loss: 0.14399529993534088 val_loss: 0.18445129692554474\n",
      "epoch:  22200 train_loss: 0.2481142282485962 val_loss: 0.27885282039642334\n",
      "epoch:  22300 train_loss: 0.02714516967535019 val_loss: 0.049146465957164764\n",
      "epoch:  22400 train_loss: 0.07483414560556412 val_loss: 0.08157598227262497\n",
      "epoch:  22500 train_loss: 0.047066960483789444 val_loss: 0.05727898329496384\n",
      "epoch:  22600 train_loss: 0.028383217751979828 val_loss: 0.04357607662677765\n",
      "epoch:  22700 train_loss: 0.05684143677353859 val_loss: 0.07194900512695312\n",
      "epoch:  22800 train_loss: 0.02700929157435894 val_loss: 0.04192083328962326\n",
      "epoch:  22900 train_loss: 0.8014383912086487 val_loss: 0.7917145490646362\n",
      "epoch:  23000 train_loss: 0.04730010777711868 val_loss: 0.0567447692155838\n",
      "epoch:  23100 train_loss: 0.02683134749531746 val_loss: 0.04141748324036598\n",
      "epoch:  23200 train_loss: 0.02715316042304039 val_loss: 0.04126693680882454\n",
      "epoch:  23300 train_loss: 0.07257033884525299 val_loss: 0.0950341746211052\n",
      "epoch:  23400 train_loss: 0.031192457303404808 val_loss: 0.14634943008422852\n",
      "epoch:  23500 train_loss: 0.032224394381046295 val_loss: 0.04519763961434364\n",
      "epoch:  23600 train_loss: 0.027231061831116676 val_loss: 0.041312918066978455\n",
      "epoch:  23700 train_loss: 0.02641371078789234 val_loss: 0.040731582790613174\n",
      "epoch:  23800 train_loss: 0.029275335371494293 val_loss: 0.0971384048461914\n",
      "epoch:  23900 train_loss: 0.03624960780143738 val_loss: 0.05546009913086891\n",
      "epoch:  24000 train_loss: 0.06017669662833214 val_loss: 0.10067545622587204\n",
      "epoch:  24100 train_loss: 0.11630608886480331 val_loss: 0.14634226262569427\n",
      "epoch:  24200 train_loss: 0.034750014543533325 val_loss: 0.05274844914674759\n",
      "epoch:  24300 train_loss: 0.39937394857406616 val_loss: 0.44748955965042114\n",
      "epoch:  24400 train_loss: 0.13960210978984833 val_loss: 0.06158885359764099\n",
      "epoch:  24500 train_loss: 0.030928201973438263 val_loss: 0.04826517403125763\n",
      "epoch:  24600 train_loss: 0.050585176795721054 val_loss: 0.05771998316049576\n",
      "epoch:  24700 train_loss: 0.028201472014188766 val_loss: 0.0404597707092762\n",
      "epoch:  24800 train_loss: 0.0421748012304306 val_loss: 0.06489261984825134\n",
      "epoch:  24900 train_loss: 0.025914045050740242 val_loss: 0.04016296565532684\n",
      "epoch:  25000 train_loss: 0.029510825872421265 val_loss: 0.04606833681464195\n",
      "epoch:  25100 train_loss: 0.10030879080295563 val_loss: 0.06629285961389542\n",
      "epoch:  25200 train_loss: 0.058717094361782074 val_loss: 0.0763193815946579\n",
      "epoch:  25300 train_loss: 0.03438752517104149 val_loss: 0.04743491858243942\n",
      "epoch:  25400 train_loss: 0.26586678624153137 val_loss: 0.349870890378952\n",
      "epoch:  25500 train_loss: 0.3772224485874176 val_loss: 0.26277315616607666\n",
      "epoch:  25600 train_loss: 0.08149928599596024 val_loss: 0.07348643243312836\n",
      "epoch:  25700 train_loss: 0.03108818829059601 val_loss: 0.044481076300144196\n",
      "epoch:  25800 train_loss: 0.02553943730890751 val_loss: 0.039521392434835434\n",
      "epoch:  25900 train_loss: 0.19215142726898193 val_loss: 0.20128615200519562\n",
      "epoch:  26000 train_loss: 0.03725210577249527 val_loss: 0.0508820116519928\n",
      "epoch:  26100 train_loss: 0.06460285931825638 val_loss: 0.07185843586921692\n",
      "epoch:  26200 train_loss: 0.20134186744689941 val_loss: 0.0979679748415947\n",
      "epoch:  26300 train_loss: 0.03777764365077019 val_loss: 0.048924028873443604\n",
      "epoch:  26400 train_loss: 0.0248628668487072 val_loss: 0.03894088417291641\n",
      "epoch:  26500 train_loss: 0.024994567036628723 val_loss: 0.039668165147304535\n",
      "epoch:  26600 train_loss: 0.04028826579451561 val_loss: 0.05462486296892166\n",
      "epoch:  26700 train_loss: 0.23123644292354584 val_loss: 0.13179238140583038\n",
      "epoch:  26800 train_loss: 0.08087549358606339 val_loss: 0.04962669312953949\n",
      "epoch:  26900 train_loss: 0.06258601695299149 val_loss: 0.07874356210231781\n",
      "epoch:  27000 train_loss: 0.12727804481983185 val_loss: 0.0832347497344017\n",
      "epoch:  27100 train_loss: 0.024620704352855682 val_loss: 0.03873003274202347\n",
      "epoch:  27200 train_loss: 0.055183880031108856 val_loss: 0.06796468049287796\n",
      "epoch:  27300 train_loss: 0.02699289470911026 val_loss: 0.04031883180141449\n",
      "epoch:  27400 train_loss: 0.10873370617628098 val_loss: 0.12433638423681259\n",
      "epoch:  27500 train_loss: 0.07194484770298004 val_loss: 0.10110990703105927\n",
      "epoch:  27600 train_loss: 0.041349101811647415 val_loss: 0.07309768348932266\n",
      "epoch:  27700 train_loss: 0.04318900406360626 val_loss: 0.0631118044257164\n",
      "epoch:  27800 train_loss: 0.03473212569952011 val_loss: 0.04559928551316261\n",
      "epoch:  27900 train_loss: 0.16475076973438263 val_loss: 0.2259923815727234\n",
      "epoch:  28000 train_loss: 0.176638662815094 val_loss: 0.2186640501022339\n",
      "epoch:  28100 train_loss: 0.03564199432730675 val_loss: 0.052618637681007385\n",
      "epoch:  28200 train_loss: 0.024528812617063522 val_loss: 0.03838663920760155\n",
      "epoch:  28300 train_loss: 0.07606033235788345 val_loss: 0.10622084885835648\n",
      "epoch:  28400 train_loss: 0.03317567706108093 val_loss: 0.05191648006439209\n",
      "epoch:  28500 train_loss: 0.02504226192831993 val_loss: 0.038419563323259354\n",
      "epoch:  28600 train_loss: 0.02460111863911152 val_loss: 0.038710858672857285\n",
      "epoch:  28700 train_loss: 0.030551761388778687 val_loss: 0.0435599647462368\n",
      "epoch:  28800 train_loss: 0.09838774055242538 val_loss: 0.10749895125627518\n",
      "epoch:  28900 train_loss: 0.20613685250282288 val_loss: 0.16453135013580322\n",
      "epoch:  29000 train_loss: 0.09526410698890686 val_loss: 0.07501791417598724\n",
      "epoch:  29100 train_loss: 0.117547407746315 val_loss: 0.12224576622247696\n",
      "epoch:  29200 train_loss: 0.09618894755840302 val_loss: 0.1341279000043869\n",
      "epoch:  29300 train_loss: 0.039560139179229736 val_loss: 0.05929826200008392\n",
      "epoch:  29400 train_loss: 0.10786901414394379 val_loss: 0.1355791985988617\n",
      "epoch:  29500 train_loss: 1.042972445487976 val_loss: 1.1114550828933716\n",
      "epoch:  29600 train_loss: 0.02363213151693344 val_loss: 0.03706744685769081\n",
      "epoch:  29700 train_loss: 0.025835227221250534 val_loss: 0.043310631066560745\n",
      "epoch:  29800 train_loss: 0.025615539401769638 val_loss: 0.039777569472789764\n",
      "epoch:  29900 train_loss: 0.024184828624129295 val_loss: 0.036812108010053635\n",
      "epoch:  30000 train_loss: 0.02512241341173649 val_loss: 0.03849345073103905\n",
      "epoch:  30100 train_loss: 0.12048128247261047 val_loss: 0.13585945963859558\n",
      "epoch:  30200 train_loss: 0.10422132909297943 val_loss: 0.09580419212579727\n",
      "epoch:  30300 train_loss: 0.1418871283531189 val_loss: 0.1651930809020996\n",
      "epoch:  30400 train_loss: 0.03356125205755234 val_loss: 0.044010236859321594\n",
      "epoch:  30500 train_loss: 0.044310227036476135 val_loss: 0.059895776212215424\n",
      "epoch:  30600 train_loss: 0.04269185662269592 val_loss: 0.052589356899261475\n",
      "epoch:  30700 train_loss: 0.026021016761660576 val_loss: 0.03720832243561745\n",
      "epoch:  30800 train_loss: 0.02397666685283184 val_loss: 0.03730960562825203\n",
      "epoch:  30900 train_loss: 0.05759943649172783 val_loss: 0.07741735130548477\n",
      "epoch:  31000 train_loss: 0.03150616213679314 val_loss: 0.13348129391670227\n",
      "epoch:  31100 train_loss: 0.027536867186427116 val_loss: 0.0392853207886219\n",
      "epoch:  31200 train_loss: 0.02953697368502617 val_loss: 0.039662230759859085\n",
      "epoch:  31300 train_loss: 0.05802568420767784 val_loss: 0.05822841078042984\n",
      "epoch:  31400 train_loss: 0.029795343056321144 val_loss: 0.04573393985629082\n",
      "epoch:  31500 train_loss: 0.13097578287124634 val_loss: 0.15725870430469513\n",
      "epoch:  31600 train_loss: 0.03147631511092186 val_loss: 0.04063277319073677\n",
      "epoch:  31700 train_loss: 0.04999827221035957 val_loss: 0.0500943586230278\n",
      "epoch:  31800 train_loss: 0.0420835055410862 val_loss: 0.05274469032883644\n",
      "epoch:  31900 train_loss: 0.027809347957372665 val_loss: 0.03878578171133995\n",
      "epoch:  32000 train_loss: 0.134445920586586 val_loss: 0.09050793945789337\n",
      "epoch:  32100 train_loss: 0.02649643085896969 val_loss: 0.043138403445482254\n",
      "epoch:  32200 train_loss: 0.03203798085451126 val_loss: 0.04324362799525261\n",
      "epoch:  32300 train_loss: 0.022655317559838295 val_loss: 0.035789743065834045\n",
      "epoch:  32400 train_loss: 0.04697601497173309 val_loss: 0.06992713361978531\n",
      "epoch:  32500 train_loss: 0.030352270230650902 val_loss: 0.03745068609714508\n",
      "epoch:  32600 train_loss: 0.02574605867266655 val_loss: 0.04100032523274422\n",
      "epoch:  32700 train_loss: 0.03401564806699753 val_loss: 0.042792920023202896\n",
      "epoch:  32800 train_loss: 0.023112306371331215 val_loss: 0.03634428605437279\n",
      "epoch:  32900 train_loss: 0.023121904581785202 val_loss: 0.036294758319854736\n",
      "epoch:  33000 train_loss: 0.023421334102749825 val_loss: 0.03690927475690842\n",
      "epoch:  33100 train_loss: 0.0267910398542881 val_loss: 0.04259886592626572\n",
      "epoch:  33200 train_loss: 0.02453818917274475 val_loss: 0.036469973623752594\n",
      "epoch:  33300 train_loss: 0.09576360881328583 val_loss: 0.10225176811218262\n",
      "epoch:  33400 train_loss: 0.0309755876660347 val_loss: 0.044018812477588654\n",
      "epoch:  33500 train_loss: 0.03336947783827782 val_loss: 0.04453812539577484\n",
      "epoch:  33600 train_loss: 0.022535566240549088 val_loss: 0.03522179275751114\n",
      "epoch:  33700 train_loss: 0.1666412353515625 val_loss: 0.1770334243774414\n",
      "epoch:  33800 train_loss: 0.06350816041231155 val_loss: 0.08288070559501648\n",
      "epoch:  33900 train_loss: 0.02212250418961048 val_loss: 0.03498568385839462\n",
      "epoch:  34000 train_loss: 0.041541628539562225 val_loss: 0.05362476035952568\n",
      "epoch:  34100 train_loss: 0.7694534063339233 val_loss: 0.6373163461685181\n",
      "epoch:  34200 train_loss: 0.039019327610731125 val_loss: 0.055040277540683746\n",
      "epoch:  34300 train_loss: 0.025612900033593178 val_loss: 0.03576993569731712\n",
      "epoch:  34400 train_loss: 0.051870204508304596 val_loss: 0.062709741294384\n",
      "epoch:  34500 train_loss: 0.04812421277165413 val_loss: 0.06655441224575043\n",
      "epoch:  34600 train_loss: 0.03350907191634178 val_loss: 0.04497089236974716\n",
      "epoch:  34700 train_loss: 0.02792689949274063 val_loss: 0.04127415269613266\n",
      "epoch:  34800 train_loss: 0.0806933268904686 val_loss: 0.0897938534617424\n",
      "epoch:  34900 train_loss: 0.035975757986307144 val_loss: 0.0478554405272007\n",
      "epoch:  35000 train_loss: 0.14525137841701508 val_loss: 0.15711914002895355\n",
      "epoch:  35100 train_loss: 0.025731293484568596 val_loss: 0.03880167752504349\n",
      "epoch:  35200 train_loss: 0.06286163628101349 val_loss: 0.08746487647294998\n",
      "epoch:  35300 train_loss: 0.037437450140714645 val_loss: 0.03712180256843567\n",
      "epoch:  35400 train_loss: 0.028772851452231407 val_loss: 0.04221782460808754\n",
      "epoch:  35500 train_loss: 0.022400924935936928 val_loss: 0.03413132205605507\n",
      "epoch:  35600 train_loss: 0.028683552518486977 val_loss: 0.03966885432600975\n",
      "epoch:  35700 train_loss: 0.20915886759757996 val_loss: 0.3155994415283203\n",
      "epoch:  35800 train_loss: 0.026985500007867813 val_loss: 0.041235752403736115\n",
      "epoch:  35900 train_loss: 0.023949500173330307 val_loss: 0.03641791641712189\n"
     ]
    }
   ],
   "source": [
    "# Training and Validation\n",
    "\n",
    "train_examples = train_examples.to(device)\n",
    "train_labels = train_labels.to(device)\n",
    "val_examples = val_examples.to(device)\n",
    "val_labels = val_labels.to(device)\n",
    "\n",
    "# Define the model filename for model.save()\n",
    "MODEL_FILENAME = \"best.pth\"\n",
    "\n",
    "# set model to Training mode\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "NUM_OF_EPOCH = 36000\n",
    "\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    y_pred = model(train_examples)\n",
    "    loss = loss_fn(y_pred, train_labels).cpu()\n",
    "    #print(t, loss.item())\n",
    "    train_losses.append(loss.item())\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    # BGD\n",
    "    optimizer.step()\n",
    "    \n",
    "    # evaluate validation loss\n",
    "    val_pred = model(val_examples)\n",
    "    loss = loss_fn(val_pred, val_labels)\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "    # check if we got better loss\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n",
    "\n",
    "    if (epoch % 100) == 0:\n",
    "        print(\"epoch: \", epoch, \"train_loss:\", train_losses[-1], \"val_loss:\", val_losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  tensor(0.4948, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Inference all testing examples and compute RMSE\n",
    "def square_error(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  square_error= loss_fn(a, b)\n",
    "  return square_error\n",
    "\n",
    "model.eval() # inference mode\n",
    "test_examples = test_examples.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "test_preds = model(test_examples)\n",
    "#print(\"example: \", test_example.cpu())\n",
    "#print(\"========================================\")\n",
    "#print(\"ground_truth:\", test_label.cpu())\n",
    "#print(\"prediction:\", test_pred.cpu())\n",
    "#print(\"========================================\")\n",
    "\n",
    "\n",
    "total_errors = 0.0\n",
    "for idx in range(len(test_examples)):\n",
    "    total_errors += square_error(test_preds[idx], test_labels[idx])\n",
    "    \n",
    "RMSE = torch.sqrt(total_errors / len(test_examples))\n",
    "print(\"RMSE: \",  RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigma = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ganerate the dataset\n",
    "i = 0\n",
    "sigma = 1.0\n",
    "my_dataset = []\n",
    "for ud in UDs:\n",
    "    example = []\n",
    "    for an in ANs:\n",
    "        noise = np.random.normal(0,sigma)\n",
    "        # 0 is mean\n",
    "        # sigma is the deviation of the normal distribution\n",
    "        d = compute_3d_distance(ud, an) + noise\n",
    "        example.append(d)\n",
    "    \n",
    "    # append x, y, z as col#10, #11, #12\n",
    "    example.append(ud[0])\n",
    "    example.append(ud[1])\n",
    "    example.append(ud[2])\n",
    "    \n",
    "    # append 1x13 example row into my_dataset\n",
    "    my_dataset.append(example)  # expected to be 3000x13  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffle = True!\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "exercise3_dataset = Exercise3Dataset(list_dataset = my_dataset, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset by 0.8: 0.1: 0.1\n",
    "train_examples, train_labels = exercise3_dataset[:int(3000*0.8)]  # (2400, 10)   # (2400, 3)\n",
    "val_examples, val_labels = exercise3_dataset[int(3000*0.8):int(3000*0.9)]    # (300, 10)   #(300, 3)\n",
    "test_examples, test_labels = exercise3_dataset[int(3000*0.9):]     #(300, 10)   # (300, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Define model, loss function and optimizer\n",
    "# if we have GPU, then use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define model\n",
    "model = Net(x_dim = train_examples.shape[1], y_dim = train_labels.shape[1]).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 train_loss: 7320.72900390625 val_loss: 7524.54345703125\n",
      "epoch:  100 train_loss: 118.86067962646484 val_loss: 110.64767456054688\n",
      "epoch:  200 train_loss: 109.67786407470703 val_loss: 102.15619659423828\n",
      "epoch:  300 train_loss: 76.98458862304688 val_loss: 72.491943359375\n",
      "epoch:  400 train_loss: 44.54806137084961 val_loss: 44.55549240112305\n",
      "epoch:  500 train_loss: 27.646541595458984 val_loss: 28.02521324157715\n",
      "epoch:  600 train_loss: 4.567259311676025 val_loss: 5.065883159637451\n",
      "epoch:  700 train_loss: 4.093167304992676 val_loss: 4.578505516052246\n",
      "epoch:  800 train_loss: 3.82961106300354 val_loss: 4.2971343994140625\n",
      "epoch:  900 train_loss: 3.638265609741211 val_loss: 4.103249549865723\n",
      "epoch:  1000 train_loss: 3.48352313041687 val_loss: 3.946786642074585\n",
      "epoch:  1100 train_loss: 3.347551107406616 val_loss: 3.8118631839752197\n",
      "epoch:  1200 train_loss: 3.2234935760498047 val_loss: 3.6872923374176025\n",
      "epoch:  1300 train_loss: 3.1082851886749268 val_loss: 3.5673484802246094\n",
      "epoch:  1400 train_loss: 2.9975597858428955 val_loss: 3.4540750980377197\n",
      "epoch:  1500 train_loss: 2.8938310146331787 val_loss: 3.348951578140259\n",
      "epoch:  1600 train_loss: 2.7898948192596436 val_loss: 3.234858512878418\n",
      "epoch:  1700 train_loss: 2.6833128929138184 val_loss: 3.1158642768859863\n",
      "epoch:  1800 train_loss: 2.574021100997925 val_loss: 2.999805212020874\n",
      "epoch:  1900 train_loss: 2.462677478790283 val_loss: 2.8752214908599854\n",
      "epoch:  2000 train_loss: 2.3451921939849854 val_loss: 2.75250244140625\n",
      "epoch:  2100 train_loss: 2.2211873531341553 val_loss: 2.61645770072937\n",
      "epoch:  2200 train_loss: 2.0911898612976074 val_loss: 2.472622871398926\n",
      "epoch:  2300 train_loss: 1.9543026685714722 val_loss: 2.3188228607177734\n",
      "epoch:  2400 train_loss: 1.8088549375534058 val_loss: 2.1613316535949707\n",
      "epoch:  2500 train_loss: 1.6539030075073242 val_loss: 1.9956140518188477\n",
      "epoch:  2600 train_loss: 1.492254376411438 val_loss: 1.8189407587051392\n",
      "epoch:  2700 train_loss: 1.330727219581604 val_loss: 1.66708505153656\n",
      "epoch:  2800 train_loss: 1.1678221225738525 val_loss: 1.4786109924316406\n",
      "epoch:  2900 train_loss: 1.0390182733535767 val_loss: 1.314241886138916\n",
      "epoch:  3000 train_loss: 0.913937509059906 val_loss: 1.1711385250091553\n",
      "epoch:  3100 train_loss: 0.8170041441917419 val_loss: 1.051554560661316\n",
      "epoch:  3200 train_loss: 0.7448661923408508 val_loss: 0.9563426375389099\n",
      "epoch:  3300 train_loss: 0.6878267526626587 val_loss: 0.8897397518157959\n",
      "epoch:  3400 train_loss: 0.6398379802703857 val_loss: 0.8237382173538208\n",
      "epoch:  3500 train_loss: 0.5969177484512329 val_loss: 0.7678536772727966\n",
      "epoch:  3600 train_loss: 0.5922173261642456 val_loss: 0.7423030734062195\n",
      "epoch:  3700 train_loss: 0.5463992953300476 val_loss: 0.688169002532959\n",
      "epoch:  3800 train_loss: 0.5298284888267517 val_loss: 0.6689537167549133\n",
      "epoch:  3900 train_loss: 0.583747923374176 val_loss: 0.7336931824684143\n",
      "epoch:  4000 train_loss: 0.5233913064002991 val_loss: 0.6223734021186829\n",
      "epoch:  4100 train_loss: 0.4834747314453125 val_loss: 0.5872918963432312\n",
      "epoch:  4200 train_loss: 0.47241654992103577 val_loss: 0.5649423003196716\n",
      "epoch:  4300 train_loss: 0.4613058567047119 val_loss: 0.5587078332901001\n",
      "epoch:  4400 train_loss: 0.45280635356903076 val_loss: 0.5422841310501099\n",
      "epoch:  4500 train_loss: 0.5361934900283813 val_loss: 0.748132050037384\n",
      "epoch:  4600 train_loss: 0.44187140464782715 val_loss: 0.5221971273422241\n",
      "epoch:  4700 train_loss: 0.4332502782344818 val_loss: 0.5166105031967163\n",
      "epoch:  4800 train_loss: 0.6095590591430664 val_loss: 0.7990389466285706\n",
      "epoch:  4900 train_loss: 0.4244210720062256 val_loss: 0.5065167546272278\n",
      "epoch:  5000 train_loss: 0.978691816329956 val_loss: 0.8998356461524963\n",
      "epoch:  5100 train_loss: 0.41409069299697876 val_loss: 0.4907474219799042\n",
      "epoch:  5200 train_loss: 0.4497101604938507 val_loss: 0.5344794988632202\n",
      "epoch:  5300 train_loss: 0.4073472321033478 val_loss: 0.487490177154541\n",
      "epoch:  5400 train_loss: 0.42261916399002075 val_loss: 0.5170406103134155\n",
      "epoch:  5500 train_loss: 0.4006495177745819 val_loss: 0.47745397686958313\n",
      "epoch:  5600 train_loss: 0.48583653569221497 val_loss: 0.5604883432388306\n",
      "epoch:  5700 train_loss: 0.7867397665977478 val_loss: 0.9123461842536926\n",
      "epoch:  5800 train_loss: 0.40685003995895386 val_loss: 0.48198366165161133\n",
      "epoch:  5900 train_loss: 0.3993823230266571 val_loss: 0.4641248285770416\n",
      "epoch:  6000 train_loss: 0.4151526093482971 val_loss: 0.47483617067337036\n",
      "epoch:  6100 train_loss: 0.4032266139984131 val_loss: 0.45768260955810547\n",
      "epoch:  6200 train_loss: 0.38219311833381653 val_loss: 0.4500671625137329\n",
      "epoch:  6300 train_loss: 0.8381801843643188 val_loss: 0.8227031826972961\n",
      "epoch:  6400 train_loss: 0.7009323835372925 val_loss: 0.7876770496368408\n",
      "epoch:  6500 train_loss: 0.37866729497909546 val_loss: 0.4509279429912567\n",
      "epoch:  6600 train_loss: 0.3753812313079834 val_loss: 0.43870723247528076\n",
      "epoch:  6700 train_loss: 0.4202837646007538 val_loss: 0.5098108649253845\n",
      "epoch:  6800 train_loss: 0.3857426047325134 val_loss: 0.44976967573165894\n",
      "epoch:  6900 train_loss: 0.3690803349018097 val_loss: 0.432388037443161\n",
      "epoch:  7000 train_loss: 0.37253493070602417 val_loss: 0.44653016328811646\n",
      "epoch:  7100 train_loss: 0.3896714150905609 val_loss: 0.44277018308639526\n",
      "epoch:  7200 train_loss: 0.40153658390045166 val_loss: 0.47819146513938904\n",
      "epoch:  7300 train_loss: 0.36174526810646057 val_loss: 0.42350101470947266\n",
      "epoch:  7400 train_loss: 0.37042346596717834 val_loss: 0.44200941920280457\n",
      "epoch:  7500 train_loss: 0.36999809741973877 val_loss: 0.4331628382205963\n",
      "epoch:  7600 train_loss: 0.612908661365509 val_loss: 0.5140413045883179\n",
      "epoch:  7700 train_loss: 1.0129337310791016 val_loss: 1.1773996353149414\n",
      "epoch:  7800 train_loss: 0.6794191598892212 val_loss: 0.8545618653297424\n",
      "epoch:  7900 train_loss: 0.8611090779304504 val_loss: 0.6309843063354492\n",
      "epoch:  8000 train_loss: 0.35230058431625366 val_loss: 0.41496992111206055\n",
      "epoch:  8100 train_loss: 0.3507906198501587 val_loss: 0.41091713309288025\n",
      "epoch:  8200 train_loss: 0.9937111139297485 val_loss: 1.1663777828216553\n",
      "epoch:  8300 train_loss: 0.3522509038448334 val_loss: 0.42072898149490356\n",
      "epoch:  8400 train_loss: 0.3677183985710144 val_loss: 0.4190123379230499\n",
      "epoch:  8500 train_loss: 0.3628304898738861 val_loss: 0.45304107666015625\n",
      "epoch:  8600 train_loss: 0.3467487394809723 val_loss: 0.41120558977127075\n",
      "epoch:  8700 train_loss: 0.46481215953826904 val_loss: 0.4693049490451813\n",
      "epoch:  8800 train_loss: 0.3721162974834442 val_loss: 0.46206605434417725\n",
      "epoch:  8900 train_loss: 0.340694397687912 val_loss: 0.3975413143634796\n",
      "epoch:  9000 train_loss: 0.39911675453186035 val_loss: 0.42680853605270386\n",
      "epoch:  9100 train_loss: 0.37848833203315735 val_loss: 0.4499630928039551\n",
      "epoch:  9200 train_loss: 0.3536016047000885 val_loss: 0.3969411849975586\n",
      "epoch:  9300 train_loss: 0.4356931746006012 val_loss: 0.4422057569026947\n",
      "epoch:  9400 train_loss: 0.3543115556240082 val_loss: 0.40687042474746704\n",
      "epoch:  9500 train_loss: 0.4550054967403412 val_loss: 0.5984519720077515\n",
      "epoch:  9600 train_loss: 0.3329119384288788 val_loss: 0.3921760618686676\n",
      "epoch:  9700 train_loss: 0.35227468609809875 val_loss: 0.3942480683326721\n",
      "epoch:  9800 train_loss: 0.34462985396385193 val_loss: 0.39355307817459106\n",
      "epoch:  9900 train_loss: 0.34248223900794983 val_loss: 0.40927886962890625\n",
      "epoch:  10000 train_loss: 0.438043475151062 val_loss: 0.5552181005477905\n",
      "epoch:  10100 train_loss: 0.3266097903251648 val_loss: 0.3848579227924347\n",
      "epoch:  10200 train_loss: 0.3325824439525604 val_loss: 0.39784300327301025\n",
      "epoch:  10300 train_loss: 0.42203864455223083 val_loss: 0.45110785961151123\n",
      "epoch:  10400 train_loss: 0.3229326009750366 val_loss: 0.3808883726596832\n",
      "epoch:  10500 train_loss: 0.3465837240219116 val_loss: 0.40006664395332336\n",
      "epoch:  10600 train_loss: 0.3547598123550415 val_loss: 0.4096866846084595\n",
      "epoch:  10700 train_loss: 0.3563087284564972 val_loss: 0.44690725207328796\n",
      "epoch:  10800 train_loss: 0.3326147496700287 val_loss: 0.3833205997943878\n",
      "epoch:  10900 train_loss: 0.32427552342414856 val_loss: 0.3784976005554199\n",
      "epoch:  11000 train_loss: 0.3460555672645569 val_loss: 0.40539634227752686\n",
      "epoch:  11100 train_loss: 0.3430318832397461 val_loss: 0.37946659326553345\n",
      "epoch:  11200 train_loss: 0.4063023328781128 val_loss: 0.46568062901496887\n",
      "epoch:  11300 train_loss: 0.31575578451156616 val_loss: 0.3782823979854584\n",
      "epoch:  11400 train_loss: 0.5149950385093689 val_loss: 0.5260569453239441\n",
      "epoch:  11500 train_loss: 0.4610412120819092 val_loss: 0.5512814521789551\n",
      "epoch:  11600 train_loss: 0.31137388944625854 val_loss: 0.37106046080589294\n",
      "epoch:  11700 train_loss: 0.3677404522895813 val_loss: 0.41034626960754395\n",
      "epoch:  11800 train_loss: 0.32354894280433655 val_loss: 0.40754544734954834\n",
      "epoch:  11900 train_loss: 0.308152437210083 val_loss: 0.37017130851745605\n",
      "epoch:  12000 train_loss: 0.4269159734249115 val_loss: 0.5529873967170715\n",
      "epoch:  12100 train_loss: 0.3339267373085022 val_loss: 0.423922061920166\n",
      "epoch:  12200 train_loss: 0.30735692381858826 val_loss: 0.3688182234764099\n",
      "epoch:  12300 train_loss: 0.30485740303993225 val_loss: 0.36583206057548523\n",
      "epoch:  12400 train_loss: 0.30262506008148193 val_loss: 0.36865243315696716\n",
      "epoch:  12500 train_loss: 0.3912883996963501 val_loss: 0.5256602168083191\n",
      "epoch:  12600 train_loss: 0.36655354499816895 val_loss: 0.41268664598464966\n",
      "epoch:  12700 train_loss: 0.39493176341056824 val_loss: 0.5305272936820984\n",
      "epoch:  12800 train_loss: 0.4329964220523834 val_loss: 0.4555404484272003\n",
      "epoch:  12900 train_loss: 0.4838384985923767 val_loss: 0.5896823406219482\n",
      "epoch:  13000 train_loss: 0.3551413416862488 val_loss: 0.4244789481163025\n",
      "epoch:  13100 train_loss: 0.49096184968948364 val_loss: 0.6953604817390442\n",
      "epoch:  13200 train_loss: 0.29329827427864075 val_loss: 0.3645516037940979\n",
      "epoch:  13300 train_loss: 0.29536280035972595 val_loss: 0.36356037855148315\n",
      "epoch:  13400 train_loss: 0.2910248637199402 val_loss: 0.3622319996356964\n",
      "epoch:  13500 train_loss: 0.2920598089694977 val_loss: 0.370877206325531\n",
      "epoch:  13600 train_loss: 0.3622726500034332 val_loss: 0.43787795305252075\n",
      "epoch:  13700 train_loss: 0.2896975576877594 val_loss: 0.3741467595100403\n",
      "epoch:  13800 train_loss: 0.4753894805908203 val_loss: 0.5417566895484924\n",
      "epoch:  13900 train_loss: 0.3533869981765747 val_loss: 0.41301429271698\n",
      "epoch:  14000 train_loss: 0.4059978127479553 val_loss: 0.4601082503795624\n",
      "epoch:  14100 train_loss: 0.3349583148956299 val_loss: 0.45441263914108276\n",
      "epoch:  14200 train_loss: 0.3516544997692108 val_loss: 0.4542207419872284\n",
      "epoch:  14300 train_loss: 0.7329350113868713 val_loss: 0.3869321048259735\n",
      "epoch:  14400 train_loss: 0.2823520302772522 val_loss: 0.362405002117157\n",
      "epoch:  14500 train_loss: 0.32167819142341614 val_loss: 0.4204135537147522\n",
      "epoch:  14600 train_loss: 0.28071358799934387 val_loss: 0.36019107699394226\n",
      "epoch:  14700 train_loss: 0.2842888832092285 val_loss: 0.36962297558784485\n",
      "epoch:  14800 train_loss: 0.27900639176368713 val_loss: 0.3623114228248596\n",
      "epoch:  14900 train_loss: 0.29326605796813965 val_loss: 0.36288878321647644\n",
      "epoch:  15000 train_loss: 0.2772321403026581 val_loss: 0.3580467700958252\n",
      "epoch:  15100 train_loss: 0.2789804935455322 val_loss: 0.3564561605453491\n",
      "epoch:  15200 train_loss: 0.2854987382888794 val_loss: 0.35641205310821533\n",
      "epoch:  15300 train_loss: 0.295760840177536 val_loss: 0.3913417458534241\n",
      "epoch:  15400 train_loss: 0.27434560656547546 val_loss: 0.3539477288722992\n",
      "epoch:  15500 train_loss: 0.3477080762386322 val_loss: 0.44499853253364563\n",
      "epoch:  15600 train_loss: 0.4263930022716522 val_loss: 0.5733450055122375\n",
      "epoch:  15700 train_loss: 0.35930734872817993 val_loss: 0.4213027358055115\n",
      "epoch:  15800 train_loss: 0.2729092240333557 val_loss: 0.36140328645706177\n",
      "epoch:  15900 train_loss: 0.2691749036312103 val_loss: 0.35410475730895996\n",
      "epoch:  16000 train_loss: 0.40819594264030457 val_loss: 0.5905761122703552\n",
      "epoch:  16100 train_loss: 0.27862611413002014 val_loss: 0.361739844083786\n",
      "epoch:  16200 train_loss: 0.29573866724967957 val_loss: 0.3908882141113281\n",
      "epoch:  16300 train_loss: 0.2810903787612915 val_loss: 0.36347582936286926\n",
      "epoch:  16400 train_loss: 0.44088807702064514 val_loss: 0.4905279576778412\n",
      "epoch:  16500 train_loss: 0.2825990915298462 val_loss: 0.366710901260376\n",
      "epoch:  16600 train_loss: 0.34428146481513977 val_loss: 0.43381959199905396\n",
      "epoch:  16700 train_loss: 0.2646372318267822 val_loss: 0.3563833236694336\n",
      "epoch:  16800 train_loss: 0.6543771624565125 val_loss: 0.7415056824684143\n",
      "epoch:  16900 train_loss: 0.272688090801239 val_loss: 0.3639560043811798\n",
      "epoch:  17000 train_loss: 0.2734260857105255 val_loss: 0.36186251044273376\n",
      "epoch:  17100 train_loss: 0.27699437737464905 val_loss: 0.371162086725235\n",
      "epoch:  17200 train_loss: 0.26970118284225464 val_loss: 0.3738829493522644\n",
      "epoch:  17300 train_loss: 0.27339738607406616 val_loss: 0.37757644057273865\n",
      "epoch:  17400 train_loss: 0.34059977531433105 val_loss: 0.43636801838874817\n",
      "epoch:  17500 train_loss: 0.25921937823295593 val_loss: 0.35475146770477295\n",
      "epoch:  17600 train_loss: 0.26561424136161804 val_loss: 0.37535977363586426\n",
      "epoch:  17700 train_loss: 0.36106738448143005 val_loss: 0.38185128569602966\n",
      "epoch:  17800 train_loss: 0.274299293756485 val_loss: 0.37666836380958557\n",
      "epoch:  17900 train_loss: 0.25662457942962646 val_loss: 0.3485315442085266\n",
      "epoch:  18000 train_loss: 0.25713852047920227 val_loss: 0.3508684039115906\n",
      "epoch:  18100 train_loss: 0.5023221969604492 val_loss: 0.5889260172843933\n",
      "epoch:  18200 train_loss: 0.28057268261909485 val_loss: 0.37468913197517395\n",
      "epoch:  18300 train_loss: 0.3318829834461212 val_loss: 0.41945940256118774\n",
      "epoch:  18400 train_loss: 0.32409173250198364 val_loss: 0.40478116273880005\n",
      "epoch:  18500 train_loss: 0.2762971520423889 val_loss: 0.3796018362045288\n",
      "epoch:  18600 train_loss: 0.3125400245189667 val_loss: 0.42019379138946533\n",
      "epoch:  18700 train_loss: 0.2971036732196808 val_loss: 0.3742598593235016\n",
      "epoch:  18800 train_loss: 0.2954888343811035 val_loss: 0.3783332109451294\n",
      "epoch:  18900 train_loss: 0.32436829805374146 val_loss: 0.39102232456207275\n",
      "epoch:  19000 train_loss: 0.511125922203064 val_loss: 0.6680483818054199\n",
      "epoch:  19100 train_loss: 0.29624274373054504 val_loss: 0.3945317268371582\n",
      "epoch:  19200 train_loss: 0.3096449077129364 val_loss: 0.3966067135334015\n",
      "epoch:  19300 train_loss: 0.2568909823894501 val_loss: 0.3545529246330261\n",
      "epoch:  19400 train_loss: 0.25387853384017944 val_loss: 0.3570214509963989\n",
      "epoch:  19500 train_loss: 0.3243959844112396 val_loss: 0.4552362859249115\n",
      "epoch:  19600 train_loss: 0.3330840468406677 val_loss: 0.48117756843566895\n",
      "epoch:  19700 train_loss: 0.4210309684276581 val_loss: 0.5492606163024902\n",
      "epoch:  19800 train_loss: 0.2648886442184448 val_loss: 0.3582151234149933\n",
      "epoch:  19900 train_loss: 0.2819488048553467 val_loss: 0.3729722797870636\n",
      "epoch:  20000 train_loss: 0.24508574604988098 val_loss: 0.35349366068840027\n",
      "epoch:  20100 train_loss: 0.2939693033695221 val_loss: 0.40962743759155273\n",
      "epoch:  20200 train_loss: 0.2662491202354431 val_loss: 0.39629507064819336\n",
      "epoch:  20300 train_loss: 0.27412623167037964 val_loss: 0.36904385685920715\n",
      "epoch:  20400 train_loss: 0.2527509927749634 val_loss: 0.3555043041706085\n",
      "epoch:  20500 train_loss: 0.30562838912010193 val_loss: 0.3979455232620239\n",
      "epoch:  20600 train_loss: 0.26814892888069153 val_loss: 0.3577662706375122\n",
      "epoch:  20700 train_loss: 0.344735324382782 val_loss: 0.4422283172607422\n",
      "epoch:  20800 train_loss: 0.2432778924703598 val_loss: 0.34750258922576904\n",
      "epoch:  20900 train_loss: 0.3271581530570984 val_loss: 0.42086297273635864\n",
      "epoch:  21000 train_loss: 0.24741220474243164 val_loss: 0.3478171229362488\n",
      "epoch:  21100 train_loss: 0.3051789700984955 val_loss: 0.42004963755607605\n",
      "epoch:  21200 train_loss: 0.2407470941543579 val_loss: 0.356062114238739\n",
      "epoch:  21300 train_loss: 0.25608813762664795 val_loss: 0.34901463985443115\n",
      "epoch:  21400 train_loss: 0.7119485139846802 val_loss: 0.887884259223938\n",
      "epoch:  21500 train_loss: 0.24053461849689484 val_loss: 0.3576947748661041\n",
      "epoch:  21600 train_loss: 0.2973347008228302 val_loss: 0.411943644285202\n",
      "epoch:  21700 train_loss: 0.24606812000274658 val_loss: 0.35627081990242004\n",
      "epoch:  21800 train_loss: 0.29635030031204224 val_loss: 0.44161346554756165\n",
      "epoch:  21900 train_loss: 0.23841054737567902 val_loss: 0.3520490825176239\n",
      "epoch:  22000 train_loss: 0.2369682490825653 val_loss: 0.36060255765914917\n",
      "epoch:  22100 train_loss: 0.23978154361248016 val_loss: 0.34953662753105164\n",
      "epoch:  22200 train_loss: 0.29603785276412964 val_loss: 0.42252516746520996\n",
      "epoch:  22300 train_loss: 0.2666492760181427 val_loss: 0.38795503973960876\n",
      "epoch:  22400 train_loss: 0.3512926697731018 val_loss: 0.43912529945373535\n",
      "epoch:  22500 train_loss: 0.3050718307495117 val_loss: 0.4628247916698456\n",
      "epoch:  22600 train_loss: 0.2549697160720825 val_loss: 0.3754633367061615\n",
      "epoch:  22700 train_loss: 0.23331642150878906 val_loss: 0.3499048054218292\n",
      "epoch:  22800 train_loss: 0.23657824099063873 val_loss: 0.3579029142856598\n",
      "epoch:  22900 train_loss: 0.23491981625556946 val_loss: 0.34564754366874695\n",
      "epoch:  23000 train_loss: 0.276953786611557 val_loss: 0.3842822313308716\n",
      "epoch:  23100 train_loss: 0.27056336402893066 val_loss: 0.3899531364440918\n",
      "epoch:  23200 train_loss: 0.2593829035758972 val_loss: 0.3652328848838806\n",
      "epoch:  23300 train_loss: 0.23381328582763672 val_loss: 0.35457584261894226\n",
      "epoch:  23400 train_loss: 0.2579535245895386 val_loss: 0.3816092908382416\n",
      "epoch:  23500 train_loss: 0.5484372973442078 val_loss: 0.49716663360595703\n",
      "epoch:  23600 train_loss: 0.2395017445087433 val_loss: 0.36246222257614136\n",
      "epoch:  23700 train_loss: 0.2501605749130249 val_loss: 0.3596424162387848\n",
      "epoch:  23800 train_loss: 0.47226861119270325 val_loss: 0.6472358107566833\n",
      "epoch:  23900 train_loss: 0.24260708689689636 val_loss: 0.377973735332489\n",
      "epoch:  24000 train_loss: 0.29046210646629333 val_loss: 0.4045012295246124\n",
      "epoch:  24100 train_loss: 0.3853176534175873 val_loss: 0.4928310215473175\n",
      "epoch:  24200 train_loss: 0.32806307077407837 val_loss: 0.48489880561828613\n",
      "epoch:  24300 train_loss: 0.2925022542476654 val_loss: 0.4104275703430176\n",
      "epoch:  24400 train_loss: 0.2933669984340668 val_loss: 0.4318230152130127\n",
      "epoch:  24500 train_loss: 0.22829262912273407 val_loss: 0.34953105449676514\n",
      "epoch:  24600 train_loss: 0.24227645993232727 val_loss: 0.3479875326156616\n",
      "epoch:  24700 train_loss: 0.2835768759250641 val_loss: 0.40210816264152527\n",
      "epoch:  24800 train_loss: 0.2446485161781311 val_loss: 0.3591659963130951\n",
      "epoch:  24900 train_loss: 0.22854645550251007 val_loss: 0.35482922196388245\n",
      "epoch:  25000 train_loss: 0.22866863012313843 val_loss: 0.34994110465049744\n",
      "epoch:  25100 train_loss: 0.253530353307724 val_loss: 0.38233235478401184\n",
      "epoch:  25200 train_loss: 0.2541670799255371 val_loss: 0.3868845999240875\n",
      "epoch:  25300 train_loss: 0.22741571068763733 val_loss: 0.34632548689842224\n",
      "epoch:  25400 train_loss: 0.9490959048271179 val_loss: 0.986985981464386\n",
      "epoch:  25500 train_loss: 0.2604140341281891 val_loss: 0.39072510600090027\n",
      "epoch:  25600 train_loss: 0.25161558389663696 val_loss: 0.4151681959629059\n",
      "epoch:  25700 train_loss: 0.22707384824752808 val_loss: 0.35128024220466614\n",
      "epoch:  25800 train_loss: 0.23029474914073944 val_loss: 0.35377368330955505\n",
      "epoch:  25900 train_loss: 0.23330377042293549 val_loss: 0.3532954454421997\n",
      "epoch:  26000 train_loss: 0.4544770121574402 val_loss: 0.5770384669303894\n",
      "epoch:  26100 train_loss: 0.2415747493505478 val_loss: 0.36941537261009216\n",
      "epoch:  26200 train_loss: 0.25210192799568176 val_loss: 0.38725411891937256\n",
      "epoch:  26300 train_loss: 0.2288404107093811 val_loss: 0.3465319275856018\n",
      "epoch:  26400 train_loss: 0.28200259804725647 val_loss: 0.4344825744628906\n",
      "epoch:  26500 train_loss: 0.5191695094108582 val_loss: 0.45719870924949646\n",
      "epoch:  26600 train_loss: 0.22949571907520294 val_loss: 0.3678477704524994\n",
      "epoch:  26700 train_loss: 0.23407401144504547 val_loss: 0.3761991560459137\n",
      "epoch:  26800 train_loss: 0.2284887135028839 val_loss: 0.3638926148414612\n",
      "epoch:  26900 train_loss: 0.2168893814086914 val_loss: 0.3451465666294098\n",
      "epoch:  27000 train_loss: 0.2174881398677826 val_loss: 0.34303179383277893\n",
      "epoch:  27100 train_loss: 0.21721911430358887 val_loss: 0.3446297347545624\n",
      "epoch:  27200 train_loss: 0.2888455390930176 val_loss: 0.39361506700515747\n",
      "epoch:  27300 train_loss: 0.2169351875782013 val_loss: 0.34800174832344055\n",
      "epoch:  27400 train_loss: 0.41759082674980164 val_loss: 0.6052627563476562\n",
      "epoch:  27500 train_loss: 0.2644177973270416 val_loss: 0.37650710344314575\n",
      "epoch:  27600 train_loss: 0.22830654680728912 val_loss: 0.3646611273288727\n",
      "epoch:  27700 train_loss: 0.45754921436309814 val_loss: 0.5825386643409729\n",
      "epoch:  27800 train_loss: 0.23525062203407288 val_loss: 0.3845056891441345\n",
      "epoch:  27900 train_loss: 0.2334926575422287 val_loss: 0.34382879734039307\n",
      "epoch:  28000 train_loss: 0.23217026889324188 val_loss: 0.3767116367816925\n",
      "epoch:  28100 train_loss: 0.2579371929168701 val_loss: 0.42999422550201416\n",
      "epoch:  28200 train_loss: 0.24351738393306732 val_loss: 0.3873079717159271\n",
      "epoch:  28300 train_loss: 0.24852049350738525 val_loss: 0.36373159289360046\n",
      "epoch:  28400 train_loss: 0.2142995297908783 val_loss: 0.34336569905281067\n",
      "epoch:  28500 train_loss: 0.2691270709037781 val_loss: 0.3915320634841919\n",
      "epoch:  28600 train_loss: 0.21632076799869537 val_loss: 0.34730082750320435\n",
      "epoch:  28700 train_loss: 0.6961303353309631 val_loss: 0.9792991280555725\n",
      "epoch:  28800 train_loss: 0.3093155324459076 val_loss: 0.41598019003868103\n",
      "epoch:  28900 train_loss: 0.3610430359840393 val_loss: 0.5107061266899109\n",
      "epoch:  29000 train_loss: 0.23309247195720673 val_loss: 0.3602634072303772\n",
      "epoch:  29100 train_loss: 0.2700863778591156 val_loss: 0.416530579328537\n",
      "epoch:  29200 train_loss: 0.23959152400493622 val_loss: 0.34794366359710693\n",
      "epoch:  29300 train_loss: 0.21330347657203674 val_loss: 0.35140877962112427\n",
      "epoch:  29400 train_loss: 0.23217235505580902 val_loss: 0.3611210584640503\n",
      "epoch:  29500 train_loss: 0.32796144485473633 val_loss: 0.43964484333992004\n",
      "epoch:  29600 train_loss: 0.2537693977355957 val_loss: 0.3865818381309509\n",
      "epoch:  29700 train_loss: 0.22937577962875366 val_loss: 0.3648030459880829\n",
      "epoch:  29800 train_loss: 0.24244628846645355 val_loss: 0.37427762150764465\n",
      "epoch:  29900 train_loss: 0.3104338049888611 val_loss: 0.44343462586402893\n",
      "epoch:  30000 train_loss: 0.2559404969215393 val_loss: 0.38597771525382996\n",
      "epoch:  30100 train_loss: 0.27801787853240967 val_loss: 0.49783453345298767\n",
      "epoch:  30200 train_loss: 0.23930247128009796 val_loss: 0.3810735046863556\n",
      "epoch:  30300 train_loss: 0.29410967230796814 val_loss: 0.38692131638526917\n",
      "epoch:  30400 train_loss: 0.646424412727356 val_loss: 0.4632173776626587\n",
      "epoch:  30500 train_loss: 0.2576194405555725 val_loss: 0.4180096387863159\n",
      "epoch:  30600 train_loss: 0.21127238869667053 val_loss: 0.3419102132320404\n",
      "epoch:  30700 train_loss: 0.2527531385421753 val_loss: 0.4105677604675293\n",
      "epoch:  30800 train_loss: 0.24727702140808105 val_loss: 0.4189430773258209\n",
      "epoch:  30900 train_loss: 0.26206010580062866 val_loss: 0.4170369505882263\n",
      "epoch:  31000 train_loss: 0.2154725044965744 val_loss: 0.35179755091667175\n",
      "epoch:  31100 train_loss: 0.2119465321302414 val_loss: 0.3479539752006531\n",
      "epoch:  31200 train_loss: 0.21753014624118805 val_loss: 0.3674869239330292\n",
      "epoch:  31300 train_loss: 0.22900424897670746 val_loss: 0.365313857793808\n",
      "epoch:  31400 train_loss: 0.24050273001194 val_loss: 0.3946407735347748\n",
      "epoch:  31500 train_loss: 0.22397589683532715 val_loss: 0.3980812132358551\n",
      "epoch:  31600 train_loss: 0.30689677596092224 val_loss: 0.5223040580749512\n",
      "epoch:  31700 train_loss: 0.20768477022647858 val_loss: 0.34533101320266724\n",
      "epoch:  31800 train_loss: 0.23898757994174957 val_loss: 0.3961832821369171\n",
      "epoch:  31900 train_loss: 0.20298795402050018 val_loss: 0.343302845954895\n",
      "epoch:  32000 train_loss: 0.21002286672592163 val_loss: 0.3594230115413666\n",
      "epoch:  32100 train_loss: 0.2036948800086975 val_loss: 0.34214505553245544\n",
      "epoch:  32200 train_loss: 0.20960162580013275 val_loss: 0.34669479727745056\n",
      "epoch:  32300 train_loss: 0.20281477272510529 val_loss: 0.3497665822505951\n",
      "epoch:  32400 train_loss: 0.22762471437454224 val_loss: 0.35438817739486694\n",
      "epoch:  32500 train_loss: 0.218340665102005 val_loss: 0.36941441893577576\n",
      "epoch:  32600 train_loss: 0.24129708111286163 val_loss: 0.34895122051239014\n",
      "epoch:  32700 train_loss: 0.20300057530403137 val_loss: 0.34695130586624146\n",
      "epoch:  32800 train_loss: 0.2046508491039276 val_loss: 0.34003424644470215\n",
      "epoch:  32900 train_loss: 0.21808107197284698 val_loss: 0.36038702726364136\n",
      "epoch:  33000 train_loss: 0.23416322469711304 val_loss: 0.3851062059402466\n",
      "epoch:  33100 train_loss: 0.20914548635482788 val_loss: 0.34643417596817017\n",
      "epoch:  33200 train_loss: 0.28972339630126953 val_loss: 0.4310007095336914\n",
      "epoch:  33300 train_loss: 0.2115512192249298 val_loss: 0.3514997661113739\n",
      "epoch:  33400 train_loss: 0.20561394095420837 val_loss: 0.3449103832244873\n",
      "epoch:  33500 train_loss: 0.2053299993276596 val_loss: 0.35301095247268677\n",
      "epoch:  33600 train_loss: 0.31287941336631775 val_loss: 0.4957750141620636\n",
      "epoch:  33700 train_loss: 0.21652483940124512 val_loss: 0.36290767788887024\n",
      "epoch:  33800 train_loss: 0.20450204610824585 val_loss: 0.3519399166107178\n",
      "epoch:  33900 train_loss: 0.2191222757101059 val_loss: 0.35062065720558167\n",
      "epoch:  34000 train_loss: 0.20026114583015442 val_loss: 0.3431229591369629\n",
      "epoch:  34100 train_loss: 0.19970160722732544 val_loss: 0.3460414707660675\n",
      "epoch:  34200 train_loss: 0.35286712646484375 val_loss: 0.6791790127754211\n",
      "epoch:  34300 train_loss: 0.26108983159065247 val_loss: 0.42249542474746704\n",
      "epoch:  34400 train_loss: 0.2547067701816559 val_loss: 0.408638596534729\n",
      "epoch:  34500 train_loss: 0.20437026023864746 val_loss: 0.35858771204948425\n",
      "epoch:  34600 train_loss: 0.2209593802690506 val_loss: 0.359401673078537\n",
      "epoch:  34700 train_loss: 0.2718389928340912 val_loss: 0.3947395980358124\n",
      "epoch:  34800 train_loss: 0.23162953555583954 val_loss: 0.40945008397102356\n",
      "epoch:  34900 train_loss: 0.2784183621406555 val_loss: 0.41628754138946533\n",
      "epoch:  35000 train_loss: 0.2946614623069763 val_loss: 0.45097291469573975\n",
      "epoch:  35100 train_loss: 0.2811012268066406 val_loss: 0.4177015721797943\n",
      "epoch:  35200 train_loss: 0.23936815559864044 val_loss: 0.40564900636672974\n",
      "epoch:  35300 train_loss: 0.336819589138031 val_loss: 0.45801618695259094\n",
      "epoch:  35400 train_loss: 0.2151440531015396 val_loss: 0.38290005922317505\n",
      "epoch:  35500 train_loss: 0.21559540927410126 val_loss: 0.36058831214904785\n",
      "epoch:  35600 train_loss: 0.19577236473560333 val_loss: 0.34938132762908936\n",
      "epoch:  35700 train_loss: 0.20435109734535217 val_loss: 0.3653786778450012\n",
      "epoch:  35800 train_loss: 0.23530103266239166 val_loss: 0.4033953547477722\n",
      "epoch:  35900 train_loss: 0.20039837062358856 val_loss: 0.3563600182533264\n"
     ]
    }
   ],
   "source": [
    "# Training and Validation\n",
    "\n",
    "train_examples = train_examples.to(device)\n",
    "train_labels = train_labels.to(device)\n",
    "val_examples = val_examples.to(device)\n",
    "val_labels = val_labels.to(device)\n",
    "\n",
    "# Define the model filename for model.save()\n",
    "MODEL_FILENAME = \"best.pth\"\n",
    "\n",
    "# set model to Training mode\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "NUM_OF_EPOCH = 36000\n",
    "\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    y_pred = model(train_examples)\n",
    "    loss = loss_fn(y_pred, train_labels).cpu()\n",
    "    #print(t, loss.item())\n",
    "    train_losses.append(loss.item())\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    # BGD\n",
    "    optimizer.step()\n",
    "    \n",
    "    # evaluate validation loss\n",
    "    val_pred = model(val_examples)\n",
    "    loss = loss_fn(val_pred, val_labels)\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "    # check if we got better loss\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n",
    "\n",
    "    if (epoch % 100) == 0:\n",
    "        print(\"epoch: \", epoch, \"train_loss:\", train_losses[-1], \"val_loss:\", val_losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  tensor(1.0454, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Inference all testing examples and compute RMSE\n",
    "def square_error(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  square_error= loss_fn(a, b)\n",
    "  return square_error\n",
    "\n",
    "model.eval() # inference mode\n",
    "test_examples = test_examples.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "test_preds = model(test_examples)\n",
    "#print(\"example: \", test_example.cpu())\n",
    "#print(\"========================================\")\n",
    "#print(\"ground_truth:\", test_label.cpu())\n",
    "#print(\"prediction:\", test_pred.cpu())\n",
    "#print(\"========================================\")\n",
    "\n",
    "\n",
    "total_errors = 0.0\n",
    "for idx in range(len(test_examples)):\n",
    "    total_errors += square_error(test_preds[idx], test_labels[idx])\n",
    "    \n",
    "RMSE = torch.sqrt(total_errors / len(test_examples))\n",
    "print(\"RMSE: \",  RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigma = 1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffle = True!\n",
      "epoch:  0 train_loss: 7329.3896484375 val_loss: 7419.66162109375\n",
      "epoch:  100 train_loss: 122.33960723876953 val_loss: 126.6779556274414\n",
      "epoch:  200 train_loss: 112.08967590332031 val_loss: 115.8821792602539\n",
      "epoch:  300 train_loss: 72.34053039550781 val_loss: 77.26819610595703\n",
      "epoch:  400 train_loss: 42.99835968017578 val_loss: 48.25032424926758\n",
      "epoch:  500 train_loss: 10.257807731628418 val_loss: 11.816949844360352\n",
      "epoch:  600 train_loss: 8.656679153442383 val_loss: 10.144126892089844\n",
      "epoch:  700 train_loss: 6.485163688659668 val_loss: 7.425844192504883\n",
      "epoch:  800 train_loss: 4.611273765563965 val_loss: 5.1042046546936035\n",
      "epoch:  900 train_loss: 3.340815544128418 val_loss: 3.6192009449005127\n",
      "epoch:  1000 train_loss: 2.565657138824463 val_loss: 2.6827499866485596\n",
      "epoch:  1100 train_loss: 2.16878342628479 val_loss: 2.2528598308563232\n",
      "epoch:  1200 train_loss: 1.943928837776184 val_loss: 1.9891771078109741\n",
      "epoch:  1300 train_loss: 1.802475929260254 val_loss: 1.8337936401367188\n",
      "epoch:  1400 train_loss: 1.7374651432037354 val_loss: 1.7675670385360718\n",
      "epoch:  1500 train_loss: 1.6394957304000854 val_loss: 1.6586116552352905\n",
      "epoch:  1600 train_loss: 1.5843223333358765 val_loss: 1.598919153213501\n",
      "epoch:  1700 train_loss: 1.5616329908370972 val_loss: 1.6224398612976074\n",
      "epoch:  1800 train_loss: 1.5045452117919922 val_loss: 1.5418184995651245\n",
      "epoch:  1900 train_loss: 1.4765501022338867 val_loss: 1.5106455087661743\n",
      "epoch:  2000 train_loss: 1.5541181564331055 val_loss: 1.5713051557540894\n",
      "epoch:  2100 train_loss: 1.4979726076126099 val_loss: 1.594687581062317\n",
      "epoch:  2200 train_loss: 1.4034252166748047 val_loss: 1.452915906906128\n",
      "epoch:  2300 train_loss: 1.3874439001083374 val_loss: 1.4340307712554932\n",
      "epoch:  2400 train_loss: 1.4297488927841187 val_loss: 1.4909032583236694\n",
      "epoch:  2500 train_loss: 1.368628740310669 val_loss: 1.404845952987671\n",
      "epoch:  2600 train_loss: 1.3503919839859009 val_loss: 1.3914636373519897\n",
      "epoch:  2700 train_loss: 1.3253812789916992 val_loss: 1.3715486526489258\n",
      "epoch:  2800 train_loss: 1.6395161151885986 val_loss: 1.7218104600906372\n",
      "epoch:  2900 train_loss: 1.441422462463379 val_loss: 1.4930356740951538\n",
      "epoch:  3000 train_loss: 1.299458622932434 val_loss: 1.325351357460022\n",
      "epoch:  3100 train_loss: 1.6029175519943237 val_loss: 1.62330162525177\n",
      "epoch:  3200 train_loss: 1.4661962985992432 val_loss: 1.5786534547805786\n",
      "epoch:  3300 train_loss: 1.2961329221725464 val_loss: 1.3392573595046997\n",
      "epoch:  3400 train_loss: 1.5987008810043335 val_loss: 1.7034627199172974\n",
      "epoch:  3500 train_loss: 1.3115136623382568 val_loss: 1.3936859369277954\n",
      "epoch:  3600 train_loss: 1.4232174158096313 val_loss: 1.4911229610443115\n",
      "epoch:  3700 train_loss: 1.296761393547058 val_loss: 1.306911826133728\n",
      "epoch:  3800 train_loss: 1.2479174137115479 val_loss: 1.278079867362976\n",
      "epoch:  3900 train_loss: 1.2222964763641357 val_loss: 1.266916036605835\n",
      "epoch:  4000 train_loss: 1.437015414237976 val_loss: 1.422644853591919\n",
      "epoch:  4100 train_loss: 1.2124078273773193 val_loss: 1.2491748332977295\n",
      "epoch:  4200 train_loss: 1.2221225500106812 val_loss: 1.2868376970291138\n",
      "epoch:  4300 train_loss: 1.1987255811691284 val_loss: 1.2423887252807617\n",
      "epoch:  4400 train_loss: 1.3745942115783691 val_loss: 1.4596154689788818\n",
      "epoch:  4500 train_loss: 1.190829873085022 val_loss: 1.2400333881378174\n",
      "epoch:  4600 train_loss: 1.1911295652389526 val_loss: 1.2606600522994995\n",
      "epoch:  4700 train_loss: 1.4918609857559204 val_loss: 1.5738474130630493\n",
      "epoch:  4800 train_loss: 1.2070293426513672 val_loss: 1.2245638370513916\n",
      "epoch:  4900 train_loss: 1.1717416048049927 val_loss: 1.214611530303955\n",
      "epoch:  5000 train_loss: 1.1650362014770508 val_loss: 1.2144149541854858\n",
      "epoch:  5100 train_loss: 1.1654630899429321 val_loss: 1.2276667356491089\n",
      "epoch:  5200 train_loss: 1.1581637859344482 val_loss: 1.2082691192626953\n",
      "epoch:  5300 train_loss: 1.1724647283554077 val_loss: 1.2278192043304443\n",
      "epoch:  5400 train_loss: 1.1841328144073486 val_loss: 1.2182825803756714\n",
      "epoch:  5500 train_loss: 1.14456045627594 val_loss: 1.1991337537765503\n",
      "epoch:  5600 train_loss: 1.2780452966690063 val_loss: 1.4679741859436035\n",
      "epoch:  5700 train_loss: 2.2601726055145264 val_loss: 2.0261096954345703\n",
      "epoch:  5800 train_loss: 1.133996844291687 val_loss: 1.202208161354065\n",
      "epoch:  5900 train_loss: 1.1410726308822632 val_loss: 1.1921188831329346\n",
      "epoch:  6000 train_loss: 2.876016855239868 val_loss: 1.9437177181243896\n",
      "epoch:  6100 train_loss: 1.1216179132461548 val_loss: 1.1859302520751953\n",
      "epoch:  6200 train_loss: 1.1173361539840698 val_loss: 1.1861391067504883\n",
      "epoch:  6300 train_loss: 1.1747143268585205 val_loss: 1.2101953029632568\n",
      "epoch:  6400 train_loss: 1.1095263957977295 val_loss: 1.1856673955917358\n",
      "epoch:  6500 train_loss: 1.106567621231079 val_loss: 1.183991551399231\n",
      "epoch:  6600 train_loss: 1.1127519607543945 val_loss: 2.125498056411743\n",
      "epoch:  6700 train_loss: 1.099623680114746 val_loss: 1.1803464889526367\n",
      "epoch:  6800 train_loss: 1.1990225315093994 val_loss: 1.3296175003051758\n",
      "epoch:  6900 train_loss: 1.1060346364974976 val_loss: 1.1844946146011353\n",
      "epoch:  7000 train_loss: 1.1342579126358032 val_loss: 1.2381116151809692\n",
      "epoch:  7100 train_loss: 1.0856515169143677 val_loss: 1.1780232191085815\n",
      "epoch:  7200 train_loss: 1.0891474485397339 val_loss: 1.1875858306884766\n",
      "epoch:  7300 train_loss: 1.0904289484024048 val_loss: 1.193992018699646\n",
      "epoch:  7400 train_loss: 1.1011998653411865 val_loss: 1.180548071861267\n",
      "epoch:  7500 train_loss: 1.0734386444091797 val_loss: 1.1716879606246948\n",
      "epoch:  7600 train_loss: 1.126913070678711 val_loss: 1.190466046333313\n",
      "epoch:  7700 train_loss: 1.0729990005493164 val_loss: 1.1766303777694702\n",
      "epoch:  7800 train_loss: 1.753011703491211 val_loss: 1.7175509929656982\n",
      "epoch:  7900 train_loss: 1.0631948709487915 val_loss: 1.1676994562149048\n",
      "epoch:  8000 train_loss: 1.0602827072143555 val_loss: 1.167014718055725\n",
      "epoch:  8100 train_loss: 1.0651512145996094 val_loss: 1.1739729642868042\n",
      "epoch:  8200 train_loss: 1.0551881790161133 val_loss: 1.1706018447875977\n",
      "epoch:  8300 train_loss: 1.0732922554016113 val_loss: 1.1749975681304932\n",
      "epoch:  8400 train_loss: 1.050740122795105 val_loss: 1.1807644367218018\n",
      "epoch:  8500 train_loss: 3.690239191055298 val_loss: 4.011659622192383\n",
      "epoch:  8600 train_loss: 1.0452804565429688 val_loss: 1.164277195930481\n",
      "epoch:  8700 train_loss: 1.0961737632751465 val_loss: 1.1803960800170898\n",
      "epoch:  8800 train_loss: 1.1605620384216309 val_loss: 1.4226394891738892\n",
      "epoch:  8900 train_loss: 1.0481963157653809 val_loss: 1.179795742034912\n",
      "epoch:  9000 train_loss: 1.0350255966186523 val_loss: 1.1632343530654907\n",
      "epoch:  9100 train_loss: 1.0343506336212158 val_loss: 1.1624188423156738\n",
      "epoch:  9200 train_loss: 1.0318751335144043 val_loss: 1.1604896783828735\n",
      "epoch:  9300 train_loss: 1.0380243062973022 val_loss: 1.18613600730896\n",
      "epoch:  9400 train_loss: 1.0355112552642822 val_loss: 1.1745953559875488\n",
      "epoch:  9500 train_loss: 1.024908423423767 val_loss: 1.1616127490997314\n",
      "epoch:  9600 train_loss: 1.0257890224456787 val_loss: 1.1603496074676514\n",
      "epoch:  9700 train_loss: 1.0315942764282227 val_loss: 1.1651287078857422\n",
      "epoch:  9800 train_loss: 1.165128231048584 val_loss: 1.2302628755569458\n",
      "epoch:  9900 train_loss: 1.0154842138290405 val_loss: 1.1597661972045898\n",
      "epoch:  10000 train_loss: 1.0912610292434692 val_loss: 1.2813972234725952\n",
      "epoch:  10100 train_loss: 1.0418578386306763 val_loss: 1.2029492855072021\n",
      "epoch:  10200 train_loss: 1.2056039571762085 val_loss: 1.4360408782958984\n",
      "epoch:  10300 train_loss: 1.1724638938903809 val_loss: 1.3203684091567993\n",
      "epoch:  10400 train_loss: 1.0085772275924683 val_loss: 1.1556955575942993\n",
      "epoch:  10500 train_loss: 1.0022484064102173 val_loss: 1.1603591442108154\n",
      "epoch:  10600 train_loss: 1.00447678565979 val_loss: 1.1562740802764893\n",
      "epoch:  10700 train_loss: 1.5790812969207764 val_loss: 1.5511982440948486\n",
      "epoch:  10800 train_loss: 0.9972336888313293 val_loss: 1.177202582359314\n",
      "epoch:  10900 train_loss: 2.628830671310425 val_loss: 2.9828267097473145\n",
      "epoch:  11000 train_loss: 0.9920920133590698 val_loss: 1.1592706441879272\n",
      "epoch:  11100 train_loss: 1.0521266460418701 val_loss: 1.1710206270217896\n",
      "epoch:  11200 train_loss: 0.9879570603370667 val_loss: 1.154697299003601\n",
      "epoch:  11300 train_loss: 0.9854030609130859 val_loss: 1.1540662050247192\n",
      "epoch:  11400 train_loss: 0.9912446737289429 val_loss: 1.1621325016021729\n",
      "epoch:  11500 train_loss: 0.98188316822052 val_loss: 1.159134030342102\n",
      "epoch:  11600 train_loss: 0.9916239380836487 val_loss: 1.1716078519821167\n",
      "epoch:  11700 train_loss: 1.175905704498291 val_loss: 1.4936472177505493\n",
      "epoch:  11800 train_loss: 0.9736995100975037 val_loss: 1.1622282266616821\n",
      "epoch:  11900 train_loss: 0.9741544127464294 val_loss: 1.1605219841003418\n",
      "epoch:  12000 train_loss: 0.9994786977767944 val_loss: 1.2282710075378418\n",
      "epoch:  12100 train_loss: 1.041709065437317 val_loss: 1.2302782535552979\n",
      "epoch:  12200 train_loss: 0.9896213412284851 val_loss: 1.2151644229888916\n",
      "epoch:  12300 train_loss: 0.9631551504135132 val_loss: 1.1625301837921143\n",
      "epoch:  12400 train_loss: 0.96452397108078 val_loss: 1.174257516860962\n",
      "epoch:  12500 train_loss: 0.9590352773666382 val_loss: 1.164196491241455\n",
      "epoch:  12600 train_loss: 0.9645782709121704 val_loss: 1.1655921936035156\n",
      "epoch:  12700 train_loss: 1.053420901298523 val_loss: 1.3072307109832764\n",
      "epoch:  12800 train_loss: 0.9757020473480225 val_loss: 1.1880027055740356\n",
      "epoch:  12900 train_loss: 0.9630823135375977 val_loss: 1.1677478551864624\n",
      "epoch:  13000 train_loss: 1.1571590900421143 val_loss: 1.5658711194992065\n",
      "epoch:  13100 train_loss: 0.9564242362976074 val_loss: 1.1700109243392944\n",
      "epoch:  13200 train_loss: 1.042540431022644 val_loss: 1.2648695707321167\n",
      "epoch:  13300 train_loss: 0.9470177292823792 val_loss: 1.1670949459075928\n",
      "epoch:  13400 train_loss: 0.9781784415245056 val_loss: 1.2028557062149048\n",
      "epoch:  13500 train_loss: 0.9495365619659424 val_loss: 1.176293134689331\n",
      "epoch:  13600 train_loss: 1.3093093633651733 val_loss: 1.5051765441894531\n",
      "epoch:  13700 train_loss: 1.0182887315750122 val_loss: 1.2336013317108154\n",
      "epoch:  13800 train_loss: 0.9347142577171326 val_loss: 1.1756733655929565\n",
      "epoch:  13900 train_loss: 1.005936622619629 val_loss: 1.263809084892273\n",
      "epoch:  14000 train_loss: 0.9297798871994019 val_loss: 1.166479229927063\n",
      "epoch:  14100 train_loss: 0.9265928864479065 val_loss: 1.1676044464111328\n",
      "epoch:  14200 train_loss: 1.0413225889205933 val_loss: 1.3137093782424927\n",
      "epoch:  14300 train_loss: 0.9286693334579468 val_loss: 1.1720187664031982\n",
      "epoch:  14400 train_loss: 0.9503887295722961 val_loss: 1.1932480335235596\n",
      "epoch:  14500 train_loss: 0.9165066480636597 val_loss: 1.169132113456726\n",
      "epoch:  14600 train_loss: 0.9143991470336914 val_loss: 1.1672579050064087\n",
      "epoch:  14700 train_loss: 0.9121941924095154 val_loss: 1.168624997138977\n",
      "epoch:  14800 train_loss: 0.9106921553611755 val_loss: 1.1676665544509888\n",
      "epoch:  14900 train_loss: 0.9900485873222351 val_loss: 1.2488718032836914\n",
      "epoch:  15000 train_loss: 0.9307466745376587 val_loss: 1.1947863101959229\n",
      "epoch:  15100 train_loss: 0.9033730030059814 val_loss: 1.1850261688232422\n",
      "epoch:  15200 train_loss: 0.9375548362731934 val_loss: 1.1991798877716064\n",
      "epoch:  15300 train_loss: 0.9016412496566772 val_loss: 1.178818702697754\n",
      "epoch:  15400 train_loss: 0.9728775024414062 val_loss: 1.2878198623657227\n",
      "epoch:  15500 train_loss: 0.8930471539497375 val_loss: 1.1797631978988647\n",
      "epoch:  15600 train_loss: 1.1084445714950562 val_loss: 1.4802271127700806\n",
      "epoch:  15700 train_loss: 1.021010398864746 val_loss: 1.3434128761291504\n",
      "epoch:  15800 train_loss: 1.1929762363433838 val_loss: 1.5524731874465942\n",
      "epoch:  15900 train_loss: 1.040879726409912 val_loss: 1.4053250551223755\n",
      "epoch:  16000 train_loss: 0.8969470262527466 val_loss: 1.1851885318756104\n",
      "epoch:  16100 train_loss: 0.8850311040878296 val_loss: 1.2014473676681519\n",
      "epoch:  16200 train_loss: 1.0006643533706665 val_loss: 1.3486846685409546\n",
      "epoch:  16300 train_loss: 0.9050632119178772 val_loss: 1.1961588859558105\n",
      "epoch:  16400 train_loss: 0.9536371827125549 val_loss: 1.2731640338897705\n",
      "epoch:  16500 train_loss: 1.0634853839874268 val_loss: 1.4344019889831543\n",
      "epoch:  16600 train_loss: 1.0471961498260498 val_loss: 1.336506962776184\n",
      "epoch:  16700 train_loss: 1.2523133754730225 val_loss: 1.778676152229309\n",
      "epoch:  16800 train_loss: 1.2364393472671509 val_loss: 1.6485778093338013\n",
      "epoch:  16900 train_loss: 0.9979984760284424 val_loss: 1.3364216089248657\n",
      "epoch:  17000 train_loss: 0.8790826797485352 val_loss: 1.215186357498169\n",
      "epoch:  17100 train_loss: 0.8535311222076416 val_loss: 1.194235920906067\n",
      "epoch:  17200 train_loss: 2.0048422813415527 val_loss: 2.5487802028656006\n",
      "epoch:  17300 train_loss: 0.9214328527450562 val_loss: 1.2699151039123535\n",
      "epoch:  17400 train_loss: 0.9133443236351013 val_loss: 1.2481646537780762\n",
      "epoch:  17500 train_loss: 0.8575279712677002 val_loss: 1.2030690908432007\n",
      "epoch:  17600 train_loss: 0.8568006753921509 val_loss: 1.2097822427749634\n",
      "epoch:  17700 train_loss: 0.9928723573684692 val_loss: 1.3727854490280151\n",
      "epoch:  17800 train_loss: 0.8724142909049988 val_loss: 1.2217191457748413\n",
      "epoch:  17900 train_loss: 0.8349437713623047 val_loss: 1.2065823078155518\n",
      "epoch:  18000 train_loss: 0.8431065082550049 val_loss: 1.2167679071426392\n",
      "epoch:  18100 train_loss: 0.830987274646759 val_loss: 1.2089881896972656\n",
      "epoch:  18200 train_loss: 0.8311658501625061 val_loss: 1.230911135673523\n",
      "epoch:  18300 train_loss: 0.8374886512756348 val_loss: 1.2261552810668945\n",
      "epoch:  18400 train_loss: 0.870475172996521 val_loss: 1.2496318817138672\n",
      "epoch:  18500 train_loss: 1.139644980430603 val_loss: 1.5145097970962524\n",
      "epoch:  18600 train_loss: 0.9670178294181824 val_loss: 1.2644355297088623\n",
      "epoch:  18700 train_loss: 0.8670586943626404 val_loss: 1.2807395458221436\n",
      "epoch:  18800 train_loss: 0.8214020729064941 val_loss: 1.2422828674316406\n",
      "epoch:  18900 train_loss: 0.8944934010505676 val_loss: 1.324828028678894\n",
      "epoch:  19000 train_loss: 0.8148627877235413 val_loss: 1.2237234115600586\n",
      "epoch:  19100 train_loss: 0.9670358896255493 val_loss: 1.4446308612823486\n",
      "epoch:  19200 train_loss: 0.8086947202682495 val_loss: 1.2288243770599365\n",
      "epoch:  19300 train_loss: 0.8379176259040833 val_loss: 1.2695578336715698\n",
      "epoch:  19400 train_loss: 0.974883496761322 val_loss: 1.3961231708526611\n",
      "epoch:  19500 train_loss: 0.8358447551727295 val_loss: 1.2590419054031372\n",
      "epoch:  19600 train_loss: 0.8055965304374695 val_loss: 1.249169945716858\n",
      "epoch:  19700 train_loss: 0.7935137748718262 val_loss: 1.2358667850494385\n",
      "epoch:  19800 train_loss: 0.8056107759475708 val_loss: 1.25783371925354\n",
      "epoch:  19900 train_loss: 0.898307740688324 val_loss: 1.3557275533676147\n",
      "epoch:  20000 train_loss: 2.145746946334839 val_loss: 2.09857177734375\n",
      "epoch:  20100 train_loss: 0.7857963442802429 val_loss: 1.2369648218154907\n",
      "epoch:  20200 train_loss: 0.8259980082511902 val_loss: 1.3034756183624268\n",
      "epoch:  20300 train_loss: 0.8339267373085022 val_loss: 1.2676117420196533\n",
      "epoch:  20400 train_loss: 0.8466805815696716 val_loss: 1.3003852367401123\n",
      "epoch:  20500 train_loss: 0.911204993724823 val_loss: 1.4479444026947021\n",
      "epoch:  20600 train_loss: 0.9407039880752563 val_loss: 1.4782099723815918\n",
      "epoch:  20700 train_loss: 0.7826600670814514 val_loss: 1.2502880096435547\n",
      "epoch:  20800 train_loss: 0.8262833952903748 val_loss: 1.279894232749939\n",
      "epoch:  20900 train_loss: 0.7737101316452026 val_loss: 1.2556757926940918\n",
      "epoch:  21000 train_loss: 0.771464467048645 val_loss: 1.2638561725616455\n",
      "epoch:  21100 train_loss: 0.783052921295166 val_loss: 1.2662972211837769\n",
      "epoch:  21200 train_loss: 0.7661844491958618 val_loss: 1.2571930885314941\n",
      "epoch:  21300 train_loss: 0.7732731699943542 val_loss: 1.263073205947876\n",
      "epoch:  21400 train_loss: 0.7615686058998108 val_loss: 1.2571113109588623\n",
      "epoch:  21500 train_loss: 0.8277050852775574 val_loss: 1.297271728515625\n",
      "epoch:  21600 train_loss: 0.7723519206047058 val_loss: 1.2684940099716187\n",
      "epoch:  21700 train_loss: 0.762745201587677 val_loss: 1.2701458930969238\n",
      "epoch:  21800 train_loss: 0.7993971705436707 val_loss: 1.3330230712890625\n",
      "epoch:  21900 train_loss: 0.8305270671844482 val_loss: 1.3322361707687378\n",
      "epoch:  22000 train_loss: 0.7558123469352722 val_loss: 1.270247459411621\n",
      "epoch:  22100 train_loss: 0.760416567325592 val_loss: 1.2697792053222656\n",
      "epoch:  22200 train_loss: 0.7536535859107971 val_loss: 1.273056983947754\n",
      "epoch:  22300 train_loss: 0.7448616623878479 val_loss: 1.274112582206726\n",
      "epoch:  22400 train_loss: 0.7725237011909485 val_loss: 1.4050687551498413\n",
      "epoch:  22500 train_loss: 0.7661939263343811 val_loss: 1.311044454574585\n",
      "epoch:  22600 train_loss: 0.7523162364959717 val_loss: 1.2949668169021606\n",
      "epoch:  22700 train_loss: 3.237687826156616 val_loss: 4.045159339904785\n",
      "epoch:  22800 train_loss: 0.7389851808547974 val_loss: 1.2853550910949707\n",
      "epoch:  22900 train_loss: 0.7772883176803589 val_loss: 1.3347361087799072\n",
      "epoch:  23000 train_loss: 0.7486569285392761 val_loss: 1.295459508895874\n",
      "epoch:  23100 train_loss: 0.7519130110740662 val_loss: 1.3118122816085815\n",
      "epoch:  23200 train_loss: 0.7406390309333801 val_loss: 1.2954474687576294\n",
      "epoch:  23300 train_loss: 0.7721647620201111 val_loss: 1.2944951057434082\n",
      "epoch:  23400 train_loss: 0.7437669634819031 val_loss: 1.2958550453186035\n",
      "epoch:  23500 train_loss: 0.8078795075416565 val_loss: 1.4038877487182617\n",
      "epoch:  23600 train_loss: 0.7527403831481934 val_loss: 1.3129420280456543\n",
      "epoch:  23700 train_loss: 0.75555419921875 val_loss: 1.3410221338272095\n",
      "epoch:  23800 train_loss: 0.7547698020935059 val_loss: 1.3220441341400146\n",
      "epoch:  23900 train_loss: 0.7402895092964172 val_loss: 1.3233639001846313\n",
      "epoch:  24000 train_loss: 0.7510921359062195 val_loss: 1.319029450416565\n",
      "epoch:  24100 train_loss: 0.7301249504089355 val_loss: 1.3107081651687622\n",
      "epoch:  24200 train_loss: 0.7259253859519958 val_loss: 1.3154853582382202\n",
      "epoch:  24300 train_loss: 0.8807240724563599 val_loss: 1.4754549264907837\n",
      "epoch:  24400 train_loss: 1.123533010482788 val_loss: 1.4519654512405396\n",
      "epoch:  24500 train_loss: 0.7797722816467285 val_loss: 1.3420692682266235\n",
      "epoch:  24600 train_loss: 0.8819910287857056 val_loss: 1.4765427112579346\n",
      "epoch:  24700 train_loss: 1.6037256717681885 val_loss: 2.4813461303710938\n",
      "epoch:  24800 train_loss: 0.77946537733078 val_loss: 1.361750602722168\n",
      "epoch:  24900 train_loss: 1.6787878274917603 val_loss: 1.8232336044311523\n",
      "epoch:  25000 train_loss: 0.7094621062278748 val_loss: 1.3146417140960693\n",
      "epoch:  25100 train_loss: 0.8414955139160156 val_loss: 1.4268330335617065\n",
      "epoch:  25200 train_loss: 0.7171924710273743 val_loss: 1.3148555755615234\n",
      "epoch:  25300 train_loss: 0.7162070274353027 val_loss: 1.3250164985656738\n",
      "epoch:  25400 train_loss: 0.8176422715187073 val_loss: 1.364561915397644\n",
      "epoch:  25500 train_loss: 0.8174220323562622 val_loss: 1.3926587104797363\n",
      "epoch:  25600 train_loss: 0.711566150188446 val_loss: 1.321643352508545\n",
      "epoch:  25700 train_loss: 1.5116604566574097 val_loss: 1.9374938011169434\n",
      "epoch:  25800 train_loss: 0.7796399593353271 val_loss: 1.3753623962402344\n",
      "epoch:  25900 train_loss: 0.7466093301773071 val_loss: 1.372312068939209\n",
      "epoch:  26000 train_loss: 0.7433211207389832 val_loss: 1.4041165113449097\n",
      "epoch:  26100 train_loss: 0.7250925302505493 val_loss: 1.3520711660385132\n",
      "epoch:  26200 train_loss: 0.7012519240379333 val_loss: 1.3303463459014893\n",
      "epoch:  26300 train_loss: 0.7049621939659119 val_loss: 1.3373295068740845\n",
      "epoch:  26400 train_loss: 0.7140150666236877 val_loss: 1.3376688957214355\n",
      "epoch:  26500 train_loss: 0.7704442143440247 val_loss: 1.3845809698104858\n",
      "epoch:  26600 train_loss: 0.7751030921936035 val_loss: 1.4289565086364746\n",
      "epoch:  26700 train_loss: 0.7086280584335327 val_loss: 1.365290641784668\n",
      "epoch:  26800 train_loss: 0.8341577053070068 val_loss: 1.565214991569519\n",
      "epoch:  26900 train_loss: 0.8488215208053589 val_loss: 1.5239369869232178\n",
      "epoch:  27000 train_loss: 0.7029406428337097 val_loss: 1.3382940292358398\n",
      "epoch:  27100 train_loss: 0.8073580861091614 val_loss: 1.4524099826812744\n",
      "epoch:  27200 train_loss: 1.0513166189193726 val_loss: 1.8535373210906982\n",
      "epoch:  27300 train_loss: 0.6955816149711609 val_loss: 1.3621853590011597\n",
      "epoch:  27400 train_loss: 0.6969071626663208 val_loss: 1.370742917060852\n",
      "epoch:  27500 train_loss: 0.7116979360580444 val_loss: 1.3876343965530396\n",
      "epoch:  27600 train_loss: 0.6974461674690247 val_loss: 1.3588327169418335\n",
      "epoch:  27700 train_loss: 0.7154907584190369 val_loss: 1.3770215511322021\n",
      "epoch:  27800 train_loss: 0.8357431292533875 val_loss: 1.4877099990844727\n",
      "epoch:  27900 train_loss: 0.6996621489524841 val_loss: 1.3801298141479492\n",
      "epoch:  28000 train_loss: 0.7003728151321411 val_loss: 1.3899731636047363\n",
      "epoch:  28100 train_loss: 0.7122541666030884 val_loss: 1.410995602607727\n",
      "epoch:  28200 train_loss: 0.8696139454841614 val_loss: 1.5006811618804932\n",
      "epoch:  28300 train_loss: 0.9140587449073792 val_loss: 1.657103180885315\n",
      "epoch:  28400 train_loss: 0.749230682849884 val_loss: 1.4232959747314453\n",
      "epoch:  28500 train_loss: 0.6951963305473328 val_loss: 1.411885380744934\n",
      "epoch:  28600 train_loss: 0.6900333762168884 val_loss: 1.406209111213684\n",
      "epoch:  28700 train_loss: 0.705839991569519 val_loss: 1.4181792736053467\n",
      "epoch:  28800 train_loss: 0.9470649361610413 val_loss: 1.6575493812561035\n",
      "epoch:  28900 train_loss: 0.8594828248023987 val_loss: 1.5596923828125\n",
      "epoch:  29000 train_loss: 0.6727213859558105 val_loss: 1.4006474018096924\n",
      "epoch:  29100 train_loss: 0.7576817870140076 val_loss: 1.4505813121795654\n",
      "epoch:  29200 train_loss: 0.6905704140663147 val_loss: 1.3818082809448242\n",
      "epoch:  29300 train_loss: 0.672667384147644 val_loss: 1.381926417350769\n",
      "epoch:  29400 train_loss: 0.6600489020347595 val_loss: 1.3787928819656372\n",
      "epoch:  29500 train_loss: 0.6984419226646423 val_loss: 1.4157688617706299\n",
      "epoch:  29600 train_loss: 0.7484521865844727 val_loss: 1.4685256481170654\n",
      "epoch:  29700 train_loss: 0.7761764526367188 val_loss: 1.5410698652267456\n",
      "epoch:  29800 train_loss: 0.6889522075653076 val_loss: 1.4566394090652466\n",
      "epoch:  29900 train_loss: 0.6771559119224548 val_loss: 1.43343186378479\n",
      "epoch:  30000 train_loss: 0.6606168746948242 val_loss: 1.3979628086090088\n",
      "epoch:  30100 train_loss: 0.7286286950111389 val_loss: 1.4615768194198608\n",
      "epoch:  30200 train_loss: 0.6790297031402588 val_loss: 1.4321956634521484\n",
      "epoch:  30300 train_loss: 0.7105785012245178 val_loss: 1.4470828771591187\n",
      "epoch:  30400 train_loss: 0.7138144373893738 val_loss: 1.4513564109802246\n",
      "epoch:  30500 train_loss: 0.8168942332267761 val_loss: 1.5986976623535156\n",
      "epoch:  30600 train_loss: 0.7488132119178772 val_loss: 1.5385416746139526\n",
      "epoch:  30700 train_loss: 0.666508138179779 val_loss: 1.4233388900756836\n",
      "epoch:  30800 train_loss: 0.6557833552360535 val_loss: 1.4055838584899902\n",
      "epoch:  30900 train_loss: 0.6519494652748108 val_loss: 1.4104479551315308\n",
      "epoch:  31000 train_loss: 0.666599690914154 val_loss: 1.41810142993927\n",
      "epoch:  31100 train_loss: 0.6589735150337219 val_loss: 1.4324877262115479\n",
      "epoch:  31200 train_loss: 0.6640760898590088 val_loss: 1.4208837747573853\n",
      "epoch:  31300 train_loss: 0.7142432928085327 val_loss: 1.4845058917999268\n",
      "epoch:  31400 train_loss: 0.8087900876998901 val_loss: 1.6304552555084229\n",
      "epoch:  31500 train_loss: 0.7733280062675476 val_loss: 1.564024567604065\n",
      "epoch:  31600 train_loss: 0.6495426297187805 val_loss: 1.4253743886947632\n",
      "epoch:  31700 train_loss: 0.6737874746322632 val_loss: 1.473807454109192\n",
      "epoch:  31800 train_loss: 1.4900206327438354 val_loss: 1.9153046607971191\n",
      "epoch:  31900 train_loss: 0.6742488741874695 val_loss: 1.4554837942123413\n",
      "epoch:  32000 train_loss: 0.6374956965446472 val_loss: 1.4205496311187744\n",
      "epoch:  32100 train_loss: 0.8109340071678162 val_loss: 1.6338273286819458\n",
      "epoch:  32200 train_loss: 0.6539759635925293 val_loss: 1.4309521913528442\n",
      "epoch:  32300 train_loss: 0.6362349390983582 val_loss: 1.4210296869277954\n",
      "epoch:  32400 train_loss: 0.6516914963722229 val_loss: 1.4274489879608154\n",
      "epoch:  32500 train_loss: 0.6777917742729187 val_loss: 1.4800995588302612\n",
      "epoch:  32600 train_loss: 1.05204439163208 val_loss: 1.728305697441101\n",
      "epoch:  32700 train_loss: 0.629182755947113 val_loss: 1.4354256391525269\n",
      "epoch:  32800 train_loss: 0.6374386548995972 val_loss: 1.4503191709518433\n",
      "epoch:  32900 train_loss: 0.7210617661476135 val_loss: 1.506144404411316\n",
      "epoch:  33000 train_loss: 0.6579763889312744 val_loss: 1.4773539304733276\n",
      "epoch:  33100 train_loss: 0.629094123840332 val_loss: 1.4451115131378174\n",
      "epoch:  33200 train_loss: 0.6691060066223145 val_loss: 1.4736121892929077\n",
      "epoch:  33300 train_loss: 0.75599205493927 val_loss: 1.6013867855072021\n",
      "epoch:  33400 train_loss: 0.6524455547332764 val_loss: 1.4871832132339478\n",
      "epoch:  33500 train_loss: 0.6804012060165405 val_loss: 1.514697551727295\n",
      "epoch:  33600 train_loss: 0.6305609941482544 val_loss: 1.4414339065551758\n",
      "epoch:  33700 train_loss: 0.6507627367973328 val_loss: 1.4639173746109009\n",
      "epoch:  33800 train_loss: 0.8263474702835083 val_loss: 1.6892372369766235\n",
      "epoch:  33900 train_loss: 0.6662198901176453 val_loss: 1.5435688495635986\n",
      "epoch:  34000 train_loss: 0.8449587821960449 val_loss: 1.482858419418335\n",
      "epoch:  34100 train_loss: 0.7817668914794922 val_loss: 1.5828007459640503\n",
      "epoch:  34200 train_loss: 0.8656619191169739 val_loss: 1.631142020225525\n",
      "epoch:  34300 train_loss: 0.8940813541412354 val_loss: 1.6784991025924683\n",
      "epoch:  34400 train_loss: 0.6226703524589539 val_loss: 1.4678374528884888\n",
      "epoch:  34500 train_loss: 0.8030552864074707 val_loss: 1.6494243144989014\n",
      "epoch:  34600 train_loss: 0.6247410178184509 val_loss: 1.4632184505462646\n",
      "epoch:  34700 train_loss: 1.0137497186660767 val_loss: 1.7831876277923584\n",
      "epoch:  34800 train_loss: 0.707842230796814 val_loss: 1.5817314386367798\n",
      "epoch:  34900 train_loss: 0.6337534189224243 val_loss: 1.4686408042907715\n",
      "epoch:  35000 train_loss: 0.649998664855957 val_loss: 1.461546540260315\n",
      "epoch:  35100 train_loss: 0.8387759327888489 val_loss: 1.731536626815796\n",
      "epoch:  35200 train_loss: 0.7276854515075684 val_loss: 1.558700442314148\n",
      "epoch:  35300 train_loss: 0.6771551966667175 val_loss: 1.5118598937988281\n",
      "epoch:  35400 train_loss: 0.62626051902771 val_loss: 1.4692637920379639\n",
      "epoch:  35500 train_loss: 0.7715560793876648 val_loss: 1.567260503768921\n",
      "epoch:  35600 train_loss: 0.9223632216453552 val_loss: 1.7033195495605469\n",
      "epoch:  35700 train_loss: 0.6077786684036255 val_loss: 1.4713187217712402\n",
      "epoch:  35800 train_loss: 0.8058005571365356 val_loss: 1.6932220458984375\n",
      "epoch:  35900 train_loss: 0.7401672005653381 val_loss: 1.659763216972351\n",
      "RMSE:  tensor(2.2507, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Ganerate the dataset\n",
    "i = 0\n",
    "sigma = 1.9\n",
    "my_dataset = []\n",
    "for ud in UDs:\n",
    "    example = []\n",
    "    for an in ANs:\n",
    "        noise = np.random.normal(0,sigma)\n",
    "        # 0 is mean\n",
    "        # sigma is the deviation of the normal distribution\n",
    "        d = compute_3d_distance(ud, an) + noise\n",
    "        example.append(d)\n",
    "    \n",
    "    # append x, y, z as col#10, #11, #12\n",
    "    example.append(ud[0])\n",
    "    example.append(ud[1])\n",
    "    example.append(ud[2])\n",
    "    \n",
    "    # append 1x13 example row into my_dataset\n",
    "    my_dataset.append(example)  # expected to be 3000x13  \n",
    "    \n",
    "# Load dataset\n",
    "exercise3_dataset = Exercise3Dataset(list_dataset = my_dataset, shuffle=True)\n",
    "\n",
    "#Split dataset by 0.8: 0.1: 0.1\n",
    "train_examples, train_labels = exercise3_dataset[:int(3000*0.8)]  # (2400, 10)   # (2400, 3)\n",
    "val_examples, val_labels = exercise3_dataset[int(3000*0.8):int(3000*0.9)]    # (300, 10)   #(300, 3)\n",
    "test_examples, test_labels = exercise3_dataset[int(3000*0.9):]     #(300, 10)   # (300, 3)\n",
    "\n",
    "###Define model, loss function and optimizer\n",
    "# if we have GPU, then use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define model\n",
    "model = Net(x_dim = train_examples.shape[1], y_dim = train_labels.shape[1]).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training and Validation\n",
    "\n",
    "train_examples = train_examples.to(device)\n",
    "train_labels = train_labels.to(device)\n",
    "val_examples = val_examples.to(device)\n",
    "val_labels = val_labels.to(device)\n",
    "\n",
    "# Define the model filename for model.save()\n",
    "MODEL_FILENAME = \"best.pth\"\n",
    "\n",
    "# set model to Training mode\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "NUM_OF_EPOCH = 36000\n",
    "\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    y_pred = model(train_examples)\n",
    "    loss = loss_fn(y_pred, train_labels).cpu()\n",
    "    #print(t, loss.item())\n",
    "    train_losses.append(loss.item())\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    # BGD\n",
    "    optimizer.step()\n",
    "    \n",
    "    # evaluate validation loss\n",
    "    val_pred = model(val_examples)\n",
    "    loss = loss_fn(val_pred, val_labels)\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "    # check if we got better loss\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n",
    "\n",
    "    if (epoch % 100) == 0:\n",
    "        print(\"epoch: \", epoch, \"train_loss:\", train_losses[-1], \"val_loss:\", val_losses[-1])\n",
    "        \n",
    "# Inference all testing examples and compute RMSE\n",
    "def square_error(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  square_error= loss_fn(a, b)\n",
    "  return square_error\n",
    "\n",
    "model.eval() # inference mode\n",
    "test_examples = test_examples.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "test_preds = model(test_examples)\n",
    "#print(\"example: \", test_example.cpu())\n",
    "#print(\"========================================\")\n",
    "#print(\"ground_truth:\", test_label.cpu())\n",
    "#print(\"prediction:\", test_pred.cpu())\n",
    "#print(\"========================================\")\n",
    "\n",
    "\n",
    "total_errors = 0.0\n",
    "for idx in range(len(test_examples)):\n",
    "    total_errors += square_error(test_preds[idx], test_labels[idx])\n",
    "    \n",
    "RMSE = torch.sqrt(total_errors / len(test_examples))\n",
    "print(\"RMSE: \",  RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigma = 2.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffle = True!\n",
      "epoch:  0 train_loss: 7327.71240234375 val_loss: 7484.2255859375\n",
      "epoch:  100 train_loss: 132.1516571044922 val_loss: 132.36734008789062\n",
      "epoch:  200 train_loss: 116.52202606201172 val_loss: 117.17523193359375\n",
      "epoch:  300 train_loss: 59.92654800415039 val_loss: 65.53368377685547\n",
      "epoch:  400 train_loss: 19.93777847290039 val_loss: 20.995403289794922\n",
      "epoch:  500 train_loss: 14.578346252441406 val_loss: 15.897821426391602\n",
      "epoch:  600 train_loss: 8.956547737121582 val_loss: 10.263716697692871\n",
      "epoch:  700 train_loss: 6.113424777984619 val_loss: 6.823578834533691\n",
      "epoch:  800 train_loss: 4.916942596435547 val_loss: 5.479316234588623\n",
      "epoch:  900 train_loss: 4.2892913818359375 val_loss: 4.742254734039307\n",
      "epoch:  1000 train_loss: 3.898369312286377 val_loss: 4.273376941680908\n",
      "epoch:  1100 train_loss: 3.6323330402374268 val_loss: 3.9458353519439697\n",
      "epoch:  1200 train_loss: 3.444193124771118 val_loss: 3.711860418319702\n",
      "epoch:  1300 train_loss: 3.303386688232422 val_loss: 3.544590473175049\n",
      "epoch:  1400 train_loss: 3.2096941471099854 val_loss: 3.4356837272644043\n",
      "epoch:  1500 train_loss: 3.1110613346099854 val_loss: 3.3219592571258545\n",
      "epoch:  1600 train_loss: 3.027052640914917 val_loss: 3.2386507987976074\n",
      "epoch:  1700 train_loss: 2.9558513164520264 val_loss: 3.1662261486053467\n",
      "epoch:  1800 train_loss: 2.901878595352173 val_loss: 3.1002869606018066\n",
      "epoch:  1900 train_loss: 2.8567655086517334 val_loss: 3.0536131858825684\n",
      "epoch:  2000 train_loss: 2.84607195854187 val_loss: 3.020493745803833\n",
      "epoch:  2100 train_loss: 2.806847333908081 val_loss: 3.006310224533081\n",
      "epoch:  2200 train_loss: 2.846456289291382 val_loss: 3.1030051708221436\n",
      "epoch:  2300 train_loss: 2.717810869216919 val_loss: 2.9235854148864746\n",
      "epoch:  2400 train_loss: 2.68884015083313 val_loss: 2.918764114379883\n",
      "epoch:  2500 train_loss: 2.6976513862609863 val_loss: 2.896055221557617\n",
      "epoch:  2600 train_loss: 2.635962963104248 val_loss: 2.848101854324341\n",
      "epoch:  2700 train_loss: 2.625274658203125 val_loss: 2.8319170475006104\n",
      "epoch:  2800 train_loss: 2.593938112258911 val_loss: 2.807124137878418\n",
      "epoch:  2900 train_loss: 2.5738494396209717 val_loss: 2.7982254028320312\n",
      "epoch:  3000 train_loss: 2.5550034046173096 val_loss: 2.7938618659973145\n",
      "epoch:  3100 train_loss: 2.544689655303955 val_loss: 2.786306858062744\n",
      "epoch:  3200 train_loss: 2.516566276550293 val_loss: 2.7779791355133057\n",
      "epoch:  3300 train_loss: 2.5007293224334717 val_loss: 2.7754712104797363\n",
      "epoch:  3400 train_loss: 2.598872661590576 val_loss: 2.9412264823913574\n",
      "epoch:  3500 train_loss: 2.4661285877227783 val_loss: 2.7442984580993652\n",
      "epoch:  3600 train_loss: 2.4550890922546387 val_loss: 2.750103712081909\n",
      "epoch:  3700 train_loss: 2.4373342990875244 val_loss: 2.741253137588501\n",
      "epoch:  3800 train_loss: 2.5296363830566406 val_loss: 2.8534154891967773\n",
      "epoch:  3900 train_loss: 2.410738706588745 val_loss: 2.729079484939575\n",
      "epoch:  4000 train_loss: 2.7381484508514404 val_loss: 3.113732099533081\n",
      "epoch:  4100 train_loss: 3.756793260574341 val_loss: 4.258732318878174\n",
      "epoch:  4200 train_loss: 2.3685710430145264 val_loss: 2.720830202102661\n",
      "epoch:  4300 train_loss: 2.3604846000671387 val_loss: 2.721480131149292\n",
      "epoch:  4400 train_loss: 2.3430533409118652 val_loss: 2.7073733806610107\n",
      "epoch:  4500 train_loss: 2.332104206085205 val_loss: 2.7100777626037598\n",
      "epoch:  4600 train_loss: 2.319183111190796 val_loss: 2.705745220184326\n",
      "epoch:  4700 train_loss: 2.334578275680542 val_loss: 2.7166495323181152\n",
      "epoch:  4800 train_loss: 2.297480344772339 val_loss: 2.705418825149536\n",
      "epoch:  4900 train_loss: 2.298837900161743 val_loss: 2.712799072265625\n",
      "epoch:  5000 train_loss: 2.706982374191284 val_loss: 3.0777840614318848\n",
      "epoch:  5100 train_loss: 2.2592318058013916 val_loss: 2.7157177925109863\n",
      "epoch:  5200 train_loss: 2.315427541732788 val_loss: 2.7432687282562256\n",
      "epoch:  5300 train_loss: 2.240530014038086 val_loss: 2.708892822265625\n",
      "epoch:  5400 train_loss: 2.299516201019287 val_loss: 2.7306056022644043\n",
      "epoch:  5500 train_loss: 2.218179702758789 val_loss: 2.722412109375\n",
      "epoch:  5600 train_loss: 2.3127737045288086 val_loss: 2.796794891357422\n",
      "epoch:  5700 train_loss: 2.196744918823242 val_loss: 2.7146201133728027\n",
      "epoch:  5800 train_loss: 2.188775062561035 val_loss: 2.7065582275390625\n",
      "epoch:  5900 train_loss: 2.509528160095215 val_loss: 3.0507853031158447\n",
      "epoch:  6000 train_loss: 2.776571273803711 val_loss: 3.129807472229004\n",
      "epoch:  6100 train_loss: 2.206521987915039 val_loss: 2.7622146606445312\n",
      "epoch:  6200 train_loss: 2.1617164611816406 val_loss: 2.7226638793945312\n",
      "epoch:  6300 train_loss: 2.263258457183838 val_loss: 2.875882148742676\n",
      "epoch:  6400 train_loss: 2.1375927925109863 val_loss: 2.7404394149780273\n",
      "epoch:  6500 train_loss: 2.9694364070892334 val_loss: 3.4879322052001953\n",
      "epoch:  6600 train_loss: 2.1666674613952637 val_loss: 2.7474913597106934\n",
      "epoch:  6700 train_loss: 2.281930923461914 val_loss: 2.9862751960754395\n",
      "epoch:  6800 train_loss: 2.10976243019104 val_loss: 2.7284505367279053\n",
      "epoch:  6900 train_loss: 2.099205255508423 val_loss: 2.7878341674804688\n",
      "epoch:  7000 train_loss: 2.1436078548431396 val_loss: 2.7362475395202637\n",
      "epoch:  7100 train_loss: 2.085972785949707 val_loss: 2.7563037872314453\n",
      "epoch:  7200 train_loss: 2.0757839679718018 val_loss: 2.7274513244628906\n",
      "epoch:  7300 train_loss: 2.071772575378418 val_loss: 2.731208324432373\n",
      "epoch:  7400 train_loss: 2.064822196960449 val_loss: 2.7332582473754883\n",
      "epoch:  7500 train_loss: 2.07028865814209 val_loss: 2.7399802207946777\n",
      "epoch:  7600 train_loss: 2.0881106853485107 val_loss: 2.7621755599975586\n",
      "epoch:  7700 train_loss: 2.5705738067626953 val_loss: 3.1045725345611572\n",
      "epoch:  7800 train_loss: 2.0824668407440186 val_loss: 2.8301761150360107\n",
      "epoch:  7900 train_loss: 2.0284323692321777 val_loss: 2.7566187381744385\n",
      "epoch:  8000 train_loss: 2.0254292488098145 val_loss: 2.7736399173736572\n",
      "epoch:  8100 train_loss: 2.0176467895507812 val_loss: 2.7816178798675537\n",
      "epoch:  8200 train_loss: 2.0058536529541016 val_loss: 2.781358003616333\n",
      "epoch:  8300 train_loss: 2.367323637008667 val_loss: 2.837582588195801\n",
      "epoch:  8400 train_loss: 1.9966011047363281 val_loss: 2.8082380294799805\n",
      "epoch:  8500 train_loss: 2.803654670715332 val_loss: 3.296325445175171\n",
      "epoch:  8600 train_loss: 2.052488327026367 val_loss: 2.867832899093628\n",
      "epoch:  8700 train_loss: 2.2113730907440186 val_loss: 3.1060280799865723\n",
      "epoch:  8800 train_loss: 2.058112382888794 val_loss: 2.842684030532837\n",
      "epoch:  8900 train_loss: 2.1947882175445557 val_loss: 3.175812244415283\n",
      "epoch:  9000 train_loss: 1.9665358066558838 val_loss: 2.830871105194092\n",
      "epoch:  9100 train_loss: 1.979099154472351 val_loss: 2.8847947120666504\n",
      "epoch:  9200 train_loss: 1.986214280128479 val_loss: 2.851634979248047\n",
      "epoch:  9300 train_loss: 1.9357943534851074 val_loss: 2.823338508605957\n",
      "epoch:  9400 train_loss: 2.1380648612976074 val_loss: 3.108903169631958\n",
      "epoch:  9500 train_loss: 2.024181365966797 val_loss: 2.9549601078033447\n",
      "epoch:  9600 train_loss: 1.939902901649475 val_loss: 2.88207745552063\n",
      "epoch:  9700 train_loss: 1.8953657150268555 val_loss: 2.854133129119873\n",
      "epoch:  9800 train_loss: 1.9079115390777588 val_loss: 2.891233444213867\n",
      "epoch:  9900 train_loss: 1.9231553077697754 val_loss: 2.91679048538208\n",
      "epoch:  10000 train_loss: 1.8698991537094116 val_loss: 2.8739774227142334\n",
      "epoch:  10100 train_loss: 1.8613682985305786 val_loss: 2.8780274391174316\n",
      "epoch:  10200 train_loss: 1.8533482551574707 val_loss: 2.888641357421875\n",
      "epoch:  10300 train_loss: 1.932682991027832 val_loss: 2.989841938018799\n",
      "epoch:  10400 train_loss: 2.163780927658081 val_loss: 3.1933465003967285\n",
      "epoch:  10500 train_loss: 1.8768082857131958 val_loss: 2.9536514282226562\n",
      "epoch:  10600 train_loss: 1.8274219036102295 val_loss: 2.9313466548919678\n",
      "epoch:  10700 train_loss: 2.350224494934082 val_loss: 3.816817283630371\n",
      "epoch:  10800 train_loss: 1.8443148136138916 val_loss: 2.951395034790039\n",
      "epoch:  10900 train_loss: 1.8045635223388672 val_loss: 2.9420673847198486\n",
      "epoch:  11000 train_loss: 2.82867169380188 val_loss: 4.197454929351807\n",
      "epoch:  11100 train_loss: 2.514051675796509 val_loss: 3.642550468444824\n",
      "epoch:  11200 train_loss: 1.8531121015548706 val_loss: 3.0726158618927\n",
      "epoch:  11300 train_loss: 1.9043270349502563 val_loss: 3.12481951713562\n",
      "epoch:  11400 train_loss: 1.8620662689208984 val_loss: 3.0883500576019287\n",
      "epoch:  11500 train_loss: 1.7851492166519165 val_loss: 3.0188255310058594\n",
      "epoch:  11600 train_loss: 1.928902506828308 val_loss: 3.084709644317627\n",
      "epoch:  11700 train_loss: 1.755357265472412 val_loss: 2.9883859157562256\n",
      "epoch:  11800 train_loss: 1.7662941217422485 val_loss: 3.0137429237365723\n",
      "epoch:  11900 train_loss: 1.7726085186004639 val_loss: 3.0075795650482178\n",
      "epoch:  12000 train_loss: 1.7480655908584595 val_loss: 3.0182700157165527\n",
      "epoch:  12100 train_loss: 2.1831891536712646 val_loss: 3.03234601020813\n",
      "epoch:  12200 train_loss: 1.7450333833694458 val_loss: 3.041443109512329\n",
      "epoch:  12300 train_loss: 1.944172739982605 val_loss: 3.212693214416504\n",
      "epoch:  12400 train_loss: 1.7824186086654663 val_loss: 3.110502004623413\n",
      "epoch:  12500 train_loss: 1.7391520738601685 val_loss: 3.069915771484375\n",
      "epoch:  12600 train_loss: 1.6976755857467651 val_loss: 3.04945969581604\n",
      "epoch:  12700 train_loss: 1.6913938522338867 val_loss: 3.054621934890747\n",
      "epoch:  12800 train_loss: 1.7307519912719727 val_loss: 3.108764886856079\n",
      "epoch:  12900 train_loss: 1.7909908294677734 val_loss: 3.2368392944335938\n",
      "epoch:  13000 train_loss: 1.8762974739074707 val_loss: 3.3515539169311523\n",
      "epoch:  13100 train_loss: 1.6611055135726929 val_loss: 3.052727460861206\n",
      "epoch:  13200 train_loss: 1.710339903831482 val_loss: 3.0781338214874268\n",
      "epoch:  13300 train_loss: 1.6653114557266235 val_loss: 3.0613248348236084\n",
      "epoch:  13400 train_loss: 1.651585578918457 val_loss: 3.0765774250030518\n",
      "epoch:  13500 train_loss: 1.690879464149475 val_loss: 3.1316869258880615\n",
      "epoch:  13600 train_loss: 2.2309012413024902 val_loss: 3.787907838821411\n",
      "epoch:  13700 train_loss: 1.6924121379852295 val_loss: 3.1725504398345947\n",
      "epoch:  13800 train_loss: 2.1307485103607178 val_loss: 3.753052234649658\n",
      "epoch:  13900 train_loss: 1.771960735321045 val_loss: 3.1698155403137207\n",
      "epoch:  14000 train_loss: 1.6766490936279297 val_loss: 3.176640748977661\n",
      "epoch:  14100 train_loss: 2.049058675765991 val_loss: 3.682216167449951\n",
      "epoch:  14200 train_loss: 1.6421219110488892 val_loss: 3.151482582092285\n",
      "epoch:  14300 train_loss: 1.7488490343093872 val_loss: 3.311155080795288\n",
      "epoch:  14400 train_loss: 1.7938721179962158 val_loss: 3.368990898132324\n",
      "epoch:  14500 train_loss: 1.679380178451538 val_loss: 3.3108584880828857\n",
      "epoch:  14600 train_loss: 1.6058571338653564 val_loss: 3.201200246810913\n",
      "epoch:  14700 train_loss: 1.6010018587112427 val_loss: 3.246577262878418\n",
      "epoch:  14800 train_loss: 1.6054270267486572 val_loss: 3.2591803073883057\n",
      "epoch:  14900 train_loss: 1.6273469924926758 val_loss: 3.3128342628479004\n",
      "epoch:  15000 train_loss: 1.6184402704238892 val_loss: 3.2654871940612793\n",
      "epoch:  15100 train_loss: 2.04654860496521 val_loss: 3.715986967086792\n",
      "epoch:  15200 train_loss: 1.5914521217346191 val_loss: 3.2723324298858643\n",
      "epoch:  15300 train_loss: 1.5779130458831787 val_loss: 3.263204574584961\n",
      "epoch:  15400 train_loss: 1.5901286602020264 val_loss: 3.278285026550293\n",
      "epoch:  15500 train_loss: 1.5587644577026367 val_loss: 3.2619519233703613\n",
      "epoch:  15600 train_loss: 1.6806600093841553 val_loss: 3.3430192470550537\n",
      "epoch:  15700 train_loss: 1.591784119606018 val_loss: 3.3221590518951416\n",
      "epoch:  15800 train_loss: 1.5551774501800537 val_loss: 3.2773640155792236\n",
      "epoch:  15900 train_loss: 1.5456606149673462 val_loss: 3.301330804824829\n",
      "epoch:  16000 train_loss: 1.7700527906417847 val_loss: 3.3949553966522217\n",
      "epoch:  16100 train_loss: 1.5483555793762207 val_loss: 3.3152053356170654\n",
      "epoch:  16200 train_loss: 1.5845117568969727 val_loss: 3.3351449966430664\n",
      "epoch:  16300 train_loss: 1.6921658515930176 val_loss: 3.3994193077087402\n",
      "epoch:  16400 train_loss: 2.1412277221679688 val_loss: 3.928724527359009\n",
      "epoch:  16500 train_loss: 1.5372333526611328 val_loss: 3.329192876815796\n",
      "epoch:  16600 train_loss: 1.6901334524154663 val_loss: 3.513955593109131\n",
      "epoch:  16700 train_loss: 1.6554619073867798 val_loss: 3.4932875633239746\n",
      "epoch:  16800 train_loss: 1.5280174016952515 val_loss: 3.3363802433013916\n",
      "epoch:  16900 train_loss: 1.7022863626480103 val_loss: 3.5919461250305176\n",
      "epoch:  17000 train_loss: 1.5513986349105835 val_loss: 3.3797755241394043\n",
      "epoch:  17100 train_loss: 1.5205169916152954 val_loss: 3.384427070617676\n",
      "epoch:  17200 train_loss: 1.5547640323638916 val_loss: 3.4149904251098633\n",
      "epoch:  17300 train_loss: 1.5758006572723389 val_loss: 3.463561773300171\n",
      "epoch:  17400 train_loss: 1.5684301853179932 val_loss: 3.4482107162475586\n",
      "epoch:  17500 train_loss: 1.5914684534072876 val_loss: 3.4806723594665527\n",
      "epoch:  17600 train_loss: 2.0235414505004883 val_loss: 3.9230518341064453\n",
      "epoch:  17700 train_loss: 1.5377289056777954 val_loss: 3.4435932636260986\n",
      "epoch:  17800 train_loss: 1.5091203451156616 val_loss: 3.4357688426971436\n",
      "epoch:  17900 train_loss: 1.7660192251205444 val_loss: 3.7056071758270264\n",
      "epoch:  18000 train_loss: 1.5707069635391235 val_loss: 3.589392900466919\n",
      "epoch:  18100 train_loss: 1.669621229171753 val_loss: 3.63562273979187\n",
      "epoch:  18200 train_loss: 1.4907557964324951 val_loss: 3.43119740486145\n",
      "epoch:  18300 train_loss: 1.5540810823440552 val_loss: 3.4669532775878906\n",
      "epoch:  18400 train_loss: 1.4956339597702026 val_loss: 3.4336299896240234\n",
      "epoch:  18500 train_loss: 1.4671432971954346 val_loss: 3.4355483055114746\n",
      "epoch:  18600 train_loss: 1.5224835872650146 val_loss: 3.5427582263946533\n",
      "epoch:  18700 train_loss: 1.5632535219192505 val_loss: 3.5866754055023193\n",
      "epoch:  18800 train_loss: 1.702333927154541 val_loss: 3.5526227951049805\n",
      "epoch:  18900 train_loss: 1.467147707939148 val_loss: 3.4431397914886475\n",
      "epoch:  19000 train_loss: 2.2061562538146973 val_loss: 4.283596038818359\n",
      "epoch:  19100 train_loss: 1.657529354095459 val_loss: 3.7881858348846436\n",
      "epoch:  19200 train_loss: 1.526041865348816 val_loss: 3.5676021575927734\n",
      "epoch:  19300 train_loss: 2.024632692337036 val_loss: 3.9569249153137207\n",
      "epoch:  19400 train_loss: 1.4736347198486328 val_loss: 3.5227479934692383\n",
      "epoch:  19500 train_loss: 1.4878439903259277 val_loss: 3.5344808101654053\n",
      "epoch:  19600 train_loss: 1.4836877584457397 val_loss: 3.563322067260742\n",
      "epoch:  19700 train_loss: 1.5089459419250488 val_loss: 3.550079345703125\n",
      "epoch:  19800 train_loss: 1.697007179260254 val_loss: 3.790133476257324\n",
      "epoch:  19900 train_loss: 1.4250398874282837 val_loss: 3.5187370777130127\n",
      "epoch:  20000 train_loss: 1.5752546787261963 val_loss: 3.610551357269287\n",
      "epoch:  20100 train_loss: 1.5815198421478271 val_loss: 3.6076183319091797\n",
      "epoch:  20200 train_loss: 1.4665768146514893 val_loss: 3.6057872772216797\n",
      "epoch:  20300 train_loss: 1.53042471408844 val_loss: 3.710416793823242\n",
      "epoch:  20400 train_loss: 1.50309157371521 val_loss: 3.6927311420440674\n",
      "epoch:  20500 train_loss: 1.4476205110549927 val_loss: 3.5785489082336426\n",
      "epoch:  20600 train_loss: 1.7253822088241577 val_loss: 3.762011766433716\n",
      "epoch:  20700 train_loss: 1.4891564846038818 val_loss: 3.6461431980133057\n",
      "epoch:  20800 train_loss: 2.2821173667907715 val_loss: 4.246272563934326\n",
      "epoch:  20900 train_loss: 1.5223733186721802 val_loss: 3.584681510925293\n",
      "epoch:  21000 train_loss: 1.5344891548156738 val_loss: 3.6987478733062744\n",
      "epoch:  21100 train_loss: 1.4581828117370605 val_loss: 3.641892910003662\n",
      "epoch:  21200 train_loss: 1.506766438484192 val_loss: 3.667313575744629\n",
      "epoch:  21300 train_loss: 1.430659532546997 val_loss: 3.5817747116088867\n",
      "epoch:  21400 train_loss: 1.3918286561965942 val_loss: 3.603652000427246\n",
      "epoch:  21500 train_loss: 1.4720977544784546 val_loss: 3.6808009147644043\n",
      "epoch:  21600 train_loss: 1.438170075416565 val_loss: 3.6353139877319336\n",
      "epoch:  21700 train_loss: 1.4046283960342407 val_loss: 3.6383495330810547\n",
      "epoch:  21800 train_loss: 1.406649112701416 val_loss: 3.593224287033081\n",
      "epoch:  21900 train_loss: 1.460910439491272 val_loss: 3.6468544006347656\n",
      "epoch:  22000 train_loss: 1.5456253290176392 val_loss: 3.7016377449035645\n",
      "epoch:  22100 train_loss: 2.332099676132202 val_loss: 4.449965000152588\n",
      "epoch:  22200 train_loss: 1.5052934885025024 val_loss: 3.7528903484344482\n",
      "epoch:  22300 train_loss: 1.39857017993927 val_loss: 3.596205711364746\n",
      "epoch:  22400 train_loss: 1.4059150218963623 val_loss: 3.6695828437805176\n",
      "epoch:  22500 train_loss: 3.286041736602783 val_loss: 4.691837310791016\n",
      "epoch:  22600 train_loss: 1.3631483316421509 val_loss: 3.6200613975524902\n",
      "epoch:  22700 train_loss: 1.3625167608261108 val_loss: 3.6554067134857178\n",
      "epoch:  22800 train_loss: 1.4767985343933105 val_loss: 3.7795584201812744\n",
      "epoch:  22900 train_loss: 1.6350009441375732 val_loss: 3.858059883117676\n",
      "epoch:  23000 train_loss: 1.4429774284362793 val_loss: 3.7924766540527344\n",
      "epoch:  23100 train_loss: 1.3438740968704224 val_loss: 3.6434733867645264\n",
      "epoch:  23200 train_loss: 1.5419269800186157 val_loss: 3.8031113147735596\n",
      "epoch:  23300 train_loss: 1.3738511800765991 val_loss: 3.699394941329956\n",
      "epoch:  23400 train_loss: 1.3817646503448486 val_loss: 3.663701295852661\n",
      "epoch:  23500 train_loss: 1.338288426399231 val_loss: 3.6525163650512695\n",
      "epoch:  23600 train_loss: 1.473254680633545 val_loss: 3.7566723823547363\n",
      "epoch:  23700 train_loss: 1.3662400245666504 val_loss: 3.7262940406799316\n",
      "epoch:  23800 train_loss: 1.6290397644042969 val_loss: 3.9924232959747314\n",
      "epoch:  23900 train_loss: 1.4922571182250977 val_loss: 3.8016865253448486\n",
      "epoch:  24000 train_loss: 1.6568481922149658 val_loss: 4.011767387390137\n",
      "epoch:  24100 train_loss: 1.3504705429077148 val_loss: 3.6711761951446533\n",
      "epoch:  24200 train_loss: 1.5365064144134521 val_loss: 3.865013837814331\n",
      "epoch:  24300 train_loss: 1.358343243598938 val_loss: 3.6678216457366943\n",
      "epoch:  24400 train_loss: 1.4101992845535278 val_loss: 3.651158571243286\n",
      "epoch:  24500 train_loss: 1.444761872291565 val_loss: 3.8395111560821533\n",
      "epoch:  24600 train_loss: 1.3887170553207397 val_loss: 3.725933313369751\n",
      "epoch:  24700 train_loss: 1.5364761352539062 val_loss: 3.9270269870758057\n",
      "epoch:  24800 train_loss: 1.3267654180526733 val_loss: 3.668745756149292\n",
      "epoch:  24900 train_loss: 1.8817378282546997 val_loss: 4.274857044219971\n",
      "epoch:  25000 train_loss: 1.43488609790802 val_loss: 3.7864794731140137\n",
      "epoch:  25100 train_loss: 1.498904824256897 val_loss: 3.863780975341797\n",
      "epoch:  25200 train_loss: 1.307444453239441 val_loss: 3.673891067504883\n",
      "epoch:  25300 train_loss: 1.675904393196106 val_loss: 4.063059329986572\n",
      "epoch:  25400 train_loss: 1.4043790102005005 val_loss: 3.8142898082733154\n",
      "epoch:  25500 train_loss: 1.5900744199752808 val_loss: 4.018442630767822\n",
      "epoch:  25600 train_loss: 1.4630305767059326 val_loss: 3.744027853012085\n",
      "epoch:  25700 train_loss: 1.483129620552063 val_loss: 4.380739212036133\n",
      "epoch:  25800 train_loss: 1.2926416397094727 val_loss: 3.6786768436431885\n",
      "epoch:  25900 train_loss: 1.3206247091293335 val_loss: 3.731614589691162\n",
      "epoch:  26000 train_loss: 1.3754563331604004 val_loss: 3.883927345275879\n",
      "epoch:  26100 train_loss: 1.3847862482070923 val_loss: 3.805612802505493\n",
      "epoch:  26200 train_loss: 1.3740707635879517 val_loss: 3.805056571960449\n",
      "epoch:  26300 train_loss: 1.3442610502243042 val_loss: 3.659925699234009\n",
      "epoch:  26400 train_loss: 1.316287875175476 val_loss: 3.7047829627990723\n",
      "epoch:  26500 train_loss: 1.2986968755722046 val_loss: 3.674901008605957\n",
      "epoch:  26600 train_loss: 1.4930925369262695 val_loss: 3.800285577774048\n",
      "epoch:  26700 train_loss: 1.3133116960525513 val_loss: 3.717130184173584\n",
      "epoch:  26800 train_loss: 1.5515804290771484 val_loss: 4.1066107749938965\n",
      "epoch:  26900 train_loss: 1.5795540809631348 val_loss: 4.1472625732421875\n",
      "epoch:  27000 train_loss: 1.4581266641616821 val_loss: 3.8819432258605957\n",
      "epoch:  27100 train_loss: 1.2701969146728516 val_loss: 3.656402587890625\n",
      "epoch:  27200 train_loss: 1.369267463684082 val_loss: 3.6914806365966797\n",
      "epoch:  27300 train_loss: 1.2856365442276 val_loss: 3.7155654430389404\n",
      "epoch:  27400 train_loss: 1.4110101461410522 val_loss: 3.8594212532043457\n",
      "epoch:  27500 train_loss: 1.4021689891815186 val_loss: 3.836574077606201\n",
      "epoch:  27600 train_loss: 1.3085156679153442 val_loss: 3.72607159614563\n",
      "epoch:  27700 train_loss: 1.2527124881744385 val_loss: 3.688178777694702\n",
      "epoch:  27800 train_loss: 1.2539676427841187 val_loss: 3.6776645183563232\n",
      "epoch:  27900 train_loss: 1.4004052877426147 val_loss: 3.78753924369812\n",
      "epoch:  28000 train_loss: 1.3398584127426147 val_loss: 3.7212765216827393\n",
      "epoch:  28100 train_loss: 1.4699037075042725 val_loss: 3.8984999656677246\n",
      "epoch:  28200 train_loss: 1.2706553936004639 val_loss: 3.7417421340942383\n",
      "epoch:  28300 train_loss: 1.7045360803604126 val_loss: 4.18495512008667\n",
      "epoch:  28400 train_loss: 1.243667483329773 val_loss: 3.690835475921631\n",
      "epoch:  28500 train_loss: 1.3297886848449707 val_loss: 3.782672643661499\n",
      "epoch:  28600 train_loss: 1.672937035560608 val_loss: 4.045257091522217\n",
      "epoch:  28700 train_loss: 1.2718238830566406 val_loss: 3.6657145023345947\n",
      "epoch:  28800 train_loss: 1.403980016708374 val_loss: 3.767204523086548\n",
      "epoch:  28900 train_loss: 1.268809199333191 val_loss: 3.672654628753662\n",
      "epoch:  29000 train_loss: 1.2884397506713867 val_loss: 3.687211513519287\n",
      "epoch:  29100 train_loss: 1.287204384803772 val_loss: 3.7466750144958496\n",
      "epoch:  29200 train_loss: 1.3826340436935425 val_loss: 3.8589324951171875\n",
      "epoch:  29300 train_loss: 1.3266570568084717 val_loss: 3.7777795791625977\n",
      "epoch:  29400 train_loss: 1.4946292638778687 val_loss: 3.881462335586548\n",
      "epoch:  29500 train_loss: 1.3082842826843262 val_loss: 3.7528443336486816\n",
      "epoch:  29600 train_loss: 1.3391714096069336 val_loss: 3.7855887413024902\n",
      "epoch:  29700 train_loss: 1.2393262386322021 val_loss: 3.644181728363037\n",
      "epoch:  29800 train_loss: 1.2620043754577637 val_loss: 3.6695706844329834\n",
      "epoch:  29900 train_loss: 2.0185811519622803 val_loss: 4.570533275604248\n",
      "epoch:  30000 train_loss: 1.2597273588180542 val_loss: 3.761235475540161\n",
      "epoch:  30100 train_loss: 1.562100887298584 val_loss: 4.058284759521484\n",
      "epoch:  30200 train_loss: 1.224961757659912 val_loss: 3.692957878112793\n",
      "epoch:  30300 train_loss: 1.279990553855896 val_loss: 3.7263901233673096\n",
      "epoch:  30400 train_loss: 1.2291293144226074 val_loss: 3.64543080329895\n",
      "epoch:  30500 train_loss: 1.3266428709030151 val_loss: 3.8441359996795654\n",
      "epoch:  30600 train_loss: 1.5204752683639526 val_loss: 3.9246420860290527\n",
      "epoch:  30700 train_loss: 1.2308673858642578 val_loss: 3.655458450317383\n",
      "epoch:  30800 train_loss: 1.2565816640853882 val_loss: 3.736063003540039\n",
      "epoch:  30900 train_loss: 1.2390986680984497 val_loss: 3.688072919845581\n",
      "epoch:  31000 train_loss: 1.1903952360153198 val_loss: 3.6673264503479004\n",
      "epoch:  31100 train_loss: 1.3441531658172607 val_loss: 3.727008104324341\n",
      "epoch:  31200 train_loss: 1.3568460941314697 val_loss: 3.757236957550049\n",
      "epoch:  31300 train_loss: 1.2992740869522095 val_loss: 3.843686819076538\n",
      "epoch:  31400 train_loss: 1.5335050821304321 val_loss: 3.916057586669922\n",
      "epoch:  31500 train_loss: 1.2235029935836792 val_loss: 3.702500581741333\n",
      "epoch:  31600 train_loss: 1.2222496271133423 val_loss: 3.6867687702178955\n",
      "epoch:  31700 train_loss: 1.207999587059021 val_loss: 3.738206148147583\n",
      "epoch:  31800 train_loss: 1.2013574838638306 val_loss: 3.7050559520721436\n",
      "epoch:  31900 train_loss: 1.208631992340088 val_loss: 3.699291706085205\n",
      "epoch:  32000 train_loss: 1.1770644187927246 val_loss: 3.649474859237671\n",
      "epoch:  32100 train_loss: 2.0489375591278076 val_loss: 4.499019145965576\n",
      "epoch:  32200 train_loss: 1.274290680885315 val_loss: 3.7250983715057373\n",
      "epoch:  32300 train_loss: 1.3310320377349854 val_loss: 3.8874170780181885\n",
      "epoch:  32400 train_loss: 1.3628820180892944 val_loss: 3.757967948913574\n",
      "epoch:  32500 train_loss: 1.1852437257766724 val_loss: 3.6526284217834473\n",
      "epoch:  32600 train_loss: 1.187432050704956 val_loss: 3.666753053665161\n",
      "epoch:  32700 train_loss: 1.3377975225448608 val_loss: 3.7459304332733154\n",
      "epoch:  32800 train_loss: 1.583556890487671 val_loss: 4.230311393737793\n",
      "epoch:  32900 train_loss: 1.3337609767913818 val_loss: 3.8965847492218018\n",
      "epoch:  33000 train_loss: 1.4164183139801025 val_loss: 4.084038257598877\n",
      "epoch:  33100 train_loss: 1.482075810432434 val_loss: 4.105356693267822\n",
      "epoch:  33200 train_loss: 1.3774688243865967 val_loss: 4.056790351867676\n",
      "epoch:  33300 train_loss: 1.8348339796066284 val_loss: 4.323904037475586\n",
      "epoch:  33400 train_loss: 1.204126238822937 val_loss: 3.701838970184326\n",
      "epoch:  33500 train_loss: 1.1856091022491455 val_loss: 3.7124457359313965\n",
      "epoch:  33600 train_loss: 1.243880271911621 val_loss: 3.7088191509246826\n",
      "epoch:  33700 train_loss: 1.1765490770339966 val_loss: 3.7023303508758545\n",
      "epoch:  33800 train_loss: 1.6586171388626099 val_loss: 4.00759744644165\n",
      "epoch:  33900 train_loss: 1.334802508354187 val_loss: 3.8196523189544678\n",
      "epoch:  34000 train_loss: 1.1983799934387207 val_loss: 3.7780041694641113\n",
      "epoch:  34100 train_loss: 1.1656826734542847 val_loss: 3.7737205028533936\n",
      "epoch:  34200 train_loss: 1.2566179037094116 val_loss: 3.8256783485412598\n",
      "epoch:  34300 train_loss: 1.217932939529419 val_loss: 3.7382960319519043\n",
      "epoch:  34400 train_loss: 1.1469645500183105 val_loss: 3.6958165168762207\n",
      "epoch:  34500 train_loss: 1.2196542024612427 val_loss: 3.842587471008301\n",
      "epoch:  34600 train_loss: 1.3220373392105103 val_loss: 3.832479476928711\n",
      "epoch:  34700 train_loss: 1.263954997062683 val_loss: 3.7626237869262695\n",
      "epoch:  34800 train_loss: 1.2875187397003174 val_loss: 3.991269111633301\n",
      "epoch:  34900 train_loss: 1.2461594343185425 val_loss: 3.843463659286499\n",
      "epoch:  35000 train_loss: 1.252508521080017 val_loss: 3.8927671909332275\n",
      "epoch:  35100 train_loss: 1.2976435422897339 val_loss: 3.7581427097320557\n",
      "epoch:  35200 train_loss: 1.203528642654419 val_loss: 3.7338156700134277\n",
      "epoch:  35300 train_loss: 1.1274590492248535 val_loss: 3.7273950576782227\n",
      "epoch:  35400 train_loss: 1.2879449129104614 val_loss: 3.8819429874420166\n",
      "epoch:  35500 train_loss: 1.1473753452301025 val_loss: 3.746645212173462\n",
      "epoch:  35600 train_loss: 1.2838661670684814 val_loss: 3.9090404510498047\n",
      "epoch:  35700 train_loss: 1.1706231832504272 val_loss: 3.757554292678833\n",
      "epoch:  35800 train_loss: 1.3106218576431274 val_loss: 3.8761608600616455\n",
      "epoch:  35900 train_loss: 1.3998390436172485 val_loss: 3.969120740890503\n",
      "RMSE:  tensor(3.4022, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Ganerate the dataset\n",
    "i = 0\n",
    "sigma = 2.8\n",
    "my_dataset = []\n",
    "for ud in UDs:\n",
    "    example = []\n",
    "    for an in ANs:\n",
    "        noise = np.random.normal(0,sigma)\n",
    "        # 0 is mean\n",
    "        # sigma is the deviation of the normal distribution\n",
    "        d = compute_3d_distance(ud, an) + noise\n",
    "        example.append(d)\n",
    "    \n",
    "    # append x, y, z as col#10, #11, #12\n",
    "    example.append(ud[0])\n",
    "    example.append(ud[1])\n",
    "    example.append(ud[2])\n",
    "    \n",
    "    # append 1x13 example row into my_dataset\n",
    "    my_dataset.append(example)  # expected to be 3000x13  \n",
    "    \n",
    "# Load dataset\n",
    "exercise3_dataset = Exercise3Dataset(list_dataset = my_dataset, shuffle=True)\n",
    "\n",
    "#Split dataset by 0.8: 0.1: 0.1\n",
    "train_examples, train_labels = exercise3_dataset[:int(3000*0.8)]  # (2400, 10)   # (2400, 3)\n",
    "val_examples, val_labels = exercise3_dataset[int(3000*0.8):int(3000*0.9)]    # (300, 10)   #(300, 3)\n",
    "test_examples, test_labels = exercise3_dataset[int(3000*0.9):]     #(300, 10)   # (300, 3)\n",
    "\n",
    "###Define model, loss function and optimizer\n",
    "# if we have GPU, then use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define model\n",
    "model = Net(x_dim = train_examples.shape[1], y_dim = train_labels.shape[1]).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training and Validation\n",
    "\n",
    "train_examples = train_examples.to(device)\n",
    "train_labels = train_labels.to(device)\n",
    "val_examples = val_examples.to(device)\n",
    "val_labels = val_labels.to(device)\n",
    "\n",
    "# Define the model filename for model.save()\n",
    "MODEL_FILENAME = \"best.pth\"\n",
    "\n",
    "# set model to Training mode\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "NUM_OF_EPOCH = 36000\n",
    "\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    y_pred = model(train_examples)\n",
    "    loss = loss_fn(y_pred, train_labels).cpu()\n",
    "    #print(t, loss.item())\n",
    "    train_losses.append(loss.item())\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    # BGD\n",
    "    optimizer.step()\n",
    "    \n",
    "    # evaluate validation loss\n",
    "    val_pred = model(val_examples)\n",
    "    loss = loss_fn(val_pred, val_labels)\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "    # check if we got better loss\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n",
    "\n",
    "    if (epoch % 100) == 0:\n",
    "        print(\"epoch: \", epoch, \"train_loss:\", train_losses[-1], \"val_loss:\", val_losses[-1])\n",
    "        \n",
    "# Inference all testing examples and compute RMSE\n",
    "def square_error(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  square_error= loss_fn(a, b)\n",
    "  return square_error\n",
    "\n",
    "model.eval() # inference mode\n",
    "test_examples = test_examples.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "test_preds = model(test_examples)\n",
    "#print(\"example: \", test_example.cpu())\n",
    "#print(\"========================================\")\n",
    "#print(\"ground_truth:\", test_label.cpu())\n",
    "#print(\"prediction:\", test_pred.cpu())\n",
    "#print(\"========================================\")\n",
    "\n",
    "\n",
    "total_errors = 0.0\n",
    "for idx in range(len(test_examples)):\n",
    "    total_errors += square_error(test_preds[idx], test_labels[idx])\n",
    "    \n",
    "RMSE = torch.sqrt(total_errors / len(test_examples))\n",
    "print(\"RMSE: \",  RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigma = 3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffle = True!\n",
      "epoch:  0 train_loss: 7353.30126953125 val_loss: 7258.71142578125\n",
      "epoch:  100 train_loss: 157.72109985351562 val_loss: 159.3646240234375\n",
      "epoch:  200 train_loss: 142.0281524658203 val_loss: 145.0710906982422\n",
      "epoch:  300 train_loss: 116.07366943359375 val_loss: 117.89925384521484\n",
      "epoch:  400 train_loss: 68.48124694824219 val_loss: 67.7967300415039\n",
      "epoch:  500 train_loss: 34.12131118774414 val_loss: 32.61881637573242\n",
      "epoch:  600 train_loss: 19.16399574279785 val_loss: 18.027055740356445\n",
      "epoch:  700 train_loss: 9.787707328796387 val_loss: 9.668728828430176\n",
      "epoch:  800 train_loss: 6.410996437072754 val_loss: 7.224423408508301\n",
      "epoch:  900 train_loss: 5.707828998565674 val_loss: 6.619510650634766\n",
      "epoch:  1000 train_loss: 5.307354927062988 val_loss: 6.168637275695801\n",
      "epoch:  1100 train_loss: 4.877196311950684 val_loss: 5.704549312591553\n",
      "epoch:  1200 train_loss: 4.633204460144043 val_loss: 5.475453853607178\n",
      "epoch:  1300 train_loss: 4.491759777069092 val_loss: 5.355988502502441\n",
      "epoch:  1400 train_loss: 4.388420104980469 val_loss: 5.282593250274658\n",
      "epoch:  1500 train_loss: 4.30782413482666 val_loss: 5.194371223449707\n",
      "epoch:  1600 train_loss: 4.2463459968566895 val_loss: 5.129140853881836\n",
      "epoch:  1700 train_loss: 4.1928277015686035 val_loss: 5.098437786102295\n",
      "epoch:  1800 train_loss: 4.164423942565918 val_loss: 5.085890293121338\n",
      "epoch:  1900 train_loss: 4.108582973480225 val_loss: 5.016585826873779\n",
      "epoch:  2000 train_loss: 4.0749311447143555 val_loss: 4.992819309234619\n",
      "epoch:  2100 train_loss: 4.040448188781738 val_loss: 4.960147380828857\n",
      "epoch:  2200 train_loss: 4.02130126953125 val_loss: 4.946704387664795\n",
      "epoch:  2300 train_loss: 3.991514205932617 val_loss: 4.923770904541016\n",
      "epoch:  2400 train_loss: 3.9604787826538086 val_loss: 4.879791259765625\n",
      "epoch:  2500 train_loss: 3.9397895336151123 val_loss: 4.850367069244385\n",
      "epoch:  2600 train_loss: 3.9177138805389404 val_loss: 4.846884727478027\n",
      "epoch:  2700 train_loss: 3.8949294090270996 val_loss: 4.825270652770996\n",
      "epoch:  2800 train_loss: 3.8846354484558105 val_loss: 4.8304762840271\n",
      "epoch:  2900 train_loss: 3.8555819988250732 val_loss: 4.786221504211426\n",
      "epoch:  3000 train_loss: 3.8659560680389404 val_loss: 4.802953243255615\n",
      "epoch:  3100 train_loss: 3.882066011428833 val_loss: 4.834971904754639\n",
      "epoch:  3200 train_loss: 3.8859448432922363 val_loss: 4.739352703094482\n",
      "epoch:  3300 train_loss: 3.981748104095459 val_loss: 4.846939563751221\n",
      "epoch:  3400 train_loss: 3.780196189880371 val_loss: 4.667865753173828\n",
      "epoch:  3500 train_loss: 3.8345947265625 val_loss: 4.675469875335693\n",
      "epoch:  3600 train_loss: 4.044260501861572 val_loss: 4.952884197235107\n",
      "epoch:  3700 train_loss: 3.668610095977783 val_loss: 4.594191551208496\n",
      "epoch:  3800 train_loss: 3.6837708950042725 val_loss: 4.569822311401367\n",
      "epoch:  3900 train_loss: 3.646327495574951 val_loss: 4.56196928024292\n",
      "epoch:  4000 train_loss: 3.611825466156006 val_loss: 4.614012718200684\n",
      "epoch:  4100 train_loss: 3.5742785930633545 val_loss: 4.584323406219482\n",
      "epoch:  4200 train_loss: 3.5781540870666504 val_loss: 4.578619003295898\n",
      "epoch:  4300 train_loss: 3.9564666748046875 val_loss: 5.008996963500977\n",
      "epoch:  4400 train_loss: 3.5156822204589844 val_loss: 4.572673797607422\n",
      "epoch:  4500 train_loss: 3.496835470199585 val_loss: 4.596161365509033\n",
      "epoch:  4600 train_loss: 3.4894397258758545 val_loss: 4.586633205413818\n",
      "epoch:  4700 train_loss: 3.460371494293213 val_loss: 4.613646030426025\n",
      "epoch:  4800 train_loss: 3.665362596511841 val_loss: 4.686559200286865\n",
      "epoch:  4900 train_loss: 3.629728317260742 val_loss: 4.757735729217529\n",
      "epoch:  5000 train_loss: 3.4167752265930176 val_loss: 4.632167339324951\n",
      "epoch:  5100 train_loss: 3.379585027694702 val_loss: 4.668613433837891\n",
      "epoch:  5200 train_loss: 3.5650012493133545 val_loss: 4.994790554046631\n",
      "epoch:  5300 train_loss: 3.4886138439178467 val_loss: 4.779308319091797\n",
      "epoch:  5400 train_loss: 3.325774908065796 val_loss: 4.713489055633545\n",
      "epoch:  5500 train_loss: 3.3019485473632812 val_loss: 4.721351623535156\n",
      "epoch:  5600 train_loss: 3.27630877494812 val_loss: 4.749063491821289\n",
      "epoch:  5700 train_loss: 3.3197591304779053 val_loss: 4.759547710418701\n",
      "epoch:  5800 train_loss: 3.257772922515869 val_loss: 4.838266372680664\n",
      "epoch:  5900 train_loss: 3.2121734619140625 val_loss: 4.802947044372559\n",
      "epoch:  6000 train_loss: 3.242633819580078 val_loss: 4.794527053833008\n",
      "epoch:  6100 train_loss: 3.179027795791626 val_loss: 4.924149036407471\n",
      "epoch:  6200 train_loss: 3.204941987991333 val_loss: 5.004637241363525\n",
      "epoch:  6300 train_loss: 3.264755964279175 val_loss: 4.995706558227539\n",
      "epoch:  6400 train_loss: 3.103487253189087 val_loss: 4.982679843902588\n",
      "epoch:  6500 train_loss: 3.116755247116089 val_loss: 5.001710414886475\n",
      "epoch:  6600 train_loss: 3.142716884613037 val_loss: 5.153764724731445\n",
      "epoch:  6700 train_loss: 3.1718485355377197 val_loss: 5.114283084869385\n",
      "epoch:  6800 train_loss: 3.0608134269714355 val_loss: 5.054095268249512\n",
      "epoch:  6900 train_loss: 3.0652518272399902 val_loss: 5.108330249786377\n",
      "epoch:  7000 train_loss: 3.0448312759399414 val_loss: 5.095016956329346\n",
      "epoch:  7100 train_loss: 3.0039215087890625 val_loss: 5.099347114562988\n",
      "epoch:  7200 train_loss: 2.9836952686309814 val_loss: 5.21537446975708\n",
      "epoch:  7300 train_loss: 3.013730049133301 val_loss: 5.1876115798950195\n",
      "epoch:  7400 train_loss: 3.0804357528686523 val_loss: 5.400165557861328\n",
      "epoch:  7500 train_loss: 2.9444103240966797 val_loss: 5.244883060455322\n",
      "epoch:  7600 train_loss: 3.083744764328003 val_loss: 5.443436145782471\n",
      "epoch:  7700 train_loss: 3.056079626083374 val_loss: 5.299676895141602\n",
      "epoch:  7800 train_loss: 2.879600763320923 val_loss: 5.252501010894775\n",
      "epoch:  7900 train_loss: 2.9306137561798096 val_loss: 5.34909200668335\n",
      "epoch:  8000 train_loss: 2.8809945583343506 val_loss: 5.343554496765137\n",
      "epoch:  8100 train_loss: 2.9084224700927734 val_loss: 5.406728267669678\n",
      "epoch:  8200 train_loss: 2.8461759090423584 val_loss: 5.356755256652832\n",
      "epoch:  8300 train_loss: 3.178097724914551 val_loss: 5.537115097045898\n",
      "epoch:  8400 train_loss: 2.950852870941162 val_loss: 5.589322090148926\n",
      "epoch:  8500 train_loss: 3.3626883029937744 val_loss: 6.213019371032715\n",
      "epoch:  8600 train_loss: 2.8458163738250732 val_loss: 5.518375873565674\n",
      "epoch:  8700 train_loss: 2.7512145042419434 val_loss: 5.439726829528809\n",
      "epoch:  8800 train_loss: 2.8505795001983643 val_loss: 5.539811134338379\n",
      "epoch:  8900 train_loss: 2.7996881008148193 val_loss: 5.49008846282959\n",
      "epoch:  9000 train_loss: 2.78041672706604 val_loss: 5.592060565948486\n",
      "epoch:  9100 train_loss: 2.820142984390259 val_loss: 5.6458845138549805\n",
      "epoch:  9200 train_loss: 2.697833776473999 val_loss: 5.507447719573975\n",
      "epoch:  9300 train_loss: 2.8719301223754883 val_loss: 5.724775314331055\n",
      "epoch:  9400 train_loss: 2.7289185523986816 val_loss: 5.599906921386719\n",
      "epoch:  9500 train_loss: 2.717914581298828 val_loss: 5.620703220367432\n",
      "epoch:  9600 train_loss: 2.7618825435638428 val_loss: 5.555357456207275\n",
      "epoch:  9700 train_loss: 2.6401174068450928 val_loss: 5.616656303405762\n",
      "epoch:  9800 train_loss: 2.6882710456848145 val_loss: 5.646673202514648\n",
      "epoch:  9900 train_loss: 2.717879056930542 val_loss: 5.695488929748535\n",
      "epoch:  10000 train_loss: 2.615001678466797 val_loss: 5.621789932250977\n",
      "epoch:  10100 train_loss: 2.6067709922790527 val_loss: 5.648741245269775\n",
      "epoch:  10200 train_loss: 2.6073427200317383 val_loss: 5.681528091430664\n",
      "epoch:  10300 train_loss: 3.1552512645721436 val_loss: 6.3724775314331055\n",
      "epoch:  10400 train_loss: 2.596649646759033 val_loss: 5.730964660644531\n",
      "epoch:  10500 train_loss: 2.714901924133301 val_loss: 5.907004356384277\n",
      "epoch:  10600 train_loss: 2.592421293258667 val_loss: 5.739129543304443\n",
      "epoch:  10700 train_loss: 2.563551187515259 val_loss: 5.773190975189209\n",
      "epoch:  10800 train_loss: 2.5949018001556396 val_loss: 5.838276386260986\n",
      "epoch:  10900 train_loss: 2.673131227493286 val_loss: 5.861980438232422\n",
      "epoch:  11000 train_loss: 2.644590377807617 val_loss: 5.887230396270752\n",
      "epoch:  11100 train_loss: 2.5062246322631836 val_loss: 5.797008514404297\n",
      "epoch:  11200 train_loss: 2.7914888858795166 val_loss: 6.22145414352417\n",
      "epoch:  11300 train_loss: 2.555366277694702 val_loss: 5.959603786468506\n",
      "epoch:  11400 train_loss: 2.493117570877075 val_loss: 5.855223655700684\n",
      "epoch:  11500 train_loss: 2.4900732040405273 val_loss: 5.868597030639648\n",
      "epoch:  11600 train_loss: 2.6379096508026123 val_loss: 5.9276909828186035\n",
      "epoch:  11700 train_loss: 2.4725120067596436 val_loss: 5.884098529815674\n",
      "epoch:  11800 train_loss: 2.554111957550049 val_loss: 5.968961715698242\n",
      "epoch:  11900 train_loss: 2.450169801712036 val_loss: 5.946040153503418\n",
      "epoch:  12000 train_loss: 2.551074743270874 val_loss: 6.009097576141357\n",
      "epoch:  12100 train_loss: 2.7805979251861572 val_loss: 6.31950044631958\n",
      "epoch:  12200 train_loss: 2.581407308578491 val_loss: 6.074244976043701\n",
      "epoch:  12300 train_loss: 2.504913091659546 val_loss: 6.039773464202881\n",
      "epoch:  12400 train_loss: 2.5039844512939453 val_loss: 6.035494804382324\n",
      "epoch:  12500 train_loss: 2.5042898654937744 val_loss: 6.063080787658691\n",
      "epoch:  12600 train_loss: 2.4393084049224854 val_loss: 6.025391101837158\n",
      "epoch:  12700 train_loss: 2.4105539321899414 val_loss: 5.970439434051514\n",
      "epoch:  12800 train_loss: 2.4335498809814453 val_loss: 6.045084476470947\n",
      "epoch:  12900 train_loss: 2.425574779510498 val_loss: 6.042488098144531\n",
      "epoch:  13000 train_loss: 2.5284602642059326 val_loss: 6.184056282043457\n",
      "epoch:  13100 train_loss: 2.417271375656128 val_loss: 6.040802955627441\n",
      "epoch:  13200 train_loss: 2.554563522338867 val_loss: 6.089051723480225\n",
      "epoch:  13300 train_loss: 2.4079384803771973 val_loss: 6.12983512878418\n",
      "epoch:  13400 train_loss: 2.36689829826355 val_loss: 6.1382293701171875\n",
      "epoch:  13500 train_loss: 2.5850272178649902 val_loss: 6.236667156219482\n",
      "epoch:  13600 train_loss: 2.434213399887085 val_loss: 6.205618858337402\n",
      "epoch:  13700 train_loss: 2.49489164352417 val_loss: 6.2081379890441895\n",
      "epoch:  13800 train_loss: 2.8476431369781494 val_loss: 6.707830905914307\n",
      "epoch:  13900 train_loss: 2.3175265789031982 val_loss: 6.139584064483643\n",
      "epoch:  14000 train_loss: 2.4014036655426025 val_loss: 6.252897262573242\n",
      "epoch:  14100 train_loss: 2.2764828205108643 val_loss: 6.11308479309082\n",
      "epoch:  14200 train_loss: 2.296217441558838 val_loss: 6.209314346313477\n",
      "epoch:  14300 train_loss: 2.486783266067505 val_loss: 6.298010349273682\n",
      "epoch:  14400 train_loss: 2.384352922439575 val_loss: 6.384171009063721\n",
      "epoch:  14500 train_loss: 2.3311612606048584 val_loss: 6.206754684448242\n",
      "epoch:  14600 train_loss: 2.9163594245910645 val_loss: 6.774823188781738\n",
      "epoch:  14700 train_loss: 2.2766146659851074 val_loss: 6.232412338256836\n",
      "epoch:  14800 train_loss: 2.34645676612854 val_loss: 6.346482276916504\n",
      "epoch:  14900 train_loss: 2.2927095890045166 val_loss: 6.328402519226074\n",
      "epoch:  15000 train_loss: 2.223116636276245 val_loss: 6.297950267791748\n",
      "epoch:  15100 train_loss: 2.31701397895813 val_loss: 6.333695888519287\n",
      "epoch:  15200 train_loss: 2.203066349029541 val_loss: 6.30882453918457\n",
      "epoch:  15300 train_loss: 2.251771926879883 val_loss: 6.281774997711182\n",
      "epoch:  15400 train_loss: 2.8318440914154053 val_loss: 7.13337516784668\n",
      "epoch:  15500 train_loss: 2.294982433319092 val_loss: 6.399992942810059\n",
      "epoch:  15600 train_loss: 2.3257575035095215 val_loss: 6.320441722869873\n",
      "epoch:  15700 train_loss: 2.7293596267700195 val_loss: 6.8860087394714355\n",
      "epoch:  15800 train_loss: 2.2265214920043945 val_loss: 6.352790832519531\n",
      "epoch:  15900 train_loss: 2.17529296875 val_loss: 6.406271934509277\n",
      "epoch:  16000 train_loss: 2.211317539215088 val_loss: 6.465513229370117\n",
      "epoch:  16100 train_loss: 2.1918957233428955 val_loss: 6.450883388519287\n",
      "epoch:  16200 train_loss: 2.2498819828033447 val_loss: 6.457812786102295\n",
      "epoch:  16300 train_loss: 2.41086745262146 val_loss: 6.644818305969238\n",
      "epoch:  16400 train_loss: 2.1465187072753906 val_loss: 6.491003513336182\n",
      "epoch:  16500 train_loss: 2.1978025436401367 val_loss: 6.424699783325195\n",
      "epoch:  16600 train_loss: 2.2855539321899414 val_loss: 6.559443950653076\n",
      "epoch:  16700 train_loss: 2.186103343963623 val_loss: 6.455930709838867\n",
      "epoch:  16800 train_loss: 2.1287622451782227 val_loss: 6.483313083648682\n",
      "epoch:  16900 train_loss: 2.150113344192505 val_loss: 6.5951151847839355\n",
      "epoch:  17000 train_loss: 2.478299140930176 val_loss: 6.718070983886719\n",
      "epoch:  17100 train_loss: 2.2175419330596924 val_loss: 6.744922161102295\n",
      "epoch:  17200 train_loss: 2.2942638397216797 val_loss: 6.580749034881592\n",
      "epoch:  17300 train_loss: 2.2058768272399902 val_loss: 6.649049758911133\n",
      "epoch:  17400 train_loss: 3.30012845993042 val_loss: 8.00717830657959\n",
      "epoch:  17500 train_loss: 2.1382880210876465 val_loss: 6.615244388580322\n",
      "epoch:  17600 train_loss: 2.1531870365142822 val_loss: 6.649051666259766\n",
      "epoch:  17700 train_loss: 2.078014850616455 val_loss: 6.6781206130981445\n",
      "epoch:  17800 train_loss: 2.133434295654297 val_loss: 6.624772071838379\n",
      "epoch:  17900 train_loss: 2.072746992111206 val_loss: 6.722318649291992\n",
      "epoch:  18000 train_loss: 2.058574914932251 val_loss: 6.6360182762146\n",
      "epoch:  18100 train_loss: 2.2752952575683594 val_loss: 6.841123104095459\n",
      "epoch:  18200 train_loss: 2.0035135746002197 val_loss: 6.661972999572754\n",
      "epoch:  18300 train_loss: 2.3424317836761475 val_loss: 6.888340473175049\n",
      "epoch:  18400 train_loss: 2.0561721324920654 val_loss: 6.69681978225708\n",
      "epoch:  18500 train_loss: 2.012146472930908 val_loss: 6.672374725341797\n",
      "epoch:  18600 train_loss: 2.137678623199463 val_loss: 6.81797981262207\n",
      "epoch:  18700 train_loss: 1.9805145263671875 val_loss: 6.697054386138916\n",
      "epoch:  18800 train_loss: 2.1078126430511475 val_loss: 6.723344802856445\n",
      "epoch:  18900 train_loss: 2.0196645259857178 val_loss: 6.830258846282959\n",
      "epoch:  19000 train_loss: 2.00750470161438 val_loss: 6.8422651290893555\n",
      "epoch:  19100 train_loss: 2.1801328659057617 val_loss: 6.962613105773926\n",
      "epoch:  19200 train_loss: 2.0264430046081543 val_loss: 6.81720495223999\n",
      "epoch:  19300 train_loss: 2.203094244003296 val_loss: 7.03389835357666\n",
      "epoch:  19400 train_loss: 2.2672767639160156 val_loss: 6.929261207580566\n",
      "epoch:  19500 train_loss: 2.111176013946533 val_loss: 6.863579750061035\n",
      "epoch:  19600 train_loss: 2.273897171020508 val_loss: 7.023987770080566\n",
      "epoch:  19700 train_loss: 2.2243714332580566 val_loss: 7.133938789367676\n",
      "epoch:  19800 train_loss: 2.176994800567627 val_loss: 7.184915542602539\n",
      "epoch:  19900 train_loss: 1.9918078184127808 val_loss: 6.777106285095215\n",
      "epoch:  20000 train_loss: 1.9417626857757568 val_loss: 6.8614044189453125\n",
      "epoch:  20100 train_loss: 2.013780355453491 val_loss: 6.892556190490723\n",
      "epoch:  20200 train_loss: 1.9305336475372314 val_loss: 6.924551010131836\n",
      "epoch:  20300 train_loss: 2.000369071960449 val_loss: 6.940860748291016\n",
      "epoch:  20400 train_loss: 2.032191276550293 val_loss: 6.978074073791504\n",
      "epoch:  20500 train_loss: 2.0710673332214355 val_loss: 6.9742255210876465\n",
      "epoch:  20600 train_loss: 1.897579550743103 val_loss: 6.953841209411621\n",
      "epoch:  20700 train_loss: 1.9775152206420898 val_loss: 6.9764628410339355\n",
      "epoch:  20800 train_loss: 2.2886645793914795 val_loss: 7.304019451141357\n",
      "epoch:  20900 train_loss: 1.9952455759048462 val_loss: 6.959569454193115\n",
      "epoch:  21000 train_loss: 1.994455337524414 val_loss: 7.075948715209961\n",
      "epoch:  21100 train_loss: 1.880700707435608 val_loss: 6.924356937408447\n",
      "epoch:  21200 train_loss: 2.2739410400390625 val_loss: 7.211668014526367\n",
      "epoch:  21300 train_loss: 2.0965912342071533 val_loss: 7.140506744384766\n",
      "epoch:  21400 train_loss: 2.037367105484009 val_loss: 6.996081829071045\n",
      "epoch:  21500 train_loss: 2.0647494792938232 val_loss: 7.216118812561035\n",
      "epoch:  21600 train_loss: 2.0619053840637207 val_loss: 7.161666393280029\n",
      "epoch:  21700 train_loss: 1.8432483673095703 val_loss: 6.981657028198242\n",
      "epoch:  21800 train_loss: 1.8334758281707764 val_loss: 7.031712055206299\n",
      "epoch:  21900 train_loss: 1.9104259014129639 val_loss: 7.046493053436279\n",
      "epoch:  22000 train_loss: 1.8457903861999512 val_loss: 7.042417049407959\n",
      "epoch:  22100 train_loss: 2.0399909019470215 val_loss: 7.185347557067871\n",
      "epoch:  22200 train_loss: 1.8294850587844849 val_loss: 7.067671775817871\n",
      "epoch:  22300 train_loss: 2.0399012565612793 val_loss: 7.167417526245117\n",
      "epoch:  22400 train_loss: 1.9355171918869019 val_loss: 7.207924842834473\n",
      "epoch:  22500 train_loss: 2.0162343978881836 val_loss: 7.34990119934082\n",
      "epoch:  22600 train_loss: 2.0310773849487305 val_loss: 7.233140468597412\n",
      "epoch:  22700 train_loss: 2.007803440093994 val_loss: 7.227843761444092\n",
      "epoch:  22800 train_loss: 1.9952754974365234 val_loss: 7.405516624450684\n",
      "epoch:  22900 train_loss: 2.0222482681274414 val_loss: 7.3754167556762695\n",
      "epoch:  23000 train_loss: 2.0691237449645996 val_loss: 7.199161529541016\n",
      "epoch:  23100 train_loss: 1.8086693286895752 val_loss: 7.125380516052246\n",
      "epoch:  23200 train_loss: 1.8065297603607178 val_loss: 7.182497024536133\n",
      "epoch:  23300 train_loss: 2.1976120471954346 val_loss: 7.4895195960998535\n",
      "epoch:  23400 train_loss: 1.828245759010315 val_loss: 7.148707389831543\n",
      "epoch:  23500 train_loss: 1.9116179943084717 val_loss: 7.277589321136475\n",
      "epoch:  23600 train_loss: 2.0277786254882812 val_loss: 7.360414505004883\n",
      "epoch:  23700 train_loss: 1.8446063995361328 val_loss: 7.177466869354248\n",
      "epoch:  23800 train_loss: 1.941725254058838 val_loss: 7.377547740936279\n",
      "epoch:  23900 train_loss: 1.9436306953430176 val_loss: 7.357694625854492\n",
      "epoch:  24000 train_loss: 1.7844336032867432 val_loss: 7.259993076324463\n",
      "epoch:  24100 train_loss: 1.9963855743408203 val_loss: 7.274781227111816\n",
      "epoch:  24200 train_loss: 1.888671636581421 val_loss: 7.309296607971191\n",
      "epoch:  24300 train_loss: 1.9773566722869873 val_loss: 7.541297912597656\n",
      "epoch:  24400 train_loss: 1.7807831764221191 val_loss: 7.296626567840576\n",
      "epoch:  24500 train_loss: 2.267171859741211 val_loss: 7.606977939605713\n",
      "epoch:  24600 train_loss: 1.8845524787902832 val_loss: 7.430256366729736\n",
      "epoch:  24700 train_loss: 1.7623207569122314 val_loss: 7.288284778594971\n",
      "epoch:  24800 train_loss: 1.9096500873565674 val_loss: 7.555102348327637\n",
      "epoch:  24900 train_loss: 1.7261204719543457 val_loss: 7.353360652923584\n",
      "epoch:  25000 train_loss: 1.721179485321045 val_loss: 7.3068742752075195\n",
      "epoch:  25100 train_loss: 1.858992099761963 val_loss: 7.341943740844727\n",
      "epoch:  25200 train_loss: 1.90931236743927 val_loss: 7.516506671905518\n",
      "epoch:  25300 train_loss: 2.065340280532837 val_loss: 7.577271938323975\n",
      "epoch:  25400 train_loss: 1.8529707193374634 val_loss: 7.535768985748291\n",
      "epoch:  25500 train_loss: 1.7674474716186523 val_loss: 7.450599193572998\n",
      "epoch:  25600 train_loss: 1.84237802028656 val_loss: 7.514870643615723\n",
      "epoch:  25700 train_loss: 1.776695966720581 val_loss: 7.492971420288086\n",
      "epoch:  25800 train_loss: 1.7463064193725586 val_loss: 7.431656360626221\n",
      "epoch:  25900 train_loss: 2.0283405780792236 val_loss: 7.751548767089844\n",
      "epoch:  26000 train_loss: 1.710213541984558 val_loss: 7.405894756317139\n",
      "epoch:  26100 train_loss: 1.795478343963623 val_loss: 7.525729179382324\n",
      "epoch:  26200 train_loss: 2.4628233909606934 val_loss: 7.979555130004883\n",
      "epoch:  26300 train_loss: 1.766463041305542 val_loss: 7.522937297821045\n",
      "epoch:  26400 train_loss: 1.6724227666854858 val_loss: 7.408908367156982\n",
      "epoch:  26500 train_loss: 2.1763718128204346 val_loss: 7.826098442077637\n",
      "epoch:  26600 train_loss: 1.7322288751602173 val_loss: 7.5034403800964355\n",
      "epoch:  26700 train_loss: 1.7733796834945679 val_loss: 7.61336088180542\n",
      "epoch:  26800 train_loss: 1.6443883180618286 val_loss: 7.467707633972168\n",
      "epoch:  26900 train_loss: 1.8092801570892334 val_loss: 7.6835103034973145\n",
      "epoch:  27000 train_loss: 1.6357181072235107 val_loss: 7.485652923583984\n",
      "epoch:  27100 train_loss: 1.637696385383606 val_loss: 7.502546787261963\n",
      "epoch:  27200 train_loss: 1.6871252059936523 val_loss: 7.534522533416748\n",
      "epoch:  27300 train_loss: 1.784374713897705 val_loss: 7.630587577819824\n",
      "epoch:  27400 train_loss: 1.68190336227417 val_loss: 7.553920745849609\n",
      "epoch:  27500 train_loss: 2.036642074584961 val_loss: 7.914202690124512\n",
      "epoch:  27600 train_loss: 2.022629737854004 val_loss: 7.950118541717529\n",
      "epoch:  27700 train_loss: 1.947401523590088 val_loss: 7.797290802001953\n",
      "epoch:  27800 train_loss: 1.6341866254806519 val_loss: 7.576865196228027\n",
      "epoch:  27900 train_loss: 2.21999454498291 val_loss: 8.089707374572754\n",
      "epoch:  28000 train_loss: 1.6302958726882935 val_loss: 7.558340072631836\n",
      "epoch:  28100 train_loss: 1.706053376197815 val_loss: 7.695321559906006\n",
      "epoch:  28200 train_loss: 1.774614691734314 val_loss: 7.666144847869873\n",
      "epoch:  28300 train_loss: 1.7593815326690674 val_loss: 7.709433078765869\n",
      "epoch:  28400 train_loss: 1.6607609987258911 val_loss: 7.695273399353027\n",
      "epoch:  28500 train_loss: 1.6741958856582642 val_loss: 7.748509407043457\n",
      "epoch:  28600 train_loss: 1.6543405055999756 val_loss: 7.68537712097168\n",
      "epoch:  28700 train_loss: 1.6692532300949097 val_loss: 7.6419196128845215\n",
      "epoch:  28800 train_loss: 1.826706886291504 val_loss: 7.860438346862793\n",
      "epoch:  28900 train_loss: 1.9591407775878906 val_loss: 7.918483257293701\n",
      "epoch:  29000 train_loss: 1.7628939151763916 val_loss: 7.694919586181641\n",
      "epoch:  29100 train_loss: 1.58433198928833 val_loss: 7.632652282714844\n",
      "epoch:  29200 train_loss: 1.6358884572982788 val_loss: 7.689636707305908\n",
      "epoch:  29300 train_loss: 1.722701072692871 val_loss: 7.755518913269043\n",
      "epoch:  29400 train_loss: 1.8651708364486694 val_loss: 7.8614020347595215\n",
      "epoch:  29500 train_loss: 1.677491307258606 val_loss: 7.79646635055542\n",
      "epoch:  29600 train_loss: 1.9326308965682983 val_loss: 8.207352638244629\n",
      "epoch:  29700 train_loss: 1.5596983432769775 val_loss: 7.703489780426025\n",
      "epoch:  29800 train_loss: 1.5906848907470703 val_loss: 7.733193397521973\n",
      "epoch:  29900 train_loss: 1.638656497001648 val_loss: 7.7023844718933105\n",
      "epoch:  30000 train_loss: 1.8289636373519897 val_loss: 7.941864013671875\n",
      "epoch:  30100 train_loss: 1.6538753509521484 val_loss: 7.857348442077637\n",
      "epoch:  30200 train_loss: 1.5379623174667358 val_loss: 7.715433120727539\n",
      "epoch:  30300 train_loss: 1.6984877586364746 val_loss: 7.895840644836426\n",
      "epoch:  30400 train_loss: 1.602282166481018 val_loss: 7.780154705047607\n",
      "epoch:  30500 train_loss: 1.6918457746505737 val_loss: 7.906603813171387\n",
      "epoch:  30600 train_loss: 1.6746735572814941 val_loss: 7.904124736785889\n",
      "epoch:  30700 train_loss: 1.7484983205795288 val_loss: 7.956876277923584\n",
      "epoch:  30800 train_loss: 1.6713166236877441 val_loss: 7.902622222900391\n",
      "epoch:  30900 train_loss: 1.8033194541931152 val_loss: 8.092514038085938\n",
      "epoch:  31000 train_loss: 1.65593683719635 val_loss: 7.804843425750732\n",
      "epoch:  31100 train_loss: 1.973137617111206 val_loss: 8.241975784301758\n",
      "epoch:  31200 train_loss: 1.6452938318252563 val_loss: 7.843451023101807\n",
      "epoch:  31300 train_loss: 2.1078054904937744 val_loss: 8.465534210205078\n",
      "epoch:  31400 train_loss: 1.5153179168701172 val_loss: 7.858665466308594\n",
      "epoch:  31500 train_loss: 1.6521921157836914 val_loss: 7.833932399749756\n",
      "epoch:  31600 train_loss: 1.5934611558914185 val_loss: 8.029809951782227\n",
      "epoch:  31700 train_loss: 1.6700963973999023 val_loss: 7.94313907623291\n",
      "epoch:  31800 train_loss: 1.6377582550048828 val_loss: 8.114898681640625\n",
      "epoch:  31900 train_loss: 1.559517502784729 val_loss: 7.951765537261963\n",
      "epoch:  32000 train_loss: 1.6224254369735718 val_loss: 7.995383262634277\n",
      "epoch:  32100 train_loss: 1.6601803302764893 val_loss: 7.951740741729736\n",
      "epoch:  32200 train_loss: 1.5069764852523804 val_loss: 7.863842010498047\n",
      "epoch:  32300 train_loss: 1.509941816329956 val_loss: 7.904768466949463\n",
      "epoch:  32400 train_loss: 1.471380352973938 val_loss: 7.84396505355835\n",
      "epoch:  32500 train_loss: 1.6013939380645752 val_loss: 7.960537433624268\n",
      "epoch:  32600 train_loss: 1.8248416185379028 val_loss: 8.08249568939209\n",
      "epoch:  32700 train_loss: 1.4995160102844238 val_loss: 8.000290870666504\n",
      "epoch:  32800 train_loss: 1.9660580158233643 val_loss: 8.521415710449219\n",
      "epoch:  32900 train_loss: 2.0065479278564453 val_loss: 8.489466667175293\n",
      "epoch:  33000 train_loss: 1.590695858001709 val_loss: 8.044099807739258\n",
      "epoch:  33100 train_loss: 1.69330632686615 val_loss: 8.040559768676758\n",
      "epoch:  33200 train_loss: 1.7490463256835938 val_loss: 8.147276878356934\n",
      "epoch:  33300 train_loss: 1.4770201444625854 val_loss: 7.940504550933838\n",
      "epoch:  33400 train_loss: 1.4981541633605957 val_loss: 7.932833194732666\n",
      "epoch:  33500 train_loss: 2.0077733993530273 val_loss: 8.461088180541992\n",
      "epoch:  33600 train_loss: 1.496224284172058 val_loss: 7.985252380371094\n",
      "epoch:  33700 train_loss: 1.6390150785446167 val_loss: 8.067675590515137\n",
      "epoch:  33800 train_loss: 1.681103229522705 val_loss: 8.19367504119873\n",
      "epoch:  33900 train_loss: 1.5364892482757568 val_loss: 7.990877151489258\n",
      "epoch:  34000 train_loss: 1.5302438735961914 val_loss: 7.988670349121094\n",
      "epoch:  34100 train_loss: 1.640825629234314 val_loss: 8.113932609558105\n",
      "epoch:  34200 train_loss: 1.6948446035385132 val_loss: 8.212079048156738\n",
      "epoch:  34300 train_loss: 1.450376272201538 val_loss: 8.015219688415527\n",
      "epoch:  34400 train_loss: 1.6941123008728027 val_loss: 8.193487167358398\n",
      "epoch:  34500 train_loss: 1.4973615407943726 val_loss: 8.057825088500977\n",
      "epoch:  34600 train_loss: 2.094834804534912 val_loss: 8.676627159118652\n",
      "epoch:  34700 train_loss: 1.5791723728179932 val_loss: 8.280935287475586\n",
      "epoch:  34800 train_loss: 1.6940079927444458 val_loss: 8.145989418029785\n",
      "epoch:  34900 train_loss: 1.3996034860610962 val_loss: 8.03175163269043\n",
      "epoch:  35000 train_loss: 1.4461174011230469 val_loss: 8.034442901611328\n",
      "epoch:  35100 train_loss: 2.118746280670166 val_loss: 8.708175659179688\n",
      "epoch:  35200 train_loss: 1.6282751560211182 val_loss: 8.197628021240234\n",
      "epoch:  35300 train_loss: 1.6469401121139526 val_loss: 8.314595222473145\n",
      "epoch:  35400 train_loss: 1.5221964120864868 val_loss: 8.115837097167969\n",
      "epoch:  35500 train_loss: 1.403841495513916 val_loss: 8.038701057434082\n",
      "epoch:  35600 train_loss: 1.502303123474121 val_loss: 8.207023620605469\n",
      "epoch:  35700 train_loss: 1.3889578580856323 val_loss: 8.056391716003418\n",
      "epoch:  35800 train_loss: 1.6745753288269043 val_loss: 8.480525016784668\n",
      "epoch:  35900 train_loss: 1.641771674156189 val_loss: 8.266977310180664\n",
      "RMSE:  tensor(4.6365, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Ganerate the dataset\n",
    "i = 0\n",
    "sigma = 3.7\n",
    "my_dataset = []\n",
    "for ud in UDs:\n",
    "    example = []\n",
    "    for an in ANs:\n",
    "        noise = np.random.normal(0,sigma)\n",
    "        # 0 is mean\n",
    "        # sigma is the deviation of the normal distribution\n",
    "        d = compute_3d_distance(ud, an) + noise\n",
    "        example.append(d)\n",
    "    \n",
    "    # append x, y, z as col#10, #11, #12\n",
    "    example.append(ud[0])\n",
    "    example.append(ud[1])\n",
    "    example.append(ud[2])\n",
    "    \n",
    "    # append 1x13 example row into my_dataset\n",
    "    my_dataset.append(example)  # expected to be 3000x13  \n",
    "    \n",
    "# Load dataset\n",
    "exercise3_dataset = Exercise3Dataset(list_dataset = my_dataset, shuffle=True)\n",
    "\n",
    "#Split dataset by 0.8: 0.1: 0.1\n",
    "train_examples, train_labels = exercise3_dataset[:int(3000*0.8)]  # (2400, 10)   # (2400, 3)\n",
    "val_examples, val_labels = exercise3_dataset[int(3000*0.8):int(3000*0.9)]    # (300, 10)   #(300, 3)\n",
    "test_examples, test_labels = exercise3_dataset[int(3000*0.9):]     #(300, 10)   # (300, 3)\n",
    "\n",
    "###Define model, loss function and optimizer\n",
    "# if we have GPU, then use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define model\n",
    "model = Net(x_dim = train_examples.shape[1], y_dim = train_labels.shape[1]).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training and Validation\n",
    "\n",
    "train_examples = train_examples.to(device)\n",
    "train_labels = train_labels.to(device)\n",
    "val_examples = val_examples.to(device)\n",
    "val_labels = val_labels.to(device)\n",
    "\n",
    "# Define the model filename for model.save()\n",
    "MODEL_FILENAME = \"best.pth\"\n",
    "\n",
    "# set model to Training mode\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "NUM_OF_EPOCH = 36000\n",
    "\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    y_pred = model(train_examples)\n",
    "    loss = loss_fn(y_pred, train_labels).cpu()\n",
    "    #print(t, loss.item())\n",
    "    train_losses.append(loss.item())\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    # BGD\n",
    "    optimizer.step()\n",
    "    \n",
    "    # evaluate validation loss\n",
    "    val_pred = model(val_examples)\n",
    "    loss = loss_fn(val_pred, val_labels)\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "    # check if we got better loss\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n",
    "\n",
    "    if (epoch % 100) == 0:\n",
    "        print(\"epoch: \", epoch, \"train_loss:\", train_losses[-1], \"val_loss:\", val_losses[-1])\n",
    "        \n",
    "# Inference all testing examples and compute RMSE\n",
    "def square_error(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  square_error= loss_fn(a, b)\n",
    "  return square_error\n",
    "\n",
    "model.eval() # inference mode\n",
    "test_examples = test_examples.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "test_preds = model(test_examples)\n",
    "#print(\"example: \", test_example.cpu())\n",
    "#print(\"========================================\")\n",
    "#print(\"ground_truth:\", test_label.cpu())\n",
    "#print(\"prediction:\", test_pred.cpu())\n",
    "#print(\"========================================\")\n",
    "\n",
    "\n",
    "total_errors = 0.0\n",
    "for idx in range(len(test_examples)):\n",
    "    total_errors += square_error(test_preds[idx], test_labels[idx])\n",
    "    \n",
    "RMSE = torch.sqrt(total_errors / len(test_examples))\n",
    "print(\"RMSE: \",  RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigma = 4.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffle = True!\n",
      "epoch:  0 train_loss: 7342.66064453125 val_loss: 7374.267578125\n",
      "epoch:  100 train_loss: 170.90211486816406 val_loss: 169.40771484375\n",
      "epoch:  200 train_loss: 148.4254150390625 val_loss: 147.75857543945312\n",
      "epoch:  300 train_loss: 84.07405853271484 val_loss: 82.43160247802734\n",
      "epoch:  400 train_loss: 22.96438217163086 val_loss: 23.543363571166992\n",
      "epoch:  500 train_loss: 11.471840858459473 val_loss: 12.23088550567627\n",
      "epoch:  600 train_loss: 9.713532447814941 val_loss: 10.557140350341797\n",
      "epoch:  700 train_loss: 8.917950630187988 val_loss: 9.817435264587402\n",
      "epoch:  800 train_loss: 8.392415046691895 val_loss: 9.342246055603027\n",
      "epoch:  900 train_loss: 7.997124671936035 val_loss: 8.983774185180664\n",
      "epoch:  1000 train_loss: 7.679679870605469 val_loss: 8.702862739562988\n",
      "epoch:  1100 train_loss: 7.423107624053955 val_loss: 8.477741241455078\n",
      "epoch:  1200 train_loss: 7.2090349197387695 val_loss: 8.287100791931152\n",
      "epoch:  1300 train_loss: 7.027744293212891 val_loss: 8.101252555847168\n",
      "epoch:  1400 train_loss: 6.856935024261475 val_loss: 7.940809726715088\n",
      "epoch:  1500 train_loss: 6.711160659790039 val_loss: 7.801354885101318\n",
      "epoch:  1600 train_loss: 6.584625720977783 val_loss: 7.682335376739502\n",
      "epoch:  1700 train_loss: 6.474044322967529 val_loss: 7.591357707977295\n",
      "epoch:  1800 train_loss: 6.371342182159424 val_loss: 7.504222869873047\n",
      "epoch:  1900 train_loss: 6.280113220214844 val_loss: 7.43314790725708\n",
      "epoch:  2000 train_loss: 6.198827266693115 val_loss: 7.365769386291504\n",
      "epoch:  2100 train_loss: 6.118502140045166 val_loss: 7.302405834197998\n",
      "epoch:  2200 train_loss: 6.04606294631958 val_loss: 7.25254487991333\n",
      "epoch:  2300 train_loss: 5.972792625427246 val_loss: 7.186775207519531\n",
      "epoch:  2400 train_loss: 5.908260822296143 val_loss: 7.152082920074463\n",
      "epoch:  2500 train_loss: 5.843657970428467 val_loss: 7.110763072967529\n",
      "epoch:  2600 train_loss: 5.780771732330322 val_loss: 7.065433979034424\n",
      "epoch:  2700 train_loss: 5.721749782562256 val_loss: 7.028079509735107\n",
      "epoch:  2800 train_loss: 5.662701606750488 val_loss: 7.005041599273682\n",
      "epoch:  2900 train_loss: 5.613215923309326 val_loss: 6.992095470428467\n",
      "epoch:  3000 train_loss: 5.549760341644287 val_loss: 6.965432643890381\n",
      "epoch:  3100 train_loss: 5.491619110107422 val_loss: 6.947877883911133\n",
      "epoch:  3200 train_loss: 5.434924125671387 val_loss: 6.9380693435668945\n",
      "epoch:  3300 train_loss: 5.382871150970459 val_loss: 6.941832542419434\n",
      "epoch:  3400 train_loss: 5.3339433670043945 val_loss: 6.943359375\n",
      "epoch:  3500 train_loss: 5.28012228012085 val_loss: 6.939174652099609\n",
      "epoch:  3600 train_loss: 5.233649730682373 val_loss: 6.954262733459473\n",
      "epoch:  3700 train_loss: 5.188996315002441 val_loss: 6.957597732543945\n",
      "epoch:  3800 train_loss: 5.135032653808594 val_loss: 6.952902793884277\n",
      "epoch:  3900 train_loss: 5.085936546325684 val_loss: 7.009167194366455\n",
      "epoch:  4000 train_loss: 5.0604939460754395 val_loss: 7.051522731781006\n",
      "epoch:  4100 train_loss: 5.069911003112793 val_loss: 7.16007137298584\n",
      "epoch:  4200 train_loss: 4.937230110168457 val_loss: 7.110802173614502\n",
      "epoch:  4300 train_loss: 4.892980575561523 val_loss: 7.132132530212402\n",
      "epoch:  4400 train_loss: 4.859951972961426 val_loss: 7.209763526916504\n",
      "epoch:  4500 train_loss: 4.823306560516357 val_loss: 7.211315155029297\n",
      "epoch:  4600 train_loss: 4.8406500816345215 val_loss: 7.273540019989014\n",
      "epoch:  4700 train_loss: 4.709486484527588 val_loss: 7.305069446563721\n",
      "epoch:  4800 train_loss: 4.762569427490234 val_loss: 7.425448894500732\n",
      "epoch:  4900 train_loss: 4.65450382232666 val_loss: 7.447479724884033\n",
      "epoch:  5000 train_loss: 4.900429725646973 val_loss: 7.67801570892334\n",
      "epoch:  5100 train_loss: 4.783635139465332 val_loss: 7.631441116333008\n",
      "epoch:  5200 train_loss: 4.596631050109863 val_loss: 7.547641754150391\n",
      "epoch:  5300 train_loss: 4.488578796386719 val_loss: 7.602215766906738\n",
      "epoch:  5400 train_loss: 4.5162353515625 val_loss: 7.625582695007324\n",
      "epoch:  5500 train_loss: 4.423849582672119 val_loss: 7.6392059326171875\n",
      "epoch:  5600 train_loss: 4.57570743560791 val_loss: 7.970453262329102\n",
      "epoch:  5700 train_loss: 4.403382778167725 val_loss: 7.762971878051758\n",
      "epoch:  5800 train_loss: 4.749682426452637 val_loss: 7.981226921081543\n",
      "epoch:  5900 train_loss: 4.28334903717041 val_loss: 7.757948875427246\n",
      "epoch:  6000 train_loss: 4.341891765594482 val_loss: 7.933652400970459\n",
      "epoch:  6100 train_loss: 4.260757923126221 val_loss: 7.825052261352539\n",
      "epoch:  6200 train_loss: 4.188876152038574 val_loss: 7.830435276031494\n",
      "epoch:  6300 train_loss: 4.323709964752197 val_loss: 8.085830688476562\n",
      "epoch:  6400 train_loss: 4.182798862457275 val_loss: 8.029664039611816\n",
      "epoch:  6500 train_loss: 4.233674049377441 val_loss: 8.069382667541504\n",
      "epoch:  6600 train_loss: 4.758500099182129 val_loss: 8.6260404586792\n",
      "epoch:  6700 train_loss: 4.042722225189209 val_loss: 7.997770309448242\n",
      "epoch:  6800 train_loss: 4.042677879333496 val_loss: 8.066420555114746\n",
      "epoch:  6900 train_loss: 3.9897143840789795 val_loss: 8.097143173217773\n",
      "epoch:  7000 train_loss: 3.9896600246429443 val_loss: 8.122337341308594\n",
      "epoch:  7100 train_loss: 4.011210918426514 val_loss: 8.239667892456055\n",
      "epoch:  7200 train_loss: 4.083233833312988 val_loss: 8.27434253692627\n",
      "epoch:  7300 train_loss: 4.134366512298584 val_loss: 8.409924507141113\n",
      "epoch:  7400 train_loss: 3.940136194229126 val_loss: 8.265453338623047\n",
      "epoch:  7500 train_loss: 4.1532883644104 val_loss: 8.691967964172363\n",
      "epoch:  7600 train_loss: 3.846827268600464 val_loss: 8.2871732711792\n",
      "epoch:  7700 train_loss: 3.807664632797241 val_loss: 8.296215057373047\n",
      "epoch:  7800 train_loss: 3.772836923599243 val_loss: 8.331900596618652\n",
      "epoch:  7900 train_loss: 3.7591984272003174 val_loss: 8.344962120056152\n",
      "epoch:  8000 train_loss: 3.732675313949585 val_loss: 8.39242172241211\n",
      "epoch:  8100 train_loss: 3.699831008911133 val_loss: 8.362418174743652\n",
      "epoch:  8200 train_loss: 3.671318531036377 val_loss: 8.450091361999512\n",
      "epoch:  8300 train_loss: 3.715663433074951 val_loss: 8.558716773986816\n",
      "epoch:  8400 train_loss: 3.83245849609375 val_loss: 8.675172805786133\n",
      "epoch:  8500 train_loss: 3.8549466133117676 val_loss: 8.737951278686523\n",
      "epoch:  8600 train_loss: 3.8526644706726074 val_loss: 8.713811874389648\n",
      "epoch:  8700 train_loss: 4.440345287322998 val_loss: 9.311630249023438\n",
      "epoch:  8800 train_loss: 3.5630486011505127 val_loss: 8.598193168640137\n",
      "epoch:  8900 train_loss: 3.5664801597595215 val_loss: 8.66956901550293\n",
      "epoch:  9000 train_loss: 3.6447386741638184 val_loss: 8.703947067260742\n",
      "epoch:  9100 train_loss: 3.642653703689575 val_loss: 8.770740509033203\n",
      "epoch:  9200 train_loss: 3.9832417964935303 val_loss: 9.02586841583252\n",
      "epoch:  9300 train_loss: 3.6861464977264404 val_loss: 9.037470817565918\n",
      "epoch:  9400 train_loss: 3.467918872833252 val_loss: 8.839803695678711\n",
      "epoch:  9500 train_loss: 3.432382345199585 val_loss: 8.757781028747559\n",
      "epoch:  9600 train_loss: 3.392148733139038 val_loss: 8.774981498718262\n",
      "epoch:  9700 train_loss: 3.3745858669281006 val_loss: 8.7946138381958\n",
      "epoch:  9800 train_loss: 3.5413150787353516 val_loss: 8.874021530151367\n",
      "epoch:  9900 train_loss: 3.3959696292877197 val_loss: 8.950149536132812\n",
      "epoch:  10000 train_loss: 3.386842966079712 val_loss: 8.932964324951172\n",
      "epoch:  10100 train_loss: 3.308689594268799 val_loss: 8.91097640991211\n",
      "epoch:  10200 train_loss: 3.303826332092285 val_loss: 9.002630233764648\n",
      "epoch:  10300 train_loss: 3.3024141788482666 val_loss: 8.967745780944824\n",
      "epoch:  10400 train_loss: 3.4881439208984375 val_loss: 9.24195671081543\n",
      "epoch:  10500 train_loss: 3.3026177883148193 val_loss: 9.016740798950195\n",
      "epoch:  10600 train_loss: 3.447737216949463 val_loss: 9.237565040588379\n",
      "epoch:  10700 train_loss: 3.2260921001434326 val_loss: 8.98961353302002\n",
      "epoch:  10800 train_loss: 3.1966168880462646 val_loss: 9.045454978942871\n",
      "epoch:  10900 train_loss: 3.1926584243774414 val_loss: 9.041887283325195\n",
      "epoch:  11000 train_loss: 3.1537435054779053 val_loss: 9.057636260986328\n",
      "epoch:  11100 train_loss: 3.234952926635742 val_loss: 9.082109451293945\n",
      "epoch:  11200 train_loss: 3.430043935775757 val_loss: 9.278892517089844\n",
      "epoch:  11300 train_loss: 3.1613929271698 val_loss: 9.157902717590332\n",
      "epoch:  11400 train_loss: 3.1807444095611572 val_loss: 9.261445999145508\n",
      "epoch:  11500 train_loss: 3.21687650680542 val_loss: 9.177096366882324\n",
      "epoch:  11600 train_loss: 3.123502731323242 val_loss: 9.131258964538574\n",
      "epoch:  11700 train_loss: 3.8028721809387207 val_loss: 9.419637680053711\n",
      "epoch:  11800 train_loss: 3.240541458129883 val_loss: 9.396185874938965\n",
      "epoch:  11900 train_loss: 3.0949578285217285 val_loss: 9.361647605895996\n",
      "epoch:  12000 train_loss: 3.4095828533172607 val_loss: 9.606727600097656\n",
      "epoch:  12100 train_loss: 3.128523349761963 val_loss: 9.332374572753906\n",
      "epoch:  12200 train_loss: 3.175218105316162 val_loss: 9.563441276550293\n",
      "epoch:  12300 train_loss: 3.0023787021636963 val_loss: 9.240423202514648\n",
      "epoch:  12400 train_loss: 3.077256917953491 val_loss: 9.388972282409668\n",
      "epoch:  12500 train_loss: 3.5856473445892334 val_loss: 9.904871940612793\n",
      "epoch:  12600 train_loss: 2.9552409648895264 val_loss: 9.358992576599121\n",
      "epoch:  12700 train_loss: 3.254173755645752 val_loss: 9.862563133239746\n",
      "epoch:  12800 train_loss: 3.020395517349243 val_loss: 9.561559677124023\n",
      "epoch:  12900 train_loss: 2.9726736545562744 val_loss: 9.55295181274414\n",
      "epoch:  13000 train_loss: 3.2589616775512695 val_loss: 9.72679615020752\n",
      "epoch:  13100 train_loss: 3.543673276901245 val_loss: 9.808807373046875\n",
      "epoch:  13200 train_loss: 3.131695508956909 val_loss: 9.824926376342773\n",
      "epoch:  13300 train_loss: 2.9159677028656006 val_loss: 9.502697944641113\n",
      "epoch:  13400 train_loss: 4.488175868988037 val_loss: 10.479679107666016\n",
      "epoch:  13500 train_loss: 3.138815402984619 val_loss: 9.62358570098877\n",
      "epoch:  13600 train_loss: 2.8819878101348877 val_loss: 9.685776710510254\n",
      "epoch:  13700 train_loss: 2.8619143962860107 val_loss: 9.660810470581055\n",
      "epoch:  13800 train_loss: 2.8638577461242676 val_loss: 9.675488471984863\n",
      "epoch:  13900 train_loss: 2.8910748958587646 val_loss: 9.660865783691406\n",
      "epoch:  14000 train_loss: 2.964012622833252 val_loss: 9.603169441223145\n",
      "epoch:  14100 train_loss: 3.16117000579834 val_loss: 10.080376625061035\n",
      "epoch:  14200 train_loss: 2.9361047744750977 val_loss: 9.955349922180176\n",
      "epoch:  14300 train_loss: 2.8850209712982178 val_loss: 9.785290718078613\n",
      "epoch:  14400 train_loss: 2.8060147762298584 val_loss: 9.768779754638672\n",
      "epoch:  14500 train_loss: 3.1331489086151123 val_loss: 10.055008888244629\n",
      "epoch:  14600 train_loss: 3.0533528327941895 val_loss: 10.047150611877441\n",
      "epoch:  14700 train_loss: 2.7827136516571045 val_loss: 9.91344165802002\n",
      "epoch:  14800 train_loss: 2.71850323677063 val_loss: 9.78248405456543\n",
      "epoch:  14900 train_loss: 2.9882123470306396 val_loss: 10.011590957641602\n",
      "epoch:  15000 train_loss: 2.890838861465454 val_loss: 9.953611373901367\n",
      "epoch:  15100 train_loss: 2.806161880493164 val_loss: 9.98816204071045\n",
      "epoch:  15200 train_loss: 3.0426313877105713 val_loss: 10.27690315246582\n",
      "epoch:  15300 train_loss: 2.8586795330047607 val_loss: 10.124566078186035\n",
      "epoch:  15400 train_loss: 2.7272794246673584 val_loss: 9.908736228942871\n",
      "epoch:  15500 train_loss: 2.6975185871124268 val_loss: 9.963528633117676\n",
      "epoch:  15600 train_loss: 2.7284257411956787 val_loss: 10.102710723876953\n",
      "epoch:  15700 train_loss: 3.095104217529297 val_loss: 10.430789947509766\n",
      "epoch:  15800 train_loss: 2.6489474773406982 val_loss: 9.905648231506348\n",
      "epoch:  15900 train_loss: 2.6696951389312744 val_loss: 10.069443702697754\n",
      "epoch:  16000 train_loss: 2.6466116905212402 val_loss: 9.980968475341797\n",
      "epoch:  16100 train_loss: 3.126258134841919 val_loss: 10.688322067260742\n",
      "epoch:  16200 train_loss: 2.6296029090881348 val_loss: 9.978838920593262\n",
      "epoch:  16300 train_loss: 2.732356309890747 val_loss: 10.109772682189941\n",
      "epoch:  16400 train_loss: 2.611987352371216 val_loss: 10.100805282592773\n",
      "epoch:  16500 train_loss: 2.6989684104919434 val_loss: 10.09681224822998\n",
      "epoch:  16600 train_loss: 3.2635691165924072 val_loss: 10.853513717651367\n",
      "epoch:  16700 train_loss: 2.5911898612976074 val_loss: 10.153437614440918\n",
      "epoch:  16800 train_loss: 3.0005736351013184 val_loss: 10.53109359741211\n",
      "epoch:  16900 train_loss: 2.602325439453125 val_loss: 10.134384155273438\n",
      "epoch:  17000 train_loss: 2.786388874053955 val_loss: 10.370243072509766\n",
      "epoch:  17100 train_loss: 2.723273515701294 val_loss: 10.399410247802734\n",
      "epoch:  17200 train_loss: 2.531332015991211 val_loss: 10.141534805297852\n",
      "epoch:  17300 train_loss: 2.603074550628662 val_loss: 10.245789527893066\n",
      "epoch:  17400 train_loss: 3.063581705093384 val_loss: 10.687361717224121\n",
      "epoch:  17500 train_loss: 2.5461409091949463 val_loss: 10.201770782470703\n",
      "epoch:  17600 train_loss: 2.53692364692688 val_loss: 10.241327285766602\n",
      "epoch:  17700 train_loss: 2.6343483924865723 val_loss: 10.345935821533203\n",
      "epoch:  17800 train_loss: 2.5293185710906982 val_loss: 10.234060287475586\n",
      "epoch:  17900 train_loss: 2.6003830432891846 val_loss: 10.351547241210938\n",
      "epoch:  18000 train_loss: 2.739809036254883 val_loss: 10.523921966552734\n",
      "epoch:  18100 train_loss: 2.5135884284973145 val_loss: 10.334904670715332\n",
      "epoch:  18200 train_loss: 2.534499406814575 val_loss: 10.436686515808105\n",
      "epoch:  18300 train_loss: 2.4757368564605713 val_loss: 10.312209129333496\n",
      "epoch:  18400 train_loss: 2.4456403255462646 val_loss: 10.364742279052734\n",
      "epoch:  18500 train_loss: 2.4438254833221436 val_loss: 10.404006004333496\n",
      "epoch:  18600 train_loss: 2.5010433197021484 val_loss: 10.456782341003418\n",
      "epoch:  18700 train_loss: 2.7307324409484863 val_loss: 10.563715934753418\n",
      "epoch:  18800 train_loss: 2.691932201385498 val_loss: 10.712349891662598\n",
      "epoch:  18900 train_loss: 2.6823909282684326 val_loss: 10.85701847076416\n",
      "epoch:  19000 train_loss: 3.3259642124176025 val_loss: 11.176018714904785\n",
      "epoch:  19100 train_loss: 2.3848838806152344 val_loss: 10.398748397827148\n",
      "epoch:  19200 train_loss: 2.4502789974212646 val_loss: 10.542515754699707\n",
      "epoch:  19300 train_loss: 2.4562952518463135 val_loss: 10.419261932373047\n",
      "epoch:  19400 train_loss: 2.402705192565918 val_loss: 10.579144477844238\n",
      "epoch:  19500 train_loss: 2.4235591888427734 val_loss: 10.492051124572754\n",
      "epoch:  19600 train_loss: 2.4540538787841797 val_loss: 10.562417984008789\n",
      "epoch:  19700 train_loss: 2.5341994762420654 val_loss: 10.76026439666748\n",
      "epoch:  19800 train_loss: 2.550658702850342 val_loss: 10.681097984313965\n",
      "epoch:  19900 train_loss: 3.026132106781006 val_loss: 10.938901901245117\n",
      "epoch:  20000 train_loss: 2.5367016792297363 val_loss: 10.743566513061523\n",
      "epoch:  20100 train_loss: 2.5765652656555176 val_loss: 10.824424743652344\n",
      "epoch:  20200 train_loss: 2.3182058334350586 val_loss: 10.553481101989746\n",
      "epoch:  20300 train_loss: 2.63496470451355 val_loss: 10.6188383102417\n",
      "epoch:  20400 train_loss: 2.522054672241211 val_loss: 10.605437278747559\n",
      "epoch:  20500 train_loss: 2.682661294937134 val_loss: 11.060089111328125\n",
      "epoch:  20600 train_loss: 2.4438085556030273 val_loss: 10.766876220703125\n",
      "epoch:  20700 train_loss: 2.359755277633667 val_loss: 10.77116870880127\n",
      "epoch:  20800 train_loss: 2.41902494430542 val_loss: 10.637541770935059\n",
      "epoch:  20900 train_loss: 2.431821584701538 val_loss: 10.822620391845703\n",
      "epoch:  21000 train_loss: 2.2732579708099365 val_loss: 10.695412635803223\n",
      "epoch:  21100 train_loss: 2.3460774421691895 val_loss: 10.771101951599121\n",
      "epoch:  21200 train_loss: 2.318976402282715 val_loss: 10.76671028137207\n",
      "epoch:  21300 train_loss: 2.304591417312622 val_loss: 10.771891593933105\n",
      "epoch:  21400 train_loss: 2.3738720417022705 val_loss: 10.758432388305664\n",
      "epoch:  21500 train_loss: 2.3128340244293213 val_loss: 10.739295959472656\n",
      "epoch:  21600 train_loss: 2.6756017208099365 val_loss: 11.307439804077148\n",
      "epoch:  21700 train_loss: 2.4014389514923096 val_loss: 10.830793380737305\n",
      "epoch:  21800 train_loss: 2.6938998699188232 val_loss: 11.170398712158203\n",
      "epoch:  21900 train_loss: 2.2784295082092285 val_loss: 10.935141563415527\n",
      "epoch:  22000 train_loss: 2.5417144298553467 val_loss: 11.060870170593262\n",
      "epoch:  22100 train_loss: 2.2043190002441406 val_loss: 10.825328826904297\n",
      "epoch:  22200 train_loss: 2.2564914226531982 val_loss: 10.848676681518555\n",
      "epoch:  22300 train_loss: 2.3395307064056396 val_loss: 11.093053817749023\n",
      "epoch:  22400 train_loss: 3.614046812057495 val_loss: 11.63074779510498\n",
      "epoch:  22500 train_loss: 2.382105588912964 val_loss: 11.184327125549316\n",
      "epoch:  22600 train_loss: 2.677968978881836 val_loss: 11.032753944396973\n",
      "epoch:  22700 train_loss: 2.5944740772247314 val_loss: 11.20512580871582\n",
      "epoch:  22800 train_loss: 2.1854288578033447 val_loss: 10.874728202819824\n",
      "epoch:  22900 train_loss: 2.5342588424682617 val_loss: 11.585119247436523\n",
      "epoch:  23000 train_loss: 2.474668025970459 val_loss: 11.338862419128418\n",
      "epoch:  23100 train_loss: 2.521897554397583 val_loss: 11.167357444763184\n",
      "epoch:  23200 train_loss: 2.956350803375244 val_loss: 12.240328788757324\n",
      "epoch:  23300 train_loss: 2.5165164470672607 val_loss: 11.277216911315918\n",
      "epoch:  23400 train_loss: 2.3523075580596924 val_loss: 11.04932975769043\n",
      "epoch:  23500 train_loss: 2.3206539154052734 val_loss: 11.084227561950684\n",
      "epoch:  23600 train_loss: 2.340322971343994 val_loss: 11.152443885803223\n",
      "epoch:  23700 train_loss: 2.12286376953125 val_loss: 11.04497241973877\n",
      "epoch:  23800 train_loss: 2.1194207668304443 val_loss: 11.015143394470215\n",
      "epoch:  23900 train_loss: 2.3107657432556152 val_loss: 11.301874160766602\n",
      "epoch:  24000 train_loss: 2.1202218532562256 val_loss: 11.063101768493652\n",
      "epoch:  24100 train_loss: 2.383404016494751 val_loss: 11.316040992736816\n",
      "epoch:  24200 train_loss: 2.5606038570404053 val_loss: 11.619203567504883\n",
      "epoch:  24300 train_loss: 2.1822261810302734 val_loss: 11.17006778717041\n",
      "epoch:  24400 train_loss: 2.198800563812256 val_loss: 11.037003517150879\n",
      "epoch:  24500 train_loss: 2.202817678451538 val_loss: 11.33023452758789\n",
      "epoch:  24600 train_loss: 2.286428928375244 val_loss: 11.352457046508789\n",
      "epoch:  24700 train_loss: 2.086214303970337 val_loss: 11.211225509643555\n",
      "epoch:  24800 train_loss: 2.515460729598999 val_loss: 11.643275260925293\n",
      "epoch:  24900 train_loss: 2.2726540565490723 val_loss: 11.180278778076172\n",
      "epoch:  25000 train_loss: 2.095341920852661 val_loss: 11.204017639160156\n",
      "epoch:  25100 train_loss: 2.1174139976501465 val_loss: 11.228248596191406\n",
      "epoch:  25200 train_loss: 2.586369514465332 val_loss: 11.84153938293457\n",
      "epoch:  25300 train_loss: 2.0759692192077637 val_loss: 11.249937057495117\n",
      "epoch:  25400 train_loss: 2.852682590484619 val_loss: 12.602677345275879\n",
      "epoch:  25500 train_loss: 2.0351333618164062 val_loss: 11.26185131072998\n",
      "epoch:  25600 train_loss: 2.0394797325134277 val_loss: 11.238323211669922\n",
      "epoch:  25700 train_loss: 2.036041498184204 val_loss: 11.308319091796875\n",
      "epoch:  25800 train_loss: 2.1156485080718994 val_loss: 11.321406364440918\n",
      "epoch:  25900 train_loss: 2.0440804958343506 val_loss: 11.197607040405273\n",
      "epoch:  26000 train_loss: 2.013420820236206 val_loss: 11.300429344177246\n",
      "epoch:  26100 train_loss: 2.034452438354492 val_loss: 11.40160846710205\n",
      "epoch:  26200 train_loss: 2.070662260055542 val_loss: 11.460206031799316\n",
      "epoch:  26300 train_loss: 2.1849985122680664 val_loss: 11.467543601989746\n",
      "epoch:  26400 train_loss: 2.154505968093872 val_loss: 11.347604751586914\n",
      "epoch:  26500 train_loss: 2.129376173019409 val_loss: 11.366273880004883\n",
      "epoch:  26600 train_loss: 2.004605770111084 val_loss: 11.393326759338379\n",
      "epoch:  26700 train_loss: 2.0618484020233154 val_loss: 11.400130271911621\n",
      "epoch:  26800 train_loss: 2.42814302444458 val_loss: 11.739447593688965\n",
      "epoch:  26900 train_loss: 2.022394895553589 val_loss: 11.475811958312988\n",
      "epoch:  27000 train_loss: 2.393563985824585 val_loss: 11.612975120544434\n",
      "epoch:  27100 train_loss: 2.2518491744995117 val_loss: 11.589591979980469\n",
      "epoch:  27200 train_loss: 2.0460996627807617 val_loss: 11.50949478149414\n",
      "epoch:  27300 train_loss: 2.0447115898132324 val_loss: 11.594690322875977\n",
      "epoch:  27400 train_loss: 2.188302755355835 val_loss: 11.672699928283691\n",
      "epoch:  27500 train_loss: 2.017073154449463 val_loss: 11.518440246582031\n",
      "epoch:  27600 train_loss: 2.2899045944213867 val_loss: 11.747260093688965\n",
      "epoch:  27700 train_loss: 2.3630220890045166 val_loss: 11.872940063476562\n",
      "epoch:  27800 train_loss: 2.2039694786071777 val_loss: 11.564470291137695\n",
      "epoch:  27900 train_loss: 2.1002860069274902 val_loss: 11.733945846557617\n",
      "epoch:  28000 train_loss: 1.994760274887085 val_loss: 11.468252182006836\n",
      "epoch:  28100 train_loss: 2.152707099914551 val_loss: 11.737115859985352\n",
      "epoch:  28200 train_loss: 2.026338815689087 val_loss: 11.616676330566406\n",
      "epoch:  28300 train_loss: 2.6127805709838867 val_loss: 12.136796951293945\n",
      "epoch:  28400 train_loss: 1.9719834327697754 val_loss: 11.571759223937988\n",
      "epoch:  28500 train_loss: 2.1114768981933594 val_loss: 11.75963306427002\n",
      "epoch:  28600 train_loss: 2.0613667964935303 val_loss: 11.684638023376465\n",
      "epoch:  28700 train_loss: 2.3666810989379883 val_loss: 12.059292793273926\n",
      "epoch:  28800 train_loss: 2.0361528396606445 val_loss: 11.60683822631836\n",
      "epoch:  28900 train_loss: 2.431126832962036 val_loss: 12.356606483459473\n",
      "epoch:  29000 train_loss: 2.0380148887634277 val_loss: 11.514065742492676\n",
      "epoch:  29100 train_loss: 1.9390273094177246 val_loss: 11.662165641784668\n",
      "epoch:  29200 train_loss: 2.0898308753967285 val_loss: 11.859655380249023\n",
      "epoch:  29300 train_loss: 2.0364224910736084 val_loss: 11.909229278564453\n",
      "epoch:  29400 train_loss: 2.596090078353882 val_loss: 12.82497501373291\n",
      "epoch:  29500 train_loss: 2.2953526973724365 val_loss: 11.963850021362305\n",
      "epoch:  29600 train_loss: 1.9887537956237793 val_loss: 11.860444068908691\n",
      "epoch:  29700 train_loss: 1.8990389108657837 val_loss: 11.75342082977295\n",
      "epoch:  29800 train_loss: 2.2444801330566406 val_loss: 11.887158393859863\n",
      "epoch:  29900 train_loss: 1.8955645561218262 val_loss: 11.752697944641113\n",
      "epoch:  30000 train_loss: 1.9341626167297363 val_loss: 11.904414176940918\n",
      "epoch:  30100 train_loss: 1.931762456893921 val_loss: 11.802315711975098\n",
      "epoch:  30200 train_loss: 2.5536341667175293 val_loss: 12.384007453918457\n",
      "epoch:  30300 train_loss: 1.9640028476715088 val_loss: 12.024538040161133\n",
      "epoch:  30400 train_loss: 1.9633100032806396 val_loss: 11.979869842529297\n",
      "epoch:  30500 train_loss: 1.9155830144882202 val_loss: 11.893599510192871\n",
      "epoch:  30600 train_loss: 2.28753662109375 val_loss: 11.994704246520996\n",
      "epoch:  30700 train_loss: 2.6893701553344727 val_loss: 12.59867000579834\n",
      "epoch:  30800 train_loss: 1.8603287935256958 val_loss: 11.82719612121582\n",
      "epoch:  30900 train_loss: 1.9211108684539795 val_loss: 11.98297119140625\n",
      "epoch:  31000 train_loss: 2.012406349182129 val_loss: 11.972805976867676\n",
      "epoch:  31100 train_loss: 2.52836275100708 val_loss: 12.677678108215332\n",
      "epoch:  31200 train_loss: 2.1374881267547607 val_loss: 12.209688186645508\n",
      "epoch:  31300 train_loss: 2.8598647117614746 val_loss: 12.883116722106934\n",
      "epoch:  31400 train_loss: 1.864501953125 val_loss: 11.936735153198242\n",
      "epoch:  31500 train_loss: 1.871957540512085 val_loss: 12.00948715209961\n",
      "epoch:  31600 train_loss: 2.221940040588379 val_loss: 12.383874893188477\n",
      "epoch:  31700 train_loss: 1.9250051975250244 val_loss: 11.972061157226562\n",
      "epoch:  31800 train_loss: 2.09289288520813 val_loss: 12.257203102111816\n",
      "epoch:  31900 train_loss: 1.850121259689331 val_loss: 11.986510276794434\n",
      "epoch:  32000 train_loss: 1.8033610582351685 val_loss: 11.953364372253418\n",
      "epoch:  32100 train_loss: 1.949604868888855 val_loss: 12.06912899017334\n",
      "epoch:  32200 train_loss: 2.054372787475586 val_loss: 11.970173835754395\n",
      "epoch:  32300 train_loss: 1.8998652696609497 val_loss: 12.205551147460938\n",
      "epoch:  32400 train_loss: 1.797056794166565 val_loss: 11.977019309997559\n",
      "epoch:  32500 train_loss: 1.843820571899414 val_loss: 12.0106782913208\n",
      "epoch:  32600 train_loss: 1.9146872758865356 val_loss: 12.12451171875\n",
      "epoch:  32700 train_loss: 2.0081698894500732 val_loss: 12.191426277160645\n",
      "epoch:  32800 train_loss: 2.0210516452789307 val_loss: 12.057703971862793\n",
      "epoch:  32900 train_loss: 1.794702410697937 val_loss: 12.142866134643555\n",
      "epoch:  33000 train_loss: 2.0961859226226807 val_loss: 12.099961280822754\n",
      "epoch:  33100 train_loss: 1.9084490537643433 val_loss: 12.240081787109375\n",
      "epoch:  33200 train_loss: 2.4016640186309814 val_loss: 12.794075965881348\n",
      "epoch:  33300 train_loss: 1.9603313207626343 val_loss: 12.10149097442627\n",
      "epoch:  33400 train_loss: 1.8177504539489746 val_loss: 11.947256088256836\n",
      "epoch:  33500 train_loss: 1.9743926525115967 val_loss: 12.172750473022461\n",
      "epoch:  33600 train_loss: 2.358198881149292 val_loss: 12.411172866821289\n",
      "epoch:  33700 train_loss: 2.3984034061431885 val_loss: 12.740686416625977\n",
      "epoch:  33800 train_loss: 1.919427752494812 val_loss: 12.179024696350098\n",
      "epoch:  33900 train_loss: 2.530954360961914 val_loss: 13.024602890014648\n",
      "epoch:  34000 train_loss: 2.289597988128662 val_loss: 13.075034141540527\n",
      "epoch:  34100 train_loss: 1.975975513458252 val_loss: 12.33129596710205\n",
      "epoch:  34200 train_loss: 1.8020304441452026 val_loss: 12.16185474395752\n",
      "epoch:  34300 train_loss: 1.8336957693099976 val_loss: 12.280044555664062\n",
      "epoch:  34400 train_loss: 1.8791024684906006 val_loss: 12.404641151428223\n",
      "epoch:  34500 train_loss: 1.9255188703536987 val_loss: 12.144859313964844\n",
      "epoch:  34600 train_loss: 1.7739113569259644 val_loss: 12.183537483215332\n",
      "epoch:  34700 train_loss: 1.7127127647399902 val_loss: 12.180764198303223\n",
      "epoch:  34800 train_loss: 2.61910343170166 val_loss: 12.938335418701172\n",
      "epoch:  34900 train_loss: 2.0278074741363525 val_loss: 12.331734657287598\n",
      "epoch:  35000 train_loss: 2.379703998565674 val_loss: 12.692520141601562\n",
      "epoch:  35100 train_loss: 1.830703854560852 val_loss: 12.340350151062012\n",
      "epoch:  35200 train_loss: 2.330549716949463 val_loss: 12.408832550048828\n",
      "epoch:  35300 train_loss: 1.7005555629730225 val_loss: 12.25698184967041\n",
      "epoch:  35400 train_loss: 2.5456364154815674 val_loss: 13.088188171386719\n",
      "epoch:  35500 train_loss: 1.7365418672561646 val_loss: 12.25256061553955\n",
      "epoch:  35600 train_loss: 1.678861379623413 val_loss: 12.229402542114258\n",
      "epoch:  35700 train_loss: 1.7447259426116943 val_loss: 12.426188468933105\n",
      "epoch:  35800 train_loss: 1.6486401557922363 val_loss: 12.272356033325195\n",
      "epoch:  35900 train_loss: 1.7242358922958374 val_loss: 12.331751823425293\n",
      "RMSE:  tensor(6.0840, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Ganerate the dataset\n",
    "i = 0\n",
    "sigma = 4.6\n",
    "my_dataset = []\n",
    "for ud in UDs:\n",
    "    example = []\n",
    "    for an in ANs:\n",
    "        noise = np.random.normal(0,sigma)\n",
    "        # 0 is mean\n",
    "        # sigma is the deviation of the normal distribution\n",
    "        d = compute_3d_distance(ud, an) + noise\n",
    "        example.append(d)\n",
    "    \n",
    "    # append x, y, z as col#10, #11, #12\n",
    "    example.append(ud[0])\n",
    "    example.append(ud[1])\n",
    "    example.append(ud[2])\n",
    "    \n",
    "    # append 1x13 example row into my_dataset\n",
    "    my_dataset.append(example)  # expected to be 3000x13  \n",
    "    \n",
    "# Load dataset\n",
    "exercise3_dataset = Exercise3Dataset(list_dataset = my_dataset, shuffle=True)\n",
    "\n",
    "#Split dataset by 0.8: 0.1: 0.1\n",
    "train_examples, train_labels = exercise3_dataset[:int(3000*0.8)]  # (2400, 10)   # (2400, 3)\n",
    "val_examples, val_labels = exercise3_dataset[int(3000*0.8):int(3000*0.9)]    # (300, 10)   #(300, 3)\n",
    "test_examples, test_labels = exercise3_dataset[int(3000*0.9):]     #(300, 10)   # (300, 3)\n",
    "\n",
    "###Define model, loss function and optimizer\n",
    "# if we have GPU, then use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define model\n",
    "model = Net(x_dim = train_examples.shape[1], y_dim = train_labels.shape[1]).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training and Validation\n",
    "\n",
    "train_examples = train_examples.to(device)\n",
    "train_labels = train_labels.to(device)\n",
    "val_examples = val_examples.to(device)\n",
    "val_labels = val_labels.to(device)\n",
    "\n",
    "# Define the model filename for model.save()\n",
    "MODEL_FILENAME = \"best.pth\"\n",
    "\n",
    "# set model to Training mode\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "NUM_OF_EPOCH = 36000\n",
    "\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    y_pred = model(train_examples)\n",
    "    loss = loss_fn(y_pred, train_labels).cpu()\n",
    "    #print(t, loss.item())\n",
    "    train_losses.append(loss.item())\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    # BGD\n",
    "    optimizer.step()\n",
    "    \n",
    "    # evaluate validation loss\n",
    "    val_pred = model(val_examples)\n",
    "    loss = loss_fn(val_pred, val_labels)\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "    # check if we got better loss\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n",
    "\n",
    "    if (epoch % 100) == 0:\n",
    "        print(\"epoch: \", epoch, \"train_loss:\", train_losses[-1], \"val_loss:\", val_losses[-1])\n",
    "        \n",
    "# Inference all testing examples and compute RMSE\n",
    "def square_error(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  square_error= loss_fn(a, b)\n",
    "  return square_error\n",
    "\n",
    "model.eval() # inference mode\n",
    "test_examples = test_examples.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "test_preds = model(test_examples)\n",
    "#print(\"example: \", test_example.cpu())\n",
    "#print(\"========================================\")\n",
    "#print(\"ground_truth:\", test_label.cpu())\n",
    "#print(\"prediction:\", test_pred.cpu())\n",
    "#print(\"========================================\")\n",
    "\n",
    "\n",
    "total_errors = 0.0\n",
    "for idx in range(len(test_examples)):\n",
    "    total_errors += square_error(test_preds[idx], test_labels[idx])\n",
    "    \n",
    "RMSE = torch.sqrt(total_errors / len(test_examples))\n",
    "print(\"RMSE: \",  RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigma = 5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffle = True!\n",
      "epoch:  0 train_loss: 7357.47216796875 val_loss: 7314.451171875\n",
      "epoch:  100 train_loss: 184.07090759277344 val_loss: 175.8680877685547\n",
      "epoch:  200 train_loss: 159.03076171875 val_loss: 153.31167602539062\n",
      "epoch:  300 train_loss: 122.99708557128906 val_loss: 119.7348403930664\n",
      "epoch:  400 train_loss: 60.47330856323242 val_loss: 61.258453369140625\n",
      "epoch:  500 train_loss: 45.90657043457031 val_loss: 47.462398529052734\n",
      "epoch:  600 train_loss: 24.868967056274414 val_loss: 25.68843650817871\n",
      "epoch:  700 train_loss: 12.047873497009277 val_loss: 12.57383918762207\n",
      "epoch:  800 train_loss: 11.013260841369629 val_loss: 11.606271743774414\n",
      "epoch:  900 train_loss: 10.393877983093262 val_loss: 10.944438934326172\n",
      "epoch:  1000 train_loss: 9.923425674438477 val_loss: 10.4317626953125\n",
      "epoch:  1100 train_loss: 9.440500259399414 val_loss: 9.897930145263672\n",
      "epoch:  1200 train_loss: 9.089978218078613 val_loss: 9.458556175231934\n",
      "epoch:  1300 train_loss: 8.852387428283691 val_loss: 9.168895721435547\n",
      "epoch:  1400 train_loss: 8.663684844970703 val_loss: 8.995346069335938\n",
      "epoch:  1500 train_loss: 8.495616912841797 val_loss: 8.873708724975586\n",
      "epoch:  1600 train_loss: 8.338750839233398 val_loss: 8.745133399963379\n",
      "epoch:  1700 train_loss: 8.184913635253906 val_loss: 8.61483097076416\n",
      "epoch:  1800 train_loss: 8.0562162399292 val_loss: 8.519116401672363\n",
      "epoch:  1900 train_loss: 7.935854911804199 val_loss: 8.452652931213379\n",
      "epoch:  2000 train_loss: 7.8294758796691895 val_loss: 8.398159980773926\n",
      "epoch:  2100 train_loss: 7.72141695022583 val_loss: 8.373882293701172\n",
      "epoch:  2200 train_loss: 7.620375633239746 val_loss: 8.358550071716309\n",
      "epoch:  2300 train_loss: 7.516211986541748 val_loss: 8.363509178161621\n",
      "epoch:  2400 train_loss: 7.4052534103393555 val_loss: 8.408360481262207\n",
      "epoch:  2500 train_loss: 7.31027889251709 val_loss: 8.413942337036133\n",
      "epoch:  2600 train_loss: 7.222220420837402 val_loss: 8.450735092163086\n",
      "epoch:  2700 train_loss: 7.135913848876953 val_loss: 8.445679664611816\n",
      "epoch:  2800 train_loss: 7.047144412994385 val_loss: 8.498871803283691\n",
      "epoch:  2900 train_loss: 6.964378356933594 val_loss: 8.525798797607422\n",
      "epoch:  3000 train_loss: 6.8805670738220215 val_loss: 8.55373477935791\n",
      "epoch:  3100 train_loss: 6.809647083282471 val_loss: 8.563586235046387\n",
      "epoch:  3200 train_loss: 6.718919277191162 val_loss: 8.603276252746582\n",
      "epoch:  3300 train_loss: 6.628986835479736 val_loss: 8.630809783935547\n",
      "epoch:  3400 train_loss: 6.554371356964111 val_loss: 8.637248039245605\n",
      "epoch:  3500 train_loss: 6.476007461547852 val_loss: 8.664061546325684\n",
      "epoch:  3600 train_loss: 6.430553913116455 val_loss: 8.673789978027344\n",
      "epoch:  3700 train_loss: 6.381288528442383 val_loss: 8.844277381896973\n",
      "epoch:  3800 train_loss: 6.325910568237305 val_loss: 8.737398147583008\n",
      "epoch:  3900 train_loss: 6.183391094207764 val_loss: 8.782757759094238\n",
      "epoch:  4000 train_loss: 6.1166157722473145 val_loss: 8.822761535644531\n",
      "epoch:  4100 train_loss: 6.050684928894043 val_loss: 8.856741905212402\n",
      "epoch:  4200 train_loss: 5.987512111663818 val_loss: 8.834345817565918\n",
      "epoch:  4300 train_loss: 5.927574157714844 val_loss: 8.910017967224121\n",
      "epoch:  4400 train_loss: 5.906946659088135 val_loss: 9.063486099243164\n",
      "epoch:  4500 train_loss: 5.802518367767334 val_loss: 9.040694236755371\n",
      "epoch:  4600 train_loss: 5.752495765686035 val_loss: 9.064476013183594\n",
      "epoch:  4700 train_loss: 5.7507710456848145 val_loss: 9.264143943786621\n",
      "epoch:  4800 train_loss: 5.76240348815918 val_loss: 9.316420555114746\n",
      "epoch:  4900 train_loss: 5.65893030166626 val_loss: 9.314913749694824\n",
      "epoch:  5000 train_loss: 5.514524936676025 val_loss: 9.263899803161621\n",
      "epoch:  5100 train_loss: 5.57820987701416 val_loss: 9.436452865600586\n",
      "epoch:  5200 train_loss: 5.418806552886963 val_loss: 9.391755104064941\n",
      "epoch:  5300 train_loss: 5.390968322753906 val_loss: 9.341667175292969\n",
      "epoch:  5400 train_loss: 5.430441379547119 val_loss: 9.412087440490723\n",
      "epoch:  5500 train_loss: 5.304398059844971 val_loss: 9.437067985534668\n",
      "epoch:  5600 train_loss: 5.903991222381592 val_loss: 10.215337753295898\n",
      "epoch:  5700 train_loss: 5.205526351928711 val_loss: 9.61301040649414\n",
      "epoch:  5800 train_loss: 5.200109004974365 val_loss: 9.578770637512207\n",
      "epoch:  5900 train_loss: 5.565655708312988 val_loss: 9.791071891784668\n",
      "epoch:  6000 train_loss: 5.10800313949585 val_loss: 9.764195442199707\n",
      "epoch:  6100 train_loss: 5.2071003913879395 val_loss: 9.773406028747559\n",
      "epoch:  6200 train_loss: 4.988455295562744 val_loss: 9.796957015991211\n",
      "epoch:  6300 train_loss: 4.9971113204956055 val_loss: 9.884449005126953\n",
      "epoch:  6400 train_loss: 5.000152111053467 val_loss: 10.059250831604004\n",
      "epoch:  6500 train_loss: 4.990443229675293 val_loss: 10.08513355255127\n",
      "epoch:  6600 train_loss: 4.87570333480835 val_loss: 9.971652030944824\n",
      "epoch:  6700 train_loss: 4.897542476654053 val_loss: 10.163897514343262\n",
      "epoch:  6800 train_loss: 4.764358997344971 val_loss: 10.12330436706543\n",
      "epoch:  6900 train_loss: 5.085699081420898 val_loss: 10.425034523010254\n",
      "epoch:  7000 train_loss: 4.800391674041748 val_loss: 10.205917358398438\n",
      "epoch:  7100 train_loss: 5.236767768859863 val_loss: 10.803316116333008\n",
      "epoch:  7200 train_loss: 4.7612810134887695 val_loss: 10.382707595825195\n",
      "epoch:  7300 train_loss: 4.701006889343262 val_loss: 10.759655952453613\n",
      "epoch:  7400 train_loss: 4.609454154968262 val_loss: 10.549371719360352\n",
      "epoch:  7500 train_loss: 4.58640193939209 val_loss: 10.51960563659668\n",
      "epoch:  7600 train_loss: 4.534471035003662 val_loss: 10.513940811157227\n",
      "epoch:  7700 train_loss: 4.599747180938721 val_loss: 10.723148345947266\n",
      "epoch:  7800 train_loss: 4.429465293884277 val_loss: 10.739444732666016\n",
      "epoch:  7900 train_loss: 4.4006147384643555 val_loss: 10.708441734313965\n",
      "epoch:  8000 train_loss: 4.378715991973877 val_loss: 10.905468940734863\n",
      "epoch:  8100 train_loss: 4.521787643432617 val_loss: 11.025273323059082\n",
      "epoch:  8200 train_loss: 4.589176654815674 val_loss: 11.14570426940918\n",
      "epoch:  8300 train_loss: 4.7487993240356445 val_loss: 11.294021606445312\n",
      "epoch:  8400 train_loss: 4.581479549407959 val_loss: 11.057938575744629\n",
      "epoch:  8500 train_loss: 4.309621810913086 val_loss: 11.043163299560547\n",
      "epoch:  8600 train_loss: 4.2177228927612305 val_loss: 11.159748077392578\n",
      "epoch:  8700 train_loss: 4.190577030181885 val_loss: 11.131254196166992\n",
      "epoch:  8800 train_loss: 4.428257942199707 val_loss: 11.340575218200684\n",
      "epoch:  8900 train_loss: 4.168447494506836 val_loss: 11.228738784790039\n",
      "epoch:  9000 train_loss: 4.288875102996826 val_loss: 11.218557357788086\n",
      "epoch:  9100 train_loss: 4.178592205047607 val_loss: 11.444042205810547\n",
      "epoch:  9200 train_loss: 4.092028617858887 val_loss: 11.306936264038086\n",
      "epoch:  9300 train_loss: 4.1616621017456055 val_loss: 11.423504829406738\n",
      "epoch:  9400 train_loss: 4.2234039306640625 val_loss: 11.365068435668945\n",
      "epoch:  9500 train_loss: 4.313063621520996 val_loss: 11.762181282043457\n",
      "epoch:  9600 train_loss: 4.004436492919922 val_loss: 11.580628395080566\n",
      "epoch:  9700 train_loss: 4.114940166473389 val_loss: 11.61777114868164\n",
      "epoch:  9800 train_loss: 4.156021595001221 val_loss: 11.696792602539062\n",
      "epoch:  9900 train_loss: 4.302052021026611 val_loss: 11.847798347473145\n",
      "epoch:  10000 train_loss: 4.093567371368408 val_loss: 11.754746437072754\n",
      "epoch:  10100 train_loss: 4.421415328979492 val_loss: 12.06000804901123\n",
      "epoch:  10200 train_loss: 3.8982748985290527 val_loss: 11.817899703979492\n",
      "epoch:  10300 train_loss: 4.330653667449951 val_loss: 11.967024803161621\n",
      "epoch:  10400 train_loss: 4.032180309295654 val_loss: 11.809466361999512\n",
      "epoch:  10500 train_loss: 4.071986675262451 val_loss: 11.984963417053223\n",
      "epoch:  10600 train_loss: 4.028989315032959 val_loss: 11.988042831420898\n",
      "epoch:  10700 train_loss: 3.952016592025757 val_loss: 11.928850173950195\n",
      "epoch:  10800 train_loss: 4.062185287475586 val_loss: 12.137495040893555\n",
      "epoch:  10900 train_loss: 3.9391427040100098 val_loss: 11.987159729003906\n",
      "epoch:  11000 train_loss: 4.116118431091309 val_loss: 12.068826675415039\n",
      "epoch:  11100 train_loss: 3.7338597774505615 val_loss: 12.189011573791504\n",
      "epoch:  11200 train_loss: 4.005704879760742 val_loss: 12.463204383850098\n",
      "epoch:  11300 train_loss: 3.712984085083008 val_loss: 12.22665023803711\n",
      "epoch:  11400 train_loss: 3.778904676437378 val_loss: 12.051620483398438\n",
      "epoch:  11500 train_loss: 3.8694722652435303 val_loss: 12.302096366882324\n",
      "epoch:  11600 train_loss: 3.661093235015869 val_loss: 12.196112632751465\n",
      "epoch:  11700 train_loss: 3.9087939262390137 val_loss: 12.413125991821289\n",
      "epoch:  11800 train_loss: 4.262320518493652 val_loss: 12.595580101013184\n",
      "epoch:  11900 train_loss: 4.114656925201416 val_loss: 13.086636543273926\n",
      "epoch:  12000 train_loss: 3.5611960887908936 val_loss: 12.178483009338379\n",
      "epoch:  12100 train_loss: 3.566746473312378 val_loss: 12.3178071975708\n",
      "epoch:  12200 train_loss: 3.8729560375213623 val_loss: 12.861720085144043\n",
      "epoch:  12300 train_loss: 3.7654733657836914 val_loss: 12.470280647277832\n",
      "epoch:  12400 train_loss: 4.136063575744629 val_loss: 12.974722862243652\n",
      "epoch:  12500 train_loss: 4.503078460693359 val_loss: 13.38529109954834\n",
      "epoch:  12600 train_loss: 3.8809516429901123 val_loss: 12.866947174072266\n",
      "epoch:  12700 train_loss: 3.46752667427063 val_loss: 12.61201000213623\n",
      "epoch:  12800 train_loss: 3.889155387878418 val_loss: 12.832494735717773\n",
      "epoch:  12900 train_loss: 3.521204948425293 val_loss: 12.759565353393555\n",
      "epoch:  13000 train_loss: 3.4722976684570312 val_loss: 12.831072807312012\n",
      "epoch:  13100 train_loss: 3.373020648956299 val_loss: 12.805575370788574\n",
      "epoch:  13200 train_loss: 3.621967315673828 val_loss: 12.794218063354492\n",
      "epoch:  13300 train_loss: 4.348018169403076 val_loss: 13.310120582580566\n",
      "epoch:  13400 train_loss: 3.5007290840148926 val_loss: 12.989642143249512\n",
      "epoch:  13500 train_loss: 3.4143528938293457 val_loss: 12.855428695678711\n",
      "epoch:  13600 train_loss: 3.3126652240753174 val_loss: 12.90673542022705\n",
      "epoch:  13700 train_loss: 3.9908106327056885 val_loss: 13.735461235046387\n",
      "epoch:  13800 train_loss: 3.5284252166748047 val_loss: 12.958520889282227\n",
      "epoch:  13900 train_loss: 3.2793924808502197 val_loss: 12.942922592163086\n",
      "epoch:  14000 train_loss: 3.3303184509277344 val_loss: 12.9732027053833\n",
      "epoch:  14100 train_loss: 3.549344062805176 val_loss: 13.373669624328613\n",
      "epoch:  14200 train_loss: 3.272963285446167 val_loss: 13.104166984558105\n",
      "epoch:  14300 train_loss: 3.273343801498413 val_loss: 13.133559226989746\n",
      "epoch:  14400 train_loss: 3.2774593830108643 val_loss: 13.18659496307373\n",
      "epoch:  14500 train_loss: 3.7902164459228516 val_loss: 13.677543640136719\n",
      "epoch:  14600 train_loss: 3.204632520675659 val_loss: 13.387348175048828\n",
      "epoch:  14700 train_loss: 3.234201431274414 val_loss: 13.177521705627441\n",
      "epoch:  14800 train_loss: 3.3249759674072266 val_loss: 13.265519142150879\n",
      "epoch:  14900 train_loss: 3.164384603500366 val_loss: 13.276238441467285\n",
      "epoch:  15000 train_loss: 3.3852782249450684 val_loss: 13.586617469787598\n",
      "epoch:  15100 train_loss: 3.4812138080596924 val_loss: 13.589436531066895\n",
      "epoch:  15200 train_loss: 3.3197836875915527 val_loss: 13.530255317687988\n",
      "epoch:  15300 train_loss: 3.615139961242676 val_loss: 13.50511360168457\n",
      "epoch:  15400 train_loss: 3.123380184173584 val_loss: 13.441903114318848\n",
      "epoch:  15500 train_loss: 3.0356462001800537 val_loss: 13.435920715332031\n",
      "epoch:  15600 train_loss: 3.698482036590576 val_loss: 13.832817077636719\n",
      "epoch:  15700 train_loss: 3.086893320083618 val_loss: 13.531967163085938\n",
      "epoch:  15800 train_loss: 3.2180604934692383 val_loss: 13.878060340881348\n",
      "epoch:  15900 train_loss: 3.1517958641052246 val_loss: 13.512126922607422\n",
      "epoch:  16000 train_loss: 2.9994618892669678 val_loss: 13.473597526550293\n",
      "epoch:  16100 train_loss: 4.457306385040283 val_loss: 15.429981231689453\n",
      "epoch:  16200 train_loss: 3.0579166412353516 val_loss: 13.610965728759766\n",
      "epoch:  16300 train_loss: 2.961366891860962 val_loss: 13.501800537109375\n",
      "epoch:  16400 train_loss: 3.3753063678741455 val_loss: 13.980829238891602\n",
      "epoch:  16500 train_loss: 4.093527793884277 val_loss: 14.675838470458984\n",
      "epoch:  16600 train_loss: 2.9063093662261963 val_loss: 13.566235542297363\n",
      "epoch:  16700 train_loss: 3.1027963161468506 val_loss: 13.765329360961914\n",
      "epoch:  16800 train_loss: 2.904772996902466 val_loss: 13.731371879577637\n",
      "epoch:  16900 train_loss: 3.204467535018921 val_loss: 13.980731010437012\n",
      "epoch:  17000 train_loss: 3.263159990310669 val_loss: 13.859017372131348\n",
      "epoch:  17100 train_loss: 2.9712443351745605 val_loss: 13.863541603088379\n",
      "epoch:  17200 train_loss: 2.9048614501953125 val_loss: 13.77971363067627\n",
      "epoch:  17300 train_loss: 2.9943604469299316 val_loss: 13.934496879577637\n",
      "epoch:  17400 train_loss: 3.2684249877929688 val_loss: 14.058485984802246\n",
      "epoch:  17500 train_loss: 3.689730405807495 val_loss: 14.530195236206055\n",
      "epoch:  17600 train_loss: 2.8609704971313477 val_loss: 13.864289283752441\n",
      "epoch:  17700 train_loss: 3.0767290592193604 val_loss: 14.20664119720459\n",
      "epoch:  17800 train_loss: 2.931304931640625 val_loss: 13.829730987548828\n",
      "epoch:  17900 train_loss: 3.107578992843628 val_loss: 13.987569808959961\n",
      "epoch:  18000 train_loss: 3.206455707550049 val_loss: 14.392292976379395\n",
      "epoch:  18100 train_loss: 2.8862271308898926 val_loss: 14.17234992980957\n",
      "epoch:  18200 train_loss: 2.832887887954712 val_loss: 13.950972557067871\n",
      "epoch:  18300 train_loss: 2.952261447906494 val_loss: 14.00602912902832\n",
      "epoch:  18400 train_loss: 2.9800937175750732 val_loss: 14.349692344665527\n",
      "epoch:  18500 train_loss: 2.740694522857666 val_loss: 14.115030288696289\n",
      "epoch:  18600 train_loss: 2.7840282917022705 val_loss: 14.08388614654541\n",
      "epoch:  18700 train_loss: 2.9746384620666504 val_loss: 14.090993881225586\n",
      "epoch:  18800 train_loss: 2.905000686645508 val_loss: 14.403153419494629\n",
      "epoch:  18900 train_loss: 3.363938331604004 val_loss: 14.926655769348145\n",
      "epoch:  19000 train_loss: 2.9004569053649902 val_loss: 14.346755027770996\n",
      "epoch:  19100 train_loss: 2.6921842098236084 val_loss: 14.175338745117188\n",
      "epoch:  19200 train_loss: 2.860464572906494 val_loss: 14.265002250671387\n",
      "epoch:  19300 train_loss: 2.970897912979126 val_loss: 14.563374519348145\n",
      "epoch:  19400 train_loss: 2.735422134399414 val_loss: 14.296736717224121\n",
      "epoch:  19500 train_loss: 2.669343948364258 val_loss: 14.283648490905762\n",
      "epoch:  19600 train_loss: 2.824143409729004 val_loss: 14.569828987121582\n",
      "epoch:  19700 train_loss: 3.0623366832733154 val_loss: 14.860876083374023\n",
      "epoch:  19800 train_loss: 2.6799488067626953 val_loss: 14.566385269165039\n",
      "epoch:  19900 train_loss: 2.6869072914123535 val_loss: 14.51803207397461\n",
      "epoch:  20000 train_loss: 3.016225576400757 val_loss: 14.678659439086914\n",
      "epoch:  20100 train_loss: 2.6271474361419678 val_loss: 14.370128631591797\n",
      "epoch:  20200 train_loss: 2.6446666717529297 val_loss: 14.442590713500977\n",
      "epoch:  20300 train_loss: 3.229982614517212 val_loss: 15.119269371032715\n",
      "epoch:  20400 train_loss: 2.88393235206604 val_loss: 14.671906471252441\n",
      "epoch:  20500 train_loss: 2.571885347366333 val_loss: 14.561110496520996\n",
      "epoch:  20600 train_loss: 3.003923177719116 val_loss: 14.831174850463867\n",
      "epoch:  20700 train_loss: 2.5981802940368652 val_loss: 14.553399085998535\n",
      "epoch:  20800 train_loss: 2.7677929401397705 val_loss: 14.758644104003906\n",
      "epoch:  20900 train_loss: 3.1256051063537598 val_loss: 15.075006484985352\n",
      "epoch:  21000 train_loss: 2.9647738933563232 val_loss: 15.237418174743652\n",
      "epoch:  21100 train_loss: 3.0130114555358887 val_loss: 15.169129371643066\n",
      "epoch:  21200 train_loss: 2.588994264602661 val_loss: 14.773258209228516\n",
      "epoch:  21300 train_loss: 2.6583476066589355 val_loss: 14.699845314025879\n",
      "epoch:  21400 train_loss: 3.144221544265747 val_loss: 15.103959083557129\n",
      "epoch:  21500 train_loss: 2.684610366821289 val_loss: 14.801263809204102\n",
      "epoch:  21600 train_loss: 2.563391923904419 val_loss: 14.727645874023438\n",
      "epoch:  21700 train_loss: 2.6576790809631348 val_loss: 14.921252250671387\n",
      "epoch:  21800 train_loss: 2.8190271854400635 val_loss: 15.072010040283203\n",
      "epoch:  21900 train_loss: 2.478153705596924 val_loss: 14.838264465332031\n",
      "epoch:  22000 train_loss: 2.582268476486206 val_loss: 15.016987800598145\n",
      "epoch:  22100 train_loss: 2.7432665824890137 val_loss: 15.008544921875\n",
      "epoch:  22200 train_loss: 2.4980154037475586 val_loss: 14.860278129577637\n",
      "epoch:  22300 train_loss: 2.7208850383758545 val_loss: 15.023707389831543\n",
      "epoch:  22400 train_loss: 2.684798240661621 val_loss: 15.12961483001709\n",
      "epoch:  22500 train_loss: 2.56064510345459 val_loss: 14.99928092956543\n",
      "epoch:  22600 train_loss: 2.400521993637085 val_loss: 14.908985137939453\n",
      "epoch:  22700 train_loss: 2.5584664344787598 val_loss: 15.140591621398926\n",
      "epoch:  22800 train_loss: 2.443033456802368 val_loss: 15.054828643798828\n",
      "epoch:  22900 train_loss: 3.0194613933563232 val_loss: 15.683489799499512\n",
      "epoch:  23000 train_loss: 2.4902687072753906 val_loss: 15.22606086730957\n",
      "epoch:  23100 train_loss: 2.425791025161743 val_loss: 15.272294998168945\n",
      "epoch:  23200 train_loss: 2.6084229946136475 val_loss: 15.21147632598877\n",
      "epoch:  23300 train_loss: 2.4785892963409424 val_loss: 15.207342147827148\n",
      "epoch:  23400 train_loss: 2.57560658454895 val_loss: 15.40140438079834\n",
      "epoch:  23500 train_loss: 2.432934522628784 val_loss: 15.18794059753418\n",
      "epoch:  23600 train_loss: 2.6923110485076904 val_loss: 15.369422912597656\n",
      "epoch:  23700 train_loss: 2.8277995586395264 val_loss: 15.627730369567871\n",
      "epoch:  23800 train_loss: 2.553173303604126 val_loss: 15.429048538208008\n",
      "epoch:  23900 train_loss: 2.3095598220825195 val_loss: 15.21188735961914\n",
      "epoch:  24000 train_loss: 2.430612564086914 val_loss: 15.478012084960938\n",
      "epoch:  24100 train_loss: 2.8144731521606445 val_loss: 15.722308158874512\n",
      "epoch:  24200 train_loss: 3.4095189571380615 val_loss: 16.505638122558594\n",
      "epoch:  24300 train_loss: 2.752562999725342 val_loss: 15.543313980102539\n",
      "epoch:  24400 train_loss: 2.650059700012207 val_loss: 15.657626152038574\n",
      "epoch:  24500 train_loss: 3.072941541671753 val_loss: 16.37136459350586\n",
      "epoch:  24600 train_loss: 2.4724860191345215 val_loss: 15.67768669128418\n",
      "epoch:  24700 train_loss: 2.5208749771118164 val_loss: 15.662002563476562\n",
      "epoch:  24800 train_loss: 2.3865573406219482 val_loss: 15.449954986572266\n",
      "epoch:  24900 train_loss: 2.273275375366211 val_loss: 15.51500129699707\n",
      "epoch:  25000 train_loss: 2.5582051277160645 val_loss: 15.660659790039062\n",
      "epoch:  25100 train_loss: 2.547246217727661 val_loss: 15.820145606994629\n",
      "epoch:  25200 train_loss: 2.5976033210754395 val_loss: 15.941259384155273\n",
      "epoch:  25300 train_loss: 2.4703845977783203 val_loss: 15.724600791931152\n",
      "epoch:  25400 train_loss: 2.441667079925537 val_loss: 15.905839920043945\n",
      "epoch:  25500 train_loss: 2.24920392036438 val_loss: 15.667706489562988\n",
      "epoch:  25600 train_loss: 2.3571364879608154 val_loss: 15.724234580993652\n",
      "epoch:  25700 train_loss: 2.2407867908477783 val_loss: 15.582281112670898\n",
      "epoch:  25800 train_loss: 2.3407723903656006 val_loss: 15.81724739074707\n",
      "epoch:  25900 train_loss: 2.494584560394287 val_loss: 15.724085807800293\n",
      "epoch:  26000 train_loss: 2.250763416290283 val_loss: 15.70331859588623\n",
      "epoch:  26100 train_loss: 2.365800380706787 val_loss: 15.74764347076416\n",
      "epoch:  26200 train_loss: 2.773037910461426 val_loss: 16.244905471801758\n",
      "epoch:  26300 train_loss: 2.210291624069214 val_loss: 15.6500825881958\n",
      "epoch:  26400 train_loss: 2.4512012004852295 val_loss: 15.971267700195312\n",
      "epoch:  26500 train_loss: 2.2728941440582275 val_loss: 15.974377632141113\n",
      "epoch:  26600 train_loss: 2.129488945007324 val_loss: 15.685627937316895\n",
      "epoch:  26700 train_loss: 2.6581692695617676 val_loss: 16.40460777282715\n",
      "epoch:  26800 train_loss: 2.456085681915283 val_loss: 15.930808067321777\n",
      "epoch:  26900 train_loss: 2.2283923625946045 val_loss: 16.018657684326172\n",
      "epoch:  27000 train_loss: 2.42724347114563 val_loss: 16.343095779418945\n",
      "epoch:  27100 train_loss: 2.515700101852417 val_loss: 16.325895309448242\n",
      "epoch:  27200 train_loss: 2.903743028640747 val_loss: 16.808454513549805\n",
      "epoch:  27300 train_loss: 2.25641131401062 val_loss: 16.25076675415039\n",
      "epoch:  27400 train_loss: 2.652902126312256 val_loss: 16.456817626953125\n",
      "epoch:  27500 train_loss: 2.2750449180603027 val_loss: 16.063186645507812\n",
      "epoch:  27600 train_loss: 2.398590564727783 val_loss: 16.063844680786133\n",
      "epoch:  27700 train_loss: 2.0734832286834717 val_loss: 15.929276466369629\n",
      "epoch:  27800 train_loss: 2.147120237350464 val_loss: 16.070119857788086\n",
      "epoch:  27900 train_loss: 2.0950043201446533 val_loss: 16.00946617126465\n",
      "epoch:  28000 train_loss: 2.429091215133667 val_loss: 16.48748779296875\n",
      "epoch:  28100 train_loss: 2.305370569229126 val_loss: 16.369918823242188\n",
      "epoch:  28200 train_loss: 2.091916084289551 val_loss: 16.125354766845703\n",
      "epoch:  28300 train_loss: 2.046224355697632 val_loss: 16.161333084106445\n",
      "epoch:  28400 train_loss: 2.3346729278564453 val_loss: 16.27546501159668\n",
      "epoch:  28500 train_loss: 2.0210981369018555 val_loss: 16.156286239624023\n",
      "epoch:  28600 train_loss: 2.5032451152801514 val_loss: 16.713613510131836\n",
      "epoch:  28700 train_loss: 2.108819007873535 val_loss: 16.17229652404785\n",
      "epoch:  28800 train_loss: 2.010801315307617 val_loss: 16.251543045043945\n",
      "epoch:  28900 train_loss: 2.1618993282318115 val_loss: 16.504268646240234\n",
      "epoch:  29000 train_loss: 2.088564157485962 val_loss: 16.257976531982422\n",
      "epoch:  29100 train_loss: 1.991794466972351 val_loss: 16.365345001220703\n",
      "epoch:  29200 train_loss: 2.0505356788635254 val_loss: 16.412029266357422\n",
      "epoch:  29300 train_loss: 1.967942476272583 val_loss: 16.316030502319336\n",
      "epoch:  29400 train_loss: 2.126678705215454 val_loss: 16.396886825561523\n",
      "epoch:  29500 train_loss: 2.343966007232666 val_loss: 16.507747650146484\n",
      "epoch:  29600 train_loss: 2.106383800506592 val_loss: 16.373090744018555\n",
      "epoch:  29700 train_loss: 2.407928228378296 val_loss: 16.792522430419922\n",
      "epoch:  29800 train_loss: 2.0405654907226562 val_loss: 16.400423049926758\n",
      "epoch:  29900 train_loss: 2.184149742126465 val_loss: 16.67467498779297\n",
      "epoch:  30000 train_loss: 1.9301146268844604 val_loss: 16.439090728759766\n",
      "epoch:  30100 train_loss: 3.334165334701538 val_loss: 18.11089515686035\n",
      "epoch:  30200 train_loss: 2.1920597553253174 val_loss: 16.795684814453125\n",
      "epoch:  30300 train_loss: 2.9506163597106934 val_loss: 17.126602172851562\n",
      "epoch:  30400 train_loss: 2.000544786453247 val_loss: 16.500465393066406\n",
      "epoch:  30500 train_loss: 2.2706618309020996 val_loss: 17.100982666015625\n",
      "epoch:  30600 train_loss: 2.103893756866455 val_loss: 16.666465759277344\n",
      "epoch:  30700 train_loss: 1.9015945196151733 val_loss: 16.559951782226562\n",
      "epoch:  30800 train_loss: 2.189105749130249 val_loss: 16.870838165283203\n",
      "epoch:  30900 train_loss: 2.5304813385009766 val_loss: 17.699586868286133\n",
      "epoch:  31000 train_loss: 2.4044981002807617 val_loss: 17.10877227783203\n",
      "epoch:  31100 train_loss: 2.408055543899536 val_loss: 17.076030731201172\n",
      "epoch:  31200 train_loss: 2.234103202819824 val_loss: 17.16435432434082\n",
      "epoch:  31300 train_loss: 2.6664583683013916 val_loss: 17.31072235107422\n",
      "epoch:  31400 train_loss: 2.7937870025634766 val_loss: 17.255874633789062\n",
      "epoch:  31500 train_loss: 2.109069347381592 val_loss: 17.091901779174805\n",
      "epoch:  31600 train_loss: 2.1292638778686523 val_loss: 17.046106338500977\n",
      "epoch:  31700 train_loss: 2.1251258850097656 val_loss: 17.099288940429688\n",
      "epoch:  31800 train_loss: 3.7386739253997803 val_loss: 19.061534881591797\n",
      "epoch:  31900 train_loss: 1.8862706422805786 val_loss: 16.9234676361084\n",
      "epoch:  32000 train_loss: 2.1986918449401855 val_loss: 17.02989387512207\n",
      "epoch:  32100 train_loss: 1.8236638307571411 val_loss: 16.83336067199707\n",
      "epoch:  32200 train_loss: 1.9177665710449219 val_loss: 16.995655059814453\n",
      "epoch:  32300 train_loss: 1.859509825706482 val_loss: 16.90457534790039\n",
      "epoch:  32400 train_loss: 1.8138352632522583 val_loss: 16.9050235748291\n",
      "epoch:  32500 train_loss: 1.945492148399353 val_loss: 16.95888328552246\n",
      "epoch:  32600 train_loss: 2.0311899185180664 val_loss: 17.680538177490234\n",
      "epoch:  32700 train_loss: 1.9979798793792725 val_loss: 17.047103881835938\n",
      "epoch:  32800 train_loss: 2.0217411518096924 val_loss: 17.01127815246582\n",
      "epoch:  32900 train_loss: 2.03812837600708 val_loss: 17.405864715576172\n",
      "epoch:  33000 train_loss: 2.030334711074829 val_loss: 17.376039505004883\n",
      "epoch:  33100 train_loss: 2.1742072105407715 val_loss: 17.29401969909668\n",
      "epoch:  33200 train_loss: 1.9031769037246704 val_loss: 17.239635467529297\n",
      "epoch:  33300 train_loss: 2.050347089767456 val_loss: 17.184572219848633\n",
      "epoch:  33400 train_loss: 2.033963441848755 val_loss: 17.460220336914062\n",
      "epoch:  33500 train_loss: 3.2069809436798096 val_loss: 18.969755172729492\n",
      "epoch:  33600 train_loss: 1.7917218208312988 val_loss: 17.032899856567383\n",
      "epoch:  33700 train_loss: 1.8195830583572388 val_loss: 17.0665225982666\n",
      "epoch:  33800 train_loss: 2.5941314697265625 val_loss: 18.318893432617188\n",
      "epoch:  33900 train_loss: 2.7125027179718018 val_loss: 18.04706382751465\n",
      "epoch:  34000 train_loss: 2.2729647159576416 val_loss: 17.795654296875\n",
      "epoch:  34100 train_loss: 1.8031675815582275 val_loss: 17.232603073120117\n",
      "epoch:  34200 train_loss: 1.893523931503296 val_loss: 17.210189819335938\n",
      "epoch:  34300 train_loss: 2.2635273933410645 val_loss: 17.61231803894043\n",
      "epoch:  34400 train_loss: 2.195338010787964 val_loss: 17.41902732849121\n",
      "epoch:  34500 train_loss: 1.8277785778045654 val_loss: 17.254436492919922\n",
      "epoch:  34600 train_loss: 1.8549937009811401 val_loss: 17.315534591674805\n",
      "epoch:  34700 train_loss: 2.5861735343933105 val_loss: 18.17298698425293\n",
      "epoch:  34800 train_loss: 1.8596394062042236 val_loss: 17.415250778198242\n",
      "epoch:  34900 train_loss: 2.191272497177124 val_loss: 17.40019416809082\n",
      "epoch:  35000 train_loss: 1.7583280801773071 val_loss: 17.444990158081055\n",
      "epoch:  35100 train_loss: 1.715742588043213 val_loss: 17.409456253051758\n",
      "epoch:  35200 train_loss: 2.112532138824463 val_loss: 18.01604461669922\n",
      "epoch:  35300 train_loss: 1.727648138999939 val_loss: 17.470844268798828\n",
      "epoch:  35400 train_loss: 1.8194013833999634 val_loss: 17.57881736755371\n",
      "epoch:  35500 train_loss: 1.7080740928649902 val_loss: 17.363361358642578\n",
      "epoch:  35600 train_loss: 1.821384072303772 val_loss: 17.482866287231445\n",
      "epoch:  35700 train_loss: 1.746944785118103 val_loss: 17.575132369995117\n",
      "epoch:  35800 train_loss: 1.7925527095794678 val_loss: 17.60331916809082\n",
      "epoch:  35900 train_loss: 1.7421563863754272 val_loss: 17.554349899291992\n",
      "RMSE:  tensor(8.3602, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Ganerate the dataset\n",
    "i = 0\n",
    "sigma = 5.5\n",
    "my_dataset = []\n",
    "for ud in UDs:\n",
    "    example = []\n",
    "    for an in ANs:\n",
    "        noise = np.random.normal(0,sigma)\n",
    "        # 0 is mean\n",
    "        # sigma is the deviation of the normal distribution\n",
    "        d = compute_3d_distance(ud, an) + noise\n",
    "        example.append(d)\n",
    "    \n",
    "    # append x, y, z as col#10, #11, #12\n",
    "    example.append(ud[0])\n",
    "    example.append(ud[1])\n",
    "    example.append(ud[2])\n",
    "    \n",
    "    # append 1x13 example row into my_dataset\n",
    "    my_dataset.append(example)  # expected to be 3000x13  \n",
    "    \n",
    "# Load dataset\n",
    "exercise3_dataset = Exercise3Dataset(list_dataset = my_dataset, shuffle=True)\n",
    "\n",
    "#Split dataset by 0.8: 0.1: 0.1\n",
    "train_examples, train_labels = exercise3_dataset[:int(3000*0.8)]  # (2400, 10)   # (2400, 3)\n",
    "val_examples, val_labels = exercise3_dataset[int(3000*0.8):int(3000*0.9)]    # (300, 10)   #(300, 3)\n",
    "test_examples, test_labels = exercise3_dataset[int(3000*0.9):]     #(300, 10)   # (300, 3)\n",
    "\n",
    "###Define model, loss function and optimizer\n",
    "# if we have GPU, then use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define model\n",
    "model = Net(x_dim = train_examples.shape[1], y_dim = train_labels.shape[1]).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training and Validation\n",
    "\n",
    "train_examples = train_examples.to(device)\n",
    "train_labels = train_labels.to(device)\n",
    "val_examples = val_examples.to(device)\n",
    "val_labels = val_labels.to(device)\n",
    "\n",
    "# Define the model filename for model.save()\n",
    "MODEL_FILENAME = \"best.pth\"\n",
    "\n",
    "# set model to Training mode\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "NUM_OF_EPOCH = 36000\n",
    "\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    y_pred = model(train_examples)\n",
    "    loss = loss_fn(y_pred, train_labels).cpu()\n",
    "    #print(t, loss.item())\n",
    "    train_losses.append(loss.item())\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    # BGD\n",
    "    optimizer.step()\n",
    "    \n",
    "    # evaluate validation loss\n",
    "    val_pred = model(val_examples)\n",
    "    loss = loss_fn(val_pred, val_labels)\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "    # check if we got better loss\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n",
    "\n",
    "    if (epoch % 100) == 0:\n",
    "        print(\"epoch: \", epoch, \"train_loss:\", train_losses[-1], \"val_loss:\", val_losses[-1])\n",
    "        \n",
    "# Inference all testing examples and compute RMSE\n",
    "def square_error(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  square_error= loss_fn(a, b)\n",
    "  return square_error\n",
    "\n",
    "model.eval() # inference mode\n",
    "test_examples = test_examples.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "test_preds = model(test_examples)\n",
    "#print(\"example: \", test_example.cpu())\n",
    "#print(\"========================================\")\n",
    "#print(\"ground_truth:\", test_label.cpu())\n",
    "#print(\"prediction:\", test_pred.cpu())\n",
    "#print(\"========================================\")\n",
    "\n",
    "\n",
    "total_errors = 0.0\n",
    "for idx in range(len(test_examples)):\n",
    "    total_errors += square_error(test_preds[idx], test_labels[idx])\n",
    "    \n",
    "RMSE = torch.sqrt(total_errors / len(test_examples))\n",
    "print(\"RMSE: \",  RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigma = 6.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffle = True!\n",
      "epoch:  0 train_loss: 7350.23779296875 val_loss: 7356.08984375\n",
      "epoch:  100 train_loss: 211.52809143066406 val_loss: 193.26695251464844\n",
      "epoch:  200 train_loss: 162.3672637939453 val_loss: 152.09458923339844\n",
      "epoch:  300 train_loss: 77.83332824707031 val_loss: 75.20858001708984\n",
      "epoch:  400 train_loss: 53.98399353027344 val_loss: 52.741363525390625\n",
      "epoch:  500 train_loss: 47.771305084228516 val_loss: 46.789024353027344\n",
      "epoch:  600 train_loss: 16.58437156677246 val_loss: 16.3565616607666\n",
      "epoch:  700 train_loss: 14.175894737243652 val_loss: 14.425811767578125\n",
      "epoch:  800 train_loss: 13.219898223876953 val_loss: 13.657466888427734\n",
      "epoch:  900 train_loss: 12.558937072753906 val_loss: 13.229507446289062\n",
      "epoch:  1000 train_loss: 12.09862232208252 val_loss: 12.883935928344727\n",
      "epoch:  1100 train_loss: 11.735516548156738 val_loss: 12.660316467285156\n",
      "epoch:  1200 train_loss: 11.438739776611328 val_loss: 12.510899543762207\n",
      "epoch:  1300 train_loss: 11.1793212890625 val_loss: 12.366981506347656\n",
      "epoch:  1400 train_loss: 10.94973087310791 val_loss: 12.287004470825195\n",
      "epoch:  1500 train_loss: 10.742606163024902 val_loss: 12.269330978393555\n",
      "epoch:  1600 train_loss: 10.55981159210205 val_loss: 12.295547485351562\n",
      "epoch:  1700 train_loss: 10.392762184143066 val_loss: 12.284171104431152\n",
      "epoch:  1800 train_loss: 10.24304485321045 val_loss: 12.30397891998291\n",
      "epoch:  1900 train_loss: 10.105820655822754 val_loss: 12.370078086853027\n",
      "epoch:  2000 train_loss: 9.956046104431152 val_loss: 12.392295837402344\n",
      "epoch:  2100 train_loss: 9.818352699279785 val_loss: 12.366085052490234\n",
      "epoch:  2200 train_loss: 9.677845001220703 val_loss: 12.346942901611328\n",
      "epoch:  2300 train_loss: 9.540124893188477 val_loss: 12.367300987243652\n",
      "epoch:  2400 train_loss: 9.397008895874023 val_loss: 12.416274070739746\n",
      "epoch:  2500 train_loss: 9.253945350646973 val_loss: 12.53650188446045\n",
      "epoch:  2600 train_loss: 9.119340896606445 val_loss: 12.658942222595215\n",
      "epoch:  2700 train_loss: 9.005863189697266 val_loss: 12.796045303344727\n",
      "epoch:  2800 train_loss: 8.861092567443848 val_loss: 13.019270896911621\n",
      "epoch:  2900 train_loss: 8.757367134094238 val_loss: 13.1393461227417\n",
      "epoch:  3000 train_loss: 8.606648445129395 val_loss: 13.37802791595459\n",
      "epoch:  3100 train_loss: 8.476303100585938 val_loss: 13.4940767288208\n",
      "epoch:  3200 train_loss: 8.33389949798584 val_loss: 13.592926979064941\n",
      "epoch:  3300 train_loss: 8.231205940246582 val_loss: 13.735306739807129\n",
      "epoch:  3400 train_loss: 8.147015571594238 val_loss: 13.99184799194336\n",
      "epoch:  3500 train_loss: 7.948996543884277 val_loss: 14.065549850463867\n",
      "epoch:  3600 train_loss: 7.811487674713135 val_loss: 14.091841697692871\n",
      "epoch:  3700 train_loss: 7.674762725830078 val_loss: 14.041350364685059\n",
      "epoch:  3800 train_loss: 7.731321334838867 val_loss: 14.701990127563477\n",
      "epoch:  3900 train_loss: 7.450229167938232 val_loss: 14.30966854095459\n",
      "epoch:  4000 train_loss: 7.464351177215576 val_loss: 14.4561128616333\n",
      "epoch:  4100 train_loss: 7.284235000610352 val_loss: 15.020635604858398\n",
      "epoch:  4200 train_loss: 7.10504674911499 val_loss: 14.909989356994629\n",
      "epoch:  4300 train_loss: 7.2245097160339355 val_loss: 15.038649559020996\n",
      "epoch:  4400 train_loss: 6.913076400756836 val_loss: 15.277209281921387\n",
      "epoch:  4500 train_loss: 6.919318675994873 val_loss: 15.413783073425293\n",
      "epoch:  4600 train_loss: 6.719804286956787 val_loss: 15.818509101867676\n",
      "epoch:  4700 train_loss: 6.637160301208496 val_loss: 15.840127944946289\n",
      "epoch:  4800 train_loss: 6.712250232696533 val_loss: 15.754778861999512\n",
      "epoch:  4900 train_loss: 6.463581085205078 val_loss: 16.08307456970215\n",
      "epoch:  5000 train_loss: 6.386375427246094 val_loss: 16.06242561340332\n",
      "epoch:  5100 train_loss: 6.443485260009766 val_loss: 16.048797607421875\n",
      "epoch:  5200 train_loss: 6.336124420166016 val_loss: 16.1185245513916\n",
      "epoch:  5300 train_loss: 6.157886028289795 val_loss: 16.269487380981445\n",
      "epoch:  5400 train_loss: 6.3057332038879395 val_loss: 16.40161895751953\n",
      "epoch:  5500 train_loss: 6.1260480880737305 val_loss: 16.543853759765625\n",
      "epoch:  5600 train_loss: 5.9657487869262695 val_loss: 16.870595932006836\n",
      "epoch:  5700 train_loss: 6.003108978271484 val_loss: 16.758264541625977\n",
      "epoch:  5800 train_loss: 6.003998279571533 val_loss: 17.452404022216797\n",
      "epoch:  5900 train_loss: 6.125855922698975 val_loss: 17.702552795410156\n",
      "epoch:  6000 train_loss: 5.69592809677124 val_loss: 17.36958122253418\n",
      "epoch:  6100 train_loss: 5.795926570892334 val_loss: 17.735950469970703\n",
      "epoch:  6200 train_loss: 5.946080684661865 val_loss: 18.149913787841797\n",
      "epoch:  6300 train_loss: 5.578540802001953 val_loss: 17.636295318603516\n",
      "epoch:  6400 train_loss: 5.591317176818848 val_loss: 17.676944732666016\n",
      "epoch:  6500 train_loss: 5.488885402679443 val_loss: 17.9939022064209\n",
      "epoch:  6600 train_loss: 5.381307601928711 val_loss: 18.092159271240234\n",
      "epoch:  6700 train_loss: 5.455212593078613 val_loss: 18.05280876159668\n",
      "epoch:  6800 train_loss: 5.447100639343262 val_loss: 19.133848190307617\n",
      "epoch:  6900 train_loss: 5.780231475830078 val_loss: 18.33028221130371\n",
      "epoch:  7000 train_loss: 5.466775417327881 val_loss: 18.464853286743164\n",
      "epoch:  7100 train_loss: 5.316997528076172 val_loss: 18.648271560668945\n",
      "epoch:  7200 train_loss: 5.495776653289795 val_loss: 19.976980209350586\n",
      "epoch:  7300 train_loss: 5.177569389343262 val_loss: 19.285581588745117\n",
      "epoch:  7400 train_loss: 5.12644100189209 val_loss: 19.13349723815918\n",
      "epoch:  7500 train_loss: 5.0652079582214355 val_loss: 19.799041748046875\n",
      "epoch:  7600 train_loss: 5.357697486877441 val_loss: 18.966928482055664\n",
      "epoch:  7700 train_loss: 5.3297810554504395 val_loss: 19.07269859313965\n",
      "epoch:  7800 train_loss: 4.8814897537231445 val_loss: 19.442272186279297\n",
      "epoch:  7900 train_loss: 4.926783561706543 val_loss: 19.782358169555664\n",
      "epoch:  8000 train_loss: 4.808495998382568 val_loss: 19.47303581237793\n",
      "epoch:  8100 train_loss: 4.954287052154541 val_loss: 19.481605529785156\n",
      "epoch:  8200 train_loss: 5.608402729034424 val_loss: 21.182878494262695\n",
      "epoch:  8300 train_loss: 5.212490558624268 val_loss: 21.063871383666992\n",
      "epoch:  8400 train_loss: 4.697378158569336 val_loss: 20.006168365478516\n",
      "epoch:  8500 train_loss: 4.76558256149292 val_loss: 20.69049072265625\n",
      "epoch:  8600 train_loss: 4.867705345153809 val_loss: 19.849327087402344\n",
      "epoch:  8700 train_loss: 4.584628105163574 val_loss: 20.58635902404785\n",
      "epoch:  8800 train_loss: 4.621211051940918 val_loss: 21.013687133789062\n",
      "epoch:  8900 train_loss: 4.573130130767822 val_loss: 20.462722778320312\n",
      "epoch:  9000 train_loss: 4.484334468841553 val_loss: 20.904401779174805\n",
      "epoch:  9100 train_loss: 4.628136157989502 val_loss: 21.19797134399414\n",
      "epoch:  9200 train_loss: 4.4720940589904785 val_loss: 20.643205642700195\n",
      "epoch:  9300 train_loss: 4.438632488250732 val_loss: 21.404634475708008\n",
      "epoch:  9400 train_loss: 4.3738627433776855 val_loss: 20.942007064819336\n",
      "epoch:  9500 train_loss: 4.322694301605225 val_loss: 21.219911575317383\n",
      "epoch:  9600 train_loss: 4.771799564361572 val_loss: 20.689571380615234\n",
      "epoch:  9700 train_loss: 4.495777606964111 val_loss: 20.797435760498047\n",
      "epoch:  9800 train_loss: 4.447451591491699 val_loss: 20.836978912353516\n",
      "epoch:  9900 train_loss: 4.372335910797119 val_loss: 22.13766098022461\n",
      "epoch:  10000 train_loss: 4.286146640777588 val_loss: 21.617300033569336\n",
      "epoch:  10100 train_loss: 4.229619979858398 val_loss: 21.616525650024414\n",
      "epoch:  10200 train_loss: 4.380489826202393 val_loss: 22.492530822753906\n",
      "epoch:  10300 train_loss: 4.229782581329346 val_loss: 21.339258193969727\n",
      "epoch:  10400 train_loss: 4.279923439025879 val_loss: 21.219791412353516\n",
      "epoch:  10500 train_loss: 4.092687129974365 val_loss: 21.646595001220703\n",
      "epoch:  10600 train_loss: 4.295916557312012 val_loss: 22.310382843017578\n",
      "epoch:  10700 train_loss: 4.3758015632629395 val_loss: 21.24614143371582\n",
      "epoch:  10800 train_loss: 4.435622692108154 val_loss: 21.299978256225586\n",
      "epoch:  10900 train_loss: 4.039210796356201 val_loss: 21.833524703979492\n",
      "epoch:  11000 train_loss: 4.36058235168457 val_loss: 23.19822120666504\n",
      "epoch:  11100 train_loss: 3.9476449489593506 val_loss: 22.30682945251465\n",
      "epoch:  11200 train_loss: 3.921712875366211 val_loss: 22.39298439025879\n",
      "epoch:  11300 train_loss: 4.607485294342041 val_loss: 21.43462371826172\n",
      "epoch:  11400 train_loss: 3.961406707763672 val_loss: 21.687664031982422\n",
      "epoch:  11500 train_loss: 3.920332431793213 val_loss: 22.379188537597656\n",
      "epoch:  11600 train_loss: 3.8388543128967285 val_loss: 22.262786865234375\n",
      "epoch:  11700 train_loss: 3.8884060382843018 val_loss: 22.808992385864258\n",
      "epoch:  11800 train_loss: 3.8961989879608154 val_loss: 22.842586517333984\n",
      "epoch:  11900 train_loss: 4.073745250701904 val_loss: 22.810997009277344\n",
      "epoch:  12000 train_loss: 3.821686267852783 val_loss: 21.870929718017578\n",
      "epoch:  12100 train_loss: 3.9850432872772217 val_loss: 21.714323043823242\n",
      "epoch:  12200 train_loss: 3.7791950702667236 val_loss: 22.277469635009766\n",
      "epoch:  12300 train_loss: 3.9852066040039062 val_loss: 22.99239730834961\n",
      "epoch:  12400 train_loss: 3.673325777053833 val_loss: 22.39272689819336\n",
      "epoch:  12500 train_loss: 3.699554443359375 val_loss: 22.25187110900879\n",
      "epoch:  12600 train_loss: 3.739250421524048 val_loss: 23.000226974487305\n",
      "epoch:  12700 train_loss: 4.256918430328369 val_loss: 21.890451431274414\n",
      "epoch:  12800 train_loss: 3.813066005706787 val_loss: 21.90945816040039\n",
      "epoch:  12900 train_loss: 3.7224252223968506 val_loss: 22.593828201293945\n",
      "epoch:  13000 train_loss: 4.031308174133301 val_loss: 21.984176635742188\n",
      "epoch:  13100 train_loss: 3.982616662979126 val_loss: 23.324827194213867\n",
      "epoch:  13200 train_loss: 3.807514190673828 val_loss: 23.414276123046875\n",
      "epoch:  13300 train_loss: 3.5331814289093018 val_loss: 22.926301956176758\n",
      "epoch:  13400 train_loss: 4.3082709312438965 val_loss: 22.05662727355957\n",
      "epoch:  13500 train_loss: 4.100327968597412 val_loss: 23.50785255432129\n",
      "epoch:  13600 train_loss: 3.480851888656616 val_loss: 22.797712326049805\n",
      "epoch:  13700 train_loss: 3.5727672576904297 val_loss: 22.391733169555664\n",
      "epoch:  13800 train_loss: 4.089942932128906 val_loss: 21.89945411682129\n",
      "epoch:  13900 train_loss: 3.66738224029541 val_loss: 22.250877380371094\n",
      "epoch:  14000 train_loss: 3.4207613468170166 val_loss: 23.011457443237305\n",
      "epoch:  14100 train_loss: 3.46683406829834 val_loss: 22.681293487548828\n",
      "epoch:  14200 train_loss: 3.4560556411743164 val_loss: 22.50489616394043\n",
      "epoch:  14300 train_loss: 3.399008274078369 val_loss: 22.303203582763672\n",
      "epoch:  14400 train_loss: 3.398446559906006 val_loss: 23.480527877807617\n",
      "epoch:  14500 train_loss: 3.3234972953796387 val_loss: 23.27461814880371\n",
      "epoch:  14600 train_loss: 3.4065306186676025 val_loss: 23.260513305664062\n",
      "epoch:  14700 train_loss: 3.7390284538269043 val_loss: 24.533023834228516\n",
      "epoch:  14800 train_loss: 3.584677219390869 val_loss: 24.032978057861328\n",
      "epoch:  14900 train_loss: 3.447038412094116 val_loss: 23.657520294189453\n",
      "epoch:  15000 train_loss: 3.508761167526245 val_loss: 22.56133270263672\n",
      "epoch:  15100 train_loss: 3.6052932739257812 val_loss: 22.53542137145996\n",
      "epoch:  15200 train_loss: 3.299586057662964 val_loss: 23.12428855895996\n",
      "epoch:  15300 train_loss: 3.4713470935821533 val_loss: 24.08022689819336\n",
      "epoch:  15400 train_loss: 3.40277361869812 val_loss: 23.98671531677246\n",
      "epoch:  15500 train_loss: 3.1762282848358154 val_loss: 23.281476974487305\n",
      "epoch:  15600 train_loss: 3.5633795261383057 val_loss: 22.64479637145996\n",
      "epoch:  15700 train_loss: 3.1688077449798584 val_loss: 23.344532012939453\n",
      "epoch:  15800 train_loss: 3.424645185470581 val_loss: 24.579904556274414\n",
      "epoch:  15900 train_loss: 4.778459548950195 val_loss: 22.7014102935791\n",
      "epoch:  16000 train_loss: 3.2911324501037598 val_loss: 23.03783416748047\n",
      "epoch:  16100 train_loss: 3.223146677017212 val_loss: 23.87885856628418\n",
      "epoch:  16200 train_loss: 3.259040355682373 val_loss: 24.236499786376953\n",
      "epoch:  16300 train_loss: 3.124173879623413 val_loss: 23.992687225341797\n",
      "epoch:  16400 train_loss: 3.0936524868011475 val_loss: 23.239604949951172\n",
      "epoch:  16500 train_loss: 3.3940589427948 val_loss: 23.211441040039062\n",
      "epoch:  16600 train_loss: 4.185922145843506 val_loss: 22.94638442993164\n",
      "epoch:  16700 train_loss: 3.3135273456573486 val_loss: 24.59659767150879\n",
      "epoch:  16800 train_loss: 3.4415359497070312 val_loss: 23.553892135620117\n",
      "epoch:  16900 train_loss: 3.1407856941223145 val_loss: 23.136629104614258\n",
      "epoch:  17000 train_loss: 3.448465347290039 val_loss: 25.48466682434082\n",
      "epoch:  17100 train_loss: 3.093698024749756 val_loss: 23.249149322509766\n",
      "epoch:  17200 train_loss: 3.178102731704712 val_loss: 24.518033981323242\n",
      "epoch:  17300 train_loss: 3.064167022705078 val_loss: 23.420881271362305\n",
      "epoch:  17400 train_loss: 3.2508933544158936 val_loss: 24.80144500732422\n",
      "epoch:  17500 train_loss: 2.924173355102539 val_loss: 24.153112411499023\n",
      "epoch:  17600 train_loss: 2.951486110687256 val_loss: 24.550161361694336\n",
      "epoch:  17700 train_loss: 3.232959508895874 val_loss: 23.27497100830078\n",
      "epoch:  17800 train_loss: 3.050685405731201 val_loss: 24.83797836303711\n",
      "epoch:  17900 train_loss: 3.0968408584594727 val_loss: 24.799379348754883\n",
      "epoch:  18000 train_loss: 3.2472610473632812 val_loss: 24.929048538208008\n",
      "epoch:  18100 train_loss: 2.841264486312866 val_loss: 23.86123275756836\n",
      "epoch:  18200 train_loss: 2.853764772415161 val_loss: 23.859010696411133\n",
      "epoch:  18300 train_loss: 2.8386006355285645 val_loss: 23.942344665527344\n",
      "epoch:  18400 train_loss: 2.8259429931640625 val_loss: 23.799625396728516\n",
      "epoch:  18500 train_loss: 2.8741888999938965 val_loss: 24.507877349853516\n",
      "epoch:  18600 train_loss: 2.9083290100097656 val_loss: 24.381763458251953\n",
      "epoch:  18700 train_loss: 3.0733158588409424 val_loss: 23.4280948638916\n",
      "epoch:  18800 train_loss: 2.8647689819335938 val_loss: 24.061614990234375\n",
      "epoch:  18900 train_loss: 2.979247570037842 val_loss: 25.103044509887695\n",
      "epoch:  19000 train_loss: 2.893439769744873 val_loss: 23.58037757873535\n",
      "epoch:  19100 train_loss: 3.1990723609924316 val_loss: 23.387313842773438\n",
      "epoch:  19200 train_loss: 3.0406978130340576 val_loss: 25.228870391845703\n",
      "epoch:  19300 train_loss: 2.774205207824707 val_loss: 24.010160446166992\n",
      "epoch:  19400 train_loss: 2.7443673610687256 val_loss: 24.009492874145508\n",
      "epoch:  19500 train_loss: 3.0299925804138184 val_loss: 23.569578170776367\n",
      "epoch:  19600 train_loss: 2.791513204574585 val_loss: 23.729610443115234\n",
      "epoch:  19700 train_loss: 3.01084041595459 val_loss: 25.478422164916992\n",
      "epoch:  19800 train_loss: 2.660050630569458 val_loss: 24.255420684814453\n",
      "epoch:  19900 train_loss: 2.7047667503356934 val_loss: 24.314889907836914\n",
      "epoch:  20000 train_loss: 3.1657497882843018 val_loss: 23.741966247558594\n",
      "epoch:  20100 train_loss: 2.769256353378296 val_loss: 24.538755416870117\n",
      "epoch:  20200 train_loss: 2.8367931842803955 val_loss: 25.071731567382812\n",
      "epoch:  20300 train_loss: 3.155348539352417 val_loss: 25.896358489990234\n",
      "epoch:  20400 train_loss: 2.9327540397644043 val_loss: 25.05837059020996\n",
      "epoch:  20500 train_loss: 2.870347023010254 val_loss: 24.009063720703125\n",
      "epoch:  20600 train_loss: 3.1535329818725586 val_loss: 23.876407623291016\n",
      "epoch:  20700 train_loss: 2.565364122390747 val_loss: 24.257410049438477\n",
      "epoch:  20800 train_loss: 2.9086241722106934 val_loss: 25.390443801879883\n",
      "epoch:  20900 train_loss: 2.6701817512512207 val_loss: 24.317462921142578\n",
      "epoch:  21000 train_loss: 3.1242568492889404 val_loss: 25.5205078125\n",
      "epoch:  21100 train_loss: 2.566206693649292 val_loss: 24.209558486938477\n",
      "epoch:  21200 train_loss: 2.7695703506469727 val_loss: 24.26078224182129\n",
      "epoch:  21300 train_loss: 2.563831090927124 val_loss: 24.2939453125\n",
      "epoch:  21400 train_loss: 2.595519542694092 val_loss: 24.543569564819336\n",
      "epoch:  21500 train_loss: 2.8888466358184814 val_loss: 24.117982864379883\n",
      "epoch:  21600 train_loss: 2.6146936416625977 val_loss: 24.42679786682129\n",
      "epoch:  21700 train_loss: 2.5514214038848877 val_loss: 25.1256160736084\n",
      "epoch:  21800 train_loss: 2.9374403953552246 val_loss: 24.257095336914062\n",
      "epoch:  21900 train_loss: 2.762983560562134 val_loss: 26.097583770751953\n",
      "epoch:  22000 train_loss: 2.57855486869812 val_loss: 24.383739471435547\n",
      "epoch:  22100 train_loss: 2.480376958847046 val_loss: 24.811847686767578\n",
      "epoch:  22200 train_loss: 2.475454807281494 val_loss: 24.878093719482422\n",
      "epoch:  22300 train_loss: 2.7265172004699707 val_loss: 26.138450622558594\n",
      "epoch:  22400 train_loss: 2.49265193939209 val_loss: 24.668630599975586\n",
      "epoch:  22500 train_loss: 2.4325826168060303 val_loss: 24.69845199584961\n",
      "epoch:  22600 train_loss: 2.436117172241211 val_loss: 25.772201538085938\n",
      "epoch:  22700 train_loss: 2.504317045211792 val_loss: 25.709732055664062\n",
      "epoch:  22800 train_loss: 2.785991668701172 val_loss: 24.55754852294922\n",
      "epoch:  22900 train_loss: 2.5763394832611084 val_loss: 25.30128288269043\n",
      "epoch:  23000 train_loss: 3.1053683757781982 val_loss: 27.28627586364746\n",
      "epoch:  23100 train_loss: 2.6507949829101562 val_loss: 26.406875610351562\n",
      "epoch:  23200 train_loss: 2.3623225688934326 val_loss: 25.617170333862305\n",
      "epoch:  23300 train_loss: 2.7467010021209717 val_loss: 26.97493553161621\n",
      "epoch:  23400 train_loss: 2.5621790885925293 val_loss: 24.881610870361328\n",
      "epoch:  23500 train_loss: 2.2856180667877197 val_loss: 25.6661376953125\n",
      "epoch:  23600 train_loss: 2.533172369003296 val_loss: 24.882020950317383\n",
      "epoch:  23700 train_loss: 2.4040262699127197 val_loss: 25.729726791381836\n",
      "epoch:  23800 train_loss: 2.5699214935302734 val_loss: 26.52456283569336\n",
      "epoch:  23900 train_loss: 2.875418186187744 val_loss: 26.969797134399414\n",
      "epoch:  24000 train_loss: 2.4453890323638916 val_loss: 25.99658966064453\n",
      "epoch:  24100 train_loss: 2.244065284729004 val_loss: 25.340585708618164\n",
      "epoch:  24200 train_loss: 2.2706103324890137 val_loss: 26.21552085876465\n",
      "epoch:  24300 train_loss: 2.740697145462036 val_loss: 24.87929344177246\n",
      "epoch:  24400 train_loss: 2.79677414894104 val_loss: 26.947254180908203\n",
      "epoch:  24500 train_loss: 2.319638252258301 val_loss: 26.27446746826172\n",
      "epoch:  24600 train_loss: 2.6139252185821533 val_loss: 24.897518157958984\n",
      "epoch:  24700 train_loss: 2.5064871311187744 val_loss: 25.111780166625977\n",
      "epoch:  24800 train_loss: 2.3366031646728516 val_loss: 25.082275390625\n",
      "epoch:  24900 train_loss: 2.1886022090911865 val_loss: 25.5961856842041\n",
      "epoch:  25000 train_loss: 2.857530117034912 val_loss: 27.544336318969727\n",
      "epoch:  25100 train_loss: 2.1683871746063232 val_loss: 26.089656829833984\n",
      "epoch:  25200 train_loss: 2.1804964542388916 val_loss: 25.527904510498047\n",
      "epoch:  25300 train_loss: 2.398890733718872 val_loss: 26.176103591918945\n",
      "epoch:  25400 train_loss: 2.179358720779419 val_loss: 26.203218460083008\n",
      "epoch:  25500 train_loss: 2.3966925144195557 val_loss: 26.183698654174805\n",
      "epoch:  25600 train_loss: 2.2506649494171143 val_loss: 25.427467346191406\n",
      "epoch:  25700 train_loss: 2.189626693725586 val_loss: 25.984548568725586\n",
      "epoch:  25800 train_loss: 2.377560615539551 val_loss: 25.131296157836914\n",
      "epoch:  25900 train_loss: 2.1109061241149902 val_loss: 25.766250610351562\n",
      "epoch:  26000 train_loss: 2.5158166885375977 val_loss: 25.386146545410156\n",
      "epoch:  26100 train_loss: 2.131138324737549 val_loss: 25.949827194213867\n",
      "epoch:  26200 train_loss: 2.233639717102051 val_loss: 25.511377334594727\n",
      "epoch:  26300 train_loss: 2.1529717445373535 val_loss: 25.5139217376709\n",
      "epoch:  26400 train_loss: 2.5601749420166016 val_loss: 27.364215850830078\n",
      "epoch:  26500 train_loss: 2.684329032897949 val_loss: 27.478992462158203\n",
      "epoch:  26600 train_loss: 2.0422298908233643 val_loss: 26.354761123657227\n",
      "epoch:  26700 train_loss: 2.540313720703125 val_loss: 26.35087776184082\n",
      "epoch:  26800 train_loss: 2.3211159706115723 val_loss: 25.445777893066406\n",
      "epoch:  26900 train_loss: 3.0862131118774414 val_loss: 28.28017807006836\n",
      "epoch:  27000 train_loss: 2.352057933807373 val_loss: 26.970104217529297\n",
      "epoch:  27100 train_loss: 2.1434288024902344 val_loss: 25.86733627319336\n",
      "epoch:  27200 train_loss: 2.0605030059814453 val_loss: 25.682231903076172\n",
      "epoch:  27300 train_loss: 2.0123136043548584 val_loss: 26.329866409301758\n",
      "epoch:  27400 train_loss: 2.2141287326812744 val_loss: 25.83937644958496\n",
      "epoch:  27500 train_loss: 2.0335533618927 val_loss: 25.80605125427246\n",
      "epoch:  27600 train_loss: 2.0736966133117676 val_loss: 25.822612762451172\n",
      "epoch:  27700 train_loss: 2.2755095958709717 val_loss: 25.68784523010254\n",
      "epoch:  27800 train_loss: 1.9703923463821411 val_loss: 26.5654296875\n",
      "epoch:  27900 train_loss: 2.1875863075256348 val_loss: 26.76657485961914\n",
      "epoch:  28000 train_loss: 2.203315019607544 val_loss: 26.83334732055664\n",
      "epoch:  28100 train_loss: 2.0466365814208984 val_loss: 25.836841583251953\n",
      "epoch:  28200 train_loss: 2.1136457920074463 val_loss: 26.105159759521484\n",
      "epoch:  28300 train_loss: 2.265390157699585 val_loss: 26.887907028198242\n",
      "epoch:  28400 train_loss: 2.0456058979034424 val_loss: 26.085668563842773\n",
      "epoch:  28500 train_loss: 2.1533403396606445 val_loss: 27.41539192199707\n",
      "epoch:  28600 train_loss: 2.1918387413024902 val_loss: 27.31917953491211\n",
      "epoch:  28700 train_loss: 2.3841114044189453 val_loss: 27.751319885253906\n",
      "epoch:  28800 train_loss: 2.5605337619781494 val_loss: 25.711532592773438\n",
      "epoch:  28900 train_loss: 2.122499704360962 val_loss: 26.873498916625977\n",
      "epoch:  29000 train_loss: 2.17183780670166 val_loss: 27.41736602783203\n",
      "epoch:  29100 train_loss: 2.1565933227539062 val_loss: 26.11151123046875\n",
      "epoch:  29200 train_loss: 1.989988088607788 val_loss: 26.465023040771484\n",
      "epoch:  29300 train_loss: 1.8572138547897339 val_loss: 26.725696563720703\n",
      "epoch:  29400 train_loss: 2.0002477169036865 val_loss: 26.6391658782959\n",
      "epoch:  29500 train_loss: 2.502920627593994 val_loss: 25.917482376098633\n",
      "epoch:  29600 train_loss: 2.094480037689209 val_loss: 27.787809371948242\n",
      "epoch:  29700 train_loss: 1.9795806407928467 val_loss: 26.087100982666016\n",
      "epoch:  29800 train_loss: 2.0586891174316406 val_loss: 27.329524993896484\n",
      "epoch:  29900 train_loss: 1.856062650680542 val_loss: 26.608516693115234\n",
      "epoch:  30000 train_loss: 2.030623435974121 val_loss: 27.243867874145508\n",
      "epoch:  30100 train_loss: 2.0391342639923096 val_loss: 27.051128387451172\n",
      "epoch:  30200 train_loss: 1.9144214391708374 val_loss: 27.126190185546875\n",
      "epoch:  30300 train_loss: 3.397320032119751 val_loss: 25.910839080810547\n",
      "epoch:  30400 train_loss: 1.978310465812683 val_loss: 26.43845558166504\n",
      "epoch:  30500 train_loss: 1.8826193809509277 val_loss: 26.348295211791992\n",
      "epoch:  30600 train_loss: 1.9078787565231323 val_loss: 26.807010650634766\n",
      "epoch:  30700 train_loss: 1.9036613702774048 val_loss: 26.64611053466797\n",
      "epoch:  30800 train_loss: 2.0280892848968506 val_loss: 26.192838668823242\n",
      "epoch:  30900 train_loss: 1.7791932821273804 val_loss: 26.561264038085938\n",
      "epoch:  31000 train_loss: 2.051246404647827 val_loss: 27.542587280273438\n",
      "epoch:  31100 train_loss: 1.7618886232376099 val_loss: 26.860082626342773\n",
      "epoch:  31200 train_loss: 1.8603410720825195 val_loss: 27.352283477783203\n",
      "epoch:  31300 train_loss: 2.137075424194336 val_loss: 27.698326110839844\n",
      "epoch:  31400 train_loss: 1.8742611408233643 val_loss: 27.250516891479492\n",
      "epoch:  31500 train_loss: 1.7693326473236084 val_loss: 27.190311431884766\n",
      "epoch:  31600 train_loss: 1.858986735343933 val_loss: 26.921836853027344\n",
      "epoch:  31700 train_loss: 2.7514419555664062 val_loss: 28.158720016479492\n",
      "epoch:  31800 train_loss: 2.217963218688965 val_loss: 28.661052703857422\n",
      "epoch:  31900 train_loss: 2.1097967624664307 val_loss: 27.595157623291016\n",
      "epoch:  32000 train_loss: 1.974255919456482 val_loss: 27.786680221557617\n",
      "epoch:  32100 train_loss: 1.7570421695709229 val_loss: 26.79444122314453\n",
      "epoch:  32200 train_loss: 1.7515498399734497 val_loss: 26.90569496154785\n",
      "epoch:  32300 train_loss: 1.919937014579773 val_loss: 27.665096282958984\n",
      "epoch:  32400 train_loss: 2.1786181926727295 val_loss: 28.9854736328125\n",
      "epoch:  32500 train_loss: 2.2994723320007324 val_loss: 28.759918212890625\n",
      "epoch:  32600 train_loss: 1.8136420249938965 val_loss: 27.628177642822266\n",
      "epoch:  32700 train_loss: 1.7413002252578735 val_loss: 27.00957679748535\n",
      "epoch:  32800 train_loss: 1.7020682096481323 val_loss: 27.105947494506836\n",
      "epoch:  32900 train_loss: 1.7663553953170776 val_loss: 26.715309143066406\n",
      "epoch:  33000 train_loss: 1.8618888854980469 val_loss: 28.052644729614258\n",
      "epoch:  33100 train_loss: 2.1382229328155518 val_loss: 26.717453002929688\n",
      "epoch:  33200 train_loss: 1.6619770526885986 val_loss: 27.35977554321289\n",
      "epoch:  33300 train_loss: 1.724865198135376 val_loss: 27.526020050048828\n",
      "epoch:  33400 train_loss: 1.6527281999588013 val_loss: 27.71672821044922\n",
      "epoch:  33500 train_loss: 2.1399552822113037 val_loss: 28.457561492919922\n",
      "epoch:  33600 train_loss: 1.9934581518173218 val_loss: 27.813819885253906\n",
      "epoch:  33700 train_loss: 1.8736685514450073 val_loss: 28.32149887084961\n",
      "epoch:  33800 train_loss: 1.6374706029891968 val_loss: 27.678308486938477\n",
      "epoch:  33900 train_loss: 1.9879878759384155 val_loss: 28.75423240661621\n",
      "epoch:  34000 train_loss: 1.8670166730880737 val_loss: 27.276540756225586\n",
      "epoch:  34100 train_loss: 1.6831670999526978 val_loss: 28.174116134643555\n",
      "epoch:  34200 train_loss: 1.7523969411849976 val_loss: 27.381120681762695\n",
      "epoch:  34300 train_loss: 1.9020376205444336 val_loss: 27.03896141052246\n",
      "epoch:  34400 train_loss: 2.187779188156128 val_loss: 29.630840301513672\n",
      "epoch:  34500 train_loss: 1.9360389709472656 val_loss: 27.27848243713379\n",
      "epoch:  34600 train_loss: 2.264533519744873 val_loss: 27.526445388793945\n",
      "epoch:  34700 train_loss: 1.6074548959732056 val_loss: 27.455638885498047\n",
      "epoch:  34800 train_loss: 1.756348729133606 val_loss: 27.178897857666016\n",
      "epoch:  34900 train_loss: 1.875399112701416 val_loss: 28.38569450378418\n",
      "epoch:  35000 train_loss: 1.843110203742981 val_loss: 28.009414672851562\n",
      "epoch:  35100 train_loss: 1.763168215751648 val_loss: 28.71621322631836\n",
      "epoch:  35200 train_loss: 1.9323433637619019 val_loss: 28.33826446533203\n",
      "epoch:  35300 train_loss: 1.5703800916671753 val_loss: 27.590591430664062\n",
      "epoch:  35400 train_loss: 1.5625994205474854 val_loss: 28.21220588684082\n",
      "epoch:  35500 train_loss: 1.7935529947280884 val_loss: 27.566884994506836\n",
      "epoch:  35600 train_loss: 1.5724284648895264 val_loss: 27.65359878540039\n",
      "epoch:  35700 train_loss: 2.0154635906219482 val_loss: 27.1635684967041\n",
      "epoch:  35800 train_loss: 2.088606357574463 val_loss: 28.066463470458984\n",
      "epoch:  35900 train_loss: 2.185594320297241 val_loss: 29.417171478271484\n",
      "RMSE:  tensor(9.2469, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Ganerate the dataset\n",
    "i = 0\n",
    "sigma = 6.4\n",
    "my_dataset = []\n",
    "for ud in UDs:\n",
    "    example = []\n",
    "    for an in ANs:\n",
    "        noise = np.random.normal(0,sigma)\n",
    "        # 0 is mean\n",
    "        # sigma is the deviation of the normal distribution\n",
    "        d = compute_3d_distance(ud, an) + noise\n",
    "        example.append(d)\n",
    "    \n",
    "    # append x, y, z as col#10, #11, #12\n",
    "    example.append(ud[0])\n",
    "    example.append(ud[1])\n",
    "    example.append(ud[2])\n",
    "    \n",
    "    # append 1x13 example row into my_dataset\n",
    "    my_dataset.append(example)  # expected to be 3000x13  \n",
    "    \n",
    "# Load dataset\n",
    "exercise3_dataset = Exercise3Dataset(list_dataset = my_dataset, shuffle=True)\n",
    "\n",
    "#Split dataset by 0.8: 0.1: 0.1\n",
    "train_examples, train_labels = exercise3_dataset[:int(3000*0.8)]  # (2400, 10)   # (2400, 3)\n",
    "val_examples, val_labels = exercise3_dataset[int(3000*0.8):int(3000*0.9)]    # (300, 10)   #(300, 3)\n",
    "test_examples, test_labels = exercise3_dataset[int(3000*0.9):]     #(300, 10)   # (300, 3)\n",
    "\n",
    "###Define model, loss function and optimizer\n",
    "# if we have GPU, then use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define model\n",
    "model = Net(x_dim = train_examples.shape[1], y_dim = train_labels.shape[1]).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training and Validation\n",
    "\n",
    "train_examples = train_examples.to(device)\n",
    "train_labels = train_labels.to(device)\n",
    "val_examples = val_examples.to(device)\n",
    "val_labels = val_labels.to(device)\n",
    "\n",
    "# Define the model filename for model.save()\n",
    "MODEL_FILENAME = \"best.pth\"\n",
    "\n",
    "# set model to Training mode\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "NUM_OF_EPOCH = 36000\n",
    "\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    y_pred = model(train_examples)\n",
    "    loss = loss_fn(y_pred, train_labels).cpu()\n",
    "    #print(t, loss.item())\n",
    "    train_losses.append(loss.item())\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    # BGD\n",
    "    optimizer.step()\n",
    "    \n",
    "    # evaluate validation loss\n",
    "    val_pred = model(val_examples)\n",
    "    loss = loss_fn(val_pred, val_labels)\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "    # check if we got better loss\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n",
    "\n",
    "    if (epoch % 100) == 0:\n",
    "        print(\"epoch: \", epoch, \"train_loss:\", train_losses[-1], \"val_loss:\", val_losses[-1])\n",
    "        \n",
    "# Inference all testing examples and compute RMSE\n",
    "def square_error(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  square_error= loss_fn(a, b)\n",
    "  return square_error\n",
    "\n",
    "model.eval() # inference mode\n",
    "test_examples = test_examples.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "test_preds = model(test_examples)\n",
    "#print(\"example: \", test_example.cpu())\n",
    "#print(\"========================================\")\n",
    "#print(\"ground_truth:\", test_label.cpu())\n",
    "#print(\"prediction:\", test_pred.cpu())\n",
    "#print(\"========================================\")\n",
    "\n",
    "\n",
    "total_errors = 0.0\n",
    "for idx in range(len(test_examples)):\n",
    "    total_errors += square_error(test_preds[idx], test_labels[idx])\n",
    "    \n",
    "RMSE = torch.sqrt(total_errors / len(test_examples))\n",
    "print(\"RMSE: \",  RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigma = 7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffle = True!\n",
      "epoch:  0 train_loss: 7345.15771484375 val_loss: 7257.99951171875\n",
      "epoch:  100 train_loss: 207.85702514648438 val_loss: 204.559326171875\n",
      "epoch:  200 train_loss: 147.24192810058594 val_loss: 150.16966247558594\n",
      "epoch:  300 train_loss: 72.73666381835938 val_loss: 77.56412506103516\n",
      "epoch:  400 train_loss: 51.473060607910156 val_loss: 56.71505355834961\n",
      "epoch:  500 train_loss: 43.778350830078125 val_loss: 48.08146667480469\n",
      "epoch:  600 train_loss: 22.657962799072266 val_loss: 24.347837448120117\n",
      "epoch:  700 train_loss: 17.880334854125977 val_loss: 19.861480712890625\n",
      "epoch:  800 train_loss: 16.937225341796875 val_loss: 18.8616886138916\n",
      "epoch:  900 train_loss: 16.267555236816406 val_loss: 18.19053077697754\n",
      "epoch:  1000 train_loss: 15.738123893737793 val_loss: 17.66830825805664\n",
      "epoch:  1100 train_loss: 15.305723190307617 val_loss: 17.22311019897461\n",
      "epoch:  1200 train_loss: 14.924114227294922 val_loss: 16.899822235107422\n",
      "epoch:  1300 train_loss: 14.588247299194336 val_loss: 16.57737922668457\n",
      "epoch:  1400 train_loss: 14.276601791381836 val_loss: 16.3160343170166\n",
      "epoch:  1500 train_loss: 13.99775505065918 val_loss: 16.101106643676758\n",
      "epoch:  1600 train_loss: 13.749781608581543 val_loss: 15.896528244018555\n",
      "epoch:  1700 train_loss: 13.522133827209473 val_loss: 15.73216438293457\n",
      "epoch:  1800 train_loss: 13.308538436889648 val_loss: 15.585737228393555\n",
      "epoch:  1900 train_loss: 13.11067008972168 val_loss: 15.499191284179688\n",
      "epoch:  2000 train_loss: 12.932997703552246 val_loss: 15.437220573425293\n",
      "epoch:  2100 train_loss: 12.760619163513184 val_loss: 15.463325500488281\n",
      "epoch:  2200 train_loss: 12.578845977783203 val_loss: 15.41367244720459\n",
      "epoch:  2300 train_loss: 12.401522636413574 val_loss: 15.469433784484863\n",
      "epoch:  2400 train_loss: 12.22795581817627 val_loss: 15.438665390014648\n",
      "epoch:  2500 train_loss: 12.055534362792969 val_loss: 15.520760536193848\n",
      "epoch:  2600 train_loss: 11.8960599899292 val_loss: 15.56032943725586\n",
      "epoch:  2700 train_loss: 11.74144172668457 val_loss: 15.562250137329102\n",
      "epoch:  2800 train_loss: 11.607619285583496 val_loss: 15.651945114135742\n",
      "epoch:  2900 train_loss: 11.46300983428955 val_loss: 15.677289962768555\n",
      "epoch:  3000 train_loss: 11.318190574645996 val_loss: 15.768341064453125\n",
      "epoch:  3100 train_loss: 11.1559476852417 val_loss: 15.951981544494629\n",
      "epoch:  3200 train_loss: 10.999236106872559 val_loss: 16.040409088134766\n",
      "epoch:  3300 train_loss: 10.844030380249023 val_loss: 16.151470184326172\n",
      "epoch:  3400 train_loss: 10.68269157409668 val_loss: 16.223901748657227\n",
      "epoch:  3500 train_loss: 10.52834415435791 val_loss: 16.36661148071289\n",
      "epoch:  3600 train_loss: 10.387726783752441 val_loss: 16.47612953186035\n",
      "epoch:  3700 train_loss: 10.219243049621582 val_loss: 16.68001937866211\n",
      "epoch:  3800 train_loss: 10.062577247619629 val_loss: 16.7855167388916\n",
      "epoch:  3900 train_loss: 9.887359619140625 val_loss: 17.029340744018555\n",
      "epoch:  4000 train_loss: 9.772215843200684 val_loss: 17.269115447998047\n",
      "epoch:  4100 train_loss: 9.581878662109375 val_loss: 17.39168930053711\n",
      "epoch:  4200 train_loss: 9.500712394714355 val_loss: 17.58366584777832\n",
      "epoch:  4300 train_loss: 9.390935897827148 val_loss: 17.84848403930664\n",
      "epoch:  4400 train_loss: 9.241629600524902 val_loss: 18.021650314331055\n",
      "epoch:  4500 train_loss: 9.089007377624512 val_loss: 17.978391647338867\n",
      "epoch:  4600 train_loss: 9.237059593200684 val_loss: 18.207059860229492\n",
      "epoch:  4700 train_loss: 8.809711456298828 val_loss: 18.156448364257812\n",
      "epoch:  4800 train_loss: 8.714815139770508 val_loss: 18.2990665435791\n",
      "epoch:  4900 train_loss: 8.600379943847656 val_loss: 18.431949615478516\n",
      "epoch:  5000 train_loss: 8.625351905822754 val_loss: 18.938745498657227\n",
      "epoch:  5100 train_loss: 8.385537147521973 val_loss: 18.715023040771484\n",
      "epoch:  5200 train_loss: 8.665270805358887 val_loss: 19.00958251953125\n",
      "epoch:  5300 train_loss: 8.336204528808594 val_loss: 19.193517684936523\n",
      "epoch:  5400 train_loss: 8.342808723449707 val_loss: 19.419828414916992\n",
      "epoch:  5500 train_loss: 8.03165054321289 val_loss: 19.10165786743164\n",
      "epoch:  5600 train_loss: 7.899994850158691 val_loss: 19.177001953125\n",
      "epoch:  5700 train_loss: 7.987336158752441 val_loss: 19.706933975219727\n",
      "epoch:  5800 train_loss: 7.900301933288574 val_loss: 19.336936950683594\n",
      "epoch:  5900 train_loss: 7.937784671783447 val_loss: 19.683320999145508\n",
      "epoch:  6000 train_loss: 7.586868762969971 val_loss: 19.555091857910156\n",
      "epoch:  6100 train_loss: 7.587706565856934 val_loss: 19.589326858520508\n",
      "epoch:  6200 train_loss: 7.45163631439209 val_loss: 19.79862403869629\n",
      "epoch:  6300 train_loss: 7.688195705413818 val_loss: 20.25617218017578\n",
      "epoch:  6400 train_loss: 7.4990129470825195 val_loss: 20.31639862060547\n",
      "epoch:  6500 train_loss: 7.214963912963867 val_loss: 19.779170989990234\n",
      "epoch:  6600 train_loss: 7.403130054473877 val_loss: 20.04324722290039\n",
      "epoch:  6700 train_loss: 7.0894317626953125 val_loss: 19.998931884765625\n",
      "epoch:  6800 train_loss: 7.0033087730407715 val_loss: 20.315078735351562\n",
      "epoch:  6900 train_loss: 7.035594940185547 val_loss: 20.4495792388916\n",
      "epoch:  7000 train_loss: 6.9986371994018555 val_loss: 20.7176456451416\n",
      "epoch:  7100 train_loss: 6.865163326263428 val_loss: 20.658187866210938\n",
      "epoch:  7200 train_loss: 6.806615829467773 val_loss: 20.777509689331055\n",
      "epoch:  7300 train_loss: 6.857236385345459 val_loss: 21.123794555664062\n",
      "epoch:  7400 train_loss: 6.6298604011535645 val_loss: 20.855899810791016\n",
      "epoch:  7500 train_loss: 6.664613723754883 val_loss: 20.695051193237305\n",
      "epoch:  7600 train_loss: 6.7382965087890625 val_loss: 20.83616828918457\n",
      "epoch:  7700 train_loss: 6.634073734283447 val_loss: 21.274658203125\n",
      "epoch:  7800 train_loss: 6.591335773468018 val_loss: 20.89251708984375\n",
      "epoch:  7900 train_loss: 6.391144275665283 val_loss: 20.963111877441406\n",
      "epoch:  8000 train_loss: 6.748214244842529 val_loss: 22.023088455200195\n",
      "epoch:  8100 train_loss: 6.344221115112305 val_loss: 20.998455047607422\n",
      "epoch:  8200 train_loss: 6.496695041656494 val_loss: 21.075319290161133\n",
      "epoch:  8300 train_loss: 6.429465293884277 val_loss: 21.301223754882812\n",
      "epoch:  8400 train_loss: 6.504763603210449 val_loss: 21.220930099487305\n",
      "epoch:  8500 train_loss: 6.352538108825684 val_loss: 22.01900291442871\n",
      "epoch:  8600 train_loss: 6.201756000518799 val_loss: 22.031909942626953\n",
      "epoch:  8700 train_loss: 6.150556564331055 val_loss: 21.352230072021484\n",
      "epoch:  8800 train_loss: 6.242799758911133 val_loss: 22.383901596069336\n",
      "epoch:  8900 train_loss: 5.965249538421631 val_loss: 22.14699935913086\n",
      "epoch:  9000 train_loss: 6.5177998542785645 val_loss: 22.03642463684082\n",
      "epoch:  9100 train_loss: 5.937367916107178 val_loss: 22.541831970214844\n",
      "epoch:  9200 train_loss: 6.058250427246094 val_loss: 22.679582595825195\n",
      "epoch:  9300 train_loss: 5.832386016845703 val_loss: 22.56084442138672\n",
      "epoch:  9400 train_loss: 6.222023963928223 val_loss: 21.97434425354004\n",
      "epoch:  9500 train_loss: 5.854101657867432 val_loss: 21.906614303588867\n",
      "epoch:  9600 train_loss: 6.037448406219482 val_loss: 22.23387336730957\n",
      "epoch:  9700 train_loss: 5.657528400421143 val_loss: 22.072418212890625\n",
      "epoch:  9800 train_loss: 6.207817077636719 val_loss: 22.066884994506836\n",
      "epoch:  9900 train_loss: 5.710188865661621 val_loss: 22.0040283203125\n",
      "epoch:  10000 train_loss: 6.10598611831665 val_loss: 22.3267765045166\n",
      "epoch:  10100 train_loss: 5.473294258117676 val_loss: 22.31725311279297\n",
      "epoch:  10200 train_loss: 5.753811836242676 val_loss: 22.287817001342773\n",
      "epoch:  10300 train_loss: 5.635493755340576 val_loss: 22.875080108642578\n",
      "epoch:  10400 train_loss: 5.521303653717041 val_loss: 23.220823287963867\n",
      "epoch:  10500 train_loss: 5.354128837585449 val_loss: 22.9348087310791\n",
      "epoch:  10600 train_loss: 5.947763919830322 val_loss: 23.78944969177246\n",
      "epoch:  10700 train_loss: 5.470699787139893 val_loss: 22.620288848876953\n",
      "epoch:  10800 train_loss: 5.488945960998535 val_loss: 23.6359806060791\n",
      "epoch:  10900 train_loss: 5.333556652069092 val_loss: 22.816387176513672\n",
      "epoch:  11000 train_loss: 5.140817165374756 val_loss: 22.855499267578125\n",
      "epoch:  11100 train_loss: 5.246603488922119 val_loss: 22.769014358520508\n",
      "epoch:  11200 train_loss: 5.2144389152526855 val_loss: 23.103893280029297\n",
      "epoch:  11300 train_loss: 5.04469633102417 val_loss: 23.054655075073242\n",
      "epoch:  11400 train_loss: 5.097020626068115 val_loss: 22.872882843017578\n",
      "epoch:  11500 train_loss: 4.988356113433838 val_loss: 23.299222946166992\n",
      "epoch:  11600 train_loss: 4.954972267150879 val_loss: 23.535755157470703\n",
      "epoch:  11700 train_loss: 5.3715925216674805 val_loss: 24.34310531616211\n",
      "epoch:  11800 train_loss: 5.028651237487793 val_loss: 23.462739944458008\n",
      "epoch:  11900 train_loss: 4.863659858703613 val_loss: 23.651288986206055\n",
      "epoch:  12000 train_loss: 4.888876914978027 val_loss: 23.42384147644043\n",
      "epoch:  12100 train_loss: 5.032079219818115 val_loss: 23.204139709472656\n",
      "epoch:  12200 train_loss: 4.925471782684326 val_loss: 23.291688919067383\n",
      "epoch:  12300 train_loss: 5.1033501625061035 val_loss: 23.976028442382812\n",
      "epoch:  12400 train_loss: 4.771006107330322 val_loss: 23.398038864135742\n",
      "epoch:  12500 train_loss: 4.90447473526001 val_loss: 23.974332809448242\n",
      "epoch:  12600 train_loss: 5.0445051193237305 val_loss: 24.458303451538086\n",
      "epoch:  12700 train_loss: 4.925163269042969 val_loss: 23.421667098999023\n",
      "epoch:  12800 train_loss: 4.815206050872803 val_loss: 24.219865798950195\n",
      "epoch:  12900 train_loss: 5.397486209869385 val_loss: 24.106603622436523\n",
      "epoch:  13000 train_loss: 5.214320659637451 val_loss: 24.593027114868164\n",
      "epoch:  13100 train_loss: 5.104822158813477 val_loss: 23.681867599487305\n",
      "epoch:  13200 train_loss: 5.366244792938232 val_loss: 24.35055923461914\n",
      "epoch:  13300 train_loss: 4.587815284729004 val_loss: 24.34212303161621\n",
      "epoch:  13400 train_loss: 4.862081050872803 val_loss: 23.75874137878418\n",
      "epoch:  13500 train_loss: 4.4547576904296875 val_loss: 23.761606216430664\n",
      "epoch:  13600 train_loss: 4.643896102905273 val_loss: 24.48404312133789\n",
      "epoch:  13700 train_loss: 4.666597366333008 val_loss: 23.920000076293945\n",
      "epoch:  13800 train_loss: 4.687854766845703 val_loss: 23.910686492919922\n",
      "epoch:  13900 train_loss: 4.526022434234619 val_loss: 23.8408203125\n",
      "epoch:  14000 train_loss: 5.335814476013184 val_loss: 25.92091941833496\n",
      "epoch:  14100 train_loss: 4.884504795074463 val_loss: 25.175241470336914\n",
      "epoch:  14200 train_loss: 4.930934429168701 val_loss: 25.37859344482422\n",
      "epoch:  14300 train_loss: 4.258732795715332 val_loss: 24.25087547302246\n",
      "epoch:  14400 train_loss: 4.258713245391846 val_loss: 24.344196319580078\n",
      "epoch:  14500 train_loss: 5.138279438018799 val_loss: 24.121835708618164\n",
      "epoch:  14600 train_loss: 4.350727081298828 val_loss: 24.68827247619629\n",
      "epoch:  14700 train_loss: 4.251963138580322 val_loss: 24.154386520385742\n",
      "epoch:  14800 train_loss: 4.212932586669922 val_loss: 24.096792221069336\n",
      "epoch:  14900 train_loss: 4.3185882568359375 val_loss: 25.03848648071289\n",
      "epoch:  15000 train_loss: 4.106550693511963 val_loss: 24.284334182739258\n",
      "epoch:  15100 train_loss: 4.691988945007324 val_loss: 25.275104522705078\n",
      "epoch:  15200 train_loss: 4.233012676239014 val_loss: 24.16539764404297\n",
      "epoch:  15300 train_loss: 4.247507572174072 val_loss: 24.765060424804688\n",
      "epoch:  15400 train_loss: 4.151741981506348 val_loss: 24.879322052001953\n",
      "epoch:  15500 train_loss: 4.3932600021362305 val_loss: 24.946809768676758\n",
      "epoch:  15600 train_loss: 4.216446399688721 val_loss: 24.40066909790039\n",
      "epoch:  15700 train_loss: 4.558069705963135 val_loss: 24.49256134033203\n",
      "epoch:  15800 train_loss: 4.615128040313721 val_loss: 25.366863250732422\n",
      "epoch:  15900 train_loss: 4.036592483520508 val_loss: 24.728717803955078\n",
      "epoch:  16000 train_loss: 4.589400291442871 val_loss: 25.393354415893555\n",
      "epoch:  16100 train_loss: 4.212613105773926 val_loss: 24.664934158325195\n",
      "epoch:  16200 train_loss: 3.9024112224578857 val_loss: 24.45326042175293\n",
      "epoch:  16300 train_loss: 3.8525619506835938 val_loss: 24.760868072509766\n",
      "epoch:  16400 train_loss: 5.175050735473633 val_loss: 24.6900577545166\n",
      "epoch:  16500 train_loss: 4.7415971755981445 val_loss: 24.792316436767578\n",
      "epoch:  16600 train_loss: 4.555306434631348 val_loss: 25.518264770507812\n",
      "epoch:  16700 train_loss: 3.8098602294921875 val_loss: 24.830394744873047\n",
      "epoch:  16800 train_loss: 3.740689754486084 val_loss: 24.779327392578125\n",
      "epoch:  16900 train_loss: 3.878187656402588 val_loss: 24.697845458984375\n",
      "epoch:  17000 train_loss: 3.769432783126831 val_loss: 24.706098556518555\n",
      "epoch:  17100 train_loss: 3.728715181350708 val_loss: 24.986412048339844\n",
      "epoch:  17200 train_loss: 4.265318870544434 val_loss: 25.74626350402832\n",
      "epoch:  17300 train_loss: 3.658430576324463 val_loss: 25.190658569335938\n",
      "epoch:  17400 train_loss: 3.8230268955230713 val_loss: 24.7882080078125\n",
      "epoch:  17500 train_loss: 3.75846529006958 val_loss: 24.89737892150879\n",
      "epoch:  17600 train_loss: 4.280904769897461 val_loss: 25.978670120239258\n",
      "epoch:  17700 train_loss: 4.097994804382324 val_loss: 26.261720657348633\n",
      "epoch:  17800 train_loss: 4.116067886352539 val_loss: 26.002094268798828\n",
      "epoch:  17900 train_loss: 3.7537598609924316 val_loss: 25.15667152404785\n",
      "epoch:  18000 train_loss: 4.508563995361328 val_loss: 24.819522857666016\n",
      "epoch:  18100 train_loss: 3.7010064125061035 val_loss: 24.774137496948242\n",
      "epoch:  18200 train_loss: 4.012587547302246 val_loss: 25.611202239990234\n",
      "epoch:  18300 train_loss: 3.769101619720459 val_loss: 25.166154861450195\n",
      "epoch:  18400 train_loss: 3.5702552795410156 val_loss: 25.163711547851562\n",
      "epoch:  18500 train_loss: 3.436997652053833 val_loss: 25.510482788085938\n",
      "epoch:  18600 train_loss: 3.4864020347595215 val_loss: 25.366825103759766\n",
      "epoch:  18700 train_loss: 3.48418927192688 val_loss: 25.49476432800293\n",
      "epoch:  18800 train_loss: 3.390380620956421 val_loss: 25.495338439941406\n",
      "epoch:  18900 train_loss: 3.7344017028808594 val_loss: 25.27787208557129\n",
      "epoch:  19000 train_loss: 3.9300806522369385 val_loss: 25.480274200439453\n",
      "epoch:  19100 train_loss: 3.339113473892212 val_loss: 25.12737464904785\n",
      "epoch:  19200 train_loss: 3.9494636058807373 val_loss: 25.242408752441406\n",
      "epoch:  19300 train_loss: 4.262648582458496 val_loss: 25.494596481323242\n",
      "epoch:  19400 train_loss: 3.557546854019165 val_loss: 25.757156372070312\n",
      "epoch:  19500 train_loss: 4.2327656745910645 val_loss: 25.93288230895996\n",
      "epoch:  19600 train_loss: 3.477187156677246 val_loss: 26.28668975830078\n",
      "epoch:  19700 train_loss: 3.5628998279571533 val_loss: 25.74985694885254\n",
      "epoch:  19800 train_loss: 3.227201223373413 val_loss: 25.517560958862305\n",
      "epoch:  19900 train_loss: 3.310603380203247 val_loss: 26.0251522064209\n",
      "epoch:  20000 train_loss: 3.5985565185546875 val_loss: 26.449220657348633\n",
      "epoch:  20100 train_loss: 3.256612777709961 val_loss: 26.081449508666992\n",
      "epoch:  20200 train_loss: 3.665452480316162 val_loss: 26.472192764282227\n",
      "epoch:  20300 train_loss: 3.3897321224212646 val_loss: 26.531471252441406\n",
      "epoch:  20400 train_loss: 3.153846025466919 val_loss: 25.743810653686523\n",
      "epoch:  20500 train_loss: 3.635882616043091 val_loss: 26.784730911254883\n",
      "epoch:  20600 train_loss: 3.423372507095337 val_loss: 27.407848358154297\n",
      "epoch:  20700 train_loss: 3.395118236541748 val_loss: 25.912647247314453\n",
      "epoch:  20800 train_loss: 4.097578525543213 val_loss: 26.695398330688477\n",
      "epoch:  20900 train_loss: 4.0780534744262695 val_loss: 26.99628448486328\n",
      "epoch:  21000 train_loss: 3.249941110610962 val_loss: 26.112899780273438\n",
      "epoch:  21100 train_loss: 3.9297215938568115 val_loss: 27.16434097290039\n",
      "epoch:  21200 train_loss: 3.035951614379883 val_loss: 26.513639450073242\n",
      "epoch:  21300 train_loss: 3.823446750640869 val_loss: 27.055322647094727\n",
      "epoch:  21400 train_loss: 3.148954153060913 val_loss: 26.536680221557617\n",
      "epoch:  21500 train_loss: 3.857923746109009 val_loss: 26.284406661987305\n",
      "epoch:  21600 train_loss: 2.985240936279297 val_loss: 26.288869857788086\n",
      "epoch:  21700 train_loss: 3.283364772796631 val_loss: 26.566801071166992\n",
      "epoch:  21800 train_loss: 2.9242773056030273 val_loss: 26.319862365722656\n",
      "epoch:  21900 train_loss: 3.2177844047546387 val_loss: 27.01179313659668\n",
      "epoch:  22000 train_loss: 3.097825527191162 val_loss: 26.41353416442871\n",
      "epoch:  22100 train_loss: 2.8810694217681885 val_loss: 26.35234832763672\n",
      "epoch:  22200 train_loss: 3.2841036319732666 val_loss: 26.123273849487305\n",
      "epoch:  22300 train_loss: 2.8891613483428955 val_loss: 26.288707733154297\n",
      "epoch:  22400 train_loss: 3.3773245811462402 val_loss: 26.211891174316406\n",
      "epoch:  22500 train_loss: 2.8204870223999023 val_loss: 26.399682998657227\n",
      "epoch:  22600 train_loss: 3.232781171798706 val_loss: 26.680166244506836\n",
      "epoch:  22700 train_loss: 2.796747922897339 val_loss: 26.73569679260254\n",
      "epoch:  22800 train_loss: 2.826061725616455 val_loss: 26.608640670776367\n",
      "epoch:  22900 train_loss: 4.192807674407959 val_loss: 27.013286590576172\n",
      "epoch:  23000 train_loss: 2.900655508041382 val_loss: 27.368362426757812\n",
      "epoch:  23100 train_loss: 3.2851717472076416 val_loss: 27.770418167114258\n",
      "epoch:  23200 train_loss: 2.991084098815918 val_loss: 26.54721450805664\n",
      "epoch:  23300 train_loss: 2.7703700065612793 val_loss: 26.817167282104492\n",
      "epoch:  23400 train_loss: 2.977060556411743 val_loss: 26.830751419067383\n",
      "epoch:  23500 train_loss: 3.0853028297424316 val_loss: 27.292314529418945\n",
      "epoch:  23600 train_loss: 3.1150400638580322 val_loss: 27.71894645690918\n",
      "epoch:  23700 train_loss: 2.750460386276245 val_loss: 27.16242218017578\n",
      "epoch:  23800 train_loss: 2.7335994243621826 val_loss: 27.045934677124023\n",
      "epoch:  23900 train_loss: 2.867421865463257 val_loss: 26.86672019958496\n",
      "epoch:  24000 train_loss: 2.6566221714019775 val_loss: 26.99844741821289\n",
      "epoch:  24100 train_loss: 3.5457143783569336 val_loss: 27.633777618408203\n",
      "epoch:  24200 train_loss: 2.6648995876312256 val_loss: 27.046754837036133\n",
      "epoch:  24300 train_loss: 2.9238579273223877 val_loss: 26.770357131958008\n",
      "epoch:  24400 train_loss: 3.461726665496826 val_loss: 27.4635066986084\n",
      "epoch:  24500 train_loss: 3.535141706466675 val_loss: 28.447402954101562\n",
      "epoch:  24600 train_loss: 3.1167240142822266 val_loss: 28.254295349121094\n",
      "epoch:  24700 train_loss: 2.6570422649383545 val_loss: 27.425643920898438\n",
      "epoch:  24800 train_loss: 3.3706705570220947 val_loss: 27.732027053833008\n",
      "epoch:  24900 train_loss: 3.0219428539276123 val_loss: 28.057865142822266\n",
      "epoch:  25000 train_loss: 2.951230525970459 val_loss: 27.635412216186523\n",
      "epoch:  25100 train_loss: 3.0601308345794678 val_loss: 28.363454818725586\n",
      "epoch:  25200 train_loss: 2.702504873275757 val_loss: 27.199264526367188\n",
      "epoch:  25300 train_loss: 2.6326491832733154 val_loss: 27.860204696655273\n",
      "epoch:  25400 train_loss: 2.8780298233032227 val_loss: 27.56317710876465\n",
      "epoch:  25500 train_loss: 4.117568492889404 val_loss: 29.449003219604492\n",
      "epoch:  25600 train_loss: 2.760497808456421 val_loss: 27.147287368774414\n",
      "epoch:  25700 train_loss: 2.5378079414367676 val_loss: 27.841726303100586\n",
      "epoch:  25800 train_loss: 3.005028247833252 val_loss: 27.343599319458008\n",
      "epoch:  25900 train_loss: 2.47794771194458 val_loss: 27.306962966918945\n",
      "epoch:  26000 train_loss: 3.1324493885040283 val_loss: 27.531593322753906\n",
      "epoch:  26100 train_loss: 2.5218722820281982 val_loss: 27.966571807861328\n",
      "epoch:  26200 train_loss: 2.7574474811553955 val_loss: 27.956680297851562\n",
      "epoch:  26300 train_loss: 2.9584949016571045 val_loss: 28.615005493164062\n",
      "epoch:  26400 train_loss: 2.4223668575286865 val_loss: 27.650304794311523\n",
      "epoch:  26500 train_loss: 2.458583116531372 val_loss: 28.18077850341797\n",
      "epoch:  26600 train_loss: 2.43074369430542 val_loss: 27.592418670654297\n",
      "epoch:  26700 train_loss: 3.4950246810913086 val_loss: 28.58414077758789\n",
      "epoch:  26800 train_loss: 2.7280099391937256 val_loss: 27.40766143798828\n",
      "epoch:  26900 train_loss: 2.6582319736480713 val_loss: 27.612899780273438\n",
      "epoch:  27000 train_loss: 2.492124080657959 val_loss: 27.60249137878418\n",
      "epoch:  27100 train_loss: 2.339526891708374 val_loss: 27.65613555908203\n",
      "epoch:  27200 train_loss: 2.4256410598754883 val_loss: 27.67864227294922\n",
      "epoch:  27300 train_loss: 2.774230718612671 val_loss: 27.50729751586914\n",
      "epoch:  27400 train_loss: 3.4566521644592285 val_loss: 27.815092086791992\n",
      "epoch:  27500 train_loss: 2.3448150157928467 val_loss: 27.855512619018555\n",
      "epoch:  27600 train_loss: 2.392056703567505 val_loss: 28.106853485107422\n",
      "epoch:  27700 train_loss: 2.325561761856079 val_loss: 28.039661407470703\n",
      "epoch:  27800 train_loss: 2.4550418853759766 val_loss: 28.166244506835938\n",
      "epoch:  27900 train_loss: 3.2929019927978516 val_loss: 29.25889778137207\n",
      "epoch:  28000 train_loss: 2.360743284225464 val_loss: 27.830183029174805\n",
      "epoch:  28100 train_loss: 3.205030679702759 val_loss: 29.449235916137695\n",
      "epoch:  28200 train_loss: 3.325122594833374 val_loss: 28.629966735839844\n",
      "epoch:  28300 train_loss: 2.736877202987671 val_loss: 27.823328018188477\n",
      "epoch:  28400 train_loss: 2.3329601287841797 val_loss: 27.808774948120117\n",
      "epoch:  28500 train_loss: 2.4631571769714355 val_loss: 27.983736038208008\n",
      "epoch:  28600 train_loss: 2.5148842334747314 val_loss: 27.945310592651367\n",
      "epoch:  28700 train_loss: 2.2620034217834473 val_loss: 28.167699813842773\n",
      "epoch:  28800 train_loss: 2.8489692211151123 val_loss: 29.18008041381836\n",
      "epoch:  28900 train_loss: 2.2575485706329346 val_loss: 27.940099716186523\n",
      "epoch:  29000 train_loss: 2.5348706245422363 val_loss: 29.04879379272461\n",
      "epoch:  29100 train_loss: 3.1011836528778076 val_loss: 27.965200424194336\n",
      "epoch:  29200 train_loss: 2.390510320663452 val_loss: 28.840312957763672\n",
      "epoch:  29300 train_loss: 2.1695408821105957 val_loss: 28.401302337646484\n",
      "epoch:  29400 train_loss: 2.204834461212158 val_loss: 28.396940231323242\n",
      "epoch:  29500 train_loss: 2.4808247089385986 val_loss: 28.89772605895996\n",
      "epoch:  29600 train_loss: 2.533623456954956 val_loss: 28.189075469970703\n",
      "epoch:  29700 train_loss: 2.3661298751831055 val_loss: 28.64595603942871\n",
      "epoch:  29800 train_loss: 2.1507856845855713 val_loss: 28.1889705657959\n",
      "epoch:  29900 train_loss: 2.194317102432251 val_loss: 28.549564361572266\n",
      "epoch:  30000 train_loss: 2.478505849838257 val_loss: 28.514463424682617\n",
      "epoch:  30100 train_loss: 2.5073211193084717 val_loss: 28.530399322509766\n",
      "epoch:  30200 train_loss: 2.7286298274993896 val_loss: 28.415925979614258\n",
      "epoch:  30300 train_loss: 3.2576775550842285 val_loss: 28.606645584106445\n",
      "epoch:  30400 train_loss: 2.623225450515747 val_loss: 29.554555892944336\n",
      "epoch:  30500 train_loss: 3.157999277114868 val_loss: 30.052410125732422\n",
      "epoch:  30600 train_loss: 2.6093127727508545 val_loss: 29.43329429626465\n",
      "epoch:  30700 train_loss: 2.263185739517212 val_loss: 28.78157615661621\n",
      "epoch:  30800 train_loss: 2.375950813293457 val_loss: 28.282222747802734\n",
      "epoch:  30900 train_loss: 2.1487627029418945 val_loss: 28.869781494140625\n",
      "epoch:  31000 train_loss: 2.4103353023529053 val_loss: 28.72986602783203\n",
      "epoch:  31100 train_loss: 3.246178388595581 val_loss: 28.612844467163086\n",
      "epoch:  31200 train_loss: 2.0427215099334717 val_loss: 28.64336395263672\n",
      "epoch:  31300 train_loss: 2.5282082557678223 val_loss: 29.433320999145508\n",
      "epoch:  31400 train_loss: 2.2308754920959473 val_loss: 29.317686080932617\n",
      "epoch:  31500 train_loss: 2.907008647918701 val_loss: 28.9290771484375\n",
      "epoch:  31600 train_loss: 2.1869654655456543 val_loss: 29.216901779174805\n",
      "epoch:  31700 train_loss: 2.6658568382263184 val_loss: 28.868152618408203\n",
      "epoch:  31800 train_loss: 2.159888744354248 val_loss: 28.465356826782227\n",
      "epoch:  31900 train_loss: 3.5669867992401123 val_loss: 30.957548141479492\n",
      "epoch:  32000 train_loss: 2.5550506114959717 val_loss: 30.0323486328125\n",
      "epoch:  32100 train_loss: 2.034609079360962 val_loss: 28.694332122802734\n",
      "epoch:  32200 train_loss: 3.2436652183532715 val_loss: 29.567119598388672\n",
      "epoch:  32300 train_loss: 2.5580532550811768 val_loss: 29.919692993164062\n",
      "epoch:  32400 train_loss: 2.113675355911255 val_loss: 29.483325958251953\n",
      "epoch:  32500 train_loss: 2.2719638347625732 val_loss: 28.74583625793457\n",
      "epoch:  32600 train_loss: 2.4014456272125244 val_loss: 29.820083618164062\n",
      "epoch:  32700 train_loss: 2.0939877033233643 val_loss: 29.022451400756836\n",
      "epoch:  32800 train_loss: 3.46889328956604 val_loss: 28.85893440246582\n",
      "epoch:  32900 train_loss: 2.1956381797790527 val_loss: 29.77555274963379\n",
      "epoch:  33000 train_loss: 2.3185718059539795 val_loss: 29.202831268310547\n",
      "epoch:  33100 train_loss: 3.5257859230041504 val_loss: 30.274185180664062\n",
      "epoch:  33200 train_loss: 2.415449619293213 val_loss: 29.34023094177246\n",
      "epoch:  33300 train_loss: 2.5554845333099365 val_loss: 30.021259307861328\n",
      "epoch:  33400 train_loss: 2.2652082443237305 val_loss: 29.650800704956055\n",
      "epoch:  33500 train_loss: 2.3843371868133545 val_loss: 29.85820960998535\n",
      "epoch:  33600 train_loss: 2.131930351257324 val_loss: 29.109872817993164\n",
      "epoch:  33700 train_loss: 1.9815161228179932 val_loss: 29.06131935119629\n",
      "epoch:  33800 train_loss: 2.539335012435913 val_loss: 29.514812469482422\n",
      "epoch:  33900 train_loss: 2.0731678009033203 val_loss: 29.589982986450195\n",
      "epoch:  34000 train_loss: 3.4109017848968506 val_loss: 31.40435028076172\n",
      "epoch:  34100 train_loss: 2.212632179260254 val_loss: 29.812238693237305\n",
      "epoch:  34200 train_loss: 1.978875756263733 val_loss: 29.30257797241211\n",
      "epoch:  34300 train_loss: 2.5494284629821777 val_loss: 30.42121124267578\n",
      "epoch:  34400 train_loss: 2.386781930923462 val_loss: 30.506301879882812\n",
      "epoch:  34500 train_loss: 2.118849992752075 val_loss: 29.09503746032715\n",
      "epoch:  34600 train_loss: 2.1032798290252686 val_loss: 29.01778793334961\n",
      "epoch:  34700 train_loss: 2.0125572681427 val_loss: 29.068347930908203\n",
      "epoch:  34800 train_loss: 2.3793153762817383 val_loss: 29.798368453979492\n",
      "epoch:  34900 train_loss: 2.5936057567596436 val_loss: 30.237882614135742\n",
      "epoch:  35000 train_loss: 2.2601990699768066 val_loss: 29.03668785095215\n",
      "epoch:  35100 train_loss: 2.135868549346924 val_loss: 30.160375595092773\n",
      "epoch:  35200 train_loss: 1.902695894241333 val_loss: 29.60066032409668\n",
      "epoch:  35300 train_loss: 2.092880964279175 val_loss: 29.589187622070312\n",
      "epoch:  35400 train_loss: 2.010989189147949 val_loss: 30.176990509033203\n",
      "epoch:  35500 train_loss: 1.9487589597702026 val_loss: 30.356718063354492\n",
      "epoch:  35600 train_loss: 3.0254032611846924 val_loss: 29.72011375427246\n",
      "epoch:  35700 train_loss: 4.656174182891846 val_loss: 33.09850311279297\n",
      "epoch:  35800 train_loss: 2.1010308265686035 val_loss: 29.368396759033203\n",
      "epoch:  35900 train_loss: 2.2088167667388916 val_loss: 30.50301742553711\n",
      "RMSE:  tensor(10.0984, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Ganerate the dataset\n",
    "i = 0\n",
    "sigma = 7.3\n",
    "my_dataset = []\n",
    "for ud in UDs:\n",
    "    example = []\n",
    "    for an in ANs:\n",
    "        noise = np.random.normal(0,sigma)\n",
    "        # 0 is mean\n",
    "        # sigma is the deviation of the normal distribution\n",
    "        d = compute_3d_distance(ud, an) + noise\n",
    "        example.append(d)\n",
    "    \n",
    "    # append x, y, z as col#10, #11, #12\n",
    "    example.append(ud[0])\n",
    "    example.append(ud[1])\n",
    "    example.append(ud[2])\n",
    "    \n",
    "    # append 1x13 example row into my_dataset\n",
    "    my_dataset.append(example)  # expected to be 3000x13  \n",
    "    \n",
    "# Load dataset\n",
    "exercise3_dataset = Exercise3Dataset(list_dataset = my_dataset, shuffle=True)\n",
    "\n",
    "#Split dataset by 0.8: 0.1: 0.1\n",
    "train_examples, train_labels = exercise3_dataset[:int(3000*0.8)]  # (2400, 10)   # (2400, 3)\n",
    "val_examples, val_labels = exercise3_dataset[int(3000*0.8):int(3000*0.9)]    # (300, 10)   #(300, 3)\n",
    "test_examples, test_labels = exercise3_dataset[int(3000*0.9):]     #(300, 10)   # (300, 3)\n",
    "\n",
    "###Define model, loss function and optimizer\n",
    "# if we have GPU, then use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define model\n",
    "model = Net(x_dim = train_examples.shape[1], y_dim = train_labels.shape[1]).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training and Validation\n",
    "\n",
    "train_examples = train_examples.to(device)\n",
    "train_labels = train_labels.to(device)\n",
    "val_examples = val_examples.to(device)\n",
    "val_labels = val_labels.to(device)\n",
    "\n",
    "# Define the model filename for model.save()\n",
    "MODEL_FILENAME = \"best.pth\"\n",
    "\n",
    "# set model to Training mode\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "NUM_OF_EPOCH = 36000\n",
    "\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    y_pred = model(train_examples)\n",
    "    loss = loss_fn(y_pred, train_labels).cpu()\n",
    "    #print(t, loss.item())\n",
    "    train_losses.append(loss.item())\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    # BGD\n",
    "    optimizer.step()\n",
    "    \n",
    "    # evaluate validation loss\n",
    "    val_pred = model(val_examples)\n",
    "    loss = loss_fn(val_pred, val_labels)\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "    # check if we got better loss\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n",
    "\n",
    "    if (epoch % 100) == 0:\n",
    "        print(\"epoch: \", epoch, \"train_loss:\", train_losses[-1], \"val_loss:\", val_losses[-1])\n",
    "        \n",
    "# Inference all testing examples and compute RMSE\n",
    "def square_error(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  square_error= loss_fn(a, b)\n",
    "  return square_error\n",
    "\n",
    "model.eval() # inference mode\n",
    "test_examples = test_examples.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "test_preds = model(test_examples)\n",
    "#print(\"example: \", test_example.cpu())\n",
    "#print(\"========================================\")\n",
    "#print(\"ground_truth:\", test_label.cpu())\n",
    "#print(\"prediction:\", test_pred.cpu())\n",
    "#print(\"========================================\")\n",
    "\n",
    "\n",
    "total_errors = 0.0\n",
    "for idx in range(len(test_examples)):\n",
    "    total_errors += square_error(test_preds[idx], test_labels[idx])\n",
    "    \n",
    "RMSE = torch.sqrt(total_errors / len(test_examples))\n",
    "print(\"RMSE: \",  RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigma = 8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffle = True!\n",
      "epoch:  0 train_loss: 7350.96630859375 val_loss: 7369.9130859375\n",
      "epoch:  100 train_loss: 239.00164794921875 val_loss: 252.09645080566406\n",
      "epoch:  200 train_loss: 181.79649353027344 val_loss: 190.40538024902344\n",
      "epoch:  300 train_loss: 88.8342056274414 val_loss: 92.01372528076172\n",
      "epoch:  400 train_loss: 56.371376037597656 val_loss: 57.30653762817383\n",
      "epoch:  500 train_loss: 39.97848129272461 val_loss: 40.55574035644531\n",
      "epoch:  600 train_loss: 25.26197052001953 val_loss: 25.151790618896484\n",
      "epoch:  700 train_loss: 22.208293914794922 val_loss: 22.422569274902344\n",
      "epoch:  800 train_loss: 20.839414596557617 val_loss: 21.060373306274414\n",
      "epoch:  900 train_loss: 19.994083404541016 val_loss: 20.309648513793945\n",
      "epoch:  1000 train_loss: 19.3709659576416 val_loss: 19.8100528717041\n",
      "epoch:  1100 train_loss: 18.853954315185547 val_loss: 19.459753036499023\n",
      "epoch:  1200 train_loss: 18.420082092285156 val_loss: 19.168720245361328\n",
      "epoch:  1300 train_loss: 18.05308723449707 val_loss: 18.930288314819336\n",
      "epoch:  1400 train_loss: 17.717592239379883 val_loss: 18.703907012939453\n",
      "epoch:  1500 train_loss: 17.402488708496094 val_loss: 18.520671844482422\n",
      "epoch:  1600 train_loss: 17.123470306396484 val_loss: 18.33378028869629\n",
      "epoch:  1700 train_loss: 16.859752655029297 val_loss: 18.173355102539062\n",
      "epoch:  1800 train_loss: 16.624284744262695 val_loss: 18.061199188232422\n",
      "epoch:  1900 train_loss: 16.406694412231445 val_loss: 17.9538516998291\n",
      "epoch:  2000 train_loss: 16.21233367919922 val_loss: 17.875425338745117\n",
      "epoch:  2100 train_loss: 16.030954360961914 val_loss: 17.79619598388672\n",
      "epoch:  2200 train_loss: 15.851947784423828 val_loss: 17.720182418823242\n",
      "epoch:  2300 train_loss: 15.677584648132324 val_loss: 17.652006149291992\n",
      "epoch:  2400 train_loss: 15.514714241027832 val_loss: 17.622089385986328\n",
      "epoch:  2500 train_loss: 15.355295181274414 val_loss: 17.602516174316406\n",
      "epoch:  2600 train_loss: 15.1991548538208 val_loss: 17.6221923828125\n",
      "epoch:  2700 train_loss: 15.048116683959961 val_loss: 17.662702560424805\n",
      "epoch:  2800 train_loss: 14.899495124816895 val_loss: 17.694869995117188\n",
      "epoch:  2900 train_loss: 14.749135971069336 val_loss: 17.77825164794922\n",
      "epoch:  3000 train_loss: 14.60016918182373 val_loss: 17.83462142944336\n",
      "epoch:  3100 train_loss: 14.448029518127441 val_loss: 17.885046005249023\n",
      "epoch:  3200 train_loss: 14.285626411437988 val_loss: 17.965404510498047\n",
      "epoch:  3300 train_loss: 14.128643035888672 val_loss: 18.085668563842773\n",
      "epoch:  3400 train_loss: 13.9583158493042 val_loss: 18.17731475830078\n",
      "epoch:  3500 train_loss: 13.773510932922363 val_loss: 18.260894775390625\n",
      "epoch:  3600 train_loss: 13.592535018920898 val_loss: 18.420867919921875\n",
      "epoch:  3700 train_loss: 13.370379447937012 val_loss: 18.558277130126953\n",
      "epoch:  3800 train_loss: 13.147459983825684 val_loss: 18.774023056030273\n",
      "epoch:  3900 train_loss: 12.94546890258789 val_loss: 19.10267448425293\n",
      "epoch:  4000 train_loss: 12.728080749511719 val_loss: 19.38886260986328\n",
      "epoch:  4100 train_loss: 12.529446601867676 val_loss: 19.74958038330078\n",
      "epoch:  4200 train_loss: 12.28470516204834 val_loss: 19.944257736206055\n",
      "epoch:  4300 train_loss: 12.029470443725586 val_loss: 20.246532440185547\n",
      "epoch:  4400 train_loss: 11.796000480651855 val_loss: 20.54742431640625\n",
      "epoch:  4500 train_loss: 12.240683555603027 val_loss: 21.64760398864746\n",
      "epoch:  4600 train_loss: 11.262731552124023 val_loss: 20.979053497314453\n",
      "epoch:  4700 train_loss: 11.172676086425781 val_loss: 21.294471740722656\n",
      "epoch:  4800 train_loss: 10.81238842010498 val_loss: 21.43191909790039\n",
      "epoch:  4900 train_loss: 10.577736854553223 val_loss: 21.675338745117188\n",
      "epoch:  5000 train_loss: 10.392608642578125 val_loss: 21.93270492553711\n",
      "epoch:  5100 train_loss: 10.208062171936035 val_loss: 22.235620498657227\n",
      "epoch:  5200 train_loss: 10.325884819030762 val_loss: 22.87103843688965\n",
      "epoch:  5300 train_loss: 9.756903648376465 val_loss: 22.816492080688477\n",
      "epoch:  5400 train_loss: 9.718851089477539 val_loss: 23.211637496948242\n",
      "epoch:  5500 train_loss: 9.423891067504883 val_loss: 23.407052993774414\n",
      "epoch:  5600 train_loss: 9.855055809020996 val_loss: 24.304908752441406\n",
      "epoch:  5700 train_loss: 9.142647743225098 val_loss: 23.88031578063965\n",
      "epoch:  5800 train_loss: 8.99973201751709 val_loss: 24.1025390625\n",
      "epoch:  5900 train_loss: 8.972397804260254 val_loss: 24.586341857910156\n",
      "epoch:  6000 train_loss: 8.940591812133789 val_loss: 24.9652156829834\n",
      "epoch:  6100 train_loss: 9.070412635803223 val_loss: 25.11562156677246\n",
      "epoch:  6200 train_loss: 8.955111503601074 val_loss: 25.386629104614258\n",
      "epoch:  6300 train_loss: 8.70182991027832 val_loss: 25.745134353637695\n",
      "epoch:  6400 train_loss: 8.435302734375 val_loss: 25.431499481201172\n",
      "epoch:  6500 train_loss: 9.32498550415039 val_loss: 26.327835083007812\n",
      "epoch:  6600 train_loss: 8.162012100219727 val_loss: 25.775468826293945\n",
      "epoch:  6700 train_loss: 8.03907299041748 val_loss: 25.69622230529785\n",
      "epoch:  6800 train_loss: 7.881516933441162 val_loss: 25.979616165161133\n",
      "epoch:  6900 train_loss: 7.8675665855407715 val_loss: 26.2824649810791\n",
      "epoch:  7000 train_loss: 8.056777000427246 val_loss: 26.96182632446289\n",
      "epoch:  7100 train_loss: 7.671397686004639 val_loss: 26.5681209564209\n",
      "epoch:  7200 train_loss: 8.046188354492188 val_loss: 27.088281631469727\n",
      "epoch:  7300 train_loss: 7.554412841796875 val_loss: 26.949932098388672\n",
      "epoch:  7400 train_loss: 7.715786933898926 val_loss: 27.496562957763672\n",
      "epoch:  7500 train_loss: 7.398858547210693 val_loss: 27.17470932006836\n",
      "epoch:  7600 train_loss: 7.527731418609619 val_loss: 27.51972198486328\n",
      "epoch:  7700 train_loss: 7.508928298950195 val_loss: 27.6059513092041\n",
      "epoch:  7800 train_loss: 7.163732051849365 val_loss: 27.674373626708984\n",
      "epoch:  7900 train_loss: 7.157433986663818 val_loss: 27.929553985595703\n",
      "epoch:  8000 train_loss: 7.107201099395752 val_loss: 28.053329467773438\n",
      "epoch:  8100 train_loss: 7.004456520080566 val_loss: 28.136484146118164\n",
      "epoch:  8200 train_loss: 7.1578168869018555 val_loss: 28.693099975585938\n",
      "epoch:  8300 train_loss: 7.621061325073242 val_loss: 28.694536209106445\n",
      "epoch:  8400 train_loss: 6.802840709686279 val_loss: 28.468538284301758\n",
      "epoch:  8500 train_loss: 6.752065658569336 val_loss: 28.595211029052734\n",
      "epoch:  8600 train_loss: 6.687562465667725 val_loss: 28.87250328063965\n",
      "epoch:  8700 train_loss: 6.809868812561035 val_loss: 29.367847442626953\n",
      "epoch:  8800 train_loss: 6.5293097496032715 val_loss: 29.197782516479492\n",
      "epoch:  8900 train_loss: 6.441593170166016 val_loss: 29.394615173339844\n",
      "epoch:  9000 train_loss: 6.60629940032959 val_loss: 29.616615295410156\n",
      "epoch:  9100 train_loss: 6.332669258117676 val_loss: 29.595205307006836\n",
      "epoch:  9200 train_loss: 6.355565071105957 val_loss: 29.930517196655273\n",
      "epoch:  9300 train_loss: 6.581090450286865 val_loss: 29.899099349975586\n",
      "epoch:  9400 train_loss: 6.248413562774658 val_loss: 29.88307762145996\n",
      "epoch:  9500 train_loss: 6.023024082183838 val_loss: 29.865842819213867\n",
      "epoch:  9600 train_loss: 6.166935443878174 val_loss: 29.964303970336914\n",
      "epoch:  9700 train_loss: 6.040877819061279 val_loss: 30.287073135375977\n",
      "epoch:  9800 train_loss: 6.154355525970459 val_loss: 30.342735290527344\n",
      "epoch:  9900 train_loss: 6.634858131408691 val_loss: 30.640287399291992\n",
      "epoch:  10000 train_loss: 5.842281818389893 val_loss: 30.30870246887207\n",
      "epoch:  10100 train_loss: 6.828275680541992 val_loss: 30.550764083862305\n",
      "epoch:  10200 train_loss: 5.946436882019043 val_loss: 30.641504287719727\n",
      "epoch:  10300 train_loss: 5.904926300048828 val_loss: 30.616928100585938\n",
      "epoch:  10400 train_loss: 6.158303260803223 val_loss: 31.069944381713867\n",
      "epoch:  10500 train_loss: 5.698360919952393 val_loss: 30.851388931274414\n",
      "epoch:  10600 train_loss: 6.524650573730469 val_loss: 31.571012496948242\n",
      "epoch:  10700 train_loss: 5.98184871673584 val_loss: 31.168603897094727\n",
      "epoch:  10800 train_loss: 6.027763843536377 val_loss: 31.22669792175293\n",
      "epoch:  10900 train_loss: 5.839946746826172 val_loss: 31.211576461791992\n",
      "epoch:  11000 train_loss: 6.214280605316162 val_loss: 31.398540496826172\n",
      "epoch:  11100 train_loss: 5.945075988769531 val_loss: 31.93813133239746\n",
      "epoch:  11200 train_loss: 5.412323474884033 val_loss: 31.182552337646484\n",
      "epoch:  11300 train_loss: 5.563837051391602 val_loss: 31.716411590576172\n",
      "epoch:  11400 train_loss: 5.51479959487915 val_loss: 31.67815589904785\n",
      "epoch:  11500 train_loss: 5.530362606048584 val_loss: 31.66722297668457\n",
      "epoch:  11600 train_loss: 6.329137325286865 val_loss: 32.681541442871094\n",
      "epoch:  11700 train_loss: 5.613928318023682 val_loss: 32.01523971557617\n",
      "epoch:  11800 train_loss: 5.246424674987793 val_loss: 31.579370498657227\n",
      "epoch:  11900 train_loss: 5.540236473083496 val_loss: 31.981355667114258\n",
      "epoch:  12000 train_loss: 5.163306713104248 val_loss: 31.70834732055664\n",
      "epoch:  12100 train_loss: 5.202561855316162 val_loss: 31.98000144958496\n",
      "epoch:  12200 train_loss: 6.151164531707764 val_loss: 33.57427215576172\n",
      "epoch:  12300 train_loss: 5.120784759521484 val_loss: 31.96320343017578\n",
      "epoch:  12400 train_loss: 5.215475559234619 val_loss: 32.185203552246094\n",
      "epoch:  12500 train_loss: 6.520622253417969 val_loss: 33.2559700012207\n",
      "epoch:  12600 train_loss: 5.096028804779053 val_loss: 32.20051574707031\n",
      "epoch:  12700 train_loss: 5.023641586303711 val_loss: 32.30740737915039\n",
      "epoch:  12800 train_loss: 5.102389812469482 val_loss: 32.54539489746094\n",
      "epoch:  12900 train_loss: 5.037315845489502 val_loss: 32.54117965698242\n",
      "epoch:  13000 train_loss: 5.3717041015625 val_loss: 33.01343536376953\n",
      "epoch:  13100 train_loss: 4.926641941070557 val_loss: 32.56808853149414\n",
      "epoch:  13200 train_loss: 4.969226360321045 val_loss: 32.94815444946289\n",
      "epoch:  13300 train_loss: 4.834995746612549 val_loss: 32.568214416503906\n",
      "epoch:  13400 train_loss: 4.783697128295898 val_loss: 32.57217788696289\n",
      "epoch:  13500 train_loss: 4.842474460601807 val_loss: 32.8405876159668\n",
      "epoch:  13600 train_loss: 4.9428391456604 val_loss: 32.93796157836914\n",
      "epoch:  13700 train_loss: 5.364938259124756 val_loss: 33.5290641784668\n",
      "epoch:  13800 train_loss: 4.922300338745117 val_loss: 32.84910583496094\n",
      "epoch:  13900 train_loss: 4.705789089202881 val_loss: 32.861549377441406\n",
      "epoch:  14000 train_loss: 4.931255340576172 val_loss: 33.23811721801758\n",
      "epoch:  14100 train_loss: 4.826312065124512 val_loss: 33.08354187011719\n",
      "epoch:  14200 train_loss: 4.915946960449219 val_loss: 33.17295837402344\n",
      "epoch:  14300 train_loss: 5.303802013397217 val_loss: 33.61639404296875\n",
      "epoch:  14400 train_loss: 4.619060516357422 val_loss: 33.11333465576172\n",
      "epoch:  14500 train_loss: 4.855928897857666 val_loss: 33.329429626464844\n",
      "epoch:  14600 train_loss: 4.783084869384766 val_loss: 33.48400115966797\n",
      "epoch:  14700 train_loss: 4.596044540405273 val_loss: 33.15030288696289\n",
      "epoch:  14800 train_loss: 4.569326400756836 val_loss: 33.41386795043945\n",
      "epoch:  14900 train_loss: 4.568066120147705 val_loss: 33.220703125\n",
      "epoch:  15000 train_loss: 4.867891311645508 val_loss: 33.407840728759766\n",
      "epoch:  15100 train_loss: 4.8358259201049805 val_loss: 33.39226150512695\n",
      "epoch:  15200 train_loss: 4.513408660888672 val_loss: 33.5728874206543\n",
      "epoch:  15300 train_loss: 4.407248020172119 val_loss: 33.382877349853516\n",
      "epoch:  15400 train_loss: 4.541517734527588 val_loss: 33.59088134765625\n",
      "epoch:  15500 train_loss: 4.7742438316345215 val_loss: 34.01698684692383\n",
      "epoch:  15600 train_loss: 4.541570663452148 val_loss: 33.49072265625\n",
      "epoch:  15700 train_loss: 4.504373073577881 val_loss: 33.84980392456055\n",
      "epoch:  15800 train_loss: 4.650827884674072 val_loss: 33.68907928466797\n",
      "epoch:  15900 train_loss: 4.573028564453125 val_loss: 33.50087356567383\n",
      "epoch:  16000 train_loss: 5.463244438171387 val_loss: 34.408226013183594\n",
      "epoch:  16100 train_loss: 4.542655944824219 val_loss: 33.57158660888672\n",
      "epoch:  16200 train_loss: 5.204807758331299 val_loss: 34.0480842590332\n",
      "epoch:  16300 train_loss: 5.434818744659424 val_loss: 34.31939697265625\n",
      "epoch:  16400 train_loss: 4.798583507537842 val_loss: 33.79606246948242\n",
      "epoch:  16500 train_loss: 4.875041484832764 val_loss: 34.34019088745117\n",
      "epoch:  16600 train_loss: 4.690331935882568 val_loss: 34.37956619262695\n",
      "epoch:  16700 train_loss: 4.910008430480957 val_loss: 34.9579963684082\n",
      "epoch:  16800 train_loss: 4.2547688484191895 val_loss: 33.92035675048828\n",
      "epoch:  16900 train_loss: 4.193786144256592 val_loss: 33.84208679199219\n",
      "epoch:  17000 train_loss: 4.100220680236816 val_loss: 34.051300048828125\n",
      "epoch:  17100 train_loss: 4.6815924644470215 val_loss: 34.3530387878418\n",
      "epoch:  17200 train_loss: 4.083934783935547 val_loss: 33.92031478881836\n",
      "epoch:  17300 train_loss: 5.125092029571533 val_loss: 35.540626525878906\n",
      "epoch:  17400 train_loss: 5.253805637359619 val_loss: 35.233158111572266\n",
      "epoch:  17500 train_loss: 4.685591697692871 val_loss: 34.678897857666016\n",
      "epoch:  17600 train_loss: 4.259690284729004 val_loss: 34.47327423095703\n",
      "epoch:  17700 train_loss: 4.079158306121826 val_loss: 34.0974235534668\n",
      "epoch:  17800 train_loss: 4.185469627380371 val_loss: 34.2834587097168\n",
      "epoch:  17900 train_loss: 4.695800304412842 val_loss: 34.7995719909668\n",
      "epoch:  18000 train_loss: 4.008979797363281 val_loss: 34.3547477722168\n",
      "epoch:  18100 train_loss: 4.467676639556885 val_loss: 35.023380279541016\n",
      "epoch:  18200 train_loss: 4.490334510803223 val_loss: 35.04126739501953\n",
      "epoch:  18300 train_loss: 3.9017698764801025 val_loss: 34.37796401977539\n",
      "epoch:  18400 train_loss: 3.8572771549224854 val_loss: 34.361820220947266\n",
      "epoch:  18500 train_loss: 3.897219657897949 val_loss: 34.42084884643555\n",
      "epoch:  18600 train_loss: 4.523507595062256 val_loss: 35.30656433105469\n",
      "epoch:  18700 train_loss: 4.122381210327148 val_loss: 35.06402587890625\n",
      "epoch:  18800 train_loss: 3.825601577758789 val_loss: 34.63889694213867\n",
      "epoch:  18900 train_loss: 3.811441659927368 val_loss: 34.55511474609375\n",
      "epoch:  19000 train_loss: 3.8140363693237305 val_loss: 34.599281311035156\n",
      "epoch:  19100 train_loss: 3.958010196685791 val_loss: 34.77971267700195\n",
      "epoch:  19200 train_loss: 3.9674384593963623 val_loss: 34.825355529785156\n",
      "epoch:  19300 train_loss: 4.207768440246582 val_loss: 35.139923095703125\n",
      "epoch:  19400 train_loss: 3.7462410926818848 val_loss: 34.858306884765625\n",
      "epoch:  19500 train_loss: 4.327948570251465 val_loss: 35.528804779052734\n",
      "epoch:  19600 train_loss: 3.8732004165649414 val_loss: 35.273624420166016\n",
      "epoch:  19700 train_loss: 3.9331066608428955 val_loss: 35.27350616455078\n",
      "epoch:  19800 train_loss: 3.8878798484802246 val_loss: 35.146827697753906\n",
      "epoch:  19900 train_loss: 3.641724109649658 val_loss: 34.958412170410156\n",
      "epoch:  20000 train_loss: 4.01474142074585 val_loss: 35.48237991333008\n",
      "epoch:  20100 train_loss: 3.761931896209717 val_loss: 35.2150993347168\n",
      "epoch:  20200 train_loss: 3.6676948070526123 val_loss: 35.492820739746094\n",
      "epoch:  20300 train_loss: 4.425717830657959 val_loss: 36.224159240722656\n",
      "epoch:  20400 train_loss: 3.6393332481384277 val_loss: 35.257389068603516\n",
      "epoch:  20500 train_loss: 3.638227701187134 val_loss: 35.50626754760742\n",
      "epoch:  20600 train_loss: 3.7139413356781006 val_loss: 35.54252624511719\n",
      "epoch:  20700 train_loss: 3.938284397125244 val_loss: 35.44180679321289\n",
      "epoch:  20800 train_loss: 3.462554454803467 val_loss: 35.2835807800293\n",
      "epoch:  20900 train_loss: 3.7870633602142334 val_loss: 35.94264221191406\n",
      "epoch:  21000 train_loss: 3.549248218536377 val_loss: 35.596065521240234\n",
      "epoch:  21100 train_loss: 3.5825276374816895 val_loss: 35.48532485961914\n",
      "epoch:  21200 train_loss: 3.6891348361968994 val_loss: 36.01356506347656\n",
      "epoch:  21300 train_loss: 3.5760395526885986 val_loss: 35.582618713378906\n",
      "epoch:  21400 train_loss: 3.4068589210510254 val_loss: 35.59538269042969\n",
      "epoch:  21500 train_loss: 3.5441911220550537 val_loss: 35.760440826416016\n",
      "epoch:  21600 train_loss: 3.785634756088257 val_loss: 35.83094787597656\n",
      "epoch:  21700 train_loss: 3.413831949234009 val_loss: 35.90859603881836\n",
      "epoch:  21800 train_loss: 3.454437017440796 val_loss: 35.81904983520508\n",
      "epoch:  21900 train_loss: 3.452958345413208 val_loss: 35.856815338134766\n",
      "epoch:  22000 train_loss: 3.392974853515625 val_loss: 36.06471252441406\n",
      "epoch:  22100 train_loss: 3.5322179794311523 val_loss: 36.120540618896484\n",
      "epoch:  22200 train_loss: 3.50357723236084 val_loss: 36.251495361328125\n",
      "epoch:  22300 train_loss: 3.5120930671691895 val_loss: 35.99208068847656\n",
      "epoch:  22400 train_loss: 3.281069040298462 val_loss: 36.08141326904297\n",
      "epoch:  22500 train_loss: 3.6554508209228516 val_loss: 36.58779525756836\n",
      "epoch:  22600 train_loss: 3.721950054168701 val_loss: 36.88234329223633\n",
      "epoch:  22700 train_loss: 3.2831037044525146 val_loss: 36.17470932006836\n",
      "epoch:  22800 train_loss: 5.749121189117432 val_loss: 37.46443557739258\n",
      "epoch:  22900 train_loss: 3.90425443649292 val_loss: 37.157814025878906\n",
      "epoch:  23000 train_loss: 3.918194055557251 val_loss: 36.98659896850586\n",
      "epoch:  23100 train_loss: 3.273637294769287 val_loss: 36.416744232177734\n",
      "epoch:  23200 train_loss: 3.1258833408355713 val_loss: 36.30535125732422\n",
      "epoch:  23300 train_loss: 3.3503713607788086 val_loss: 36.78487014770508\n",
      "epoch:  23400 train_loss: 3.0916996002197266 val_loss: 36.400550842285156\n",
      "epoch:  23500 train_loss: 6.210633754730225 val_loss: 40.28201675415039\n",
      "epoch:  23600 train_loss: 3.092991828918457 val_loss: 36.58586120605469\n",
      "epoch:  23700 train_loss: 3.66500186920166 val_loss: 36.97637939453125\n",
      "epoch:  23800 train_loss: 3.3132197856903076 val_loss: 36.61860275268555\n",
      "epoch:  23900 train_loss: 3.4463493824005127 val_loss: 37.214393615722656\n",
      "epoch:  24000 train_loss: 3.0775511264801025 val_loss: 36.68478012084961\n",
      "epoch:  24100 train_loss: 3.7485785484313965 val_loss: 36.440704345703125\n",
      "epoch:  24200 train_loss: 3.021998405456543 val_loss: 36.632171630859375\n",
      "epoch:  24300 train_loss: 3.2847535610198975 val_loss: 37.33952331542969\n",
      "epoch:  24400 train_loss: 3.2449021339416504 val_loss: 36.688995361328125\n",
      "epoch:  24500 train_loss: 3.2451627254486084 val_loss: 36.96602249145508\n",
      "epoch:  24600 train_loss: 3.3409464359283447 val_loss: 37.02267074584961\n",
      "epoch:  24700 train_loss: 2.92912220954895 val_loss: 36.74421691894531\n",
      "epoch:  24800 train_loss: 3.6563124656677246 val_loss: 37.874488830566406\n",
      "epoch:  24900 train_loss: 4.086299896240234 val_loss: 37.07518005371094\n",
      "epoch:  25000 train_loss: 3.2057690620422363 val_loss: 37.344947814941406\n",
      "epoch:  25100 train_loss: 2.9474384784698486 val_loss: 37.194602966308594\n",
      "epoch:  25200 train_loss: 2.927987575531006 val_loss: 37.16461944580078\n",
      "epoch:  25300 train_loss: 3.1463441848754883 val_loss: 37.414180755615234\n",
      "epoch:  25400 train_loss: 3.9973092079162598 val_loss: 38.665306091308594\n",
      "epoch:  25500 train_loss: 2.8580074310302734 val_loss: 37.28835678100586\n",
      "epoch:  25600 train_loss: 3.129178762435913 val_loss: 37.56685256958008\n",
      "epoch:  25700 train_loss: 2.788315534591675 val_loss: 37.43422317504883\n",
      "epoch:  25800 train_loss: 3.42775821685791 val_loss: 38.021183013916016\n",
      "epoch:  25900 train_loss: 3.50628924369812 val_loss: 38.178871154785156\n",
      "epoch:  26000 train_loss: 3.40226411819458 val_loss: 37.59535598754883\n",
      "epoch:  26100 train_loss: 3.4861879348754883 val_loss: 37.90730285644531\n",
      "epoch:  26200 train_loss: 3.071120023727417 val_loss: 37.78398895263672\n",
      "epoch:  26300 train_loss: 3.876722812652588 val_loss: 38.396278381347656\n",
      "epoch:  26400 train_loss: 2.829200029373169 val_loss: 37.715518951416016\n",
      "epoch:  26500 train_loss: 3.402845621109009 val_loss: 38.641334533691406\n",
      "epoch:  26600 train_loss: 3.1822595596313477 val_loss: 38.118186950683594\n",
      "epoch:  26700 train_loss: 3.0225720405578613 val_loss: 37.77790451049805\n",
      "epoch:  26800 train_loss: 2.85709810256958 val_loss: 37.713809967041016\n",
      "epoch:  26900 train_loss: 3.342050790786743 val_loss: 38.64645004272461\n",
      "epoch:  27000 train_loss: 2.861431360244751 val_loss: 38.12379455566406\n",
      "epoch:  27100 train_loss: 2.7191550731658936 val_loss: 37.75700759887695\n",
      "epoch:  27200 train_loss: 3.0764012336730957 val_loss: 37.769775390625\n",
      "epoch:  27300 train_loss: 2.7706596851348877 val_loss: 37.776885986328125\n",
      "epoch:  27400 train_loss: 3.795982599258423 val_loss: 38.99673843383789\n",
      "epoch:  27500 train_loss: 2.979888916015625 val_loss: 38.53614807128906\n",
      "epoch:  27600 train_loss: 2.7037432193756104 val_loss: 37.92406463623047\n",
      "epoch:  27700 train_loss: 3.161734104156494 val_loss: 38.115596771240234\n",
      "epoch:  27800 train_loss: 3.103515625 val_loss: 38.1367073059082\n",
      "epoch:  27900 train_loss: 2.5958025455474854 val_loss: 37.58305740356445\n",
      "epoch:  28000 train_loss: 2.661027193069458 val_loss: 37.920772552490234\n",
      "epoch:  28100 train_loss: 2.780083417892456 val_loss: 38.637733459472656\n",
      "epoch:  28200 train_loss: 2.856476306915283 val_loss: 38.07352066040039\n",
      "epoch:  28300 train_loss: 2.556187152862549 val_loss: 38.017024993896484\n",
      "epoch:  28400 train_loss: 3.2899045944213867 val_loss: 39.282127380371094\n",
      "epoch:  28500 train_loss: 2.8128151893615723 val_loss: 38.197662353515625\n",
      "epoch:  28600 train_loss: 2.944239377975464 val_loss: 38.531009674072266\n",
      "epoch:  28700 train_loss: 2.704080104827881 val_loss: 38.64630889892578\n",
      "epoch:  28800 train_loss: 2.5584287643432617 val_loss: 38.14006042480469\n",
      "epoch:  28900 train_loss: 2.4254281520843506 val_loss: 38.141136169433594\n",
      "epoch:  29000 train_loss: 3.3581347465515137 val_loss: 39.04142379760742\n",
      "epoch:  29100 train_loss: 2.654888868331909 val_loss: 38.257205963134766\n",
      "epoch:  29200 train_loss: 2.444859266281128 val_loss: 38.327545166015625\n",
      "epoch:  29300 train_loss: 2.802125930786133 val_loss: 38.762149810791016\n",
      "epoch:  29400 train_loss: 2.843827486038208 val_loss: 38.59108352661133\n",
      "epoch:  29500 train_loss: 3.047912359237671 val_loss: 38.65644073486328\n",
      "epoch:  29600 train_loss: 2.4898931980133057 val_loss: 38.47624969482422\n",
      "epoch:  29700 train_loss: 2.4286177158355713 val_loss: 38.10404586791992\n",
      "epoch:  29800 train_loss: 2.97829270362854 val_loss: 39.091033935546875\n",
      "epoch:  29900 train_loss: 3.0811855792999268 val_loss: 39.06551742553711\n",
      "epoch:  30000 train_loss: 2.34256911277771 val_loss: 38.487422943115234\n",
      "epoch:  30100 train_loss: 2.5614898204803467 val_loss: 38.66413116455078\n",
      "epoch:  30200 train_loss: 3.039015531539917 val_loss: 38.46106719970703\n",
      "epoch:  30300 train_loss: 2.543473482131958 val_loss: 38.649070739746094\n",
      "epoch:  30400 train_loss: 2.3423471450805664 val_loss: 38.71826171875\n",
      "epoch:  30500 train_loss: 2.7320971488952637 val_loss: 39.15464401245117\n",
      "epoch:  30600 train_loss: 2.5807530879974365 val_loss: 38.74543380737305\n",
      "epoch:  30700 train_loss: 2.439741373062134 val_loss: 38.60432815551758\n",
      "epoch:  30800 train_loss: 3.1390514373779297 val_loss: 39.622806549072266\n",
      "epoch:  30900 train_loss: 2.328598976135254 val_loss: 38.88730239868164\n",
      "epoch:  31000 train_loss: 2.4755361080169678 val_loss: 39.05495834350586\n",
      "epoch:  31100 train_loss: 2.539205312728882 val_loss: 39.165164947509766\n",
      "epoch:  31200 train_loss: 2.854734420776367 val_loss: 38.84346008300781\n",
      "epoch:  31300 train_loss: 2.9638712406158447 val_loss: 39.354209899902344\n",
      "epoch:  31400 train_loss: 2.8337180614471436 val_loss: 39.71354293823242\n",
      "epoch:  31500 train_loss: 2.23367977142334 val_loss: 38.96158218383789\n",
      "epoch:  31600 train_loss: 2.3520047664642334 val_loss: 39.20465087890625\n",
      "epoch:  31700 train_loss: 3.1066060066223145 val_loss: 39.78213119506836\n",
      "epoch:  31800 train_loss: 2.3713083267211914 val_loss: 39.058250427246094\n",
      "epoch:  31900 train_loss: 2.4278764724731445 val_loss: 39.12263870239258\n",
      "epoch:  32000 train_loss: 2.187464475631714 val_loss: 38.785011291503906\n",
      "epoch:  32100 train_loss: 2.417494058609009 val_loss: 39.18997573852539\n",
      "epoch:  32200 train_loss: 2.7236433029174805 val_loss: 39.85337448120117\n",
      "epoch:  32300 train_loss: 2.759476900100708 val_loss: 39.09660720825195\n",
      "epoch:  32400 train_loss: 2.5386292934417725 val_loss: 39.1363639831543\n",
      "epoch:  32500 train_loss: 2.461717128753662 val_loss: 39.162803649902344\n",
      "epoch:  32600 train_loss: 2.3661789894104004 val_loss: 39.6114501953125\n",
      "epoch:  32700 train_loss: 2.4521169662475586 val_loss: 39.64125442504883\n",
      "epoch:  32800 train_loss: 2.8271126747131348 val_loss: 39.55219268798828\n",
      "epoch:  32900 train_loss: 3.1191797256469727 val_loss: 38.7144660949707\n",
      "epoch:  33000 train_loss: 2.4180729389190674 val_loss: 39.390594482421875\n",
      "epoch:  33100 train_loss: 2.769707679748535 val_loss: 39.66002655029297\n",
      "epoch:  33200 train_loss: 2.2979822158813477 val_loss: 39.30815887451172\n",
      "epoch:  33300 train_loss: 3.3157336711883545 val_loss: 40.12760543823242\n",
      "epoch:  33400 train_loss: 2.501011371612549 val_loss: 39.235565185546875\n",
      "epoch:  33500 train_loss: 4.791165828704834 val_loss: 41.858543395996094\n",
      "epoch:  33600 train_loss: 2.196291446685791 val_loss: 39.34941101074219\n",
      "epoch:  33700 train_loss: 2.6717209815979004 val_loss: 40.2309684753418\n",
      "epoch:  33800 train_loss: 2.0926358699798584 val_loss: 39.50260543823242\n",
      "epoch:  33900 train_loss: 2.1265742778778076 val_loss: 39.69426345825195\n",
      "epoch:  34000 train_loss: 2.1794867515563965 val_loss: 39.75005340576172\n",
      "epoch:  34100 train_loss: 2.3384768962860107 val_loss: 39.792137145996094\n",
      "epoch:  34200 train_loss: 2.225546360015869 val_loss: 39.50607681274414\n",
      "epoch:  34300 train_loss: 2.1270625591278076 val_loss: 39.41624069213867\n",
      "epoch:  34400 train_loss: 2.053098678588867 val_loss: 39.42240524291992\n",
      "epoch:  34500 train_loss: 2.1222565174102783 val_loss: 39.518733978271484\n",
      "epoch:  34600 train_loss: 2.0317392349243164 val_loss: 39.372467041015625\n",
      "epoch:  34700 train_loss: 2.017420530319214 val_loss: 39.75034713745117\n",
      "epoch:  34800 train_loss: 1.9462900161743164 val_loss: 39.33616256713867\n",
      "epoch:  34900 train_loss: 2.1109864711761475 val_loss: 39.77488708496094\n",
      "epoch:  35000 train_loss: 2.7853429317474365 val_loss: 40.28889083862305\n",
      "epoch:  35100 train_loss: 1.915448546409607 val_loss: 39.508235931396484\n",
      "epoch:  35200 train_loss: 1.9315744638442993 val_loss: 39.5575065612793\n",
      "epoch:  35300 train_loss: 2.0640292167663574 val_loss: 39.52874755859375\n",
      "epoch:  35400 train_loss: 2.3948473930358887 val_loss: 40.03601837158203\n",
      "epoch:  35500 train_loss: 2.3540046215057373 val_loss: 39.913116455078125\n",
      "epoch:  35600 train_loss: 2.2327029705047607 val_loss: 39.94356918334961\n",
      "epoch:  35700 train_loss: 2.4174132347106934 val_loss: 40.27322006225586\n",
      "epoch:  35800 train_loss: 2.7765119075775146 val_loss: 40.50650405883789\n",
      "epoch:  35900 train_loss: 2.7624144554138184 val_loss: 40.59465408325195\n",
      "RMSE:  tensor(11.3101, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Ganerate the dataset\n",
    "i = 0\n",
    "sigma = 8.2\n",
    "my_dataset = []\n",
    "for ud in UDs:\n",
    "    example = []\n",
    "    for an in ANs:\n",
    "        noise = np.random.normal(0,sigma)\n",
    "        # 0 is mean\n",
    "        # sigma is the deviation of the normal distribution\n",
    "        d = compute_3d_distance(ud, an) + noise\n",
    "        example.append(d)\n",
    "    \n",
    "    # append x, y, z as col#10, #11, #12\n",
    "    example.append(ud[0])\n",
    "    example.append(ud[1])\n",
    "    example.append(ud[2])\n",
    "    \n",
    "    # append 1x13 example row into my_dataset\n",
    "    my_dataset.append(example)  # expected to be 3000x13  \n",
    "    \n",
    "# Load dataset\n",
    "exercise3_dataset = Exercise3Dataset(list_dataset = my_dataset, shuffle=True)\n",
    "\n",
    "#Split dataset by 0.8: 0.1: 0.1\n",
    "train_examples, train_labels = exercise3_dataset[:int(3000*0.8)]  # (2400, 10)   # (2400, 3)\n",
    "val_examples, val_labels = exercise3_dataset[int(3000*0.8):int(3000*0.9)]    # (300, 10)   #(300, 3)\n",
    "test_examples, test_labels = exercise3_dataset[int(3000*0.9):]     #(300, 10)   # (300, 3)\n",
    "\n",
    "###Define model, loss function and optimizer\n",
    "# if we have GPU, then use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define model\n",
    "model = Net(x_dim = train_examples.shape[1], y_dim = train_labels.shape[1]).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training and Validation\n",
    "\n",
    "train_examples = train_examples.to(device)\n",
    "train_labels = train_labels.to(device)\n",
    "val_examples = val_examples.to(device)\n",
    "val_labels = val_labels.to(device)\n",
    "\n",
    "# Define the model filename for model.save()\n",
    "MODEL_FILENAME = \"best.pth\"\n",
    "\n",
    "# set model to Training mode\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "NUM_OF_EPOCH = 36000\n",
    "\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    y_pred = model(train_examples)\n",
    "    loss = loss_fn(y_pred, train_labels).cpu()\n",
    "    #print(t, loss.item())\n",
    "    train_losses.append(loss.item())\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    # BGD\n",
    "    optimizer.step()\n",
    "    \n",
    "    # evaluate validation loss\n",
    "    val_pred = model(val_examples)\n",
    "    loss = loss_fn(val_pred, val_labels)\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "    # check if we got better loss\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n",
    "\n",
    "    if (epoch % 100) == 0:\n",
    "        print(\"epoch: \", epoch, \"train_loss:\", train_losses[-1], \"val_loss:\", val_losses[-1])\n",
    "        \n",
    "# Inference all testing examples and compute RMSE\n",
    "def square_error(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  square_error= loss_fn(a, b)\n",
    "  return square_error\n",
    "\n",
    "model.eval() # inference mode\n",
    "test_examples = test_examples.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "test_preds = model(test_examples)\n",
    "#print(\"example: \", test_example.cpu())\n",
    "#print(\"========================================\")\n",
    "#print(\"ground_truth:\", test_label.cpu())\n",
    "#print(\"prediction:\", test_pred.cpu())\n",
    "#print(\"========================================\")\n",
    "\n",
    "\n",
    "total_errors = 0.0\n",
    "for idx in range(len(test_examples)):\n",
    "    total_errors += square_error(test_preds[idx], test_labels[idx])\n",
    "    \n",
    "RMSE = torch.sqrt(total_errors / len(test_examples))\n",
    "print(\"RMSE: \",  RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigma = 9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffle = True!\n",
      "epoch:  0 train_loss: 7329.24365234375 val_loss: 7525.63330078125\n",
      "epoch:  100 train_loss: 240.5502166748047 val_loss: 233.05003356933594\n",
      "epoch:  200 train_loss: 182.1666259765625 val_loss: 181.7696533203125\n",
      "epoch:  300 train_loss: 121.94241333007812 val_loss: 124.36412811279297\n",
      "epoch:  400 train_loss: 60.064571380615234 val_loss: 65.2287826538086\n",
      "epoch:  500 train_loss: 52.58778762817383 val_loss: 56.81800079345703\n",
      "epoch:  600 train_loss: 42.85805130004883 val_loss: 46.4849739074707\n",
      "epoch:  700 train_loss: 27.399093627929688 val_loss: 30.98227882385254\n",
      "epoch:  800 train_loss: 23.860647201538086 val_loss: 27.423816680908203\n",
      "epoch:  900 train_loss: 23.000041961669922 val_loss: 26.514511108398438\n",
      "epoch:  1000 train_loss: 22.419050216674805 val_loss: 26.00786590576172\n",
      "epoch:  1100 train_loss: 21.949275970458984 val_loss: 25.586610794067383\n",
      "epoch:  1200 train_loss: 21.51454734802246 val_loss: 25.227706909179688\n",
      "epoch:  1300 train_loss: 20.971111297607422 val_loss: 24.576318740844727\n",
      "epoch:  1400 train_loss: 20.494125366210938 val_loss: 24.242149353027344\n",
      "epoch:  1500 train_loss: 20.090885162353516 val_loss: 24.166946411132812\n",
      "epoch:  1600 train_loss: 19.735862731933594 val_loss: 24.219139099121094\n",
      "epoch:  1700 train_loss: 19.399219512939453 val_loss: 24.334781646728516\n",
      "epoch:  1800 train_loss: 19.092390060424805 val_loss: 24.505569458007812\n",
      "epoch:  1900 train_loss: 18.786754608154297 val_loss: 24.807205200195312\n",
      "epoch:  2000 train_loss: 18.48602867126465 val_loss: 24.985017776489258\n",
      "epoch:  2100 train_loss: 18.213438034057617 val_loss: 25.158912658691406\n",
      "epoch:  2200 train_loss: 17.949060440063477 val_loss: 25.31608009338379\n",
      "epoch:  2300 train_loss: 17.61489486694336 val_loss: 25.4683895111084\n",
      "epoch:  2400 train_loss: 17.248851776123047 val_loss: 25.6832332611084\n",
      "epoch:  2500 train_loss: 16.95271873474121 val_loss: 25.9599609375\n",
      "epoch:  2600 train_loss: 16.656028747558594 val_loss: 26.183923721313477\n",
      "epoch:  2700 train_loss: 16.331634521484375 val_loss: 26.28021240234375\n",
      "epoch:  2800 train_loss: 16.01531982421875 val_loss: 26.522533416748047\n",
      "epoch:  2900 train_loss: 15.670814514160156 val_loss: 26.702075958251953\n",
      "epoch:  3000 train_loss: 15.445170402526855 val_loss: 26.859453201293945\n",
      "epoch:  3100 train_loss: 15.045249938964844 val_loss: 27.225027084350586\n",
      "epoch:  3200 train_loss: 14.85535717010498 val_loss: 27.403587341308594\n",
      "epoch:  3300 train_loss: 14.539938926696777 val_loss: 27.68132209777832\n",
      "epoch:  3400 train_loss: 14.292901992797852 val_loss: 28.10401153564453\n",
      "epoch:  3500 train_loss: 14.43071460723877 val_loss: 28.032005310058594\n",
      "epoch:  3600 train_loss: 14.140026092529297 val_loss: 28.34963607788086\n",
      "epoch:  3700 train_loss: 13.574997901916504 val_loss: 29.072656631469727\n",
      "epoch:  3800 train_loss: 13.287782669067383 val_loss: 28.954669952392578\n",
      "epoch:  3900 train_loss: 13.27489185333252 val_loss: 29.06197166442871\n",
      "epoch:  4000 train_loss: 13.09859848022461 val_loss: 29.308425903320312\n",
      "epoch:  4100 train_loss: 12.81966781616211 val_loss: 29.461204528808594\n",
      "epoch:  4200 train_loss: 12.52328872680664 val_loss: 29.8089542388916\n",
      "epoch:  4300 train_loss: 12.388811111450195 val_loss: 30.784303665161133\n",
      "epoch:  4400 train_loss: 12.392871856689453 val_loss: 30.66047477722168\n",
      "epoch:  4500 train_loss: 12.098372459411621 val_loss: 30.976795196533203\n",
      "epoch:  4600 train_loss: 12.00272274017334 val_loss: 31.712709426879883\n",
      "epoch:  4700 train_loss: 12.381291389465332 val_loss: 33.45252990722656\n",
      "epoch:  4800 train_loss: 11.660968780517578 val_loss: 32.18345642089844\n",
      "epoch:  4900 train_loss: 12.276396751403809 val_loss: 33.22459030151367\n",
      "epoch:  5000 train_loss: 11.407207489013672 val_loss: 32.105186462402344\n",
      "epoch:  5100 train_loss: 11.97667407989502 val_loss: 34.016536712646484\n",
      "epoch:  5200 train_loss: 11.34933853149414 val_loss: 32.27194595336914\n",
      "epoch:  5300 train_loss: 11.195867538452148 val_loss: 33.180049896240234\n",
      "epoch:  5400 train_loss: 11.170636177062988 val_loss: 34.02248764038086\n",
      "epoch:  5500 train_loss: 11.546765327453613 val_loss: 35.15095901489258\n",
      "epoch:  5600 train_loss: 10.930410385131836 val_loss: 33.57617950439453\n",
      "epoch:  5700 train_loss: 10.733338356018066 val_loss: 34.56806564331055\n",
      "epoch:  5800 train_loss: 10.655794143676758 val_loss: 33.83661651611328\n",
      "epoch:  5900 train_loss: 10.777634620666504 val_loss: 34.492488861083984\n",
      "epoch:  6000 train_loss: 10.669846534729004 val_loss: 34.809329986572266\n",
      "epoch:  6100 train_loss: 10.422262191772461 val_loss: 34.769771575927734\n",
      "epoch:  6200 train_loss: 10.437358856201172 val_loss: 35.095314025878906\n",
      "epoch:  6300 train_loss: 10.37251091003418 val_loss: 33.79145812988281\n",
      "epoch:  6400 train_loss: 10.170475959777832 val_loss: 34.044742584228516\n",
      "epoch:  6500 train_loss: 10.291539192199707 val_loss: 35.33430480957031\n",
      "epoch:  6600 train_loss: 9.922858238220215 val_loss: 34.649356842041016\n",
      "epoch:  6700 train_loss: 10.291897773742676 val_loss: 34.15217208862305\n",
      "epoch:  6800 train_loss: 9.688782691955566 val_loss: 34.927337646484375\n",
      "epoch:  6900 train_loss: 10.148012161254883 val_loss: 34.456642150878906\n",
      "epoch:  7000 train_loss: 9.567630767822266 val_loss: 35.67084884643555\n",
      "epoch:  7100 train_loss: 9.845946311950684 val_loss: 36.540382385253906\n",
      "epoch:  7200 train_loss: 9.81368637084961 val_loss: 35.78209686279297\n",
      "epoch:  7300 train_loss: 9.686984062194824 val_loss: 36.48591232299805\n",
      "epoch:  7400 train_loss: 10.590039253234863 val_loss: 35.13204574584961\n",
      "epoch:  7500 train_loss: 9.305206298828125 val_loss: 35.15861129760742\n",
      "epoch:  7600 train_loss: 9.168582916259766 val_loss: 35.79439163208008\n",
      "epoch:  7700 train_loss: 10.017460823059082 val_loss: 35.350547790527344\n",
      "epoch:  7800 train_loss: 9.074131965637207 val_loss: 36.33131408691406\n",
      "epoch:  7900 train_loss: 9.593111038208008 val_loss: 35.580047607421875\n",
      "epoch:  8000 train_loss: 9.073684692382812 val_loss: 35.94989776611328\n",
      "epoch:  8100 train_loss: 8.90723991394043 val_loss: 36.337677001953125\n",
      "epoch:  8200 train_loss: 8.897726058959961 val_loss: 36.92586898803711\n",
      "epoch:  8300 train_loss: 9.103819847106934 val_loss: 36.066925048828125\n",
      "epoch:  8400 train_loss: 8.836296081542969 val_loss: 37.47124099731445\n",
      "epoch:  8500 train_loss: 8.793048858642578 val_loss: 36.46641540527344\n",
      "epoch:  8600 train_loss: 9.064419746398926 val_loss: 36.453495025634766\n",
      "epoch:  8700 train_loss: 8.600960731506348 val_loss: 37.015621185302734\n",
      "epoch:  8800 train_loss: 8.596452713012695 val_loss: 37.53654098510742\n",
      "epoch:  8900 train_loss: 8.5954008102417 val_loss: 38.542293548583984\n",
      "epoch:  9000 train_loss: 8.5191650390625 val_loss: 37.288570404052734\n",
      "epoch:  9100 train_loss: 8.484227180480957 val_loss: 37.955726623535156\n",
      "epoch:  9200 train_loss: 8.679951667785645 val_loss: 39.64710235595703\n",
      "epoch:  9300 train_loss: 8.436918258666992 val_loss: 37.526390075683594\n",
      "epoch:  9400 train_loss: 8.492945671081543 val_loss: 37.34562683105469\n",
      "epoch:  9500 train_loss: 8.444585800170898 val_loss: 39.45139694213867\n",
      "epoch:  9600 train_loss: 8.090197563171387 val_loss: 38.6519889831543\n",
      "epoch:  9700 train_loss: 8.155952453613281 val_loss: 38.48135757446289\n",
      "epoch:  9800 train_loss: 8.360248565673828 val_loss: 39.25752639770508\n",
      "epoch:  9900 train_loss: 8.11962604522705 val_loss: 39.286468505859375\n",
      "epoch:  10000 train_loss: 8.364317893981934 val_loss: 39.4217643737793\n",
      "epoch:  10100 train_loss: 8.061976432800293 val_loss: 39.061241149902344\n",
      "epoch:  10200 train_loss: 8.140408515930176 val_loss: 39.25059127807617\n",
      "epoch:  10300 train_loss: 7.92870569229126 val_loss: 39.20149230957031\n",
      "epoch:  10400 train_loss: 7.845153331756592 val_loss: 39.80341339111328\n",
      "epoch:  10500 train_loss: 7.609012603759766 val_loss: 39.0709228515625\n",
      "epoch:  10600 train_loss: 7.996701240539551 val_loss: 38.191715240478516\n",
      "epoch:  10700 train_loss: 8.236305236816406 val_loss: 41.18839645385742\n",
      "epoch:  10800 train_loss: 7.679703235626221 val_loss: 38.82297897338867\n",
      "epoch:  10900 train_loss: 7.474179744720459 val_loss: 39.85697555541992\n",
      "epoch:  11000 train_loss: 7.928544044494629 val_loss: 38.381431579589844\n",
      "epoch:  11100 train_loss: 7.430272579193115 val_loss: 39.44846725463867\n",
      "epoch:  11200 train_loss: 7.617190361022949 val_loss: 38.603370666503906\n",
      "epoch:  11300 train_loss: 7.368042945861816 val_loss: 39.07780456542969\n",
      "epoch:  11400 train_loss: 7.691667079925537 val_loss: 40.547298431396484\n",
      "epoch:  11500 train_loss: 8.615545272827148 val_loss: 39.02787399291992\n",
      "epoch:  11600 train_loss: 7.102314472198486 val_loss: 39.34745788574219\n",
      "epoch:  11700 train_loss: 7.364070415496826 val_loss: 39.47447204589844\n",
      "epoch:  11800 train_loss: 7.54976749420166 val_loss: 38.97705078125\n",
      "epoch:  11900 train_loss: 6.901789665222168 val_loss: 39.75407028198242\n",
      "epoch:  12000 train_loss: 7.009624004364014 val_loss: 39.348182678222656\n",
      "epoch:  12100 train_loss: 6.940359115600586 val_loss: 40.93295669555664\n",
      "epoch:  12200 train_loss: 7.254890441894531 val_loss: 41.56291580200195\n",
      "epoch:  12300 train_loss: 7.790632247924805 val_loss: 39.38423538208008\n",
      "epoch:  12400 train_loss: 6.902268886566162 val_loss: 39.46617889404297\n",
      "epoch:  12500 train_loss: 7.536154747009277 val_loss: 42.196319580078125\n",
      "epoch:  12600 train_loss: 6.827269077301025 val_loss: 40.01044464111328\n",
      "epoch:  12700 train_loss: 6.57332706451416 val_loss: 40.575870513916016\n",
      "epoch:  12800 train_loss: 6.6946797370910645 val_loss: 41.44981002807617\n",
      "epoch:  12900 train_loss: 7.22638463973999 val_loss: 39.60026550292969\n",
      "epoch:  13000 train_loss: 7.130221366882324 val_loss: 39.829315185546875\n",
      "epoch:  13100 train_loss: 6.6854095458984375 val_loss: 39.77442932128906\n",
      "epoch:  13200 train_loss: 7.084970951080322 val_loss: 42.426170349121094\n",
      "epoch:  13300 train_loss: 6.870218276977539 val_loss: 39.956607818603516\n",
      "epoch:  13400 train_loss: 6.304520606994629 val_loss: 40.423057556152344\n",
      "epoch:  13500 train_loss: 6.638435363769531 val_loss: 40.22900390625\n",
      "epoch:  13600 train_loss: 6.855967998504639 val_loss: 42.842857360839844\n",
      "epoch:  13700 train_loss: 7.198411464691162 val_loss: 42.869754791259766\n",
      "epoch:  13800 train_loss: 6.177793025970459 val_loss: 40.773136138916016\n",
      "epoch:  13900 train_loss: 6.154865264892578 val_loss: 40.73396301269531\n",
      "epoch:  14000 train_loss: 6.145016193389893 val_loss: 41.9772834777832\n",
      "epoch:  14100 train_loss: 6.0515570640563965 val_loss: 41.76561737060547\n",
      "epoch:  14200 train_loss: 6.361934661865234 val_loss: 40.72896957397461\n",
      "epoch:  14300 train_loss: 6.094878673553467 val_loss: 40.92839813232422\n",
      "epoch:  14400 train_loss: 6.10017204284668 val_loss: 41.413795471191406\n",
      "epoch:  14500 train_loss: 6.383901119232178 val_loss: 42.645164489746094\n",
      "epoch:  14600 train_loss: 5.888537883758545 val_loss: 41.471458435058594\n",
      "epoch:  14700 train_loss: 6.095076560974121 val_loss: 41.17308807373047\n",
      "epoch:  14800 train_loss: 6.174877166748047 val_loss: 41.106903076171875\n",
      "epoch:  14900 train_loss: 5.9985809326171875 val_loss: 42.80839538574219\n",
      "epoch:  15000 train_loss: 5.763071537017822 val_loss: 41.93055725097656\n",
      "epoch:  15100 train_loss: 6.790799140930176 val_loss: 41.57099914550781\n",
      "epoch:  15200 train_loss: 6.15629243850708 val_loss: 43.308448791503906\n",
      "epoch:  15300 train_loss: 5.99572229385376 val_loss: 41.850730895996094\n",
      "epoch:  15400 train_loss: 6.601687908172607 val_loss: 44.91627883911133\n",
      "epoch:  15500 train_loss: 5.759003162384033 val_loss: 43.152313232421875\n",
      "epoch:  15600 train_loss: 5.898767471313477 val_loss: 41.888362884521484\n",
      "epoch:  15700 train_loss: 5.53542947769165 val_loss: 42.37421798706055\n",
      "epoch:  15800 train_loss: 5.640732765197754 val_loss: 42.20634460449219\n",
      "epoch:  15900 train_loss: 6.165125846862793 val_loss: 44.05696105957031\n",
      "epoch:  16000 train_loss: 6.265284538269043 val_loss: 41.8765869140625\n",
      "epoch:  16100 train_loss: 6.065184593200684 val_loss: 41.9635124206543\n",
      "epoch:  16200 train_loss: 5.903401851654053 val_loss: 41.97146987915039\n",
      "epoch:  16300 train_loss: 5.375979423522949 val_loss: 43.19158172607422\n",
      "epoch:  16400 train_loss: 5.3255534172058105 val_loss: 42.59990310668945\n",
      "epoch:  16500 train_loss: 6.03994607925415 val_loss: 44.9810905456543\n",
      "epoch:  16600 train_loss: 5.650601387023926 val_loss: 42.3625373840332\n",
      "epoch:  16700 train_loss: 5.892396926879883 val_loss: 42.74454116821289\n",
      "epoch:  16800 train_loss: 5.237215518951416 val_loss: 43.82839584350586\n",
      "epoch:  16900 train_loss: 5.208193302154541 val_loss: 43.333919525146484\n",
      "epoch:  17000 train_loss: 5.1763153076171875 val_loss: 43.78334426879883\n",
      "epoch:  17100 train_loss: 5.241085052490234 val_loss: 44.01837921142578\n",
      "epoch:  17200 train_loss: 6.673863887786865 val_loss: 43.35070037841797\n",
      "epoch:  17300 train_loss: 6.121325969696045 val_loss: 45.65908432006836\n",
      "epoch:  17400 train_loss: 6.046038627624512 val_loss: 45.30760192871094\n",
      "epoch:  17500 train_loss: 5.735937595367432 val_loss: 45.21871566772461\n",
      "epoch:  17600 train_loss: 5.064752101898193 val_loss: 43.7981071472168\n",
      "epoch:  17700 train_loss: 5.36858606338501 val_loss: 44.6688117980957\n",
      "epoch:  17800 train_loss: 5.028327941894531 val_loss: 43.86265563964844\n",
      "epoch:  17900 train_loss: 5.216623306274414 val_loss: 43.34929656982422\n",
      "epoch:  18000 train_loss: 4.922643184661865 val_loss: 44.131412506103516\n",
      "epoch:  18100 train_loss: 5.502007961273193 val_loss: 44.8698844909668\n",
      "epoch:  18200 train_loss: 5.067489147186279 val_loss: 43.57313537597656\n",
      "epoch:  18300 train_loss: 5.535919189453125 val_loss: 45.64678955078125\n",
      "epoch:  18400 train_loss: 4.992091178894043 val_loss: 43.72002029418945\n",
      "epoch:  18500 train_loss: 5.33262825012207 val_loss: 43.88138961791992\n",
      "epoch:  18600 train_loss: 6.731171131134033 val_loss: 44.012874603271484\n",
      "epoch:  18700 train_loss: 5.056456089019775 val_loss: 44.02122497558594\n",
      "epoch:  18800 train_loss: 6.748132705688477 val_loss: 47.156150817871094\n",
      "epoch:  18900 train_loss: 5.424501895904541 val_loss: 45.98341369628906\n",
      "epoch:  19000 train_loss: 4.640002250671387 val_loss: 44.109619140625\n",
      "epoch:  19100 train_loss: 4.943775177001953 val_loss: 44.2818603515625\n",
      "epoch:  19200 train_loss: 4.684459209442139 val_loss: 44.44655990600586\n",
      "epoch:  19300 train_loss: 4.845493793487549 val_loss: 44.24442672729492\n",
      "epoch:  19400 train_loss: 5.231860637664795 val_loss: 44.1069450378418\n",
      "epoch:  19500 train_loss: 4.767637729644775 val_loss: 44.24761962890625\n",
      "epoch:  19600 train_loss: 4.5385308265686035 val_loss: 44.63055419921875\n",
      "epoch:  19700 train_loss: 4.970061302185059 val_loss: 45.98415756225586\n",
      "epoch:  19800 train_loss: 4.517487525939941 val_loss: 44.58779525756836\n",
      "epoch:  19900 train_loss: 5.1854753494262695 val_loss: 46.2045783996582\n",
      "epoch:  20000 train_loss: 4.855851173400879 val_loss: 45.45368194580078\n",
      "epoch:  20100 train_loss: 4.750296115875244 val_loss: 45.81845474243164\n",
      "epoch:  20200 train_loss: 4.702240943908691 val_loss: 44.52729415893555\n",
      "epoch:  20300 train_loss: 5.482825756072998 val_loss: 46.52964782714844\n",
      "epoch:  20400 train_loss: 5.403586387634277 val_loss: 45.02004623413086\n",
      "epoch:  20500 train_loss: 4.693353176116943 val_loss: 46.01911544799805\n",
      "epoch:  20600 train_loss: 4.691126346588135 val_loss: 44.94782257080078\n",
      "epoch:  20700 train_loss: 4.2845964431762695 val_loss: 45.31785583496094\n",
      "epoch:  20800 train_loss: 4.368039608001709 val_loss: 45.09991455078125\n",
      "epoch:  20900 train_loss: 4.94825553894043 val_loss: 44.99231719970703\n",
      "epoch:  21000 train_loss: 4.464001655578613 val_loss: 45.369956970214844\n",
      "epoch:  21100 train_loss: 4.430509090423584 val_loss: 46.285343170166016\n",
      "epoch:  21200 train_loss: 5.691988945007324 val_loss: 47.597103118896484\n",
      "epoch:  21300 train_loss: 4.90207576751709 val_loss: 46.283451080322266\n",
      "epoch:  21400 train_loss: 4.631015300750732 val_loss: 45.235008239746094\n",
      "epoch:  21500 train_loss: 4.162112712860107 val_loss: 45.410247802734375\n",
      "epoch:  21600 train_loss: 4.416696548461914 val_loss: 46.02272415161133\n",
      "epoch:  21700 train_loss: 4.284278869628906 val_loss: 46.51747512817383\n",
      "epoch:  21800 train_loss: 4.29425048828125 val_loss: 46.41276168823242\n",
      "epoch:  21900 train_loss: 5.423636436462402 val_loss: 47.96284103393555\n",
      "epoch:  22000 train_loss: 5.001396656036377 val_loss: 45.625282287597656\n",
      "epoch:  22100 train_loss: 4.066774845123291 val_loss: 46.126075744628906\n",
      "epoch:  22200 train_loss: 5.156589984893799 val_loss: 48.199623107910156\n",
      "epoch:  22300 train_loss: 4.333541393280029 val_loss: 45.82691192626953\n",
      "epoch:  22400 train_loss: 4.209045886993408 val_loss: 45.89604187011719\n",
      "epoch:  22500 train_loss: 4.288769245147705 val_loss: 46.10895919799805\n",
      "epoch:  22600 train_loss: 4.2133941650390625 val_loss: 45.950313568115234\n",
      "epoch:  22700 train_loss: 4.544393062591553 val_loss: 48.1848258972168\n",
      "epoch:  22800 train_loss: 4.395508289337158 val_loss: 45.89459991455078\n",
      "epoch:  22900 train_loss: 4.00136661529541 val_loss: 46.764381408691406\n",
      "epoch:  23000 train_loss: 4.037936210632324 val_loss: 47.15989685058594\n",
      "epoch:  23100 train_loss: 4.188485145568848 val_loss: 46.057552337646484\n",
      "epoch:  23200 train_loss: 4.13570499420166 val_loss: 46.58723068237305\n",
      "epoch:  23300 train_loss: 3.8413925170898438 val_loss: 46.60979461669922\n",
      "epoch:  23400 train_loss: 4.321590423583984 val_loss: 47.165138244628906\n",
      "epoch:  23500 train_loss: 4.054930686950684 val_loss: 46.44835662841797\n",
      "epoch:  23600 train_loss: 3.9801807403564453 val_loss: 46.4604377746582\n",
      "epoch:  23700 train_loss: 3.7624871730804443 val_loss: 46.78218460083008\n",
      "epoch:  23800 train_loss: 4.036379814147949 val_loss: 47.47198486328125\n",
      "epoch:  23900 train_loss: 4.321714401245117 val_loss: 48.17940902709961\n",
      "epoch:  24000 train_loss: 3.760390281677246 val_loss: 47.09100341796875\n",
      "epoch:  24100 train_loss: 4.922906875610352 val_loss: 46.83552932739258\n",
      "epoch:  24200 train_loss: 3.6946637630462646 val_loss: 46.735111236572266\n",
      "epoch:  24300 train_loss: 3.8194851875305176 val_loss: 47.85105514526367\n",
      "epoch:  24400 train_loss: 4.203873157501221 val_loss: 46.803985595703125\n",
      "epoch:  24500 train_loss: 4.4555840492248535 val_loss: 46.848182678222656\n",
      "epoch:  24600 train_loss: 3.5873517990112305 val_loss: 47.610469818115234\n",
      "epoch:  24700 train_loss: 3.8960845470428467 val_loss: 46.89126968383789\n",
      "epoch:  24800 train_loss: 3.5832619667053223 val_loss: 47.277828216552734\n",
      "epoch:  24900 train_loss: 3.6175079345703125 val_loss: 47.52524948120117\n",
      "epoch:  25000 train_loss: 3.9161040782928467 val_loss: 46.936126708984375\n",
      "epoch:  25100 train_loss: 3.575059652328491 val_loss: 48.03315734863281\n",
      "epoch:  25200 train_loss: 3.955446720123291 val_loss: 47.65711212158203\n",
      "epoch:  25300 train_loss: 3.5572586059570312 val_loss: 47.968753814697266\n",
      "epoch:  25400 train_loss: 3.465810537338257 val_loss: 47.76205825805664\n",
      "epoch:  25500 train_loss: 3.73527193069458 val_loss: 47.84294509887695\n",
      "epoch:  25600 train_loss: 3.6423499584198 val_loss: 48.024967193603516\n",
      "epoch:  25700 train_loss: 4.4017014503479 val_loss: 47.20497131347656\n",
      "epoch:  25800 train_loss: 4.3717546463012695 val_loss: 48.88910675048828\n",
      "epoch:  25900 train_loss: 3.408668041229248 val_loss: 47.519371032714844\n",
      "epoch:  26000 train_loss: 3.494588613510132 val_loss: 47.65507888793945\n",
      "epoch:  26100 train_loss: 4.914621353149414 val_loss: 51.19226837158203\n",
      "epoch:  26200 train_loss: 5.648502349853516 val_loss: 47.55097961425781\n",
      "epoch:  26300 train_loss: 3.73612904548645 val_loss: 48.946136474609375\n",
      "epoch:  26400 train_loss: 3.386826276779175 val_loss: 48.407073974609375\n",
      "epoch:  26500 train_loss: 3.4116148948669434 val_loss: 48.255714416503906\n",
      "epoch:  26600 train_loss: 3.490300178527832 val_loss: 48.52923583984375\n",
      "epoch:  26700 train_loss: 3.8839447498321533 val_loss: 47.73994827270508\n",
      "epoch:  26800 train_loss: 3.8358778953552246 val_loss: 48.57170867919922\n",
      "epoch:  26900 train_loss: 3.5213890075683594 val_loss: 48.77436828613281\n",
      "epoch:  27000 train_loss: 3.3511035442352295 val_loss: 47.884437561035156\n",
      "epoch:  27100 train_loss: 3.5576531887054443 val_loss: 49.58633804321289\n",
      "epoch:  27200 train_loss: 3.24240779876709 val_loss: 48.792049407958984\n",
      "epoch:  27300 train_loss: 3.3430349826812744 val_loss: 48.01416778564453\n",
      "epoch:  27400 train_loss: 3.888338565826416 val_loss: 49.36798858642578\n",
      "epoch:  27500 train_loss: 3.52858829498291 val_loss: 48.40620422363281\n",
      "epoch:  27600 train_loss: 3.3827643394470215 val_loss: 48.17961883544922\n",
      "epoch:  27700 train_loss: 4.225924968719482 val_loss: 48.324588775634766\n",
      "epoch:  27800 train_loss: 3.45458722114563 val_loss: 48.0306510925293\n",
      "epoch:  27900 train_loss: 3.6773128509521484 val_loss: 48.526702880859375\n",
      "epoch:  28000 train_loss: 3.625934362411499 val_loss: 48.8530387878418\n",
      "epoch:  28100 train_loss: 3.4836366176605225 val_loss: 48.15863800048828\n",
      "epoch:  28200 train_loss: 3.333122968673706 val_loss: 48.69453430175781\n",
      "epoch:  28300 train_loss: 3.117666006088257 val_loss: 48.51356887817383\n",
      "epoch:  28400 train_loss: 3.8934435844421387 val_loss: 50.2094612121582\n",
      "epoch:  28500 train_loss: 3.2093517780303955 val_loss: 48.570030212402344\n",
      "epoch:  28600 train_loss: 4.184203624725342 val_loss: 48.355777740478516\n",
      "epoch:  28700 train_loss: 3.2501466274261475 val_loss: 48.988433837890625\n",
      "epoch:  28800 train_loss: 3.6497299671173096 val_loss: 48.81829833984375\n",
      "epoch:  28900 train_loss: 3.491478204727173 val_loss: 49.68578338623047\n",
      "epoch:  29000 train_loss: 3.158186435699463 val_loss: 49.0546760559082\n",
      "epoch:  29100 train_loss: 3.069844961166382 val_loss: 49.08200454711914\n",
      "epoch:  29200 train_loss: 3.371354818344116 val_loss: 49.410545349121094\n",
      "epoch:  29300 train_loss: 3.5409181118011475 val_loss: 50.016510009765625\n",
      "epoch:  29400 train_loss: 3.6506965160369873 val_loss: 49.954586029052734\n",
      "epoch:  29500 train_loss: 3.1081771850585938 val_loss: 48.796024322509766\n",
      "epoch:  29600 train_loss: 3.7142438888549805 val_loss: 49.2026481628418\n",
      "epoch:  29700 train_loss: 3.090810537338257 val_loss: 48.751468658447266\n",
      "epoch:  29800 train_loss: 3.7578020095825195 val_loss: 50.00714874267578\n",
      "epoch:  29900 train_loss: 3.6875510215759277 val_loss: 48.88465118408203\n",
      "epoch:  30000 train_loss: 2.896294593811035 val_loss: 49.102596282958984\n",
      "epoch:  30100 train_loss: 3.310220956802368 val_loss: 48.6749153137207\n",
      "epoch:  30200 train_loss: 3.26442813873291 val_loss: 50.034210205078125\n",
      "epoch:  30300 train_loss: 3.0315892696380615 val_loss: 48.741119384765625\n",
      "epoch:  30400 train_loss: 2.8695223331451416 val_loss: 48.90599060058594\n",
      "epoch:  30500 train_loss: 3.0569310188293457 val_loss: 49.35089874267578\n",
      "epoch:  30600 train_loss: 5.125535011291504 val_loss: 51.81462860107422\n",
      "epoch:  30700 train_loss: 3.1407508850097656 val_loss: 49.291595458984375\n",
      "epoch:  30800 train_loss: 2.909799337387085 val_loss: 48.874488830566406\n",
      "epoch:  30900 train_loss: 2.98087739944458 val_loss: 49.94431686401367\n",
      "epoch:  31000 train_loss: 3.2906196117401123 val_loss: 49.57466125488281\n",
      "epoch:  31100 train_loss: 3.7852721214294434 val_loss: 51.49052047729492\n",
      "epoch:  31200 train_loss: 2.8979270458221436 val_loss: 49.6203498840332\n",
      "epoch:  31300 train_loss: 3.0498290061950684 val_loss: 49.977996826171875\n",
      "epoch:  31400 train_loss: 3.5294694900512695 val_loss: 49.075382232666016\n",
      "epoch:  31500 train_loss: 2.9777023792266846 val_loss: 49.982948303222656\n",
      "epoch:  31600 train_loss: 2.902432441711426 val_loss: 50.104061126708984\n",
      "epoch:  31700 train_loss: 3.1114180088043213 val_loss: 49.08246994018555\n",
      "epoch:  31800 train_loss: 2.684981107711792 val_loss: 49.83530044555664\n",
      "epoch:  31900 train_loss: 2.9022011756896973 val_loss: 49.92268371582031\n",
      "epoch:  32000 train_loss: 3.111907958984375 val_loss: 49.2850341796875\n",
      "epoch:  32100 train_loss: 2.904330015182495 val_loss: 50.538822174072266\n",
      "epoch:  32200 train_loss: 3.1596593856811523 val_loss: 49.26911163330078\n",
      "epoch:  32300 train_loss: 2.9447126388549805 val_loss: 49.548133850097656\n",
      "epoch:  32400 train_loss: 2.9181885719299316 val_loss: 49.70355987548828\n",
      "epoch:  32500 train_loss: 3.851313591003418 val_loss: 49.34076690673828\n",
      "epoch:  32600 train_loss: 2.7086212635040283 val_loss: 49.600830078125\n",
      "epoch:  32700 train_loss: 3.6758432388305664 val_loss: 49.72720718383789\n",
      "epoch:  32800 train_loss: 2.701627731323242 val_loss: 49.78300476074219\n",
      "epoch:  32900 train_loss: 3.7971177101135254 val_loss: 50.8249397277832\n",
      "epoch:  33000 train_loss: 2.681485414505005 val_loss: 49.5131721496582\n",
      "epoch:  33100 train_loss: 2.7322380542755127 val_loss: 50.39006805419922\n",
      "epoch:  33200 train_loss: 2.7301249504089355 val_loss: 50.048248291015625\n",
      "epoch:  33300 train_loss: 2.618834972381592 val_loss: 50.26897430419922\n",
      "epoch:  33400 train_loss: 3.0155162811279297 val_loss: 49.898773193359375\n",
      "epoch:  33500 train_loss: 2.796207904815674 val_loss: 50.26832580566406\n",
      "epoch:  33600 train_loss: 2.6975295543670654 val_loss: 49.75492477416992\n",
      "epoch:  33700 train_loss: 3.6008899211883545 val_loss: 50.33491897583008\n",
      "epoch:  33800 train_loss: 2.7082300186157227 val_loss: 49.97171401977539\n",
      "epoch:  33900 train_loss: 2.9275949001312256 val_loss: 51.182769775390625\n",
      "epoch:  34000 train_loss: 2.674677848815918 val_loss: 49.871315002441406\n",
      "epoch:  34100 train_loss: 3.2017340660095215 val_loss: 52.21112823486328\n",
      "epoch:  34200 train_loss: 3.1666505336761475 val_loss: 50.9420051574707\n",
      "epoch:  34300 train_loss: 2.703364372253418 val_loss: 49.95122146606445\n",
      "epoch:  34400 train_loss: 2.7698090076446533 val_loss: 50.48918151855469\n",
      "epoch:  34500 train_loss: 3.400256872177124 val_loss: 52.02354431152344\n",
      "epoch:  34600 train_loss: 3.0259764194488525 val_loss: 51.68563461303711\n",
      "epoch:  34700 train_loss: 2.778733491897583 val_loss: 50.015174865722656\n",
      "epoch:  34800 train_loss: 2.81779408454895 val_loss: 51.18358612060547\n",
      "epoch:  34900 train_loss: 2.742530345916748 val_loss: 50.899776458740234\n",
      "epoch:  35000 train_loss: 2.565148115158081 val_loss: 50.21202087402344\n",
      "epoch:  35100 train_loss: 2.514108419418335 val_loss: 50.907493591308594\n",
      "epoch:  35200 train_loss: 2.584951162338257 val_loss: 50.62140655517578\n",
      "epoch:  35300 train_loss: 2.462984085083008 val_loss: 50.622371673583984\n",
      "epoch:  35400 train_loss: 3.070387601852417 val_loss: 51.52212905883789\n",
      "epoch:  35500 train_loss: 3.1434924602508545 val_loss: 52.26936340332031\n",
      "epoch:  35600 train_loss: 2.6761319637298584 val_loss: 51.345184326171875\n",
      "epoch:  35700 train_loss: 3.0387158393859863 val_loss: 52.23982620239258\n",
      "epoch:  35800 train_loss: 2.740879535675049 val_loss: 50.48328399658203\n",
      "epoch:  35900 train_loss: 2.7269368171691895 val_loss: 50.2335090637207\n",
      "RMSE:  tensor(12.7875, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Ganerate the dataset\n",
    "i = 0\n",
    "sigma = 9.1\n",
    "my_dataset = []\n",
    "for ud in UDs:\n",
    "    example = []\n",
    "    for an in ANs:\n",
    "        noise = np.random.normal(0,sigma)\n",
    "        # 0 is mean\n",
    "        # sigma is the deviation of the normal distribution\n",
    "        d = compute_3d_distance(ud, an) + noise\n",
    "        example.append(d)\n",
    "    \n",
    "    # append x, y, z as col#10, #11, #12\n",
    "    example.append(ud[0])\n",
    "    example.append(ud[1])\n",
    "    example.append(ud[2])\n",
    "    \n",
    "    # append 1x13 example row into my_dataset\n",
    "    my_dataset.append(example)  # expected to be 3000x13  \n",
    "    \n",
    "# Load dataset\n",
    "exercise3_dataset = Exercise3Dataset(list_dataset = my_dataset, shuffle=True)\n",
    "\n",
    "#Split dataset by 0.8: 0.1: 0.1\n",
    "train_examples, train_labels = exercise3_dataset[:int(3000*0.8)]  # (2400, 10)   # (2400, 3)\n",
    "val_examples, val_labels = exercise3_dataset[int(3000*0.8):int(3000*0.9)]    # (300, 10)   #(300, 3)\n",
    "test_examples, test_labels = exercise3_dataset[int(3000*0.9):]     #(300, 10)   # (300, 3)\n",
    "\n",
    "###Define model, loss function and optimizer\n",
    "# if we have GPU, then use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define model\n",
    "model = Net(x_dim = train_examples.shape[1], y_dim = train_labels.shape[1]).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training and Validation\n",
    "\n",
    "train_examples = train_examples.to(device)\n",
    "train_labels = train_labels.to(device)\n",
    "val_examples = val_examples.to(device)\n",
    "val_labels = val_labels.to(device)\n",
    "\n",
    "# Define the model filename for model.save()\n",
    "MODEL_FILENAME = \"best.pth\"\n",
    "\n",
    "# set model to Training mode\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "NUM_OF_EPOCH = 36000\n",
    "\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    y_pred = model(train_examples)\n",
    "    loss = loss_fn(y_pred, train_labels).cpu()\n",
    "    #print(t, loss.item())\n",
    "    train_losses.append(loss.item())\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    # BGD\n",
    "    optimizer.step()\n",
    "    \n",
    "    # evaluate validation loss\n",
    "    val_pred = model(val_examples)\n",
    "    loss = loss_fn(val_pred, val_labels)\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "    # check if we got better loss\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n",
    "\n",
    "    if (epoch % 100) == 0:\n",
    "        print(\"epoch: \", epoch, \"train_loss:\", train_losses[-1], \"val_loss:\", val_losses[-1])\n",
    "        \n",
    "# Inference all testing examples and compute RMSE\n",
    "def square_error(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  square_error= loss_fn(a, b)\n",
    "  return square_error\n",
    "\n",
    "model.eval() # inference mode\n",
    "test_examples = test_examples.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "test_preds = model(test_examples)\n",
    "#print(\"example: \", test_example.cpu())\n",
    "#print(\"========================================\")\n",
    "#print(\"ground_truth:\", test_label.cpu())\n",
    "#print(\"prediction:\", test_pred.cpu())\n",
    "#print(\"========================================\")\n",
    "\n",
    "\n",
    "total_errors = 0.0\n",
    "for idx in range(len(test_examples)):\n",
    "    total_errors += square_error(test_preds[idx], test_labels[idx])\n",
    "    \n",
    "RMSE = torch.sqrt(total_errors / len(test_examples))\n",
    "print(\"RMSE: \",  RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigma = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shuffle = True!\n",
      "epoch:  0 train_loss: 7342.7978515625 val_loss: 7284.76123046875\n",
      "epoch:  100 train_loss: 276.61865234375 val_loss: 264.3043518066406\n",
      "epoch:  200 train_loss: 164.25416564941406 val_loss: 159.97097778320312\n",
      "epoch:  300 train_loss: 92.66922760009766 val_loss: 90.31532287597656\n",
      "epoch:  400 train_loss: 60.51521682739258 val_loss: 59.7673454284668\n",
      "epoch:  500 train_loss: 39.60945129394531 val_loss: 42.144073486328125\n",
      "epoch:  600 train_loss: 29.78264808654785 val_loss: 33.650657653808594\n",
      "epoch:  700 train_loss: 27.997509002685547 val_loss: 31.98150634765625\n",
      "epoch:  800 train_loss: 26.81488037109375 val_loss: 30.853378295898438\n",
      "epoch:  900 train_loss: 25.88899803161621 val_loss: 29.9373836517334\n",
      "epoch:  1000 train_loss: 25.132404327392578 val_loss: 29.2901554107666\n",
      "epoch:  1100 train_loss: 24.372838973999023 val_loss: 28.63304328918457\n",
      "epoch:  1200 train_loss: 23.578773498535156 val_loss: 27.989822387695312\n",
      "epoch:  1300 train_loss: 22.91539192199707 val_loss: 27.65152931213379\n",
      "epoch:  1400 train_loss: 22.342628479003906 val_loss: 27.413312911987305\n",
      "epoch:  1500 train_loss: 21.856962203979492 val_loss: 27.270261764526367\n",
      "epoch:  1600 train_loss: 21.423662185668945 val_loss: 27.15196990966797\n",
      "epoch:  1700 train_loss: 21.036319732666016 val_loss: 27.18738555908203\n",
      "epoch:  1800 train_loss: 20.64378547668457 val_loss: 27.189289093017578\n",
      "epoch:  1900 train_loss: 20.25072479248047 val_loss: 27.31336784362793\n",
      "epoch:  2000 train_loss: 19.85940170288086 val_loss: 27.47158432006836\n",
      "epoch:  2100 train_loss: 19.487951278686523 val_loss: 27.563081741333008\n",
      "epoch:  2200 train_loss: 19.14804458618164 val_loss: 27.71087646484375\n",
      "epoch:  2300 train_loss: 18.80805206298828 val_loss: 28.025222778320312\n",
      "epoch:  2400 train_loss: 18.487375259399414 val_loss: 28.199514389038086\n",
      "epoch:  2500 train_loss: 18.191137313842773 val_loss: 28.381710052490234\n",
      "epoch:  2600 train_loss: 17.898977279663086 val_loss: 29.123516082763672\n",
      "epoch:  2700 train_loss: 17.607141494750977 val_loss: 28.964982986450195\n",
      "epoch:  2800 train_loss: 17.24627113342285 val_loss: 29.700315475463867\n",
      "epoch:  2900 train_loss: 16.94464111328125 val_loss: 30.421415328979492\n",
      "epoch:  3000 train_loss: 16.56311798095703 val_loss: 30.230260848999023\n",
      "epoch:  3100 train_loss: 16.1860294342041 val_loss: 31.085529327392578\n",
      "epoch:  3200 train_loss: 15.898049354553223 val_loss: 31.60677719116211\n",
      "epoch:  3300 train_loss: 15.653287887573242 val_loss: 31.539905548095703\n",
      "epoch:  3400 train_loss: 15.553227424621582 val_loss: 31.61362075805664\n",
      "epoch:  3500 train_loss: 15.016286849975586 val_loss: 32.53407287597656\n",
      "epoch:  3600 train_loss: 14.860658645629883 val_loss: 32.54974365234375\n",
      "epoch:  3700 train_loss: 14.547772407531738 val_loss: 32.839908599853516\n",
      "epoch:  3800 train_loss: 14.34611988067627 val_loss: 34.063011169433594\n",
      "epoch:  3900 train_loss: 14.4656982421875 val_loss: 33.26298522949219\n",
      "epoch:  4000 train_loss: 14.042498588562012 val_loss: 35.079715728759766\n",
      "epoch:  4100 train_loss: 13.895440101623535 val_loss: 35.82796096801758\n",
      "epoch:  4200 train_loss: 13.88669490814209 val_loss: 35.87316131591797\n",
      "epoch:  4300 train_loss: 13.242277145385742 val_loss: 35.109588623046875\n",
      "epoch:  4400 train_loss: 13.085479736328125 val_loss: 36.077640533447266\n",
      "epoch:  4500 train_loss: 13.326001167297363 val_loss: 34.92937469482422\n",
      "epoch:  4600 train_loss: 12.661816596984863 val_loss: 36.129371643066406\n",
      "epoch:  4700 train_loss: 12.808761596679688 val_loss: 35.375518798828125\n",
      "epoch:  4800 train_loss: 12.364327430725098 val_loss: 37.065956115722656\n",
      "epoch:  4900 train_loss: 12.241108894348145 val_loss: 36.271026611328125\n",
      "epoch:  5000 train_loss: 12.233678817749023 val_loss: 35.8731575012207\n",
      "epoch:  5100 train_loss: 12.297422409057617 val_loss: 36.1154899597168\n",
      "epoch:  5200 train_loss: 11.68106460571289 val_loss: 36.940547943115234\n",
      "epoch:  5300 train_loss: 11.954490661621094 val_loss: 36.54376983642578\n",
      "epoch:  5400 train_loss: 11.405792236328125 val_loss: 36.964229583740234\n",
      "epoch:  5500 train_loss: 11.762843132019043 val_loss: 36.76403045654297\n",
      "epoch:  5600 train_loss: 11.126916885375977 val_loss: 38.65870666503906\n",
      "epoch:  5700 train_loss: 10.917763710021973 val_loss: 37.989620208740234\n",
      "epoch:  5800 train_loss: 10.80398941040039 val_loss: 38.73591232299805\n",
      "epoch:  5900 train_loss: 10.970044136047363 val_loss: 40.15254592895508\n",
      "epoch:  6000 train_loss: 10.79942512512207 val_loss: 40.112979888916016\n",
      "epoch:  6100 train_loss: 10.398781776428223 val_loss: 38.94742202758789\n",
      "epoch:  6200 train_loss: 10.234020233154297 val_loss: 39.91270065307617\n",
      "epoch:  6300 train_loss: 10.099577903747559 val_loss: 41.27227020263672\n",
      "epoch:  6400 train_loss: 10.511124610900879 val_loss: 39.498191833496094\n",
      "epoch:  6500 train_loss: 9.923686027526855 val_loss: 40.47552490234375\n",
      "epoch:  6600 train_loss: 10.111373901367188 val_loss: 42.11711502075195\n",
      "epoch:  6700 train_loss: 10.116106986999512 val_loss: 44.139678955078125\n",
      "epoch:  6800 train_loss: 9.470622062683105 val_loss: 42.040428161621094\n",
      "epoch:  6900 train_loss: 9.852751731872559 val_loss: 40.69812774658203\n",
      "epoch:  7000 train_loss: 9.955085754394531 val_loss: 44.58013153076172\n",
      "epoch:  7100 train_loss: 9.29549503326416 val_loss: 41.42670822143555\n",
      "epoch:  7200 train_loss: 9.036467552185059 val_loss: 42.94744110107422\n",
      "epoch:  7300 train_loss: 9.101751327514648 val_loss: 42.19129180908203\n",
      "epoch:  7400 train_loss: 8.930572509765625 val_loss: 42.308013916015625\n",
      "epoch:  7500 train_loss: 8.94182014465332 val_loss: 42.58302688598633\n",
      "epoch:  7600 train_loss: 8.649162292480469 val_loss: 43.63056182861328\n",
      "epoch:  7700 train_loss: 9.620501518249512 val_loss: 41.94854736328125\n",
      "epoch:  7800 train_loss: 9.032526969909668 val_loss: 42.68408966064453\n",
      "epoch:  7900 train_loss: 8.616048812866211 val_loss: 45.200355529785156\n",
      "epoch:  8000 train_loss: 8.3645658493042 val_loss: 44.770599365234375\n",
      "epoch:  8100 train_loss: 8.32520866394043 val_loss: 43.51348114013672\n",
      "epoch:  8200 train_loss: 8.201173782348633 val_loss: 46.25816345214844\n",
      "epoch:  8300 train_loss: 8.480652809143066 val_loss: 43.51708984375\n",
      "epoch:  8400 train_loss: 8.047341346740723 val_loss: 44.69933319091797\n",
      "epoch:  8500 train_loss: 7.9231085777282715 val_loss: 46.94169235229492\n",
      "epoch:  8600 train_loss: 7.773794174194336 val_loss: 46.11664962768555\n",
      "epoch:  8700 train_loss: 7.974507808685303 val_loss: 44.364986419677734\n",
      "epoch:  8800 train_loss: 7.582306861877441 val_loss: 46.97889709472656\n",
      "epoch:  8900 train_loss: 7.448592662811279 val_loss: 45.50499725341797\n",
      "epoch:  9000 train_loss: 8.123997688293457 val_loss: 44.7967529296875\n",
      "epoch:  9100 train_loss: 7.294748783111572 val_loss: 47.580238342285156\n",
      "epoch:  9200 train_loss: 7.388844966888428 val_loss: 48.1674919128418\n",
      "epoch:  9300 train_loss: 8.472623825073242 val_loss: 44.872718811035156\n",
      "epoch:  9400 train_loss: 7.280069828033447 val_loss: 48.73729705810547\n",
      "epoch:  9500 train_loss: 7.142856121063232 val_loss: 48.432891845703125\n",
      "epoch:  9600 train_loss: 8.441697120666504 val_loss: 51.485652923583984\n",
      "epoch:  9700 train_loss: 8.190423011779785 val_loss: 49.86153793334961\n",
      "epoch:  9800 train_loss: 6.8935322761535645 val_loss: 46.839176177978516\n",
      "epoch:  9900 train_loss: 6.7689738273620605 val_loss: 48.19846725463867\n",
      "epoch:  10000 train_loss: 8.2032470703125 val_loss: 52.91661071777344\n",
      "epoch:  10100 train_loss: 6.669881820678711 val_loss: 49.925018310546875\n",
      "epoch:  10200 train_loss: 6.624808311462402 val_loss: 47.93156433105469\n",
      "epoch:  10300 train_loss: 6.6072821617126465 val_loss: 49.361263275146484\n",
      "epoch:  10400 train_loss: 6.437795162200928 val_loss: 49.36677169799805\n",
      "epoch:  10500 train_loss: 6.358232498168945 val_loss: 50.53864288330078\n",
      "epoch:  10600 train_loss: 6.3201069831848145 val_loss: 48.855228424072266\n",
      "epoch:  10700 train_loss: 7.128330230712891 val_loss: 47.08394241333008\n",
      "epoch:  10800 train_loss: 7.016652584075928 val_loss: 47.4586296081543\n",
      "epoch:  10900 train_loss: 6.397783279418945 val_loss: 48.200626373291016\n",
      "epoch:  11000 train_loss: 6.452236652374268 val_loss: 51.5507926940918\n",
      "epoch:  11100 train_loss: 5.911433696746826 val_loss: 49.56759262084961\n",
      "epoch:  11200 train_loss: 6.503329277038574 val_loss: 48.647098541259766\n",
      "epoch:  11300 train_loss: 6.046225070953369 val_loss: 52.995853424072266\n",
      "epoch:  11400 train_loss: 6.25908088684082 val_loss: 53.35884094238281\n",
      "epoch:  11500 train_loss: 5.878404140472412 val_loss: 49.18473815917969\n",
      "epoch:  11600 train_loss: 6.112486362457275 val_loss: 48.82554626464844\n",
      "epoch:  11700 train_loss: 5.690125465393066 val_loss: 50.18317413330078\n",
      "epoch:  11800 train_loss: 5.674590110778809 val_loss: 52.58821487426758\n",
      "epoch:  11900 train_loss: 5.4811110496521 val_loss: 51.94873046875\n",
      "epoch:  12000 train_loss: 5.438258647918701 val_loss: 52.318878173828125\n",
      "epoch:  12100 train_loss: 6.087983131408691 val_loss: 49.50065994262695\n",
      "epoch:  12200 train_loss: 6.1536383628845215 val_loss: 50.335365295410156\n",
      "epoch:  12300 train_loss: 5.242753028869629 val_loss: 52.94186782836914\n",
      "epoch:  12400 train_loss: 5.358236789703369 val_loss: 52.74822998046875\n",
      "epoch:  12500 train_loss: 5.9810261726379395 val_loss: 49.92655944824219\n",
      "epoch:  12600 train_loss: 5.8914031982421875 val_loss: 54.858402252197266\n",
      "epoch:  12700 train_loss: 5.376098155975342 val_loss: 54.24256896972656\n",
      "epoch:  12800 train_loss: 5.710450649261475 val_loss: 56.247440338134766\n",
      "epoch:  12900 train_loss: 5.005825996398926 val_loss: 52.29861068725586\n",
      "epoch:  13000 train_loss: 5.0072126388549805 val_loss: 53.19852066040039\n",
      "epoch:  13100 train_loss: 5.112083435058594 val_loss: 54.2508659362793\n",
      "epoch:  13200 train_loss: 6.091406345367432 val_loss: 50.92181396484375\n",
      "epoch:  13300 train_loss: 5.153637886047363 val_loss: 51.89662170410156\n",
      "epoch:  13400 train_loss: 5.275643348693848 val_loss: 55.9546012878418\n",
      "epoch:  13500 train_loss: 5.032612323760986 val_loss: 54.65629196166992\n",
      "epoch:  13600 train_loss: 5.473015308380127 val_loss: 51.73432922363281\n",
      "epoch:  13700 train_loss: 4.6969146728515625 val_loss: 53.41762161254883\n",
      "epoch:  13800 train_loss: 5.498894214630127 val_loss: 51.7785758972168\n",
      "epoch:  13900 train_loss: 4.7824296951293945 val_loss: 55.020973205566406\n",
      "epoch:  14000 train_loss: 4.782673358917236 val_loss: 53.17974853515625\n",
      "epoch:  14100 train_loss: 4.818251132965088 val_loss: 55.4986572265625\n",
      "epoch:  14200 train_loss: 4.659156799316406 val_loss: 53.39181900024414\n",
      "epoch:  14300 train_loss: 4.575753211975098 val_loss: 56.45479202270508\n",
      "epoch:  14400 train_loss: 4.5006866455078125 val_loss: 55.20311737060547\n",
      "epoch:  14500 train_loss: 5.174831867218018 val_loss: 58.07074737548828\n",
      "epoch:  14600 train_loss: 4.8465375900268555 val_loss: 53.3352165222168\n",
      "epoch:  14700 train_loss: 5.394499778747559 val_loss: 59.706756591796875\n",
      "epoch:  14800 train_loss: 4.8470778465271 val_loss: 53.47120666503906\n",
      "epoch:  14900 train_loss: 4.45916223526001 val_loss: 54.355525970458984\n",
      "epoch:  15000 train_loss: 5.177549362182617 val_loss: 53.33878707885742\n",
      "epoch:  15100 train_loss: 4.297746181488037 val_loss: 55.73474884033203\n",
      "epoch:  15200 train_loss: 5.144393444061279 val_loss: 60.356781005859375\n",
      "epoch:  15300 train_loss: 5.027688980102539 val_loss: 57.4639778137207\n",
      "epoch:  15400 train_loss: 4.494770526885986 val_loss: 54.8335075378418\n",
      "epoch:  15500 train_loss: 4.332169532775879 val_loss: 54.831790924072266\n",
      "epoch:  15600 train_loss: 4.855194568634033 val_loss: 59.698455810546875\n",
      "epoch:  15700 train_loss: 4.5515875816345215 val_loss: 59.17556381225586\n",
      "epoch:  15800 train_loss: 4.665477752685547 val_loss: 60.817405700683594\n",
      "epoch:  15900 train_loss: 4.7012553215026855 val_loss: 59.475040435791016\n",
      "epoch:  16000 train_loss: 4.1149001121521 val_loss: 56.23838806152344\n",
      "epoch:  16100 train_loss: 5.162345886230469 val_loss: 53.831016540527344\n",
      "epoch:  16200 train_loss: 4.574319839477539 val_loss: 59.7379264831543\n",
      "epoch:  16300 train_loss: 3.960550308227539 val_loss: 56.48068618774414\n",
      "epoch:  16400 train_loss: 3.9268436431884766 val_loss: 56.76707458496094\n",
      "epoch:  16500 train_loss: 4.418930530548096 val_loss: 59.9406623840332\n",
      "epoch:  16600 train_loss: 4.155223369598389 val_loss: 55.83897018432617\n",
      "epoch:  16700 train_loss: 4.810312747955322 val_loss: 54.56047821044922\n",
      "epoch:  16800 train_loss: 4.1068572998046875 val_loss: 57.09840393066406\n",
      "epoch:  16900 train_loss: 4.585264205932617 val_loss: 55.264259338378906\n",
      "epoch:  17000 train_loss: 4.567453384399414 val_loss: 60.24019241333008\n",
      "epoch:  17100 train_loss: 4.104433059692383 val_loss: 60.347049713134766\n",
      "epoch:  17200 train_loss: 3.901188850402832 val_loss: 56.8005485534668\n",
      "epoch:  17300 train_loss: 4.502455711364746 val_loss: 56.7353515625\n",
      "epoch:  17400 train_loss: 3.771148920059204 val_loss: 58.470176696777344\n",
      "epoch:  17500 train_loss: 3.6891794204711914 val_loss: 58.11266326904297\n",
      "epoch:  17600 train_loss: 3.8731448650360107 val_loss: 56.57391357421875\n",
      "epoch:  17700 train_loss: 4.468437671661377 val_loss: 57.401851654052734\n",
      "epoch:  17800 train_loss: 4.451958179473877 val_loss: 56.477420806884766\n",
      "epoch:  17900 train_loss: 4.384255886077881 val_loss: 55.915523529052734\n",
      "epoch:  18000 train_loss: 3.81083083152771 val_loss: 57.65673065185547\n",
      "epoch:  18100 train_loss: 3.714747190475464 val_loss: 60.603416442871094\n",
      "epoch:  18200 train_loss: 3.8315625190734863 val_loss: 61.214012145996094\n",
      "epoch:  18300 train_loss: 4.644461154937744 val_loss: 64.57654571533203\n",
      "epoch:  18400 train_loss: 3.7619643211364746 val_loss: 60.214454650878906\n",
      "epoch:  18500 train_loss: 3.4732251167297363 val_loss: 59.20795440673828\n",
      "epoch:  18600 train_loss: 4.552837371826172 val_loss: 63.02451705932617\n",
      "epoch:  18700 train_loss: 3.7352442741394043 val_loss: 59.155574798583984\n",
      "epoch:  18800 train_loss: 3.563000202178955 val_loss: 62.76967239379883\n",
      "epoch:  18900 train_loss: 3.444291591644287 val_loss: 60.13692092895508\n",
      "epoch:  19000 train_loss: 4.197476387023926 val_loss: 63.70529556274414\n",
      "epoch:  19100 train_loss: 4.105595111846924 val_loss: 57.54011535644531\n",
      "epoch:  19200 train_loss: 3.435699701309204 val_loss: 61.15082550048828\n",
      "epoch:  19300 train_loss: 4.39365291595459 val_loss: 63.657833099365234\n",
      "epoch:  19400 train_loss: 3.6824371814727783 val_loss: 58.5379753112793\n",
      "epoch:  19500 train_loss: 3.7011020183563232 val_loss: 62.51614761352539\n",
      "epoch:  19600 train_loss: 3.84515643119812 val_loss: 58.00074005126953\n",
      "epoch:  19700 train_loss: 4.448464870452881 val_loss: 57.39617156982422\n",
      "epoch:  19800 train_loss: 3.3857948780059814 val_loss: 62.53949737548828\n",
      "epoch:  19900 train_loss: 3.9593799114227295 val_loss: 64.95166015625\n",
      "epoch:  20000 train_loss: 3.2535765171051025 val_loss: 59.46180725097656\n",
      "epoch:  20100 train_loss: 3.5869884490966797 val_loss: 58.27225875854492\n",
      "epoch:  20200 train_loss: 3.3223209381103516 val_loss: 59.42186737060547\n",
      "epoch:  20300 train_loss: 3.251328468322754 val_loss: 60.37118148803711\n",
      "epoch:  20400 train_loss: 3.414853096008301 val_loss: 62.274776458740234\n",
      "epoch:  20500 train_loss: 3.3763620853424072 val_loss: 62.74643325805664\n",
      "epoch:  20600 train_loss: 3.3568460941314697 val_loss: 59.32221603393555\n",
      "epoch:  20700 train_loss: 3.4907286167144775 val_loss: 59.76420211791992\n",
      "epoch:  20800 train_loss: 3.171858787536621 val_loss: 60.70046615600586\n",
      "epoch:  20900 train_loss: 3.794968605041504 val_loss: 65.15017700195312\n",
      "epoch:  21000 train_loss: 4.119071006774902 val_loss: 59.287742614746094\n",
      "epoch:  21100 train_loss: 3.7319557666778564 val_loss: 59.10579299926758\n",
      "epoch:  21200 train_loss: 3.739375591278076 val_loss: 63.29442596435547\n",
      "epoch:  21300 train_loss: 3.2684266567230225 val_loss: 59.821044921875\n",
      "epoch:  21400 train_loss: 3.162238597869873 val_loss: 62.74403381347656\n",
      "epoch:  21500 train_loss: 3.1915860176086426 val_loss: 59.54921340942383\n",
      "epoch:  21600 train_loss: 3.1017069816589355 val_loss: 63.19435119628906\n",
      "epoch:  21700 train_loss: 4.155460834503174 val_loss: 66.66649627685547\n",
      "epoch:  21800 train_loss: 3.198350191116333 val_loss: 62.5837516784668\n",
      "epoch:  21900 train_loss: 3.009202003479004 val_loss: 63.202083587646484\n",
      "epoch:  22000 train_loss: 2.9338181018829346 val_loss: 62.06599426269531\n",
      "epoch:  22100 train_loss: 3.044395923614502 val_loss: 65.35093688964844\n",
      "epoch:  22200 train_loss: 2.9614415168762207 val_loss: 63.3287467956543\n",
      "epoch:  22300 train_loss: 3.2922890186309814 val_loss: 64.98753356933594\n",
      "epoch:  22400 train_loss: 3.001436710357666 val_loss: 62.03740692138672\n",
      "epoch:  22500 train_loss: 3.9845149517059326 val_loss: 58.74637985229492\n",
      "epoch:  22600 train_loss: 3.070363998413086 val_loss: 63.69424819946289\n",
      "epoch:  22700 train_loss: 3.0613012313842773 val_loss: 64.72389221191406\n",
      "epoch:  22800 train_loss: 2.7676444053649902 val_loss: 61.99308395385742\n",
      "epoch:  22900 train_loss: 3.306410789489746 val_loss: 59.6219596862793\n",
      "epoch:  23000 train_loss: 3.4916131496429443 val_loss: 65.3829345703125\n",
      "epoch:  23100 train_loss: 3.247495174407959 val_loss: 63.46126174926758\n",
      "epoch:  23200 train_loss: 2.8579368591308594 val_loss: 63.20978546142578\n",
      "epoch:  23300 train_loss: 2.8826210498809814 val_loss: 60.85370635986328\n",
      "epoch:  23400 train_loss: 3.39091157913208 val_loss: 64.92828369140625\n",
      "epoch:  23500 train_loss: 2.8099279403686523 val_loss: 62.07537841796875\n",
      "epoch:  23600 train_loss: 3.737222194671631 val_loss: 59.66135025024414\n",
      "epoch:  23700 train_loss: 3.5508036613464355 val_loss: 60.1887092590332\n",
      "epoch:  23800 train_loss: 3.2416694164276123 val_loss: 59.79510498046875\n",
      "epoch:  23900 train_loss: 2.9084413051605225 val_loss: 61.34932327270508\n",
      "epoch:  24000 train_loss: 3.307957410812378 val_loss: 66.17469024658203\n",
      "epoch:  24100 train_loss: 3.2005093097686768 val_loss: 66.13720703125\n",
      "epoch:  24200 train_loss: 2.943469524383545 val_loss: 65.07654571533203\n",
      "epoch:  24300 train_loss: 3.0348634719848633 val_loss: 65.50372314453125\n",
      "epoch:  24400 train_loss: 2.9527604579925537 val_loss: 61.300636291503906\n",
      "epoch:  24500 train_loss: 3.4942758083343506 val_loss: 68.0244369506836\n",
      "epoch:  24600 train_loss: 2.9988019466400146 val_loss: 61.324153900146484\n",
      "epoch:  24700 train_loss: 2.703721523284912 val_loss: 64.58218383789062\n",
      "epoch:  24800 train_loss: 2.7818245887756348 val_loss: 60.44688415527344\n",
      "epoch:  24900 train_loss: 2.814368724822998 val_loss: 65.64054107666016\n",
      "epoch:  25000 train_loss: 3.1912918090820312 val_loss: 65.66310119628906\n",
      "epoch:  25100 train_loss: 2.6603126525878906 val_loss: 65.0919189453125\n",
      "epoch:  25200 train_loss: 2.5872037410736084 val_loss: 65.4961929321289\n",
      "epoch:  25300 train_loss: 3.268798351287842 val_loss: 65.233154296875\n",
      "epoch:  25400 train_loss: 2.630988121032715 val_loss: 64.2469482421875\n",
      "epoch:  25500 train_loss: 2.6590583324432373 val_loss: 62.98094940185547\n",
      "epoch:  25600 train_loss: 2.7733633518218994 val_loss: 62.11613082885742\n",
      "epoch:  25700 train_loss: 3.6403896808624268 val_loss: 60.38396072387695\n",
      "epoch:  25800 train_loss: 2.80118989944458 val_loss: 62.42207717895508\n",
      "epoch:  25900 train_loss: 3.4168736934661865 val_loss: 62.504722595214844\n",
      "epoch:  26000 train_loss: 2.6455228328704834 val_loss: 64.00924682617188\n",
      "epoch:  26100 train_loss: 3.922170877456665 val_loss: 59.71219253540039\n",
      "epoch:  26200 train_loss: 3.3449902534484863 val_loss: 60.65837860107422\n",
      "epoch:  26300 train_loss: 2.9428324699401855 val_loss: 60.997283935546875\n",
      "epoch:  26400 train_loss: 2.41106915473938 val_loss: 63.3140754699707\n",
      "epoch:  26500 train_loss: 2.7083375453948975 val_loss: 64.81745147705078\n",
      "epoch:  26600 train_loss: 2.5905606746673584 val_loss: 65.8315200805664\n",
      "epoch:  26700 train_loss: 2.841632604598999 val_loss: 66.96644592285156\n",
      "epoch:  26800 train_loss: 3.4185545444488525 val_loss: 66.99002838134766\n",
      "epoch:  26900 train_loss: 2.950904369354248 val_loss: 67.71488952636719\n",
      "epoch:  27000 train_loss: 3.109241008758545 val_loss: 61.62893295288086\n",
      "epoch:  27100 train_loss: 2.58729887008667 val_loss: 63.01431655883789\n",
      "epoch:  27200 train_loss: 2.3954389095306396 val_loss: 62.31236267089844\n",
      "epoch:  27300 train_loss: 3.735936164855957 val_loss: 60.567413330078125\n",
      "epoch:  27400 train_loss: 2.550199270248413 val_loss: 61.63712692260742\n",
      "epoch:  27500 train_loss: 2.2736563682556152 val_loss: 63.307918548583984\n",
      "epoch:  27600 train_loss: 2.7874317169189453 val_loss: 61.99185562133789\n",
      "epoch:  27700 train_loss: 2.861825704574585 val_loss: 65.28437042236328\n",
      "epoch:  27800 train_loss: 3.250624418258667 val_loss: 67.55657196044922\n",
      "epoch:  27900 train_loss: 2.598660469055176 val_loss: 67.46678924560547\n",
      "epoch:  28000 train_loss: 2.424518346786499 val_loss: 66.74507904052734\n",
      "epoch:  28100 train_loss: 2.810608148574829 val_loss: 63.230430603027344\n",
      "epoch:  28200 train_loss: 2.463900327682495 val_loss: 64.65629577636719\n",
      "epoch:  28300 train_loss: 2.341784715652466 val_loss: 62.86887741088867\n",
      "epoch:  28400 train_loss: 3.298614501953125 val_loss: 66.93035888671875\n",
      "epoch:  28500 train_loss: 2.557384490966797 val_loss: 66.00807189941406\n",
      "epoch:  28600 train_loss: 2.777208089828491 val_loss: 66.67591857910156\n",
      "epoch:  28700 train_loss: 2.3972830772399902 val_loss: 63.42373275756836\n",
      "epoch:  28800 train_loss: 2.343552589416504 val_loss: 64.07284545898438\n",
      "epoch:  28900 train_loss: 2.1132218837738037 val_loss: 64.65178680419922\n",
      "epoch:  29000 train_loss: 2.3160088062286377 val_loss: 65.28532409667969\n",
      "epoch:  29100 train_loss: 2.376213788986206 val_loss: 66.54884338378906\n",
      "epoch:  29200 train_loss: 2.42155385017395 val_loss: 66.31536865234375\n",
      "epoch:  29300 train_loss: 2.16279935836792 val_loss: 65.13861083984375\n",
      "epoch:  29400 train_loss: 2.8829269409179688 val_loss: 62.22705078125\n",
      "epoch:  29500 train_loss: 2.2587103843688965 val_loss: 67.28892517089844\n",
      "epoch:  29600 train_loss: 3.038935899734497 val_loss: 62.76592254638672\n",
      "epoch:  29700 train_loss: 3.061065435409546 val_loss: 62.43442916870117\n",
      "epoch:  29800 train_loss: 2.35772442817688 val_loss: 66.84091186523438\n",
      "epoch:  29900 train_loss: 3.9220314025878906 val_loss: 69.22002410888672\n",
      "epoch:  30000 train_loss: 2.264256238937378 val_loss: 63.42303466796875\n",
      "epoch:  30100 train_loss: 3.219021797180176 val_loss: 69.5202865600586\n",
      "epoch:  30200 train_loss: 2.0351803302764893 val_loss: 64.34165954589844\n",
      "epoch:  30300 train_loss: 2.092203378677368 val_loss: 64.48479461669922\n",
      "epoch:  30400 train_loss: 2.3782525062561035 val_loss: 66.9918212890625\n",
      "epoch:  30500 train_loss: 2.795806884765625 val_loss: 66.87434387207031\n",
      "epoch:  30600 train_loss: 2.0722227096557617 val_loss: 64.44844055175781\n",
      "epoch:  30700 train_loss: 2.8337273597717285 val_loss: 62.708587646484375\n",
      "epoch:  30800 train_loss: 2.031142473220825 val_loss: 63.88709259033203\n",
      "epoch:  30900 train_loss: 2.478015899658203 val_loss: 63.44297790527344\n",
      "epoch:  31000 train_loss: 2.0176315307617188 val_loss: 64.78720092773438\n",
      "epoch:  31100 train_loss: 3.2695469856262207 val_loss: 70.54588317871094\n",
      "epoch:  31200 train_loss: 2.1773955821990967 val_loss: 63.80214309692383\n",
      "epoch:  31300 train_loss: 2.041044235229492 val_loss: 65.32367706298828\n",
      "epoch:  31400 train_loss: 2.877275228500366 val_loss: 70.0157699584961\n",
      "epoch:  31500 train_loss: 2.3121111392974854 val_loss: 65.7330322265625\n",
      "epoch:  31600 train_loss: 2.1299819946289062 val_loss: 66.98318481445312\n",
      "epoch:  31700 train_loss: 2.1027655601501465 val_loss: 64.61351776123047\n",
      "epoch:  31800 train_loss: 2.2318665981292725 val_loss: 68.01805114746094\n",
      "epoch:  31900 train_loss: 2.3273000717163086 val_loss: 69.69602966308594\n",
      "epoch:  32000 train_loss: 3.6026744842529297 val_loss: 68.73062896728516\n",
      "epoch:  32100 train_loss: 2.565382480621338 val_loss: 65.49555969238281\n",
      "epoch:  32200 train_loss: 2.135108232498169 val_loss: 68.49954223632812\n",
      "epoch:  32300 train_loss: 3.1319258213043213 val_loss: 70.14765167236328\n",
      "epoch:  32400 train_loss: 1.9548453092575073 val_loss: 65.12772369384766\n",
      "epoch:  32500 train_loss: 2.0863046646118164 val_loss: 65.07504272460938\n",
      "epoch:  32600 train_loss: 1.8767176866531372 val_loss: 64.73612213134766\n",
      "epoch:  32700 train_loss: 2.0871171951293945 val_loss: 63.73695373535156\n",
      "epoch:  32800 train_loss: 2.2315926551818848 val_loss: 66.89203643798828\n",
      "epoch:  32900 train_loss: 2.3257253170013428 val_loss: 68.15501403808594\n",
      "epoch:  33000 train_loss: 2.122830629348755 val_loss: 66.48587799072266\n",
      "epoch:  33100 train_loss: 3.978010892868042 val_loss: 63.47084426879883\n",
      "epoch:  33200 train_loss: 1.9486808776855469 val_loss: 65.25957489013672\n",
      "epoch:  33300 train_loss: 2.664822578430176 val_loss: 69.3540267944336\n",
      "epoch:  33400 train_loss: 2.2846250534057617 val_loss: 68.66149139404297\n",
      "epoch:  33500 train_loss: 2.397555112838745 val_loss: 68.63811492919922\n",
      "epoch:  33600 train_loss: 2.0438623428344727 val_loss: 67.0345687866211\n",
      "epoch:  33700 train_loss: 2.0564422607421875 val_loss: 65.2158432006836\n",
      "epoch:  33800 train_loss: 2.737255811691284 val_loss: 70.35181427001953\n",
      "epoch:  33900 train_loss: 2.1229045391082764 val_loss: 67.40190124511719\n",
      "epoch:  34000 train_loss: 1.9737801551818848 val_loss: 64.77088928222656\n",
      "epoch:  34100 train_loss: 2.3351821899414062 val_loss: 63.263153076171875\n",
      "epoch:  34200 train_loss: 1.9847204685211182 val_loss: 68.32412719726562\n",
      "epoch:  34300 train_loss: 1.9096256494522095 val_loss: 66.25150299072266\n",
      "epoch:  34400 train_loss: 1.8896273374557495 val_loss: 64.56004333496094\n",
      "epoch:  34500 train_loss: 2.6195406913757324 val_loss: 63.448211669921875\n",
      "epoch:  34600 train_loss: 2.057504653930664 val_loss: 67.92089080810547\n",
      "epoch:  34700 train_loss: 1.9619195461273193 val_loss: 67.66938781738281\n",
      "epoch:  34800 train_loss: 2.8652617931365967 val_loss: 70.74568939208984\n",
      "epoch:  34900 train_loss: 2.0694730281829834 val_loss: 64.75231170654297\n",
      "epoch:  35000 train_loss: 2.3476808071136475 val_loss: 70.06348419189453\n",
      "epoch:  35100 train_loss: 1.9411286115646362 val_loss: 66.81836700439453\n",
      "epoch:  35200 train_loss: 2.113150119781494 val_loss: 64.6522445678711\n",
      "epoch:  35300 train_loss: 1.8907796144485474 val_loss: 67.20764923095703\n",
      "epoch:  35400 train_loss: 2.243532180786133 val_loss: 69.94017791748047\n",
      "epoch:  35500 train_loss: 1.863548755645752 val_loss: 67.82595825195312\n",
      "epoch:  35600 train_loss: 1.8513880968093872 val_loss: 65.52812957763672\n",
      "epoch:  35700 train_loss: 2.462848424911499 val_loss: 69.939208984375\n",
      "epoch:  35800 train_loss: 2.004002809524536 val_loss: 66.27344512939453\n",
      "epoch:  35900 train_loss: 2.083228349685669 val_loss: 68.56092834472656\n",
      "RMSE:  tensor(13.5534, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Ganerate the dataset\n",
    "i = 0\n",
    "sigma = 10.0\n",
    "my_dataset = []\n",
    "for ud in UDs:\n",
    "    example = []\n",
    "    for an in ANs:\n",
    "        noise = np.random.normal(0,sigma)\n",
    "        # 0 is mean\n",
    "        # sigma is the deviation of the normal distribution\n",
    "        d = compute_3d_distance(ud, an) + noise\n",
    "        example.append(d)\n",
    "    \n",
    "    # append x, y, z as col#10, #11, #12\n",
    "    example.append(ud[0])\n",
    "    example.append(ud[1])\n",
    "    example.append(ud[2])\n",
    "    \n",
    "    # append 1x13 example row into my_dataset\n",
    "    my_dataset.append(example)  # expected to be 3000x13  \n",
    "    \n",
    "# Load dataset\n",
    "exercise3_dataset = Exercise3Dataset(list_dataset = my_dataset, shuffle=True)\n",
    "\n",
    "#Split dataset by 0.8: 0.1: 0.1\n",
    "train_examples, train_labels = exercise3_dataset[:int(3000*0.8)]  # (2400, 10)   # (2400, 3)\n",
    "val_examples, val_labels = exercise3_dataset[int(3000*0.8):int(3000*0.9)]    # (300, 10)   #(300, 3)\n",
    "test_examples, test_labels = exercise3_dataset[int(3000*0.9):]     #(300, 10)   # (300, 3)\n",
    "\n",
    "###Define model, loss function and optimizer\n",
    "# if we have GPU, then use it\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define model\n",
    "model = Net(x_dim = train_examples.shape[1], y_dim = train_labels.shape[1]).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training and Validation\n",
    "\n",
    "train_examples = train_examples.to(device)\n",
    "train_labels = train_labels.to(device)\n",
    "val_examples = val_examples.to(device)\n",
    "val_labels = val_labels.to(device)\n",
    "\n",
    "# Define the model filename for model.save()\n",
    "MODEL_FILENAME = \"best.pth\"\n",
    "\n",
    "# set model to Training mode\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "NUM_OF_EPOCH = 36000\n",
    "\n",
    "for epoch in range(NUM_OF_EPOCH):\n",
    "    y_pred = model(train_examples)\n",
    "    loss = loss_fn(y_pred, train_labels).cpu()\n",
    "    #print(t, loss.item())\n",
    "    train_losses.append(loss.item())\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    # BGD\n",
    "    optimizer.step()\n",
    "    \n",
    "    # evaluate validation loss\n",
    "    val_pred = model(val_examples)\n",
    "    loss = loss_fn(val_pred, val_labels)\n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "    # check if we got better loss\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        torch.save(model.state_dict(), MODEL_FILENAME)   # save the model\n",
    "\n",
    "    if (epoch % 100) == 0:\n",
    "        print(\"epoch: \", epoch, \"train_loss:\", train_losses[-1], \"val_loss:\", val_losses[-1])\n",
    "        \n",
    "# Inference all testing examples and compute RMSE\n",
    "def square_error(a, b):\n",
    "  loss_fn = nn.MSELoss(reduction='sum')  \n",
    "  square_error= loss_fn(a, b)\n",
    "  return square_error\n",
    "\n",
    "model.eval() # inference mode\n",
    "test_examples = test_examples.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "test_preds = model(test_examples)\n",
    "#print(\"example: \", test_example.cpu())\n",
    "#print(\"========================================\")\n",
    "#print(\"ground_truth:\", test_label.cpu())\n",
    "#print(\"prediction:\", test_pred.cpu())\n",
    "#print(\"========================================\")\n",
    "\n",
    "\n",
    "total_errors = 0.0\n",
    "for idx in range(len(test_examples)):\n",
    "    total_errors += square_error(test_preds[idx], test_labels[idx])\n",
    "    \n",
    "RMSE = torch.sqrt(total_errors / len(test_examples))\n",
    "print(\"RMSE: \",  RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the RMSE by measurement noise diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6wAAAIcCAYAAADyhiOFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzde3yP9f/H8ce188xs2Bw2bM6nOW5GJIfmED8ZUSGhdPomKV/fIvVVX9LxW0IlETk3YUKoTCrmfD7lbHaIjc3svM+u3x/4fFsbRrbPxvN+u7m1va/39X6/rt2u3Pb0vj7vyzBNExEREREREZHixs7WBYiIiIiIiIjkR4FVREREREREiiUFVhERERERESmWFFhFRERERESkWFJgFRERERERkWJJgVVERERERESKJQVWERERERERKZYUWEVERERERG4zwzBGG4YRZhjGccMwTMMwTl6n7zuGYWw0DOOsYRgZhmFEGYaxwjCM9jcx3+Ar8+T3Z0o+/U9ep7/XX/oOMgxjjWEYZwzDSDcM45xhGJuuzGl/g7rsrvQ1DcNYUdDrucrhZk8QERERERGRG3obOA/sADxv0LcVsAf4FrgAVAIeAyIMw3jcNM05Nznvwb+0Hb5G30PAhHzak//yffMrdU0FzgKlge7AV0Bb4Mnr1PMPIOD6JV+bYZrmrZ4rIiIiIiIi+TAMo4ZpmsevfL0PKG2apv9NnF8aOAYkmKbZoAD9B3M5QHYwTXN9AfqfBE6aptm+oDXlM8ZK4AHAxzTNuHyOVwEOAOOAD4GVpmn+383MoUeCRUREREREbrOrYfVvnH8JSADK3uy5hmG4G4bhVMC+DoZhlLnZOa44BRiAxzWOTwWOA5NucXwFVhERERERkeLAMAwvwzAqGIbR5MrnTusDq25ymOXARSDdMIzdhmE8dp2+LYFUIMkwjETDMGYbhuFznfo8rtRY2zCMYcATwO/A0Xz69gF6AM+apmm5yWv43zgl4ZFgLy8v09/f32bzJyYm4ul5o8fORYqG7kcpTnQ/SnGi+1GKE92P8mf79+8nJyeHRo0aXbOPxWJh165d1u8Nw6B8+fJUqVIFe/vr7msEwPnz50lKSsLd3R0HBwcyMzM5e/YsGRkZlC1blho1auTqf+TIEUqXLo2LiwumaZKcnEx8fDyOjo7Uq1cPJ6e8C7QHDx4kNTXV+r27uzt+fn44OzvnuZb9+/fj4eGBn58fANu3b8fDw4NatWrlW//27dvjTdP0/mt7idh0yd/fn23bttls/vDwcHr27Gmz+UX+TPejFCe6H6U40f0oxYnuR/mzgIAALl26dN1MY7FYiIiIIDs7m1OnTjFv3jyqVq3Kxx9/jLd3nhxXIBkZGQQFBXHw4EEWL17MjRYB58+fz4ABA2jZsiXTp0/Pc3zLli1cvHiR2NhYVq5cyR9//MEHH3xAYGBgrn7PPPMMsbGxHDp0yPoPN4ZhcO+997JiRf4bBRuGcSq/dj0SLCIiIiIiYmP29vaEhITQtWtXnnnmGSIiIjh9+jQdO3YkKyvrlsZ0dnbmn//8JxaLhbVr196wf//+/fH392flypX5Hg8ODiYkJISBAweycOFCWrVqxX333cexY8esfX755RemT5/Ohx9+eFueMii0wGoYxswr7xHal8+xkfm930dEREREREQuB9gBAwawb98+NmzYcMvjXF1VjY+PL3D/gvYdNGgQqampzJo1y9o2bNgwmjRpQsuWLTl69Kj1D0BqaipHjx4t8PhQuI8EzwKmAF//udEwjKpAZ+B0Ic4tIiIiIiJSoqWlpQGXP596q44cOQJAxYoVC9T/6NGjBe6bX32nTp0iKSmJ2rVr5+kfERFB7dq1ef7555kyZUqB5ii0wGqa5gbDMPzzOfQR8C8gvLDmFhERERERKQkuXLiAm5tbnk2OUlJSmDFjBnZ2dgQHB1vbU1NTOX36NB4eHlSuXNnanpCQQPny5XONkZSUxLvvvouDgwNdunSxtp8/f55y5crlqWXq1KmcOXOG5557ztqWnZ1NUlJSnrEBJk+eDECrVq2sbV9//TWZmZl5+vbt25fAwEBeffXVa268lJ8i3XTJMIyeQLRpmrsNwyjKqUVERERERIrMnDlzOHXq8j5C586dIzMzk/HjxwPg5+fHwIEDAfj555955plneOihh6hVqxbu7u6cOHGCOXPmcObMGf79739bd9qFyxsfdejQgUGDBuV6FLdRo0a0a9eORo0aUaFCBU6ePMnMmTOJjY1lyJAhVKlSxdr366+/ZsaMGXTt2hV/f3+ys7NZv349y5Yto2bNmrz55pvWvpcuXaJKlSr06tWLgIAAKlasSFxcHMuWLWPbtm3cf//99O/f39r/wQcfvObPpFKlSvTp0+emfo6F+lqbKyusK0zTDDAMoxQQAXQ2TTPJMIyTQJBpmvk+wGwYxtPA0wDe3t6B+e1SJSIiIiIiUhy99tpr7N+/P99jDRs2ZMKECQDExsby7bffcujQIc6fP09GRgbu7u7UqlWLrl27EhQUlOvcvXv38vrrr9OhQwdefPFFa/vMmTPZt28f586dIzU1lVKlSlG7dm169OhBs2bNco1x8OBBlixZwokTJ7h48SKmaVKxYkWCg4Pp3bs3pUuXtvbNyspi7ty5HDhwgLi4OFJSUnB1daVatWq0bduWzp074+Bw43XQ0NBQgoKCGDt27LWObzdNM+iv7UUZWBsBP3H5xbQAVYAYINg0zbjrjRMUFGTqtTYil+l+lOJE96MUJ7ofpTjR/SjFSUm4Hw3DyDewFtkjwaZp7gUq/Kmgk1xnhVVERERERETuboX5WpsFwCagrmEYZwzDeLKw5hIREREREZE7T2HuEtzvBsf9C2tuERERERERKfkKbYVVRERERERE5O9QYBUREREREZFiSYFVREREREREiiUFVhERERERESmWFFhFRERERESkWFJgFRERERERkWJJgVVERERERESKJQVWERERERGRO9CyndG0eWcdL26yp80761i2M9rWJd00B1sXICIiIiIiIrfXsp3RjF6yl7QsC2AQnZjG6CV7AQht5mvb4m6CVlhFRERERKTAJk6cSN++falRowaGYeDv759vv/T0dKZPn07Pnj3x9/fH1dWVGjVq0K9fPw4ePFjg+fz9/TEM45p/nnrqqVz9s7Ky+PTTTwkMDMTT0xNPT0+aN2/OpEmTyMzMzNX3euMahsGECRMK1L906dIFvp6i8u7qQ1fC6v+kZVl4f81hG1V0a7TCKiIiIiIiBTZmzBjKlStH8+bNSUxMvGa/kydP8vTTT3Pvvffy5JNP4uPjw/Hjx/nss89YsmQJq1evpkOHDjec7+OPP+bSpUt52qdOnUpkZCQ9evTI1T548GDmz5/PQw89xNChQ7FYLHz33XeMGDGCjRs3smjRImvfOXPm5DvnuHHjOHbsWJ6xAdq2bcvTTz+dq83R0fGG11EUUjOz+eHAHyzbGU1sUnq+fWIS04q4qr9HgVVERERERArs2LFj1KhRA4CAgIB8wySAt7c3O3fupGnTprnaBwwYQLNmzRg1ahTbtm274XyhoaF52tLS0hg2bBiVK1emW7du1vaYmBjmz59PaGgoixcvtrY///zz3HfffYSFhfH5559TtmxZAB577LE8Y585c4YTJ04QFBRE48aN8xyvUaNGvufZSpYlh1+OnCN8Vwxr9/9BWpYFHw8XSjs7cCkjO09/H09XG1R56xRYRURERESkwK6G1RspX7485cuXz9PeoEEDAgIC2Ldv3y3XsHjxYpKSknjuuedwcPhfpElOTgbAx8cnV3/DMKhcuTJ2dna4uLhcd+yvvvqKnJwchg4des0+mZmZZGZm2uxR4Jwckx2nL7BsVzQr98RyITULz1KO9GruS88mPrTwL8fy3TF/+gzrZa6O9ozqUtcmNd8qBVYRERERESkyOTk5xMbGUrFixVseY8aMGRiGwZNPPpmrvWbNmtSsWZOZM2fSrFkzQkJCsFgshIeHs2TJEkaPHo2r67VXGE3T5KuvvsLNzY1+/frl22fx4sXMnTsXi8WCt7c3jzzyCOPHj8fDw+OWr6egDsclE74rmvBdMUQnpuHiaEdI/YqENvXlvjreODn8b4uiqxsrvb/mMNGJqfh6lmJUl7olasMlUGAVEREREZEi9PnnnxMbG8vrr79+S+cfPXqUDRs20K5dO2rVqpXrmIODA8uXL2fQoEG5NmNydHRk8uTJPPfcc9cde926dZw4cYLBgwdTpkyZPMeDg4Pp27cvtWrV4uLFi6xatYopU6bw888/s3HjxkJZcY1OTGP5rhjCd0VzKC4ZezuDe2t5MbJzHTo3rERp52tHutBmvoQ28yU8PJyePTve9tqKggKriIiIiIgUiY0bN/Lyyy/TpEkTxowZc0tjzJgxA9M086yuXuXq6krt2rVp0aIFHTt2JDU1ldmzZzNs2DDc3Nx4/PHHrzn2l19+CXDNsTdv3pzr+8cff5zGjRvz2muvMWnSJF577bVbuqa/SkzNZOXeWMJ3xbDlxHkAmlXz5M0HG9KtUWW83Z1vyzwlgQKriIiIiIgUuu3bt9O9e3d8fHxYuXLlDT9Lmh+LxcLs2bPx9PSkT58+eY7HxcXRokULhg4dyjvvvGNtf+yxx2jTpg3Dhg2jR48e1k2X/uz8+fMsXbqUevXqce+99xa4plGjRvHmm2+ycuXKvxVY0zIt/HjwD8J3RfPz7+fIspjU9HZjZKc69GzqS7XypW557JJMgVVERERERArVjh076NSpEx4eHkRERODre2ufo1y1ahWxsbE8//zz+QbeL774goSEBPr27Zur3c7Ojj59+hAZGcmOHTu4//7785w7b948MjIyrrm6ei2Ojo74+PgQHx9/cxcDZFty+PVoPMt3xbBmfxwpmRYqlXFhSJvqPNjEh4Y+ZTAM46bHvZMosIqIiIiISKHZsWMHISEhuLu7ExERgZ+f3y2PdfWR3Wvt4BsdHQ1cXon9q+zs7Fz//asZM2bg6Oh43UeG85Oens6ZM2do1apVgfqbpsnOqETCd0azYk8sCSmZlHFxoEcTH3o29SW4ejns7e7ukPpnCqwiIiIiIlIodu7cSadOnShdujQRERFUr179mn1TU1M5ffo0Hh4eVK5cOc/xuLg4Vq1aRfPmzfO82/WqBg0aADBr1iyCg4Ot7VlZWcyfPx8HBweaNWuW57xt27axe/duevfuTYUKFfIdOyEhId/X9Lz++utkZ2fTo0ePa14bwNGzySzbGUP47miizqfh5GBHSP0K9GzqS/u63jg72F/3/LuVAquIiIiIiBTYnDlzOHXqFADnzp0jMzOT8ePHA+Dn58fAgQMBOHXqFJ06deLChQsMHz6cjRs3snHjxlxj9erVCzc3NwC2bNlChw4dGDRoELNmzcoz7+zZs8nOzr7u+1GHDBnCpEmT+Oyzzzhz5gxdunQhNTWVuXPnsmfPHkaNGpVvIJ0xYwZw7ZVbgPHjxxMZGUmHDh2oVq0aly5dYtWqVURERNCyZUteeOGFPOfEJqXx3e4Ylu2M4UDsRewMaFPLi+Eda9M1oBLuLo7XnE8uU2AVEREREZECmzFjBj///HOutquvqGnXrp01sJ44cYKEhAQAxo0bl+9YJ06csAbWG5k5cyaurq7079//mn3KlClDZGQkb731FitXrmT16tU4OjrSsGFDvvjii3wDaVpaGgsWLKBq1ap06dLlmmO3b9+eAwcOMHv2bBISErC3t6d27dpMmDCBl19+2fqZ2qTULL7fF8uyXdFsPnEe04QmVTx44/8a8H+NK1OhzM1vNnU3U2AVEREREZECW79+fYH6tW/fHtM0CzzujfofPny4QONUqFCBKVOmMGXKlAL1d3V1JTEx8Yb9evbsSc+ePfM9lp5lYeWeWMJ3RbP+8DkyLTlU93Ljxftr07OpL9W9ChbKJS8FVhERERERkZuUbclh0/EElu28vMPvpYxsKrg7M/AeP3o29aGRr8ddv8Pv7aDAKiIiIiIiUgCmabL7TBLhu6L5bncs8ZcycHd24IGASoQ286VVjfLa4fc2U2AVERERERG5juPnLrFsVwzLd0VzMiEVJ3s7OtarQM+mPnSoVwEXR+3wW1gUWEVERERERP7ij4vpfLc7hvBdMeyNTsIw4J4a5flH+1p0CaiEh6t2+C0KCqwiIiIiIiLAxfQsVu+NI3x3NBuPJWCa0MjXg7Hd69OjiQ8VtcNvkVNgFRERERGRu1Z6loX1h8+ybGcM6w6fJTM7B7/ypXihY20ebOJDrQqlbV3iXU2BVURERERE7iqWHJPI4wmE74rm+31xJKdn41Xaif7B1Qht5kuTKtrht7hQYBURERERkTueaZrsi77Isl3RfLc7hrPJGZR2dqBLw0r0bOpD65rlcbC3s3WZ8hcKrCIiIiIicsc6GZ9C+K4YwndHc/xcCo72Bu3rViC0qS/319cOv8WdAquIiIiIiNxRzians2J3LOG7Y9gdlYhhQMvq5XiqbQ26BVTGo5R2+C0pFFhFRERERKREWbYzmvfXHCYmMQ0fT1dGdanL/fUrsGb/H4Tviua3o/HkmNCgchnGdKvH/zX2wcfT1dZlyy1QYBURERERkRJj2c5oRi/ZS1qWBYDoxDRGfrMLAIsJVcu58o/2tejZ1IfaFd1tWarcBgqsIiIiIiJSYry/5rA1rF5lMcHNyZ6vn2xJ82qe2uH3DqLAKiIiIiIiJUZMYlq+7amZFgL9yhZxNVLYFFhFRERERKTYM02TsO1nrnlcn1G9MymwioiIiIhIsXY2OZ0xS/by48Gz1PRy40xiGhnZOdbjro72jOpS14YVSmFRYBURERERkWJr5Z5Yxi7bS0qmhbHd6/NEm+os3x2TZ5fg0Ga+ti5VCoECq4iIiIiIFDuJqZm8Hr6f73bH0KSKBx8+3IRaFS7v+hvazFcB9S6hwCoiIiIiIsVKxKGzvPLtHs6nZDKyUx2ea18TB3s7W5clNqDAKiIiIiIixcKljGzGrzjAwq1R1K3ozszBLQjw9bB1WWJDCqwiIiIiImJzm44lMGrxbmIS03i2XU1e6lQbZwd7W5clNqbAKiIiIiIiNpOeZeG91YeZ+dsJ/MuXIuzZewj0K2frsqSYUGAVERERERGb2BWVyMvf7OL4uRQG3ePHKw/Uo5STIor8j+4GEREREREpUpnZOUxed4RP1x+jorszc59syb21vWxdlhRDCqwiIiIiIlJkDsVd5OVFuzkQe5GHmlfh3w82oIyLo63LkmJKgVVERERERAqdJcdk2oZjfPTD73i4OvLFwEA6N6xk67KkmFNgFRERERGRQnUiPoWR3+xix+lEujWqxPjQRpRzc7J1WVICKLCKiIiIiEihyMkxmRN5ionfH8TJ3o5JjzblwSY+GIZh69KkhFBgFRERERGR2y46MY1/Ld7Nb0cTaFfHm/f6NKZiGRdblyUljAKriIiIiIjcNqZpsnj7Gd767gAW0+TtXo3oF1xVq6pySxRYRURERETktjibnM6YJfv48eAfBFcvxwd9mlCtfClblyUlmAKriIiIiIj8bav2xvLa0r2kZFoY270+T7Spjp2dVlXl71FgFRERERGRW5aYmsm/l+8nfFcMjat48N+Hm1Crgruty5I7hAKriIiIiIjckojDZ3ll8R7Op2Tycqc6/KN9TRzs7WxdltxBFFhFREREROSmXMrIZsLKAyzYEkWdiqWZObgFAb4eti5L7kAKrCIiIiIiUmCRxxP4Z9huohPTeKZdDV7uVAdnB3tblyV3qEILrIZhzAT+DzhrmmbAlbb3gR5AJnAMGGKaZmJh1SAiIiIiIrdHepaF99ccZuZvJ6hWrhSLn72HQL9yti5L7nCF+YD5LKDrX9p+AAJM02wM/A6MLsT5RURERERuysSJE+nbty81atTAMAz8/f2v2feHH37g2WefpUWLFri4uGAYBuvXr7+p+T788EPat29P5cqVcXZ2pnLlynTo0IGlS5f+7foANm/eTEhICO7u7pQpU4auXbuya9euPP0OHz7MP//5Tzp27IinpyeGYTBu3Djr8d1RiXT/5Bdm/HqCx1r68f2LbRVWpUgUWmA1TXMDcP4vbWtN08y+8m0kUKWw5hcRERERuVljxoxh3bp11KxZk7Jly16377x585g5cyYWi4X69evf0nxbtmzB39+fl156ic8++4yRI0eSmppK7969+c9//vO36ouMjKRdu3acOHGCt956izfffJMjR47Qtm1b9u7dm6vvpk2b+O9//0tUVBSBgYHW9szsHD5ce5jen20kNdPCnCeD+U9oAKWc9MlCKRq2vNOeABbZcH4RERERkVyOHTtGjRo1AAgICODSpUvX7DthwgSmTZuGs7MzH3zwQb4rlzeyaFHeX4dHjBhBYGAg7733HmPGjMHe/n+fD72Z+oYPH46TkxMbNmzA19cXgIcffpj69eszcuRI1q5da+374IMPcv78eTw9Pdm2bRstWrQg/lIGvT79jf0xF3moeRXe6NEAD1fHm75Gkb/DJoHVMIzXgGxg3nX6PA08DeDt7U14eHgRVZc/W88v8me6H6U40f0oxYnuR7kdrq4+Jicnk5aWVqD7av/+/QD8+uuvJCUlAX/vfnRwcCAlJYUlS5bg5OR00/XFxsaydetW7r//frZt28a2bdusx4KDg/nxxx+ZNWtWvqu0vx85CsC8yFP4uibxZN0cGjufZP3ak7d8PWJ7JfXvxyIPrIZhDObyZkz3m6ZpXqufaZpfAF8ABAUFmT179iyaAvMRHh6OLecX+TPdj1Kc6H6U4kT3o9xur732GoZhFOi+OnLkCAD33nsv7du3v+n78fz581gsFuLj4wkLC2Pnzp106NCBvn373lJ9CxYsAODRRx/Nc/zs2bP89NNPeHt7071791zHTsanMGlTPAA1K5RmzSudKF/aucDXIcVTSf77sUgDq2EYXYF/Ae1M00wtyrlFRERERIqrOnXqkJCQAFxeXX3ooYf49NNPb3m8mJgYAOujwH92tS06OtralpNjMnfzKSauOkTW+cu/pndvVFlhVWyuMF9rswBoD3gZhnEG+DeXdwV2Bn4wDAMg0jTNZwurBhERERGRkmDJkiWkp6cTHR1NWFgYaWlpJCcn4+3tfUvjpaZeDp3OznkDp4uLS64+MYlp/GvxHn49Gk+7Ot70u785D0yHK7+vi9hUoQVW0zT75dM8o7DmExEREREpqe677z7r10OGDKFfv360adOGAwcO3HA34PyUKlUKgIyMjDzH0tPTAXB1dWXx9jO8uXw/FtPk7V6N6Bdcle3bt9/iVYjcfoX5HlYREREREbkFgwYNIi4ujiVLltzS+T4+PkDux36vutq25HAa/wzbTf3KZVj94n30b1lNq6pS7CiwioiIiIgUM2lpacDlzZhuRYsWLYDL71f9q8XfrwPD4EiON2O712fh062oVr7UrRcrUogUWEVERERECllSUhKHDh0iPj7e2paSkpLve1QtFgtTp04FoFWrVrc0X61atQgKCiIsLMy6AVNSahZPfrqWH1aG41W7OWtGP8jQtjWws9OqqhRfNnkPq4iIiIhIcTRnzhxOnToFwLlz58jMzGT8+PEA+Pn5MXDgQGvfPXv2sHz5cgB+++036/m//vorBw8epH379nh4eACwdOlShgwZwr///W/GjRsHXH4VTrt27ejTpw9169alXLlyREdHs2DBAg4fPsygQYNo27btLdc3adIkOnToQNu2ben6yGBW7I4lZuNSHO0Mvl8wndoV3a19k5KSmDx5MvC/HYY3bNhgHfvBBx+kcePGf/fHK3LTFFhFRERERK6YMWMGP//8c662119/HYB27drlCoQ7duywHrtq5syZ1q8nTJhgDaz5qVKlCgMHDuSXX35h6dKlJCcn4+HhQbNmzXj99dfp37//36qvdevWrFr7I0++8E8+++Bt7OwMWra6h8n/fZ/mzZvlGuPChQt5riUiIoKIiAhrrQqsYgsKrCIiIiIiV6xfv77AfQcPHszgwYPzPRYeHo6/v/91+3p5eTFlypRCq2/z8QTGbc7C6P4GE96pwUud6uDiaJ9vX39/f0zTvKlaRIqCAquIiIiIyB0kPcvC+2sOM/O3E1QrV4qwZ+4hyL+crcsSuSUKrCIiIiIid4g9ZxJ5+ZvdHD17iYGt/Hj1gXq4OetXfim5dPeKiIiIiJRwmdk5TIk4ytSIo1Rwd+brJ4K5r463rcsS+dsUWEVERERESrDDccm8/M0u9sdcpHdzX/7doyEero62LkvktlBgFREREREpgSw5JtN/Oc5/1/6Ou4sD0wYG0qVhJVuXJXJbKbCKiIiIiJQwJ+NTGBm2m+2nLtC1YSUm9AqgfGlnW5clctspsIqIiIiIlBCmaTI38hRvrzqEo73Bx480pWdTHwzDsHVpIoVCgVVEREREpASISUzjlW/38MuReO6r4827DzWisoerrcsSKVQKrCIiIiIixZhpmizZEc247/ZjyTGZ0CuA/sHVtKoqdwUFVhERERGRYmTZzmjeX3OYmMQ0Knq44OXmxL6Yi7TwL8sHfZvgV97N1iWKFBkFVhERERGRYmLZzmhGL9lLWpYFgLikdOKS0unZxIf/PtIUezutqsrdxc7WBYiIiIiIyGXvrzlsDat/tu3UBYVVuSspsIqIiIiIFANpmRaiE9PyPRZzjXaRO50eCRYRERERsaGcHJOlVz63ei0+ntoNWO5OWmEVEREREbGRTccSeHDqr4wM202FMs680LEWro72ufq4OtozqktdG1UoYltaYRURERERKWLHz11i4veH+OHAH/h4uPDxI015sIkPdnYGNb1LW3cJ9vF0ZVSXuoQ287V1ySI2ocAqIiIiIlJEzqdk8slPR5gbeQqXKyunT95bHZc/raqGNvNVQBW5QoFVRERERKSQZWRbmL3xJJPXHSUlI5t+wdUYEVIHb3dnW5cmUqwpsIqIiIiIFBLTNFm1N453Vh8k6nwa7et6M6ZbfepUdLd1aSIlggKriIiIiEgh2HH6AhNWHmT7qQvUq+TOnCeDaVvb29ZliZQoCqwiIiIiIrdR1PlUZv1ux85NG5DPPPwAACAASURBVPF2d+bdhxrRJ7Aq9naGrUsTKXEUWEVEREREboOL6VlMjTjKV7+dxMwxGN6xFs+0q4mbs37lFrlV+r9HRERERORvyLLksGDLaT7+8QgXUjPp3awKjTnJoM56d6rI36XAKiIiIiJyC0zT5KeDZ3n7+4McP5dCqxrlGNu9AQG+HoSHn7R1eSJ3BAVWEREREZGbtC86iQkrD7LpeAI1vNyY/ngQIfUrYBj6nKrI7aTAKiIiIiJSQHFJ6Xyw9jDf7jiDp6sjbz7YkP4tq+Fob2fr0kTuSAqsIiIiIiI3kJKRzbQNx5m+4TiWHJOn29bgHx1q4eHqaOvSRO5o+qcgERERkbvAxIkT6du3LzVq1MAwDPz9/a/bf/PmzYSEhODu7k6ZMmXo2rUru3btuqk5b2aMdevWERISgoeHB6VKlSIoKIivv/46375ZWVl8+umnBAYG4unpiaenJ82bN2fSpElkZmZet6bPPvsMwzAwDIP4+PgbXoMlx+SbrVF0+GA9n/x0hI71K/DTyHaM7lZfYVWkCGiFVUREROQuMGbMGMqVK0fz5s1JTEy8bt/IyEjat2+Pr68vb731FgBTpkyhbdu2bNy4kUaNGt1wvpsZY8GCBQwYMIDq1aszevRo3NzcWLJkCYMGDeLMmTOMGTMm19iDBw9m/vz5PPTQQwwdOhSLxcJ3333HiBEj2LhxI4sWLcq3ppiYGF599VVKly7NpUuXbngNvx6JZ/zKAxyKS6ZZNU8+eyyQQL+yNzxPRG4fBVYRERGRu8CxY8eoUaMGAAEBAdcNbMOHD8fJyYkNGzbg6+sLwMMPP0z9+vUZOXIka9euveF8BR0jKyuL4cOHU6FCBbZv346npycAw4YNo1u3bowbN45HH33UWntMTAzz588nNDSUxYsXW+d7/vnnue+++wgLC+Pzzz+nbNm8wfL555+nZs2aNGzYkLlz516z9iN/JPP2qoNEHD5HlbKuTOnfjO6NKmtDJREb0CPBIiIiIneBq4HvRo4ePcrWrVvp27evNWgC+Pr60rdvX3788Ufi4uJu2xj79u0jPj6e0NBQa1gFMAyDxx9/nKysLObNm2dtT05OBsDHxyfXnIZhULlyZezs7HBxcclT09KlS1m+fDmff/459vb2+dYdfymD15bupeukX9h26gKjH6jHjy+34/8a+yisitiIAquIiIiIWG3duhWAe+65J8+xVq1aYZom27dvv21jZGRkAFCqVKk8fa+2RUZGWttq1qxJzZo1mTlzJl9++SUnT57k2LFj/Pe//2XJkiWMHj0aV1fXXONcvHiRYcOG8cwzzxAcHJxnnvQsC5+uP0r799ezcGsUj7Wsxs+jOvBMu5q4OOYfbkWkaOiRYBERERGxiomJAci1MnrV1bbo6OjbNkbdunWxt7dn/fr1mKaZayUzIiICgKioKGubg4MDy5cvZ9CgQTz11FPWdkdHRyZPnsxzzz2XZ85XXnmFnJwcJk6cmKs9J8ckfFc0760+THRiGiH1KzK6Wz1qepe+7vWJSNFRYBURERERq9TUVACcnZ3zHLv6qO3VPrdjjLJly/LEE08wffp0Bg8ezMsvv2zddGn69On5zufq6krt2rVp0aIFHTt2JDU1ldmzZzNs2DDc3Nx4/PHHrX1/++03pk2bxrx58/Dw8Mg1zuMzN3Mo0aChTxne79uY1jW9rntdIlL0FFhFRERExOrqY7hXH9X9s/T09Fx9btcYn3zyCYZhMHPmTOurbLy9vfnyyy/p378/ZcqUsfaNi4ujRYsWDB06lHfeecfa/thjj9GmTRuGDRtGjx49KFu2LJmZmTz99NOEhITQr18/AE4lpLDpWAIA55Iz+aBvML2b+WJnp8+oihRH+gyriIiIiFhd3cwov8d+r7bl96jv3xnDxcWFadOmcfbsWX799Ve2bNnCmTNnaNKkCQD16tWz9v3iiy9ISEigb9++uca1s7OjT58+JCcns2PHDgCmTp3KoUOHePnll9m59yAjvvie+8YuIDb+AgAfd/ehedlMhVWRYkwrrCIiIiJi1aJFCwA2bdrE0KFDcx2LjIzEMAwCAwMLZYyyZcvSpk0b6/erVq0CoFu3bta2q4HXYrHkOT87OzvXf0+dOkVOTg4PPPBAvnXe1+Ye3NzcCvROVhGxDa2wioiIiIhVrVq1CAoKIiwszLp5ElzeSCksLIyOHTtSqVIla3t8fDyHDh0iKSnplsfIz4kTJ3j33XepU6dOrtXUBg0aADBr1qxc/bOyspg/fz4ODg40a9YM0zSp07YHDR77N149X6Xts2/z0RezCQsLo3379gDMnDnzuu9jFRHb0wqriIiIyF1gzpw5nDp1CoBz586RmZnJ+PHjAfDz82PgwIHWvpMmTaJDhw60bduWF154AYDJkyeTk5PDhx9+mGvcKVOm8Oabb/LVV18xePDgWxpj2rRprFixgrZt2+Ll5cWhQ4eYPn06Dg4OhIWF5dq8aciQIUyaNInPPvuMM2fO0KVLF1JTU5k7dy579uxh1KhRxGU6MWxaJFtOplO7WQemdK9P+zre1h2IV6xYAUCPHj3w8tJGSyLFmQKriIiIyF1gxowZ/Pzzz7naXn/9dQDatWuXK7C2bt2a9evXM3bsWMaOHYthGLRu3ZqwsDDr50pv5GbGaNCgAQsXLuT999/n4sWLVKpUiX79+jF27Fjr52GvKlOmDJGRkbz11lusXLmS1atX4+joSMOGDXn34ylEV7iHB6f8hldpJyb0CuCRoKo42OuhQpGSyjBN09Y13FBQUJC5bds2m80fHh5Oz549bTa/yJ/pfpTiRPejFCe6H+9elzKy+Wz9Ub785QQAT95bnefa18TdxdFmNel+lOKkJNyPhmFsN00z6K/tWmEVERERkRIp25LDom1RfPTD78RfyiS0qQ+jutbD19PV1qWJyG2iwCoiIiIiJc76w2d5e9VBfv/jEsH+5ZgxqD5NqnrauiwRuc0UWEVERESkxDgUd5EJKw/yy5F4/MuX4vPHmtOlYSXrhkoicmdRYBURERGRYu9scjr/Xfs732yLwt3Fkdf/rwEDW/nh5KANlUTuZAqsIiIiIlJspWVamP7LcT7/+RhZlhyGtKnOCx1r4VnKydaliUgRUGAVERERkWInJ8dk6c5o3l9zmLiL6XRtWIlXH6iHv5ebrUsTkSKkwCoiIiIixcqmYwlMWHWAfdEXaVLFg0/6NSO4ejlblyUiNqDAKiIiIiLFwrFzl5i46hA/HvwDX09XJj3alB6NfbCz04ZKIncrBVYRERERsanzKZl88tMR5kaewsXRnn91rcsTbarj4mhv69JExMYUWEVERESkSCy78pnUmMQ0fDxdeSmkNudTM5m87igpGdn0C67GS53q4FXa2dalikgxocAqIiIiIoVu2c5oRi/ZS1qWBYDoxDRGLd6DCXSo682YbvWpXdHdtkWKSLGjwCoiIiIihe79NYetYfUqEyjv5sRXQ4JtU5SIFHuF9qZlwzBmGoZx1jCMfX9qK2cYxg+GYRy58t+yhTW/iIiIiBQPiamZRCem5XvsfEpmEVcjIiVJoQVWYBbQ9S9trwI/maZZG/jpyvciIiIicocxTZNNxxIYsXAnwW//dM1+Pp6uRViViJQ0hfZIsGmaGwzD8P9Lc0+g/ZWvZwPrgVcKqwYRERERKVrnkjP4dscZFm2N4kR8Cu4uDjzaoioVyjgzdd2xXI8FuzraM6pLXRtWKyLFXWGusOanommasVe+jgMqFvH8IiIicpf4448/ePbZZ6latSpOTk5Uq1aNF198kcTExBuee+HCBSZNmkTnzp2pWrUqrq6u1K1bl6effpqoqKgbnr9nzx4cHR0xDIPFixfn2yc7O5tPPvmE5s2b4+bmhoeHB82bN2fatGl5+q5bt46QkBA8PDwoVaoUQUFBfP311zf+IRQRS45JxOGzPDtnO/dM/Il3vj+Ed2lnPuzbhC1jQnirZwDDOtRmYu9G+Hq6YgC+nq5M7N2I0Ga+ti5fRIoxwzTNwhv88grrCtM0A658n2iapuefjl8wTTPfz7EahvE08DSAt7d34PTp0wutThEREbmzJCYmMmrUKC5cuEDnzp3x8/Pj1KlTrF27lqpVq/LOO+/g7HztV6fs2LGD8ePH07hxYxo3boy7uzunT59mzZo1ODg48O6771K1atV8z83JyeGVV14hKiqK9PR0/vWvf9G6detcfbKysnj77bfZu3cv7dq1o06dOlgsFmJjY3FycmLgwIHWvhs2bOCjjz6iQoUKdO7cGWdnZyIjI9m3bx8DBgygb9++t+eHdgvOZ8Dmswabz9pxIdPAzcGkpbdJq4o5VNSTviJyE0JDQ7ebphmU54BpmoX2B/AH9v3p+8NA5StfVwYOF2ScwMBA05aWLVtm0/lF/kz3oxQnuh+lOPnz/fjiiy+agDl//vxcfebPn28C5n/+85/rjnXixAnz6NGjedp/+OEHEzAfeuiha5778ccfm25ubuabb75pAmZYWFiePmPHjjXt7e3NdevWXbeOzMxM08vLy6xYsaJ54cIFa3tOTo7ZtWtX09HR0Tx27Nh1x7jdMrMt5vd7Y81BMzeb/q+uMP1fXWE+9mWkuWJ3jJmRZSnSWooz/f0oxUlJuB+BbWY+WbCoHwleDgy68vUgILyI5xcREZG7QEREBK6urjz66KO52h955BFcXFz46quvrnu+v78/NWvWzNMeEhJCuXLl2LdvXz5nQVRUFGPHjmXcuHFUq1Yt3z4pKSlMmjSJnj170qFDB0zTJDk5Od+++/btIz4+ntDQUDw9rQ+pYRgGjz/+OFlZWcybN++613K7nIhP4Z3vD3HPxHU8O3c7B2MvMqxDLTaM6sCcJ1vSvXFlnByK+ldLEbnTFeZrbRYAm4C6hmGcMQzjSeAdoJNhGEeAkCvfi4iIiNxWGRkZuLi4YBhGrnY7OztcXV05fvw48fHxNz1uUlISycnJVKyY/zYczz33HDVq1GDEiBHXHOOXX34hOTmZwMBAXnzxRcqUKUOZMmXw9vZmzJgxZGdn57oOgFKlSuUZ52pbZGTkTV9HQaVnWQjfFc2jX2yiwwfrmf7LcZpV82TGoCB+e6UjIzvXpWq5vLWJiNwuhblLcL9rHLq/sOYUERERAWjYsCGHDx9m165dNG3a1Nq+a9cuLly4AMDp06fx8vK6qXEnTJhAVlYWgwYNynNs0aJFrFq1it9++w0Hh2v/inX48GEAPv74Y5ycnHjvvfcoX7488+bNY+LEiURHRzN79mwA6tati729PevXr8c0zVwBPCIiAqBAm0DdrMNxySzYcpqlO6NJSsuiajlXRnWpS5/AKlQs43Lb5xMRuZZCC6wiIiIitjJixAiWLVvGww8/zMcff0xAQAD79+9nxIgRODo6kpWVRWpq6k2NuXjxYj744AO6du3KkCFDch27cOECL774Ik899RT33HPPdce5+vjv+fPn2b9/P3XrXn6ty8MPP0yHDh34+uuvefXVV6lfvz5ly5bliSeeYPr06QwePJiXX34ZNzc3lixZwtUNKW/2Oq4lJSObFXtiWLAlil1RiTjZ29EloBKPtqjKPTXKY2dn3HgQEZHbTIFVRERE7jht27Zl4cKFDB8+nO7duwNgb2/P0KFDadiwIUuXLqVMmTIFHm/VqlUMGDCAwMBAFi1alOdR41GjRmGaJu+8c+NPO7m6Xt4+t1WrVtawetXjjz/O+vXrWb9+PfXr1wfgk08+wTAMZs6caX2Vjbe3N19++SX9+/e/qev4K9M02X0miUVbT7N8VwwpmRZqVSjN2O716d28CuXcnG55bBGR20GBVURERO5Iffv2pXfv3uzdu5fk5GTq1q1LhQoVCA4OxsHBgVq1ahVonNWrV9O7d28aNmzI2rVr8wTEHTt2MHPmTN58800SEhJISEgA4OzZswDExcVx9OhRqlatirOzM1WqVAGgUqVKeeaqXLkygPWxZQAXFxemTZvGO++8w4EDB3BycqJJkyYcPXoUgHr16t3kTwaSUrNYtiuaBVtOcyguGVdHe/6vcWUeDa5K82pl8wRyERFbUWAVERGRO5a9vX2uz7DGxcWxc+dO2rVrl+9GRn+1evVqQkNDqVevHj/++CNly+Z9ffzp06cxTZM33niDN954I8/xF154AYCtW7cSFBREcHAwAGfOnMnT92pbhQoV8hwrW7Ysbdq0sX6/atUqALp163bD64DLq6lbTpxn4dYoVu2NJSM7h0a+HowPDeDBpj6UcXEs0DgiIkVJgVVERETuCjk5OQwfPhyLxcJrr71mbY+NjSUpKYlq1arlCrFr166lV69e1K1bl59++oly5crlO25wcDBhYWF52tevX8/UqVMZOXIkrVq1sr4mp3r16rRp04aNGzeyY8cOmjdvDoDFYmH69Ok4ODjQuXPn617LiRMnePfdd6lTpw59+/a9bt/4Sxl8u/0Mi7ZGcTw+BXdnB/oGVeHRFtUI8PW47rkiIramwCoiIiJ3nEuXLhEcHEyvXr2oXr06SUlJLFiwgO3btzNhwgQ6dOhg7Tt69Ghmz55NREQE7du3B2Dbtm307NkT0zQZMmQI33//fZ45HnvsMQB8fHzo06dPvjXA5c+q/vX45MmTadu2LSEhIQwfPpzy5cuzaNEitmzZwhtvvJHrHa7Tpk1jxYoVtG3bFi8vLw4dOmQNtmFhYTg7O+eZ25Jj8uvReBZuOc0PB/4gO8ekhX9Z/tGhFt0bVcbVyf7mf6giIjagwCoiIiJ3nKuf85w/fz6xsbGUKlWKFi1asHr1arp06XLD8/ft20d6ejoAL730Ur59rgbWW9GsWTM2btzI2LFj+fjjj0lPT6d+/fp89dVXDB48OFffBg0asHDhQt5//30uXrxIpUqV6NevH2PHjsXHxydX39ikNL7ZeoZvtkURnZhG2VKODG7tz6PBValVwf2W6xURsRUFVhEREbnjODk5sWDBggL1nTVrFrNmzcrVNnjw4DzB8WbdaIzGjRuzfPnyG47Ttm1b6ztX85NlyWHdobMs3HKan38/R44J99byYnS3enRqUBFnB62mikjJpcAqIiIiUgKdSkhh4dYoFm8/w7nkDCqWceYf7WvxSIuqVC134w2lRERKAgVWERERkRIiPcvCmv1xLNwSxabjCdgZ0LFeBR5tUY32db1xsLezdYkiIreVAquIiIhIMff7H8ks2HKapTujSUzNomo5V/7ZuQ59AqtSycPF1uWJiBQaBVYRERGRYig1M5sVu2NZsPU0O08n4mhv0LlhJfq1qEbrmuWxszNsXaKISKFTYBUREREpJkzTZG90Egu2RPHd7hguZWRT09uNsd3r07t5Fcq5Odm6RBGRIqXAKiIiImJjSWlZhO+KZuGWKA7EXsTF0Y7ujXzoF1yVQL+yGIZWU0Xk7qTAKiIiImIDpmmy9eQFFm45zcq9sWRk59DQpwz/CQ2gZ1Mfyrg42rpEERGbU2AVERERKUIJlzL4dscZFm6N4vi5FEo7O9AnsAr9gqsR4Oth6/JERIoVBVYRERGRQpaTY/Lr0XgWbY1i7YE4siwmQX5lea5PTbo3rkwpJ/1KJiKSH/3tKCIiIvI3LdsZzftrDhOTmIaPpyujutQltJkvsUlphG07w6KtUUQnplG2lCOP3+PPoy2qUruiu63LFhEp9hRYRURERP6GZTujGb1kL2lZFgCiE9P41+LdfLHhGIfikskxoU2t8rz6QD06N6yIs4O9jSsWESk5FFhFRERE/ob31xy2htWrMi0mh+KSea59TR4Jqka18qVsVJ2ISMmmwCoiIiJyiyw5JtGJafkeM00Y1aVeEVckInJnUWAVERERuUlnL6azcGsUC7ecvmYfH0/XIqxIROTOpMAqIiIiUgCmabLpWAJzN59i7f4/yM4xaVvbiy4BlViw5TTpWTnWvq6O9ozqUteG1YqI3BkUWEVERESuIzE1k8XbzzB/82mOx6fgWcqRJ+6tTr/galT3cgOgSRXPfHcJFhGRv8fO1gWIiIjIzbl06RJvv/02jRo1wt3dHS8vL1q3bs2sWbMwTfO65549e5YhQ4bQuHFjypUrh4uLC7Vq1eLJJ5/k6NGj1zxv06ZN9OzZEy8vL1xcXKhevTr9+vUjMzMzV7+cnBw++ugj6tWrh4uLC1WrVmXkyJGkpKTk6nfhwgUmTZpE586dqVq1Kq6urtStW5enn36aqKioW//h3CamabLz9AX+Gbablm//xPiVB/Es5ch/H25C5Oj7GdOtvjWsAoQ28+W3Vzty4p3u/PZqR4VVEZHbRCusIiIiJUhOTg4PPPAAGzduZNCgQbzwwgukpqayYMEChgwZwsGDB3n33Xevef6FCxf4/fff6dy5M35+fri6unLkyBFmzpxJWFgYkZGRNGjQINc5X331FUOHDqVly5aMHj0aT09PYmJi+OWXX8jOzsbJycna96WXXuKTTz6hV69ejBw5koMHD/LJJ5+wc+dOfvzxR+zsLv9b+ebNmxk5ciT3338/w4YNw8vLi3379jFt2jS++eYbNm7cmKeOopCamU34rhjmRp5if8xF3Jzs6RNYhQEt/WjgU6bI6xERudspsIqIiJQgmzdv5tdff2XEiBF89NFH1vZ//OMf1KtXj2nTpl03sNatW5fffvstT3ufPn0IDg5mypQpfPrpp9b2AwcO8OyzzzJkyBCmT5+OYRjXHHv//v1MnjyZ3r178+2331rbq1evzvDhw1m4cCH9+/cHoF69ehw+fJiaNWvmGqN79+506tSJN954g8WLF9/4B3Kb/P5HMnMjT7F0RzTJGdnUq+TOf0IDCG3qg7uLY5HVISIiuSmwioiIlCAXL14EwMfHJ1e7k5MTXl5eZGRk3NK4fn5+wOUV2D/74IMPME2T9957D8MwSElJwdnZGQeHvL9CLFiwANM0GTFiRK72p556ildffZW5c+daA6u/v3++dYSEhFCuXDn27dt3S9dxMzKyLazeF8e8yNNsOXkeJ3s7ujeuzICW1Qj0K3vdcC4iIkVDgVVERKQECQ4OxtPTk/feew9/f39atmxJamoqs2fPZvv27Xz++ecFGicrK4ukpCSysrI4evQo48aNA6Bbt265+n3//ffUq1ePn3/+mVGjRnHs2DEcHR0JCQlh0qRJ1K5d29p369at2NnZERwcnGsMFxcXmjZtytatW29YV1JSEsnJyQQEBBToOm5F1PlU5m85zTdbo0hIycSvfClGP1CPvkFVKefmdOMBRESkyCiwioiIlCBly5Zl+fLlDB06lIcfftja7u7uzrfffktoaGiBxlmzZg09evSwfl+xYkU+/PBDBg4caG1LSkoiLi6OzMxMHn74YYYNG8Z9993Hnj17mDhxIvfeey+7d++mUqVKAMTExODl5YWzs3Oe+Xx9fdm4cSOZmZm5PvP6VxMmTCArK4tBgwYV6DoKypJjEnHoLHM3n+Ln389hACH1K/JYKz/ureWFnZ1WU0VEiiMFVhERkRKmdOnSBAQE8OCDD9K6dWvOnz/P1KlT6d+/P+Hh4XTq1OmGY7Rq1YoffviBtLQ0Dhw4wMKFC7lw4QLZ2dnWx32Tk5MBOH/+PK+99hrjx48HoFevXvj5+TFkyBA++ugj62dmU1NT8w2rcHmV9WqfawXWxYsX88EHH9C1a1eGDBlycz+UazibnM6iLVEs2HKamKR0Krg780LH2vQLrkplD9fbMoeIiBQeBVYREZESZO/evbRu3ZqPPvqIZ5991trer18/AgICeOqppzh27Bj29vbXHcfLy4uQkBAAevTowcCBA2ncuDFnz55l2rRpALi6/i/QDR48ONf5AwYMYOjQoaxfv97aVqpUKc6ePZvvfOnp6dY++Vm1ahUDBgwgMDDw/9m77/gaz/+P4687kciwiREjVqyoPYKvotJSalSNWiUtqlWjtFr9qhrVX1tatLRqU7RaVbTULKrD3iuomWGVhMhOrt8fkXyliSRGckLez8fjPJxz3dd9359zHgd557rv62LJkiX3df+oMYa/Tv3Dom3nWHv4AjFxhv+UL8SoNlVoXrkIDvZa1U9E5GGhf7FFREQeIpMmTSIiIoJOnTolaXdxcaF169acPXuWM2fO3PVx3d3d8fHxYfbs2YkTNxUoUCAxYCZc9pvAwcGBQoUKJZmkyd3dnStXrqQ48VNAQACFChVKcXR1zZo1dOjQAS8vL9atW0eePPe2fExYDMz+/TTNP91Ct5nb+f3kFXo3LM2vw5qwsE99WlYtprAqIvKQ0b/aIiIiD5GAgAAAYmNjk22LiYlJ8ufdCg8PJzY2NnEmYsuyqFOnDgD+/v5J+kZGRnL58mUKFy6c2Fa3bl3i4uLYsWNHkr4RERHs27cv8Vi3W7NmDe3bt6dSpUps2LCB/Pnz33Xd+88H8+b3+xm1255xPx8hr7MDn3SqzvZ3mjPymSqUdct118cUEZGsQYFVRETkIVKlShUA5s2bl6Q9ODiYFStWkD9/fsqXLw/AuXPnOHbsGNHR0Yn9Ll68mOJxjxw5wsaNGylXrhxubm6J7QmTMH355ZdJ+s+YMYO4uLgkswp36dIFy7KYPHlykr4zZ84kLCyM7t27J2lft24dzz77LBUrVmTjxo0UKFAgPR8BAGFRMXy74xxtPv+ddtP+YNXBIOoWMqwa9B9+fLURz9UugZND6pdFi4hI1qd7WEVERB4iQ4YMYcGCBbz99tscPHiQRo0acfXqVWbOnElQUBDTpk1LvH/1hRdeYMuWLZw+fTpx3dP/+7//Y/369bRu3ZrSpUtjjOHQoUN8/fXXREdHM23atCTn8/X1ZcGCBXz22WdcuXKFxo0bc/DgQb766iu8vLwYNGhQYt/HHnuMAQMGMHXqVDp06ECrVq04evQon332GU2aNElcgxVg165dtGvXDmMMvr6+/PLLL8nea48ePZK1nbh4taeRUAAAIABJREFUg0Xbz/HDHn9uRMRQsUhuxrXzon3N4vy6djVe7nkfxMcsIiJZhAKriIjIQ8TDw4MdO3YwduxYNm7cyLfffouzszM1atTgk08+oUOHDqnu/8wzz+Dv7893333HpUuXiI2NpXjx4nTq1Ik33ngDLy+vJP3t7e355ZdfGDduHN9++y3ff/89bm5u9O/fn3HjxpErV9LLbSdPnkzp0qWZMWMGq1atolChQgwcOJCxY8diZ/e/C7sOHTqUOBHT66+/nmKtCYE1KiaONYcvsHDbWXacvoqjvR1PP1aUHt4e1PHIf18TNImISNamwCoiIvKQKVeuHPPnz0+z3+0z+Cbw8fFJnB04vVxdXfnwww/58MMP0+xrb2/PsGHDGDZsWKr9evfunWzm4X87fzWMb3ac47td57kSGkXJAs68/XQlOtUuQcFcKS+fIyIijxYFVhEREckyYuMMm/0usXDbWTYfv4wFPFGpCD28S/G4pxt2dhpNFRHJThRYRURExOYu3Yjgu53n+WbHeQKCw3HLnZOBzcrzfL1SuOdzTvsAIiLySFJgFREREZswxrDt1FUWbj/L2kMXiIkzNCxXkP+2rsyTVYpozVQREVFgFRERkcwVEh7ND7v9WbT9LH9fvkleZwd6NSxNt/qlKKc1U0VE5DYKrCIiIpIpDvgHs3DbWVbuDyQiOo7qJfMxoWM12lR315qpIiKSIgVWERERyTDhUbGs3B/Aou3nOOAfgrODPc/WLE73+h5ULa41U0VEJHUKrCIiIvLAnbx0g4XbzvHDHn9uRMTgWTgXY9p68Wyt4uRxcrB1eSIi8pBQYBUREZEHIiomjrWHL7Bo+1m2nbqKg73F01WL0cPbg7ql82NZWpJGRETujgKriIiI3Bf/a2F8s+McS3b6cyU0khL5nRnesiKd65SkUK6cti5PREQeYgqsIiIictdi4wxbjl9i4bZzbPK7hAU8Uakw3b09aOLphp2dRlNFROT+KbCKiIjIHS3fG8CEtX4EBofjns+Zl5uU5UZEDIu3nyMgOJxCuXIyoGl5utYvRfF8zrYuV0REHjEKrCIiIpKi5XsDGLHsIOHRsQAEBIczasVhABqULcg7rSrzlFcRHOztbFmmiIg8whRYRUREJEUT1volhtXbFc6dk2/6edugIhERyW70K1ERERFJUWBweIrtl29EZnIlIiKSXSmwioiISDLGGFxzpnwhlrvuVRURkUyiwCoiIiLJTP31JKGRMdj/a7ZfZwd73mxR0UZViYhIdpOue1gty6oDNAbcgXDgELDeGHMtA2sTERERG5i19RSfrD9Oh5rFaVy+EBPXH0+cJfjNFhVpX7O4rUsUEZFsItXAalmWLzAQOA3sBvwAJ+A/wFuWZR0C3jXGnMvoQkVERCTjfbPjHO+vOsrTVYvyccdq5LC349naJWxdloiIZFNpjbC6AI2MMSnOumBZVg3AE1BgFRERecit2BfAOz8epGlFN6Y8X5McWq5GRERsLNXAaoyZlsb2fQ+2HBEREbGFtYcvMPS7/dQvU4DpPWrjmENhVUREbC+997CWIf7S4NK372OMaZsxZYmIiEhm+e34ZQYu3stjxfMyq1ddnBzsbV2SiIgIkM7ACiwHZgM/AXEZV46IiIhkph2nr9Lv612UK5yL+b71yHWHpWxERERsIb3/K0UYYz57UCe1LOt1oA9ggIOArzEm4kEdX0RERNK2/3wwL87biXs+Z75+qR55XRxsXZKIiEgS6b1BZYplWe9ZltXAsqxaCY97OaFlWcWBQUAdY0xVwB54/l6OJSIiIvfm2IXrvDBnB/ldHVjcx5tCuXLauiQREZFk0jvC+hjQE3iC/10SbG69vtfzOluWFU38TMSB93gcERERuUunLofSY9YOnBzsWNzHm6J5nWxdkoiISIosY0zanSzrJFDFGBP1QE5qWYOB8UA4sM4Y0z2FPv2AfgBubm61Z86c+SBOLSIikq1djYQph+yJiYNBVWMp4mzrikRERKB9+/a7jTF1/t2e3hHWQ0A+4NL9FmJZVn6gHVAGCAa+tyyrhzFm4e39jDEzgBkAderUMe3atbvfU9+zFStWYMvzi9xO30fJSvR9fLhcuh5Bp6/+Is4uiiX9vfFyz2vrkh4ofR8lK9H3UbKSh/n7mN7Amg84ZlnWTiAyofEel7XxAU4bYy4DWJa1DGgILEx1LxEREblnV29G0X3Wdi7fiGRhn/qPXFgVEZFHU3oD63sP8JznAG/LslyIvyS4ObDrAR5fREREbnM9IpoX5mzn3NUw5vnWo1ap/LYuSUREJF1SDayWZVkm3pa0+qT3hMaY7ZZlLQX2ADHAXm5d+isiIiIPVlhUDL5zd+J34QYzetahQbmCti5JREQk3dJa1maTZVkDLcsqdXujZVmOlmU9YVnWfKDX3Z7UGPOeMaaSMaaqMaanMSYy7b1ERETkbkREx9J3wS72nrvGZ8/XpFmlwrYuSURE5K6kdUlwS+BF4BvLshImSXImPuiuAyYbY/ZmbIkiIiJyt6Jj43ht8R7+OPkPn3SqztOPFbN1SSIiInct1cBqjIkAvgC+sCzLASgEhBtjgjOjOBEREbl7sXGG15fsY8PRS4xrX5XnapewdUkiIiL3JNVLgi3LeuK2lyWMMUEJYdWyrA4ZWpmIiIjctbg4w9s/HODnA0GMeLoSPb09bF2SiIjIPUvrHtaJtz3/4V/bRj7gWkREROQ+GGMY+/MRvt/tz6DmnrzcpJytSxIREbkvaQVW6w7PU3otIiIiNjRxnR/z/jxDn/+U4XUfT1uXIyIict/SCqzmDs9Tei0iIiI2Mm3TSaZt+puu9Urx39aVsSz9XllERB5+ac0SXNayrJXEj6YmPOfW6zIZWpmIiIiky9w/TjNhrR/ta7jzfvuqCqsiIvLISCuwtrvt+cR/bfv3axEREclk3+08z5ifjtDCqwgTO1XH3k5hVUREHh1pLWuz5fbXt5a2qQoEGGMuZWRhIiIikrqV+wN5a9kBHq/gxmdda5LDPq07fURERB4uaS1rM92yLK9bz/MC+4EFwF7LsrpmQn0iIiKSgg1HLjJ0yT7qehTgqx61yZnD3tYliYiIPHBp/Sq2sTHm8K3nvsBxY8xjQG1geIZWJiIiIin6/cQVXl28By/3PMzuXQdnR4VVERF5NKUVWKNue/4ksBzAGHMhwyoSERGRO9p15ip9F+yibCFX5r9Yj9xODrYuSUREJMOkFViDLct6xrKsmkAjYA2AZVk5AOeMLk5ERET+51BACL5zd1IsrxNfv1SffC6Oti5JREQkQ6U1S/DLwGdAUWDIbSOrzYFVGVmYiIiI/M/xizfoOXs7eZwdWNinPm65c9q6JBERkQyX1izBx4GWKbSvBdZmVFEiIiLyP2eu3KT7rO042NuxuG993PPpIicREckeUg2slmV9ltp2Y8ygB1uOiIiI3C4gOJzus7YTExvHdy83wKOgq61LEhERyTRpXRLcHzgEfAcEAlqNXEREJJNcuhFBj1nbuR4ezTf9vPEsktvWJYmIiGSqtAJrMaAT0AWIAZYAS40xwRldmIiISHZ27WYUPWft4EJIBAv71KNq8by2LklERCTTpTpLsDHmH2PMdGNMM+LXYc0HHLEsq2emVCciIpIN3YiIptfcHZz+5yazetWhtkcBW5ckIiJiE2mNsAJgWVYtoCvxa7H+AuzOyKJERESyq7CoGF6ct5Mjgdf5qmdtGpUvZOuSREREbCatSZfGAq2Bo8C3wAhjTExmFCYiIpLdRMbE8vLXu9l99hpTnq9J88pFbF2SiIiITaU1wjoSOA1Uv/X4wLIsiJ98yRhjqmVseSIiItlDdGwcry3ey9YTV/i4YzXaVHe3dUkiIiI2l1ZgLZMpVYiIiGRjsXGGN77fz/ojFxnT1ovOdUrauiQREZEsIdXAaow5m1K7ZVl2xN/TmuJ2ERERSR9jDP/98SAr9gUyvGVFejUsbeuSREREsoxUZwm2LCuPZVkjLMuaalnWU1a8gcApoHPmlCgiIvJoMsYw7uejfLvzPK81K8+rTcvbuiQREZEsJa1Lgr8GrgF/AX2Ad4i/f7W9MWZfBtcmIiLySJu0/jhz/jhN74alGfZUBVuXIyIikuWkFVjLGmMeA7AsaxYQBJQyxkRkeGUiIiKPsOlb/uazX0/SpU5JRj1ThVuTGoqIiMhtUr0kGIhOeGKMiQX8FVZFRETuz9d/neHDX47Rpro7H3R4DDs7hVUREZGUpDXCWt2yrOu3nluA863XCcva5MnQ6kRERB4xS3f78+6Kw/hULsKnnatjr7AqIiJyR2nNEmyfWYWIiIg86lYfDGL40v38p3whpnariYN9Whc6iYiIZG/6n1JERCQT/HrsIoO+2UutUvmZ8UJtnBz0O2EREZG0KLCKiIhksD//vkL/hXuoXCwPc3zr4uKY1h05IiIiAgqsIiIiGWr32Wv0mb+L0gVdmP9iPfI4Odi6JBERkYeGAquIiDwUrl69yhtvvEH58uVxcnLCzc2NZs2asXXr1nTtv2DBAmrWrImzszNFihShT58+XL58OcW+v/zyC82bN6do0aK4urpSsWJF3njjDS5evJjqOQ4cOICDgwOWZbF06VIOBYTQe+4OCufOycKX6lPA1fGu37eIiEh2lq5rkizL6gB8BBQmfoZgzRIsIiKZ5uzZszRt2pTQ0FBeeuklKlSoQEhICAcOHCAgICDN/SdNmsTQoUNp0qQJU6ZMwd/fn08//ZS//vqLHTt24Orqmth35syZ9OvXj9q1a/PWW2/h6urKzp07mTx5MsuWLePgwYNJ+ieIi4ujb9++ODk5ERoaSlBIOB/M2UHunDlY2Kc+hfM4PdDPREREJDtI7000HwNtjDFHM7IYERGRlPTo0YOYmBgOHDhAsWLF7mrfK1euMHLkSOrWrcvGjRuxt4+f7Khu3bq0bduWKVOm8M477yT2nzhxIsWKFeP333/HySk+ZPbr148iRYowfvx41q9fT/v27ZOd5/PPP+fw4cMMHz6c9957j882niBvlWIs6utNifwu9/HuRUREsq/0XhJ8UWFVRERs4bfffuP3339n+PDhFCtWjOjoaMLCwtK9//LlywkLC2PgwIGJYRWgTZs2lC1bloULFybpf/36dfLnz58YVhO4u7sDpDi6ev78eUaOHMno0aPJU6goANGxhkV96lOmUPL+IiIikj7pDay7LMtaYllWV8uyOiQ8MrQyERERYPXq1QCUKlWKNm3a4OzsjKurKxUqVEgWNlOyc+dOABo0aJBsm7e3N8eOHSM0NDSxrUWLFhw5coRhw4Zx9OhRzp8/z7Jlyxg3bhxNmjThiSeeSHacV155hbJly9Kjzyt89dspAAY+UZ6KRXPf03sWERGReOm9JDgPEAY8dVubAZY98IpERERu4+fnB0Dfvn3x9PRk/vz5REVF8cknn9CzZ0+io6Px9fW94/6BgYEAFC9ePNm24sWLY4whMDCQChUqADBlyhTCwsKYMmUKn376aWJfX19fvvrqqySjtABLlixh9erVrNm4md7zdhMcFgWAR0GNrIqIiNyvdAVWY8ydfxIQERHJQDdu3AAgd+7cbNq0CUfH+Jl227dvT9myZXnnnXfo1asXdnYpXzSUcPlwzpw5k21LuOz39kuMHRwcKFWqFM8++yxt2rTBxcWFtWvXMmfOHOzt7Zk5c2Zi32vXrjF48GB6v/gS047Yc+rydXwbleH/fnow711ERCS7S+8swSWAz4FGt5q2AoONMf4ZVZiIiAiAs7MzAF27dk0MqwD58+enbdu2LFiwAD8/PypXrpzi/i4u8RMeRUZGJh4rQURERJI+cXFxtGzZkpiYGP744w8sywKgY8eOFCxYkI8++oguXbrg4+MDwJtvvokxhmtVOnIoIIQvu9cicGfqS9+IiIhI+qX3Hta5wErA/dbjp1ttIiIiGapEiRIAFC1aNNm2hBmDr127dsf9EyZLSmn5m4CAACzLSuzz+++/s3XrVp577rnEsJqgU6dOAGzZsgWAPXv2MGfOHNwbtmfn8XO86Z2HsjlDuXTpEgAXLlzg5MmTREZG3tX7FRERkf9Jb2B1M8bMNcbE3HrMA9wysC4REREA6tWrB4C/f/KLehLaChcufMf969atC8Bff/2VbNu2bduoWLEiuXLlAv4XamNjY5P1jYmJSfLn6TNnMMawb/kMAr7qxyvtGuPp6clbb70FwMCBA/H09OTgwYPpe6MiIiKSTHoD6z+WZfWwLMv+1qMH8E9GFiYiIgLx96rmzp2bhQsXJpnNNygoiOXLl1OhQgXKly8PwLlz5zh27BjR0dGJ/dq1a4ezszNTp05NEkR/+uknTp06Rffu3RPbqlSpAsCiRYuSHANg3rx5QHwAjoszrL2Yi0Lt3uaVsVP5/vvvEx8DBgwAYNiwYXz//feUK1fuwX4gIiIi2Uh6Zwl+kfh7WCcRPzvwn4AmYhIRkQyXP39+Jk6cyMsvv4y3tzcvvvgiUVFRfPnll0RFRfH5558n9n3hhRfYsmULp0+fpnTp0gC4ubkxbtw43njjDXx8fOjatSsBAQF88sknVKpUiSFDhiTuX716dZ577jl++OEH6tSpQ48ePRInXfrpp5/w9vambdu2vLviEOvORvPeoBd57QnPJPUmhGpvb286duyY8R+QiIjIIyy9swSfBdpmcC0iIiIp6tevH4UKFeLjjz/m3Xffxc7OjgYNGrB48WIaNWqU5v7Dhg2jYMGCTJo0iUGDBpEnTx46d+7Mhx9+mHg5cILFixczefJkFi1axKhRo4iLi8PDw4MRI0bwzjvv8PG6Eyzafo5XmpZjQLPyGfWWRUREhDQCq2VZw40xH1uW9TnxI6tJGGMGZVhlIiIit+nQoQMdOnRItc/mzZvvuK1379707t07zfM4OjoyfPhwhg8fnmzblA0nmPHbKXo18GB4i4rJJma6m/OIiIhI2tIaYT16689dGV2IiIhIVjbzt1NM2nCcjrVL8F4brxTDqoiIiDxYqQZWY0zC0udhxpjvb99mWVanDKtKREQkC1m0/SzjVx+ldbVifPRcNezsFFZFREQyQ3pnCR6RzjYREZFHyo97/Rm5/BBPVCrMpM41sFdYFRERyTRp3cP6NNAKKG5Z1me3bcoDxGRkYSIiIra25lAQb3x/gAZlC/JF91o45kjv73lFRETkQUjrHtZA4u9fbQvsvq39BvB6RhUlIiJia5v9LjHwm71UL5GXmS/UwcnB3tYliYiIZDtp3cO6H9hvWdYiY4xGVEVEJFvYduofXv56NxWK5Gaubz1cc6Z32XIRERF5kNK6JPg7Y0xnYK9lWbcva2MBxhhTLUOrExERyWT7zgfz0rydlCzgwoIX65HX2cHWJYmIiGRbaf3KePCtP5/J6EJERERs7WjQdXrN2UHBXDlZ1Kc+BXPltHVJIiIi2Vqqs0cYY4JuPb0CnDfGnAVyAtWJv79VRETkkfD35VB6zt6Oi6M9i/rUp0geJ1uXJCIiku2l96ac34DGlmXlB9YBO4EuQPeMKkxERCQjLd8bwIS1fgQGh1M4T07Co2JxzGHHwj71KVnAxdbliYiICOlfh9UyxoQBHYAvjDGdAK+MK0tERCTjLN8bwIhlBwkIDscAF69Hcj0iBt9GZSjnlsvW5YmIiMgt6Q6slmU1IH5EddWtNs3vLyIiD6UJa/0Ij45N1r54+zkbVCMiIiJ3kt7AOgQYAfxojDlsWVZZYNO9ntSyrHyWZS21LOuYZVlHb4VhERGRTBEYHH5X7SIiImIb6bqH1RizBdhiWVYuy7JyGWNOAYPu47xTgDXGmI6WZTkCullIREQyRUBwOI457IiMiUu2zT2fsw0qEhERkTtJ1wirZVmPWZa1FzgMHLEsa7dlWfd0D6tlWXmBx4HZAMaYKGNM8L0cS0REJL2MMXyz4xwtJv1GnDE42FtJtjs72PNmi4o2qk5ERERSYhlj0u5kWX8C/zXGbLr1uinwgTGm4V2f0LJqADOAI8Qvj7MbGGyMufmvfv2AfgBubm61Z86cebenEhERAeBqJCz5245jIXZ45omja7k4Tt+w+PmcHdeiIL8jPFMqjjpuaf+fKCIiIg9e+/btdxtj6vy7Pb2Bdb8xpnpabelhWVYdYBvQyBiz3bKsKcB1Y8y7d9qnTp06ZteuXXd7qgdmxYoVtGvXzmbnF7mdvo+SlWT176MxhiU7z/P+qqPEGcOIpyvRvb4HdnZW2jvLQyerfx8le9H3UbKSh+H7aFlWioE1veuwnrIs613g61uvewCn7rEWf8DfGLP91uulwNv3eCwREZEUBQaH8/ayg/x2/DLeZQswoWN1ra8qIiLykElvYH0RGAMsAwyw9VbbXTPGXLAs67xlWRWNMX5Ac+IvDxYREblvxhi+23We938+SkycYWw7L3poVFVEROShlGpgtSzLCegPlAcOAsOMMdEP4LwDgUW3Zgg+Bfg+gGOKiEg2FxQSzts/HGTL8cvULxM/qlqqoEZVRUREHlZpjbDOB6KJH1F9GqhM/Jqs98UYsw9Idn2yiIjIvTDG8P0uf8b9fISYOMOYtl709NaoqoiIyMMurcBaxRjzGIBlWbOBHRlfkoiISPoFhYQzYtlBNvtdpl6ZAkzoWA2Pgq62LktEREQegLQCa+Llv8aYGMvSb6pFRCRrMMbw/e5bo6qxhtFtqvBCg9IaVRUREXmEpBVYq1uWdf3WcwtwvvXaAowxJk+GViciIpKCCyERjFh2gE1+l6lXugATOmlUVURE5FGUamA1xthnViEiIiJpMcawdLc/Y38+QnRsHO+1qUIvjaqKiIg8stK7rI2IiIhNXQiJ4J0fD/LrsUvULZ2fCR2rU7qQRlVFREQeZQqsIiKSpRlj+GFPAGN/OkxUbBzvPlMF34YaVRUREckOFFhFRCTLung9gneWHWTjsUvU8cjPhE7VKaNRVRERkWxDgVVERLIcYww/7g1g9MrDRMbEMbJ1ZXwblcFeo6oiIiLZigKriIhkKZeux9+ruuGoRlVFRESyOwVWERHJEjSqKiIiIv+mwCoiIjYXP6p6iA1HL1KrVD4mdKpOObdcti5LREREbEyBVUREbMYYw4p9gby38jAR0bH8t1VlXvyPRlVFREQkngKriIjYxKUbEfz3x0OsP3KRmqXyMVGjqiIiIvIvCqwiIpKpjDGs3B8/qhoWFcs7rSrx0n/KalRVREREkrGzdQEiItlRWFgYZcuWxbIsXnvttXTvFxMTw2effUatWrVwdXUlb9681KpVi6+++ipJv/nz59OiRQtKlCiBk5MTbm5uNGjQgHnz5hEbG3vHmsaOHYuXlxfOzs4UKFCABg0a8OOPPybpN3r0aCzLwrIs2rdvn/jcsiwmTpyYav2Xb0Ty8te7GfztPsoUcmX1oMb0e7ycwqqIiIikSCOsIiI2MGrUKC5fvnxX+0RFRdG2bVs2bdpE9+7d6d+/PzExMZw4cYKzZ88m6btnzx7y58/PgAEDKFy4MKGhoaxatQpfX1+2bt3K7Nmzk/S/du0azZs358SJE/j6+jJ06FBu3rzJ0aNHkx07waRJkzh79iy1a9dObLv9+e3+Pao64ulK9GmsUVURERFJnQKriEgm27NnD5MnT+bjjz9m2LBh6d5v3LhxbNiwgfXr19OsWbNU+06ZMiVZ2+DBg2ndujVz585l/PjxFC1aNHHboEGDOHnyJNu3b6dKlSrpqqd9+/bs37+fdu3apdrv8o1IRi4/yNrDF6lRMh8TO1WjfOHc6TqHiIiIZG+6JFhEJBPFxsbSt29fWrZsSYcOHdK9382bN5kyZQrt2rWjWbNmGGO4cePGXZ/fw8MDYwwhISGJbWfOnGHx4sX07duXKlWqEBsbS2hoaLqOFxYWRkxMTIrbEkZVn5q0hU1+l3n76Uos7d9AYVVERETSTYFVRCQTTZo0iWPHjjF16tS72m/r1q3cuHGD2rVrM3jwYPLkyUOePHlwc3PjnXfeuWNoDAkJ4cqVK5w4cYKpU6cyZ84cKlSoQPny5RP7rFmzhri4OKpUqULPnj1xcXEhd+7clChRgkmTJt2xpmrVqtGtWzecnJxo2LAhv/zyS+K2K6GRvLJwD4O+2Uupgq6sGvgf+jcpRw57/bcjIiIi6adLgkVEMsnp06d57733GDVqFKVLl+bMmTPp3tfPzw+AyZMn4+joyMcff0zBggVZtGgR//d//0dAQADz589Ptl/z5s3ZvXs3AJZl4ePjw/Tp07G3t0927BEjRlCoUCGmT5+Oo6Mj06dPZ+jQoQQHBzNmzJjE/vny5aNfv340bNiQ48ePky9fPiZPnkzr1q2ZM2cOhWo9xbvLD3EzMpa3Wlaib+MyCqoiIiJyTxRYRUQySf/+/SlbtixDhw69630TLv+9evUqhw8fpmLFigB07tyZZs2asWDBAt5++20qV66cZL8vvviC69evExQUxKpVq7h48SLXrl1L8dhRUVFs3bqVggULJh67SpUqfPzxxwwZMoT8+fMDMGTIkMR9V6xYQbt27XjxxRep4lWVlwcMosjLc6hZtigTO1XHs4gu/xUREZF7p195i4hkgoULF7J+/Xq+/PJLHBwc7np/Z2dnALy9vRPDaoIXXngBgM2bNyfbr169evj4+NCzZ0++/fZbvL29efzxx/n777+THfuZZ55JDKsADg4OdOvWjYiICLZt25ZqfdsCorCr8iRRYTdoV+wGP7zSUGFVRERE7psCq4hIBouMjGTo0KG0atWKokWLcvLkSU6ePJm4XExISAgnT54kODj4jscoUaIEQJKZfRMUK1YMINnIaUp69epFWFgY8+bNeyDHDo2GVxftZsDiPRQtXhKABsVz6hJgEREReSD0E4WISAYLDw/n8uXLrFq1Ck9Pz8RH06ZNgfjRV09PT2bNmnXHY9SrVw8Af3//ZNu4+55rAAAgAElEQVQS2goXLpyuWiD+0uL7PfaqA0F8sM+e9Ucu8maLijwdn1cpUqRImnWIiIiIpIfuYRURyWCurq58//33ydovX77Mq6++SsuWLXnppZeoVq0aAEFBQYSEhFCqVClcXFwAKFOmDI0aNeLPP/9kz5491KpVC4hfJmfmzJnkyJGDp556CoCYmBhCQkKSXN6b4PPPPwfiLy1O8Pjjj+Ph4cFPP/1EQEAAxYsXB+KX0lmwYAH58uWjQYMGicc+f/EqE7f4s+pAECVdYVbfxrhEB1Oj43QKFixIw4YNH9RHJyIiItmcAquISAZzcHCgY8eOydoTZgkuV65cku0jRoxg/vz5bNq0KXEUFuLDZuPGjfHx8WHQoEEULFiQJUuWsGPHDkaNGkWpUqUACA0NpUSJEjz77LNUrVqVIkWKcOHCBZYvX86uXbto3rw53bp1Szyuvb09X3zxBW3btqVBgwa8+uqrODo6MnfuXM6fP8/s2bNxdXUF4MftJ+nqUxeXCt48Ub8mxa7fZObEzcyaNYvQ0FC++eabxHtiRURERO6XAquIyEOiZs2a/Pnnn4wcOZLJkycTERFB5cqVmTt3Lr17907s5+LiwoABA/jtt99Yt24dwcHB5M6dGy8vL6ZOnUq/fv2SLGsD0KpVKzZu3MiYMWMYP348sbGx1KxZk5UrV9KmTRuu3oxi1IpD/LTnHO41muAUfJot3+/ixo0buLm54ePjw/DhwxMvLxYRERF5EBRYRURspHTp0hhjkrXPmzcvyaRIt6tWrRorV65M9biOjo5MnDjxrutp0qQJv/76a7L2NYeCGLn8ECHh0bzxtBf9P1qJw61JlRKWtRERERHJCAqsIiKSoqs3o3hv5WF+2h+Il3sevn6pPpWL5bF1WSIiIpKNKLCKiEgyaw5dYOTyg4SERzP0yQq80rRc4qiqiIiISGZRYBURkUTXbo2qrtwfSJViGlUVERER21JgFRERANYevsB/fzxEcFgUr/tU4NVmGlUVERER21JgFRHJ5q7djGL0T4dZsS9+VHXBi/Wo4q5RVREREbE9BVYRkWxs3eELvHNrVHWIjycDmpXXqKqIiIhkGQqsIiLZUHBYFGN+OsKPewOoXCwP81+si5d7XluXJSIiIpKEAquISDaz/shF3vnxINduRjG4efyoqmMOjaqKiIhI1qPAKiKSTdw+qlqpaG7m9q5L1eIaVRUREZGsS4FVROQRtHxvABPW+hEYHI57PmeerlqUlfsDuXozikHNPXlNo6oiIiLyEFBgFRF5xCzfG8CIZQcJj44FICA4nFm/n6ZYnpwsH9BIo6oiIiLy0NCv10VEHjET1volhtXbWZalsCoiIiIPFQVWEZFHTGBweIrtQSERmVyJiIiIyP3RJcEiIo+I4LAopmw8gbnDdvd8zplaj4iIiMj9UmAVEXnIRcfGsXj7OSZtOM718GgalC3A3nPBRMTEJfZxdrDnzRYVbViliIiIyN1TYBUReYht9rvE+6uOcvJSKA3LFeTdZ6pQuVieZLMEv9miIu1rFrd1uSIiIiJ3RYFVROQhdPLSDd5fdZTNfpcpXdCFmS/UwadyYSzLAqB9zeIKqCIiIvLQU2AVEXmIXLsZf5/q19vO4uJoz8jWlXmhQWmtqSoiIiKPJAVWEZGHQHRsHF//dZYpG09wIyKa7vU9GOLjScFcOW1dmoiIiEiGUWAVEcnCjDFsunWf6qnLN2nsWYiRratQsWhuW5cmIiIikuEUWEVEsqjjF28w7ucjbD1xhbKFXJnTuw7NKv7vPlURERGRR50Cq4hIFnP1ZhST1h9n0faz5MqZg1HPVKGHt4fuUxUREZFsR4FVRCSLiIqJY8FfZ5iy8QRhUbH09PZgiE8F8rs62ro0EREREZtQYBURsTFjDBuOXmL8qiOc+SeMJhXcGNm6Mp5FdJ+qiIiIZG8KrCIiNnQ06DrvrzrCHyf/oXzhXMz1rUuzioVtXZaIiIhIlqDAKiJiA1dCI/lk3XGW7DxHHmcHxrT1olv9UjjY6z5VERERkQQKrCIimSgyJpZ5f5xh6q8nCY+OpVfD0gxu7kk+F92nKiIiIvJvCqwiIpnAGMPawxf5YPVRzl0No3mlwrzTujLl3HLZujQRERGRLEvXnonIffHz86N79+5UrlyZvHnz4uLiQqVKlRg6dChBQUH3dMwuXbpgWRZVq1ZNcXtISAgDBw6kePHiODk54eXlxZdffokxJkm/48ePM2rUKLy9vXFzcyN37tzUqFGD8ePHc/PmzSR9jTEsXLiQ559/nvLly+Pi4kKpUqVo27Yt27dvv6f3keBwYAhdZ26j/8LdODnYseDFeszuXVdhVURERCQNGmEVkfvi7+9PUFAQzz77LCVKlCBHjhwcPHiQGTNm8O2337Jv3z4KF07/JEI///wzS5cuxdnZOcXtUVFRPPnkk+zdu5eBAwdSuXJlfvnlF1599VUuXrzI6NGjE/vOmTOHadOm0bZtW7p3746DgwObNm1i5MiRfPfdd2zbti3xPJGRkfTs2ZMaNWrw/PPPU6ZMGYKCgpg+fToNGjRgwYIF9OjR464+m0s3Ivh03XGW7DpPPmcHxrWvSte6Jcmh+1RFRERE0kWBVUTuS/PmzWnevHmy9scff5zOnTszb948hg8fnq5jhYaG8uqrrzJgwABWrlyZYp9Zs2axc+dOPvvsMwYOHAhA3759ee655/jggw/w9fXFw8MDgI4dOzJixAjy5s2buH///v3x9PRk/PjxzJ49m9deew2AHDlysHnzZpo0aZLkfH379sXLy4thw4bRrVs37OzSDpsR0bHM+eM00349SVRsHC81KsPA5p7kdXZI1+cgIiIiIvFs9mt+y7LsLcvaa1nWz7aqQUQyTkJovHbtWrr3+e9//0tsbCzvv//+HfssXrwYFxcX+vbtm6R9yJAhREdHs2TJksS2OnXqJAmrCbp06QLAoUOHEtty5MiRLKwCFClShCZNmnDp0iUuXbqUav3GGFYfDMLn0y18vMaPhuULse71Jox8porCqoiIiMg9sOUI62DgKJDHhjWIyAMSERFBaGgoERERHDlyhLfeeguAVq1apWv/HTt2MHXqVL755hvy5En5n4W4uDj27NlDrVq1cHJySrKtXr16WJbFzp070zyXv78/EB9G08Pf3x9HR0fy5ct3xz6HAkIY+9MRdpy5SqWiuVnUpz6NyhdK1/FFREREJGU2CayWZZUAWgPjgaG2qEFEHqxZs2YlXqILULp0aRYuXEjjxo3T3DcmJoY+ffrw1FNP0blz5zv2u3btGuHh4RQvXjzZtpw5c1KoUCECAgJSPVdsbCzjxo0jR44cdOvWLc3aVq9ezY4dO+jZs2eykAxw6XoEE9b6sXSPPwVcHPng2cfoUrck9nZWmscWERERkdTZaoR1MjAcyH2nDpZl9QP6Abi5ubFixYpMKi1ltj6/yO2y4vfR2dmZMWPGEB4ezunTp9mxYwebNm0iV660Z8JdunQpfn5+DBgwIPG9hYWFYYxJ8l4vX74MwKVLl1L8DIwxBAUFpfr5zJgxg7/++osePXpw7Ngxjh07dse+gYGBvPXWWxQsWBAfH58kx42Khc1BFusD7Ig10KyY4aniYThf2MvPP+1N8z0/SrLi91GyL30fJSvR91Gykof2+2iMydQH8Azwxa3nTYGf09qndu3axpaWL19u0/OL3O5h+T7u37/fODo6mg8++CDVfidOnDBOTk7m/fffT9Lu4eFhvLy8krRduXLFAKZz584pHsvNzc00aNDgjucaOXKkAUy/fv3SrP/UqVOmZMmSpmDBgubAgQOJ7XFxcWblvgDT8P82Go+3fjYvL9hlzlwJTfN4j6qH5fso2YO+j5KV6PsoWcnD8H0EdpkUsqAtRlgbAW0ty2oFOAF5LMtaaIy5u/UiRCRLq1atGjVr1uSLL75gxIgRd+w3bNgwChQowLPPPsvJkycT22NiYoiKiuLkyZO4urpSrFgx8ufPj7Ozc4qX/UZGRnLlypUUJ04CGD16NO+//z6+vr5Mnz491drPnDlDs2bNCA0NZePGjTz22GMA7D8fzLifj7Dr7DUqF8vDxE7VaVCuYHo+DhERERG5B5keWI0xI4ARAJZlNQXeUFgVeTSFh4dz9erVVPucPXuWwMBAvLy8Utzu6elJ69at+fnnn7Gzs6NWrVrs3buXyMhIcubMmdhvx44dGGOoU6dOsmOMHj2aMWPG0KtXL2bNmoVl3fn+0jNnztC0aVNCQkLYsGEDNWvW5EJIBB+vPcayPQEUypWTj557jI61dZ+qiIiISEbTOqwicl8uXLhA0aJFk7Vv2rSJQ4cO0bRp08S2oKAgQkJCKFWqFC4uLgBMnDiR4ODgZPu/+uqrODk58emnn1KsWLHE9q5du/LHH38wY8aMJJM8TZ48mRw5ciQuWZNg7NixjBkzhp49ezJnzpxU11E9e/YszZo1Izg4mPXr11PlsRp8tvEEX27+m9g4wytNy/Fq03LkdtISNSIiIiKZwaaB1RizGdhsyxpE5P688sorBAUF8cQTT+Dh4UFERAS7d+/m22+/JXfu3HzyySeJfUeMGMH8+fPZtGlTYpD18fFJ8bhvvPEGuXLlomPHjkna+/bty9y5cxk6dChnzpyhcuXKrF69mh9//JGRI0dSunTpxL7Tpk3jvffeo1SpUvj4+LB48eIkxypSpAhPPvkkADdu3KBZs2acOXOG1157jcXr/uLnCcu4Fh5NjRJ5aVPdnedr1lJYFREREclEGmEVkfvStWtXFixYwNdff83ly5exLAsPDw9efvll3nzzTUqVKvVAz+fo6MiGDRsYOXIk33zzDf/88w/lypXj888/Z8CAAUn6JqzJeu7cOXr16pXsWE2aNEkMrP/88w+nT58GYOrUqUn6bbz1qF5pU7rXbhURERGR+6fAKiL3pXPnzqmunXq7efPmMW/evHT1PXPmzB235cuXj6lTpyYLlvdzPsd8RRj8zR6W7wvELXdOhreoyHO1SmCn+1RFREREbEaBVUSytbCoGL7acoqvfvubOAOvNSvPK03L4ZpT/zyKiIiI2Jp+IhORbCkuzrBifwAf/eLHhesRPFOtGG8/XYkS+V1sXZqIiIiI3KLAKiLZzu6zVxn70xH2+4dQvURepnarSZ3SBWxdloiIiIj8iwKriGQb/tfC+GiNHz/tD6RInpx82rk67WsU132qIiIiIlmUAquIPPJuRsYwfcvfzPjtFACDmnvSv0lZXBz1T6CIiIhIVqaf1kTkkRUXZ/hhjz8T1vpx6UYk7Wq4M7xlJYrnc7Z1aSIiIiKSDgqsIvJI2nH6KuN+PsLBgBBqlMzH9J61qVUqv63LEhEREZG7oMAqIo+U81fD+PCXY6w6GESxvE5Meb4Gbaq56z5VERERkYeQAquIPBJCI2P4YtNJZv1+GnvL4nWfCvR7vCzOjva2Lk1ERERE7pECq4g81GLjDEt3n2fC2uNcCY2kQ63iDG9RiaJ5nWxdmoiIiIjcJwVWEXmoLN8bwIS1fgQGh1MwlyOO9nYEhkRQ2yM/s3rVoUbJfLYuUUREREQeEAVWEXloLN8bwIhlBwmPjgXgSmgUFvBCAw/GtPXCsnSfqoiIiMijxM7WBYiIpNeHvxxLDKsJDLDx6CWFVREREZFHkEZYRSTLux4RzczfTnHhekSK2wODwzO5IhERERHJDAqsIpJlRUTH8vVfZ5m2+STBYdE4O9gnG2EFcM/nbIPqRERERCSjKbCKSJYTExvHD3v8mbzhBEEhETxewY3hLSpy8lJokntYAZwd7HmzRUUbVisiIiIiGUWBVUSyDGMMaw5dYMI6P05dvkmNkvn4pHN1GpYrBEDV4nkBEmcJds/nzJstKtK+ZnFbli0iIiIiGUSBVUSyhD9PXuGjNcfY7x9C+cK5+KpnbZ6qUiTZZErtaxZXQBURERHJJhRYRcSmDvgHM2GtH1tPXME9rxMTOlajQ60S2Ntp1l8RERGR7E6BVURs4u/LoXy67jirDgZRwNWRd5+pQvf6pXBysLd1aSIiIiKSRSiwikimCgoJ57ONJ/hulz9OOewY3NyTPo3LkNvJwdaliYiIiEgWo8AqIpkiOCyKLzf/zbw/zxBnDD29PXjtifIUypXT1qWJiIiISBalwCoiGSosKoa5f5xh+pa/CY2MoUPNEgzx8aRkARdblyYiIiIiWZwCq4hkiKiYOJbsPMeUjSe5EhqJT+UivNmiIhWL5rZ1aSIiIiLykFBgFZEHKi7O8NOBQD5Zd5xzV8OoV7oAX/WsRW2PArYuTUREREQeMna2LkAkqzp+/DijRo3C29sbNzc3cufOTY0aNRg/fjw3b95Mc/9r164xZcoUnnrqKUqWLImzszMVK1akX79+nD9/Pln/zZs3Y1lWio9nnnkmxXOsXr2ahg0b4urqSoECBejUqROnT59O1u9Ox014jB8//u4/oH8xxrDp2CVaf/47g7/dh2vOHMz1rcuSl70VVkVERETknmiEVeQO5syZw7Rp02jbti3du3fHwcGBTZs2MXLkSL777ju2bduGs7PzHfffvn07w4YNo3nz5rz22msUKlSIQ4cO8dVXX/Hdd9/x559/UqVKlWT79evXj8aNGydpK1GiRLJ+y5Yto2PHjlSvXp0JEyYQEhLC5MmTadSoEbt27cLd3T2x79dff51ijaNHj+bvv/+mTZs26f1YUrT77FU+WuPHjtNXKVXAhSnP16BNNXfstJaqiIiIiNwHBVaRO+jYsSMjRowgb968iW39+/fH09OT8ePHM3v2bF577bU77l+pUiX8/PwoV65ckvbWrVvz5JNPMmrUKJYuXZpsvwYNGtCjR49Ua4uOjmbgwIGULFmSrVu3kitXLgCefvppateuzejRo5kxY0Zi/5SO5+/vz+nTp6lTpw7VqlVL9Xx34nfhBhPW+rHh6EXccudkXPuqdKlTEsccunhDRERERO6ffqoUuYM6deokCasJunTpAsChQ4dS3b906dLJwiqAj48PBQoUSHX/mzdvEhERccftW7ZsITAwkD59+iSGVYAaNWrQtGlTlixZQnR0dKr1zZ07l7i4OPr06ZNqv5ScvxrG0O/20XLKb2w/9Q9vtqjIljeb0tPbQ2FVRERERB4Y/WQpcpf8/f0BKFKkyD3tHxISwo0bN+64/+DBg8mVKxfOzs5UqFCBKVOmYIxJ0mfnzp1A/Gjsv3l7e3P9+nWOHz9+xxqMMcydOxdXV1e6du2a7tqvhEYyeuVhnvhkM6sOBNGvcVl+G96MAc3K4+KoCzZERERE5MHST5gidyE2NpZx48aRI0cOunXrdk/HGD9+PNHR0fTq1StJu4ODA23btqVVq1a4u7sTGBjI7NmzGTJkCPv27WPu3LmJfQMDAwEoXrx4suMntAUEBODl5ZViDb/++iunT5+md+/e5MmTJ82ab0REM3PraWZtPUVkTByd65RgUHNPiuW98z28IiIiIiL3S4FV5C4MGTKEv/76iw8++ICKFSve9f5Lly5l4sSJtGzZEl9f3yTbGjVqxIoVK5K09e3bl1atWjFv3jz69OlDo0aNAAgLCwMgZ86cyc7h5OSUpE9KZs2aBcBLL72Uar0R0bEs3HaWaZtOci0smtaPFWPoUxUo55Yr1f1ERERERB4EBVaRdHr33XeZOnUq/fr1Y8SIEXe9/+rVq+nevTu1a9dmyZIlWFbaM+ja2dkxYsQI1q5dy6pVqxIDq4uLCwCRkZHJ9km49zWhz79dvXqVH3/8kUqVKvGf//wnxT4xsXEs2xvA5PXHCQyJoLFnId5sUZFqJfKl672KiIiIiDwICqwi6TB69Gjef/99fH19mT59+l3vv2bNGjp06ICXlxfr1q1L12W4CUqXLg3AlStXEtsSlqwJCAigcuXKSfoHBAQAKV8uDLBo0SIiIyNTHF01xrD28EUmrvPj5KVQqpfIy4RO1WlUvlC66xUREREReVAUWEXSMHr0aMaMGUOvXr2YNWtWukZGb7dmzRrat29PpUqV2LBhA/nz57+r/U+cOAEkneSpbt26APz111/4+Pgk6b9t2zby5MlDhQoVUjze7NmzcXBw4IUXXkjS/uffV/hojR/7zwdT1s2V6T1q0cKr6F2/XxERERGRB0WzBIukYuzYsYwZM4aePXsyZ84c7OxS/isTFBTEsWPHkt03um7dOp599lkqVqzIxo0bKVCgwB3P9c8//yRri4yMZPTo0QC0adMmsb1JkyYUK1aMWbNmERoamti+f/9+Nm/eTKdOnXBwcEh2vF27drF//37atGlD4cKFATgUEELP2dvpNnM7l65H8NFzj7FuyOO0rFpMYVVEREREbEojrCJ3MG3aNN577z1KlSqFj48PixcvTrK9SJEiPPnkkwCMGDGC+fPns2nTJpo2bQrEh8N27dphjMHX15dffvkl2Tl69OiR+Lxly5a4u7tTu3btxFmCFy5cyIkTJxg4cCD16tVL7Ovg4MCUKVPo0qULjRs3pm/fvly/fp1Jkybh5ubGmDFjUnxPs2fPBqBPnz6cvnKTT9b58fOBIPK5OPDfVpXp2cADJwf7+/rcREREREQeFAVWkTtIWOv03LlzyZaggfhRzoTAmpJDhw4lToD0+uuvp9jn9sDasWNHli9fzueff05wcDCurq7UrFmTMWPGpLhWaqdOnXB2dub999/njTfeIGfOnDRv3pz/b+/Ow6uqzvaPf5+EACEMIQkihEBIQFAQARkEpaDVgqhMrwOCA30x/qQFqiDFEUtxqCKCgrY/oIhFipViQSuCFgWsgCCDFWQOBAgIYQhTEoZkvX+ckzSBAEmA7JPk/lxXruSsvfbazzlshTtr77VfffXVfO9fTU9PZ8aMGUTXqcPitNoMfGMR5YODGHRLAxJ+FkfVimfPyIqIiIiIeEmBVeQcpk6dytSpU4vct1+/fvTr16/Axxs+fDjDhw8veIHAnXfeyZ133lmgviddOZ6asYx3v9nG31cl80Dbugy8pSE1qpz9aBwRERERkUCgwCpSyqWfzOTdJdv408KtHD1xmh7No3ni1quoG5n/Y29ERERERAKFAqtIKXUqM4u/rdjJWws2s+/oCW5pfAXDOjfi6loFf6SOiIiIiIiXFFhFSpmsLMc/f9jDmM83knQgjVb1qjOhT0va1D/3CsUiIiIiIoFIgVWklHDOsWhTCq/N28iPe47Q+MoqTOnXipsbXaHH04iIiIhIiaTAKlIKrEw6xGvzNvDttoPUqR7K2Puuo9t10QQHKaiKiIiISMmlwCpSgm3ae5TR8zfyxY97iapcnpHdmnB/m7qULxfkdWkiIiIiIhdNgVWkBNp1KI1x/9rMR6t2EVa+HENvu4r/vak+YRX0n7SIiIiIlB76161ICXLg2Ak+2h7EsOWLwKD/TfUZ0KkBEWHlvS5NREREROSSU2AVKQGOnTjN5K8TmbQ4kbSTxr2tovnNrQ2pHR7qdWkiIiIiIpeNAqtIADtxOpPpy3Yw4astHDx+ki5NrqRFuV38v7ubeV2aiIiIiMhlp8AqEiBmr05m9PyN7E5Np1Z4RTpeVYPFm/aTnJpOu7hIht/emOYx4cyZs8vrUkVEREREioUCq0gAmL06mac/+oH0U5kA7E7NYMbyndQJD2Va/zbc1CBKz1IVERERkTJHgVUkAIyevzEnrOaWhaNDwxoeVCQiIiIi4j09rFHEYzsPppGcmp7vtj2pGcVcjYiIiIhI4NAMq4hHDqedYsJXm3lvSdI5+2gVYBEREREpyxRYRYrZydNZvL8sibe+3Mzh9FPc3bIOTaKr8upneS8LDg0JZljnRh5WKiIiIiLiLQVWkWLinGP+up/4w2cb2H4gjRsbRPJM16tpUrsaAOGh5XNWCa4dHsqwzo3o0SLa46pFRERERLyjwCpSDNbsTOWlT39kxfZDNLyiMu/2a02nRjXyrPzbo0W0AqqIiIiISC7FHljNLAb4C1ATcMBE59ybxV2HSHHYeTCN1+Zv5JPvdxNVuTwv9WzKfa1iKBes9c5ERERERC7EixnW08BQ59wqM6sCrDSzL5xzP3pQi8hlcTj9FO98tYV3v9mOGQy8uQGPdYqncgVd1CAiIiIiUlDF/q9n59weYI//56Nmth6IBhRYpcQ7lZnF9GVJvLlgM6npp+jZIpphnRtRq5pW+xURERERKSxzznl3cLNYYDHQ1Dl35IxtjwKPAtSoUeP6SZMmFXt9IgXlHPxwyPg4KYiUDKNh1Sy618siprLXlYmIiIiIBL4ePXqsdM61OrPds8BqZpWBRcBLzrmPzte3VatW7rvvviuewvIxZ84cunfv7tnxJbB9vzOVl+auZ/m2gzS4ojLPdG3MzY2uyLOg0qWk81ECic5HCSQ6HyWQ6HyUQFISzkczyzewenJDnZmFALOA6RcKqyKBatehNEbP38icNbuJDCvPiz2a0ru1FlQSEREREblUvFgl2IA/A+udc28U9/FFLtaRjFO889VWpnyzDQN+fXM8j3WMp0rFEK9LExEREREpVbyYYb0ReBD4wczW+Nuecc7N9aAWkQI7lZnFjOU7GPevzRw8fpJeLaIZ2rkR0eFaUElERERE5HLwYpXgfwOX5+Y+kcvAOce/1u/jlc/Wk5hynLb1I3jujmu4tk41r0sTERERESnVdLNdGfXKK69wzz33EBcXh5kRGxtbpHH+8pe/0KJFC0JDQ6lZsyaPPPIIKSkpF9xv+PDhmBmVK5+9jO727dsxs3y/mjZtelFjF9YPuw5z/6RlJPzFt+jX5Ida8cGjNyisioiIiIgUA08WXRLvPfPMM0RERNCyZUtSU1OLNMbYsWMZMmQIHTt25M0332TXrl288cYbLF26lOXLlxMWFpbvfmvWrOGNN96gcuXKnG+V6p49e9KrV688beHh4eetqaBjX8ju1HRGz9/IP1YnE2OclbAAAByJSURBVBFWnlHdm9C7TV1CtKCSiIiIiEixUWAto7Zu3UpcXBwATZs25dixY4Xaf//+/Tz33HO0bt2aBQsWEBwcDEDr1q3p1q0bb775Js8888xZ+2VmZpKQkMDtt9/OkSNHON/jipo1a8YDDzxQ4JoKM/a5HM04xR8XbuXP/96GAwZ0imdAp3iqakElEREREZFip+miMio7rBbV7NmzSUtLY9CgQTlhFeCuu+4iLi6O999/P9/93nrrLX788UfGjx9foONkZGSQlpZWoL6FHTu305lZTFuWRKfRC3ln4VZub3olXw7tyPAujRVWRUREREQ8osAqRbJixQoA2rVrd9a2G264gQ0bNpw1a5uUlMTzzz/PCy+8QL169S54jDFjxlCpUiXCwsKIiYlhxIgRnDhxIt++hR07m3OOBev30nncYp6fvZb4Kyrz8cAbGde7BXWqVyrwOCIiIiIicunpkmApkt27dwMQHR191rbo6Gicc+zevZurrroqp33AgAHExcUxZMiQ844dFBTELbfcQo8ePahXrx4pKSl8+OGHjBo1iqVLlzJv3rw8s7qFGTu3tcmHeenT9SxNPEBcVBgTH7ye266pie9RwSIiIiIi4jUFVimS7Mt0K1SocNa2ihUr5ukDMGPGDObNm8e///1vypU7/2lXt25dFixYkKetf//+PProo0yaNIkPPviAvn37Fmls8C2o9PrnvgWVwkNDGNmtCX3aakElEREREZFAo3+hS5FUquS7XDa/S3QzMjLy9Dl48CCPP/44/fv3p3379kU+5rPPPgvAp59+mtNWmLGPnTjN6/M3cvPrC/nnf/bw6M/iWDjsZh5uH6uwKiIiIiISgDTDKkVSu3ZtAJKTk2nQoEGebcnJyZhZTp+RI0dy/PhxEhIS2LJlS06/9PR0nHNs2bKFChUqEBMTc95jxsTEEBwczP79+3PaCjJ2cLkQluyFsV9sYv+xk3S7rjbDOjciJkL3qIqIiIiIBDIFVimS1q1bM3HiRJYuXXpWYF22bBmNGjWicuXKgG9BpOPHj9O2bdt8x2rYsCFNmjRh7dq15z1mYmIimZmZ1KxZM6etIGOHXRlL1MMTaB1bnckPt6Z5zPmf5SoiIiIiIoFBgVUuaMeOHaSlpREfH09IiO8RL927d2fw4MFMmDCBPn365CyC9Mknn5CYmMioUaNy9h8+fHi+z1N94YUXSExMZNq0aVSrVi2n/cCBA0RGRubpm5WVxXPPPQf4Hp1zobGfevZ5tm9LpHrXIdSqEcFrD1xP5yZaUElEREREpCRRYC2jpk2bRlJSEgApKSmcPHmSF198EYB69erx4IMP5vR96KGHWLRoEdu2bSM2NhaAGjVqMGrUKJ588kluvfVW7r//fpKTkxkzZgyNGzfm8ccfz9k/v0ffAEyYMIGkpCTuvvvuPO0JCQkcOXKE9u3bExMTw/79+5k1axYrV66ke/fuefqfOfZPhzN4/fON7Eovh7MgXhv2KH3b1qN8Od2jKiIiIiJS0iiwllF//vOfWbRoUZ62559/HoCOHTvmCaznMnToUCIjIxk7diyDBw+matWq3HvvvfzhD3/IuRy4KO644w6mTZvGxIkTOXjwIBUqVKBJkya8/fbbPPbYYwQFnR0+j504zcRFW5n4dSJZWVA7PJR9B4P55Y31i1yHiIiIiIh4S4G1jFq4cOEl6duvXz/69et3SWvo378//fv3L9AYpzOzmLlyF2M+38T+Yye467ra/LZzI2JeWl6kmkREREREJHAosEqJ5Jxj4aYUXpm7nk17j9GqXnUmPXQ9LepW97o0ERERERG5RBRYpcT5cfcRXvlsPV9v3k+9yEr8sW9LujS9UgsqiYiIiIiUMgqsUmLsPZLBmM83MnPlLqpWDOH5O6/hwRu0oJKIiIiISGmlwCoB7/iJ00xcnMjExYmczsqi/431GXRLQ6pVCvG6NBERERERuYwUWCVgZWY5/r5yJ2M+38S+oye4o1kthnduTN3ISl6XJiIiIiIixaDUXUuZlZXF2LFjady4MRUrViQmJoahQ4dy/PjxQo+VlpZGXFwcPXr0YODAgfn2mTlzJu3btycsLIwqVarQoUMH5s6dW+CxzeycYy9dupRu3bpRp04dQkNDiY+PJyEhgcTExEK/l5Jm8aYU7njra4bP+oE61UOZNaA9b/dpqbAqIiIiIlKGlLrA+sQTTzBkyBCuueYaxo8fzz333MNbb73FXXfdRVZWVqHGGjFiBCkpKefc/uqrr3LvvfeSkZHBqFGjGDlyJMePH+fOO+9k+vTpFzX2vHnzuOmmm9iwYQMDBw5k/PjxdOvWjb/+9a+0atWK5OTkQr2XkmLjT0d5aMpyHpqynLSTmbzTtyWzBrTn+npa/VdEREREpKwpVZcEr1u3jvHjx9OrVy9mzZqV016/fn0GDx7MBx98QJ8+fQo01qpVqxg3bhyvvfYaQ4cOPWv73r17GTFiBE2bNuXbb78lJMR3P+WgQYNo2bIlgwYN4q677qJq1aqFHhtg7NixBAcHs2TJEqKionLamzRpQkJCAjNnzuTxxx8v0HspCfYdyeCNLzbx4Xc7qVIxhOfuuJoH29WjQrlgr0sTERERERGPlKoZ1hkzZuCcOyvIJSQkUKlSJd5///0CjZOZmUlCQgJdunShV69e+fZZsmQJJ0+epG/fvjlhFSAkJIQ+ffpw6NAh5syZU6SxAY4cOULFihWpXj3vzGLt2rUBCAsLK9B7CXRpJ08z7l+b6PT6Qmat2sUvb6zPomGdeKRDnMKqiIiIiEgZV6pmWFesWEFQUBBt2rTJ016xYkWaN2/OihUrCjTO2LFj2bBhQ55Z2jOdOHECgEqVzr6nMrtt2bJlPPjgg4UeG6Bz584sW7aMhx9+mGHDhhEVFcXatWsZOnQoV199Nb179y7QewlUmVmOWSt38frnG9l39ARdr72S33ZuTGxU6QjiIiIiIiJy8UpVYN29ezdRUVFUqFDhrG3R0dE5s6Lly5c/5xjbtm3jhRdeYMSIEcTGxrJ9+/Z8+zVp0gSAL7/8ksGDB+fZ9tVXXwGwc+fOIo0N8PTTT7Nv3z6mTJmS537Yrl27MmPGDKpUqXLOfQPN7NXJjJ6/kd2p6dQOD+Wu62qxcGMKG346SvOYcN7p25JWsRFelykiIiIiIgGmVAXWtLS0fMMq+GZZs/ucL7A+9thjxMXFMWTIkPMe69prr+W2225jzpw5/Pa3v+WXv/wlAFOnTuWzzz7LOVZRxgYIDg4mOjqaW2+9lZ49exIREcE333zD+PHj6d27N3PmzMlzKXKgmr06mac/+oH0U5kAJKem86dFiVSvFML4+1twZ7NamJnHVYqIiIiISCAqVYG1UqVK7Nu3L99tGRkZOX3O5f333+eLL75g8eLFBQqDf/vb33jkkUd4/fXXGT16NACxsbG8/fbbJCQk5FlwqbBj9+vXjyVLlrBu3TpCQ0MB6NmzJw0aNGDAgAG89957PPLIIxccx0sZpzJ58dMfc8JqbqEhwdx1XW0PqhIRERERkZKiVC26VLt2bfbv359zf2luycnJREVFnXN29cSJEwwZMoSuXbty5ZVXsmXLFrZs2UJSUhIAhw8fZsuWLaSmpubsU716dWbNmsWePXtYvHgxq1atYuvWrTkLIzVu3LhIY+/YsYPp06dzxx135ITVbPfccw8AixYtupiP6rI4eTqL5dsO8ua/NtN74lKajfyc/cdO5tt3z+GMYq5ORERERERKmlIVWFu3bk1WVhbLly/P056RkcGaNWto1arVOfdNT08nJSWFTz/9lIYNG+Z8derUCfDNkDZs2JDJkyeftW/NmjXp0KEDLVq0ICgoiLlz5wK++02LMnb2M1YzM8+emTx9+nSe7146lZnFqh2HePurLTww+VuajZzPvf9/KeMWbOJoxmkeuqEekWH5/4Kgdnhovu0iIiIiIiLZStUlwffddx8vv/wy48aNo0OHDjntkyZNIi0tjb59++a0bd26lVOnTuXMgoaFhTFz5syzxkxJSeFXv/oVXbp0oX///jRr1uy8NXz33XdMnjyZjh07ctNNNxVp7EaNGhEcHMzs2bN5+eWXCQ8Pz9ln6tSpgC+cF7fMLMe63YdZuvUASxMPsGLbQY6f9IXqxldWoXfrurSLj6Rt/QjCK/mCatPoannuYQXf5cDDOjcq9vpFRERERKRkKVWB9dprr+XXv/41EyZMoFevXnTt2pX169fz1ltv0bFjR/r06ZPT9+c//zlJSUk45wDf81Pvvvvus8bMXsk3Pj7+rO3PP/88mzdvpk2bNlSrVo1Vq1bx7rvvEh0dzbRp03L6FXbsiIgIHn/8ccaMGUOLFi1ISEjIWXRp+vTpxMfHF8v9q1lZjvU/HWHp1gMsSzzAt9sOcjTDN7MbXyOMni2jaRcXxQ1xEURWzn+xqx4togHyrBI8rHOjnHYREREREZFzKVWBFWDcuHHExsYyceJEPv30U6Kiohg0aBC///3vCQq6tFdAt2zZkgULFvD555+TlpZG3bp1GTRoEE8//XSeWdGiGD16NI0aNWLy5Mm8/PLLnDhxgujoaAYMGMDvfve7PAs6XSrOOTbtPcbSrftZ6g+oqWmnAIiNrMSdzWpxQ1wk7eIiuaJqxQKP26NFtAKqiIiIiIgUWqkLrMHBwQwdOpShQ4eet9/5noGaW2xsLLNnz6Z79+5nbevZsyc9e/YsSpk5Y2fP8J7JzEhISCAhIaHI41+Ic47E/cd9l/j6Z1EPHPctklSneii3XV2TdvGRtIuPpFY13XMqIiIiIiLFq9QFVjk35xw7Dqbl3IO6dOsB9h31rahcq1pFOl5VgxvifTOoMRHnfvyPiIiIiIhIcVBgLeV2HfpvQF229QC7/Y+TiapcwTd7GuebQY2NrISZeVytiIiIiIjIfymwljI/Hc5gaeL+nJC682A6ABFh5bkhLoIB/oAaX6OyAqqIiIiIiAQ0BdYSLuXoCZYl/vcS3237jwNQLTSEtvUj+N8b69MuPpKrrqhCUJACqoiIiIiIlBwKrCXMweMn+TZXQN287xgAlSuUo239CPq2rcsNcZFcXasqwQqoIiIiIiJSgimwBrjD6afyBNQNPx0FoFL5YFrFRtCrZR3axUfStHZVygVf2sf2iIiIiIiIeEmBNcAczTjFiu0Hc+5BXbf7CM5BhXJBtIqtzpO/uIp28ZE0qxNOiAKqiIiIiIiUYgqsHks7eZrvth9iaeIBlmw9wNrkw2RmOcoHB9Gibji/+XlD2sVF0rxuOBXKBXtdroiIiIiISLFRYC1mGacyWZV0KOcS3+93pXIq01EuyGgeE86vOsXTLi6SlvWqUzFEAVVERERERMouBdbL7MTpTNbsSM0JqKt3pnLydBbBQUbT6Gr0vymOdvGRtKpXnbAK+uMQERERERHJpoR0kWavTmb0/I3sTk2ndngoQ25rSGxUWM49qCuTDpFxKgszaFK7Kg+3q0e7+Ehax0ZQpWKI1+WLiIiIiIgELAXWizB7dTJPffQfMk5lAZCcms7Qmf/J2d74yirc36Yu7eIiaVs/kmqVFFBFREREREQKSoH1IoyevzEnrOYWUSmEfw3tRERYeQ+qEhERERERKR30XJSLsDs1Pd/2Q2mnFFZFREREREQukgLrRagdHlqodhERERERESk4BdaLMKxzI0LPePRMaEgwwzo38qgiERERERGR0kP3sF6EHi2iAfKsEjysc6OcdhERERERESk6BdaL1KNFtAKqiIiIiIjIZaBLgkVERERERCQgKbCKiIiIiIhIQFJgFRERERERkYCkwCoiIiIiIiIBSYFVREREREREApICq4iIiIiIiAQkBVYREREREREJSAqsIiIiIiIiEpA8Caxm1sXMNprZFjN7yosaREREREREJLAVe2A1s2DgbeB24BrgfjO7prjrEBERERERkcDmxQxrG2CLcy7ROXcS+ADo7kEdIiIiIiIiEsDMOVe8BzS7G+jinHvE//pBoK1zbuAZ/R4FHgWoUaPG9ZMmTSrWOkVERERERKR49OjRY6VzrtWZ7eW8KKYgnHMTgYkArVq1ct27ezcJO2fOHLw8vkhuOh8lkOh8lECi81ECic5HCSQl+Xz04pLgZCAm1+s6/jYRERERERGRHF4E1hVAQzOrb2blgd7Axx7UISIiIiIiIgGs2C8Jds6dNrOBwHwgGJjinFtX3HWIiIiIiIhIYPPkHlbn3FxgrhfHFhERERERkZKh2FcJLgozSwGSPCwhCtjv4fFFctP5KIFE56MEEp2PEkh0PkogKQnnYz3nXI0zG0tEYPWamX2X3xLLIl7Q+SiBROejBBKdjxJIdD5KICnJ56MXiy6JiIiIiIiIXJACq4iIiIiIiAQkBdaCmeh1ASK56HyUQKLzUQKJzkcJJDofJZCU2PNR97CKiIiIiIhIQNIMq4iIiIiIiAQkBdYLMLMuZrbRzLaY2VNe1yNll5nFmNlXZvajma0zs994XZOImQWb2Woz+6fXtUjZZmbhZvZ3M9tgZuvNrJ3XNUnZZWZP+P+uXmtmM8ysotc1SdlhZlPMbJ+Zrc3VFmFmX5jZZv/36l7WWBgKrOdhZsHA28DtwDXA/WZ2jbdVSRl2GhjqnLsGuAH4tc5HCQC/AdZ7XYQI8CYwzznXGLgOnZfiETOLBgYDrZxzTYFgoLe3VUkZMxXockbbU8AC51xDYIH/dYmgwHp+bYAtzrlE59xJ4AOgu8c1SRnlnNvjnFvl//kovn+MRXtblZRlZlYHuAOY7HUtUraZWTXgZ8CfAZxzJ51zqd5WJWVcOSDUzMoBlYDdHtcjZYhzbjFw8Izm7sB7/p/fA3oUa1EXQYH1/KKBnble70IBQQKAmcUCLYBvva1EyrhxwG+BLK8LkTKvPpACvOu/RH2ymYV5XZSUTc65ZOB1YAewBzjsnPvc26pEqOmc2+P/+SegppfFFIYCq0gJY2aVgVnA4865I17XI2WTmd0J7HPOrfS6FhF8s1ktgT8651oAxylBl7tJ6eK/N7A7vl+k1AbCzOwBb6sS+S/ne0xMiXlUjALr+SUDMble1/G3iXjCzELwhdXpzrmPvK5HyrQbgW5mth3f7RK3mNn73pYkZdguYJdzLvuqk7/jC7AiXrgV2OacS3HOnQI+Atp7XJPIXjOrBeD/vs/jegpMgfX8VgANzay+mZXHd8P8xx7XJGWUmRm++7PWO+fe8LoeKducc0875+o452Lx/b/xS+ecZhDEE865n4CdZtbI3/Rz4EcPS5KybQdwg5lV8v/d/XO0CJh472PgYf/PDwNzPKylUMp5XUAgc86dNrOBwHx8K7xNcc6t87gsKbtuBB4EfjCzNf62Z5xzcz2sSUQkUAwCpvt/wZwI/NLjeqSMcs59a2Z/B1bhW+F/NTDR26qkLDGzGUAnIMrMdgEvAH8APjSz/kAScK93FRaO+S5hFhEREREREQksuiRYREREREREApICq4iIiIiIiAQkBVYREREREREJSAqsIiIiIiIiEpAUWEVERERERCQgKbCKiEixMDNnZu/nel3OzFLM7J9e1lVczKyTmbU/x7Z+ZpZlZs1yta01s9gLjDnXzMIvbaVgZq3M7K1LPe4FjlmrsOeCmb1uZrdcrppERMR7CqwiIlJcjgNNzSzU//o2INmLQszMi+eQdwLyDax+u4BnCzOgc66rcy71Yoo6x7jfOecGX+pxL2AIMKmQ+4wHnroMtYiISIBQYBURkeI0F7jD//P9wIzsDWYWZmZTzGy5ma02s+7+9lgz+9rMVvm/2vvba5nZYjNb45+N7OBvP5ZrzLvNbKr/56lm9icz+xZ4zczizWyema30j984V78/mtkyM0v0z4xOMbP12WP5+/3CzJb6a5ppZpX97dvNbKS//Qcza+yfKX0MeMJfb4d8Ppt/Ak3MrNGZG8zsfv9Ya83s1Vzt280syv/ZfWpm3/v73Offfr2ZLfK/x/lmViufse/x7/O9mS32t3XKnu00sxpm9oWZrTOzyWaW5D9mrJlt8H9em8xsupndambfmNlmM2vj37+N/3NabWZL8nt/fv8DzPPv08/MZvuPu93MBprZEP8Yy8wsAsA5lwREmtmV5xhTRERKOAVWEREpTh8Avc2sItAM+DbXtmeBL51zbYCbgdFmFgbsA25zzrUE7gOyL1XtA8x3zjUHrgPWFOD4dYD2zrkhwERgkHPueuBJ4J1c/aoD7YAngI+BsUAT4Foza25mUcBzwK3+ur7DN0OYbb+//Y/Ak8657cCfgLHOuebOua/zqS0LeA14JnejmdUGXgVuAZoDrc2sxxn7dgF2O+euc841BeaZWQi+Gci7/e9xCvBSPscdAXR2zl0HdMtn+wv4/lyaAH8H6uba1gAYAzT2f/UBbsL3eWa/jw1AB+dcC/+xXj7zAGZWHzjknDuRq7kp0Ato7a87zT/GUuChXP1WATfmU7eIiJQCXlwSJSIiZZRz7j/+2cb78c225vYLoJuZPel/XRFfONoNTDCz5kAmcJV/+wpgij+YzXbOFSSwznTOZfpnQ9sDM80se1uFXP0+cc45M/sB2Ouc+wHAzNYBsfiC7zXAN/79y+MLUtk+8n9fiS90FdRfgWf9AS5ba2Chcy7FX8N04GfA7Fx9fgDG+Gdf/+mc+9rMmuILfV/4awwG9uRzzG+AqWb2Ya66c7sJ6AngnJtnZodybdt2xmezINfnFuvvUw14z8waAg4IyecYtYCUM9q+cs4dBY6a2WHgk1zvtVmufvuA2vmMKSIipYACq4iIFLePgdfx3dMZmavdgP9xzm3M3dnMfgfsxTeLGgRkADjnFpvZz/BdYjzVzN5wzv0FXyjKVvGMYx/3fw8CUv2zs/nJnunLyvVz9uty+ILzF865+y+wfyaF+LvWOXfazMYAwwu6j3+/TWbWEugKvGhmC4B/AOucc+0usO9jZtYW3+e40syuL8Shz/xscn9u2e97FL7w2dP/y4qF+YyTztl/VgUZG/9+6YWoWUREShBdEiwiIsVtCjAye2Yul/nAIPNPB5pZC397NWCPcy4LeBDfTCFmVg/f7OckYDLQ0t9/r5ldbWZB+GcGz+ScOwJsM7N7/GOZmV1XiPewDLjRzBr49w8zs6susM9RoEoBxp4K3ArU8L9eDnT03zcajG92elHuHfyXDac5594HRuP7LDYCNcysnb9PiJk1OfNgZhbvnPvWOTcC3yxnzBldvgHu9ff9Bb7LpQujGv9dXKvfOfps4r8zsoV1FbC2iPuKiEiAU2AVEZFi5Zzb5ZzL75Epo/BdLvof/+Wlo/zt7wAPm9n3+O6TzJ4l7QR8b2ar8d3b+qa//Sl8CxgtIf9LYLP1Bfr7x10HdC/Ee0jBF75mmNl/8F0O3PgCu30C9DzPokvZY5/Ed5/uFf7Xe/C9p6+A74GVzrk5Z+x2LbDczNbgu+f0Rf84dwOv+t/jGvJfpXh09oJO+D6z78/YPhL4hX/7PcBP+MJ3Qb0GvOL/c8p3ttk5dxzYmv0LgILyXw7eAN89xCIiUgqZc+7CvURERKRMMrMKQKb/cuV2wB/Pcyn1xRynJ3C9c+65Qu7T0jn3/KWuR0REAoPuYRUREZHzqQt86L/E+iSQcDkO4pz7h5lFXrhnHuXwrVIsIiKllGZYRUREREREJCDpHlYREREREREJSAqsIiIiIiIiEpAUWEVERERERCQgKbCKiIiIiIhIQFJgFRERERERkYCkwCoiIiIiIiIB6f8AnyfSwBPlBH8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sigmas = [0.1, 1.0, 1.9, 2.8, 3.7, 4.6, 5.5, 6.4, 7.3, 8.2, 9.1, 10.0]\n",
    "RMSEs = [0.4948, 1.0454, 2.2507, 3.4022, 4.6365, 6.0840, 8.3602, 9.2469, 10.0984, 11.3101, 12.7875, 13.5534]\n",
    "plt.ylabel(\"Position RMSE(m)\")\n",
    "plt.xlabel(\"Measurement Noise sigma (m)\")\n",
    "plt.grid(True)\n",
    "plt.plot(sigmas, RMSEs, marker='o')\n",
    "\n",
    "for a, b in zip(sigmas, RMSEs):\n",
    "    plt.text(a, b+0.3, b, ha='center', va='bottom', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
